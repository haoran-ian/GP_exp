{"id": "19883754-35a9-49aa-82a8-2eb9891a1e39", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "A novel Swarm-inspired Adaptive Search Algorithm that dynamically balances exploration and exploitation using an adaptive population strategy for efficient black box optimization.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity)\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 139, in evaluate_gp_func\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 31, in update_positions_and_velocities\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n.", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 139, in evaluate_gp_func\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 31, in update_positions_and_velocities\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "fdc7ebb2-968c-438d-bf8b-b3bd521ee23c", "fitness": 0.06316613941960902, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "An Enhanced Swarm-inspired Adaptive Search Algorithm integrating a boundary-checking mechanism to efficiently handle exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06317 with standard deviation 0.00385.", "error": "", "parent_ids": ["19883754-35a9-49aa-82a8-2eb9891a1e39"], "operator": null, "metadata": {"aucs": [0.05781323124226556, 0.0666791815389004, 0.06500600547766111]}}
{"id": "cedd5c45-09df-4208-b6fa-f22607e8f547", "fitness": 0.05165602818479013, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "A refined Enhanced Swarm-inspired Adaptive Search Algorithm introducing adaptive adjustment of inertia weight to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9  # Changed from 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for adaptive inertia weight adjustment\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05166 with standard deviation 0.00325.", "error": "", "parent_ids": ["fdc7ebb2-968c-438d-bf8b-b3bd521ee23c"], "operator": null, "metadata": {"aucs": [0.05299621527143383, 0.05479731154795031, 0.047174557734986244]}}
{"id": "c8fc90df-180a-4a82-8d6c-4c0d285e934a", "fitness": 0.05853678487499928, "name": "QuantumAdaptiveSwarmOptimizer", "description": "Adaptive Quantum-inspired Swarm Optimizer integrates quantum superposition principles to enhance exploration and convergence efficiency in black box optimization tasks.", "code": "import numpy as np\n\nclass QuantumAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.q_superposition_factor = 0.1\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.q_superposition_factor * np.random.uniform(-1, 1, self.dim) * (ub - lb)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm QuantumAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05854 with standard deviation 0.00231.", "error": "", "parent_ids": ["fdc7ebb2-968c-438d-bf8b-b3bd521ee23c"], "operator": null, "metadata": {"aucs": [0.06161169886361806, 0.056057080937193526, 0.05794157482418627]}}
{"id": "a0d0691e-684e-4549-9088-88fefbab3bcf", "fitness": 0.06463274623358783, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "A Quantum-Enhanced Adaptive Swarm Optimizer utilizing quantum-inspired initialization and dynamic parameter adaptation to balance exploration and exploitation for enhanced convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.4 / self.budget) * self.population_size\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06463 with standard deviation 0.01365.", "error": "", "parent_ids": ["fdc7ebb2-968c-438d-bf8b-b3bd521ee23c"], "operator": null, "metadata": {"aucs": [0.08072576996696013, 0.04734291739350904, 0.06582955134029433]}}
{"id": "fb3da9c9-1a94-406e-a0b7-7b9fd4ffdf4c", "fitness": 0.0, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "Enhanced exploitation strategy by introducing an adaptive learning rate for cognitive and social components.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.4 / self.budget) * self.population_size\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        adaptive_learning_rate = 0.5 + 0.5 * (self.global_best_score / max(self.best_scores))\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = adaptive_learning_rate * self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = adaptive_learning_rate * self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00000 with standard deviation 0.00000.", "error": "", "parent_ids": ["a0d0691e-684e-4549-9088-88fefbab3bcf"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0]}}
{"id": "4df8cc73-02be-4c8a-965f-fa636338c5b6", "fitness": 0.06610478718233992, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "A Quantum-Enhanced Adaptive Swarm Optimizer with an enhanced inertia decay rate for improved convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size  # Updated\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)  # Updated\n\n        return self.global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06610 with standard deviation 0.01521.", "error": "", "parent_ids": ["a0d0691e-684e-4549-9088-88fefbab3bcf"], "operator": null, "metadata": {"aucs": [0.07891533038869125, 0.044735187953171995, 0.07466384320515651]}}
{"id": "aac7c9bc-23e5-4134-9305-65fd025c0367", "fitness": 0.061602103383076846, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "A Quantum-Enhanced Adaptive Swarm Optimizer with dynamic quantum tunneling for enhanced exploration capabilities.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.quantum_tunneling_probability = 0.1  # New parameter\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < self.quantum_tunneling_probability:\n                # Dynamic Quantum Tunneling to enhance exploration\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06160 with standard deviation 0.01407.", "error": "", "parent_ids": ["4df8cc73-02be-4c8a-965f-fa636338c5b6"], "operator": null, "metadata": {"aucs": [0.06500318125803428, 0.07687923403637653, 0.04292389485481973]}}
{"id": "d00bc768-d2d1-4896-8203-7446a1767eae", "fitness": 0.06587119099130252, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "An Adaptive Quantum-Enhanced Swarm Optimizer with dynamic cognitive and social coefficients for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n            self.cognitive_const = 1.4 + 0.1 * (1 - evaluations / self.budget)  # Updated\n            self.social_const = 1.6 - 0.1 * (evaluations / self.budget)  # Updated\n\n        return self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06587 with standard deviation 0.01344.", "error": "", "parent_ids": ["4df8cc73-02be-4c8a-965f-fa636338c5b6"], "operator": null, "metadata": {"aucs": [0.08025493831545272, 0.04792503072693621, 0.06943360393151865]}}
{"id": "02a17cde-fb83-46f9-9781-3bf78b015d58", "fitness": 0.059840462889057755, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "A Quantum-Enhanced Adaptive Swarm Optimizer with adaptive social and cognitive constants for improved convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size  # Updated\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)  # Updated\n            self.cognitive_const = 1.4 + 0.2 * (self.budget - evaluations) / self.budget  # New\n            self.social_const = 1.6 + 0.2 * evaluations / self.budget  # New\n\n        return self.global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05984 with standard deviation 0.00378.", "error": "", "parent_ids": ["4df8cc73-02be-4c8a-965f-fa636338c5b6"], "operator": null, "metadata": {"aucs": [0.06069578542666254, 0.05483780627471779, 0.06398779696579293]}}
{"id": "62a01afd-d46f-4632-99d2-aa496ba8057a", "fitness": 0.06716303525217449, "name": "QuantumEnhancedAdaptiveSwarmOptimizer", "description": "Introducing dynamic cognitive and social constants in the Quantum-Enhanced Adaptive Swarm Optimizer to balance exploration and exploitation.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size  # Updated\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.0 + (0.4 * (self.budget - evaluations) / self.budget)  # Updated\n            self.social_const = 2.0 - (0.4 * (self.budget - evaluations) / self.budget)  # Updated\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)  # Updated\n\n        return self.global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06716 with standard deviation 0.01098.", "error": "", "parent_ids": ["4df8cc73-02be-4c8a-965f-fa636338c5b6"], "operator": null, "metadata": {"aucs": [0.08017847331898875, 0.05333236892173787, 0.06797826351579683]}}
{"id": "2fa7c7ed-b66e-4f5d-b79e-a310622f09f6", "fitness": 0.06316483196282856, "name": "QuantumEnhancedAdaptiveSwarmOptimizerWithMutation", "description": "Introducing adaptive mutation and quantum tunneling to improve diversity and convergence in the Quantum-Enhanced Adaptive Swarm Optimizer.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimizerWithMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.mutation_rate = 0.1\n        self.quantum_tunnel_prob = 0.05\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            \n            # Mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation_vector = np.random.normal(0, 0.1 * (ub - lb), self.dim)\n                self.positions[i] = np.clip(self.positions[i] + mutation_vector, lb, ub)\n            \n            # Quantum tunneling\n            if np.random.rand() < self.quantum_tunnel_prob:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.0 + (0.4 * (self.budget - evaluations) / self.budget)\n            self.social_const = 2.0 - (0.4 * (self.budget - evaluations) / self.budget)\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimizerWithMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06316 with standard deviation 0.00493.", "error": "", "parent_ids": ["62a01afd-d46f-4632-99d2-aa496ba8057a"], "operator": null, "metadata": {"aucs": [0.06945521702056434, 0.05740995368379587, 0.06262932518412545]}}
{"id": "92859780-9f5d-46e4-bc3c-e198d344bc3a", "fitness": 0.07369243441415223, "name": "QuantumEnhancedLevySwarmOptimizer", "description": "Integrating Levy Flight into Quantum-Enhanced Swarm Optimization for enhanced exploration capabilities and preventing premature convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  0.01 * levy_vel)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.0 + (0.4 * (self.budget - evaluations) / self.budget)\n            self.social_const = 2.0 - (0.4 * (self.budget - evaluations) / self.budget)\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm QuantumEnhancedLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07369 with standard deviation 0.00465.", "error": "", "parent_ids": ["62a01afd-d46f-4632-99d2-aa496ba8057a"], "operator": null, "metadata": {"aucs": [0.0725516814548276, 0.07987537191786909, 0.06865024986975998]}}
{"id": "77e9cd46-d523-47a0-9066-e93acec2f5b2", "fitness": 0.04603556481485346, "name": "QuantumEnhancedLevySwarmOptimizer", "description": "Introducing Dynamic Quantum Range Adjustment to the Quantum-Enhanced Levy Swarm Optimizer for improved adaptation to varying landscapes.", "code": "import numpy as np\n\nclass QuantumEnhancedLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  0.01 * levy_vel)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def dynamic_quantum_range(self, evaluations, total_budget, lb, ub):\n        factor = 1 - (evaluations / total_budget)\n        return ((ub - lb) / 2) * factor\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.cognitive_const = 1.0 + (0.4 * (self.budget - evaluations) / self.budget)\n            self.social_const = 2.0 - (0.4 * (self.budget - evaluations) / self.budget)\n            quantum_range = self.dynamic_quantum_range(evaluations, self.budget, bounds.lb, bounds.ub)\n            self.positions = np.clip(self.positions + quantum_range * np.random.randn(self.population_size, self.dim), bounds.lb, bounds.ub)\n            self.update_positions_and_velocities(bounds)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm QuantumEnhancedLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04604 with standard deviation 0.00571.", "error": "", "parent_ids": ["92859780-9f5d-46e4-bc3c-e198d344bc3a"], "operator": null, "metadata": {"aucs": [0.04597377051676321, 0.03907293055014349, 0.05305999337765366]}}
{"id": "9bbbbd28-f1c7-4485-a3d7-9172f4cd76b1", "fitness": 0.07370237025477373, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Introducing Adaptive Quantum Levy Flight with Dynamic Attraction: Enhancing exploration-exploitation balance by dynamically adjusting the influence of quantum and swarm components based on optimization progress.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.01 * (1 - progress_factor)  # More influence early on\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07370 with standard deviation 0.00464.", "error": "", "parent_ids": ["92859780-9f5d-46e4-bc3c-e198d344bc3a"], "operator": null, "metadata": {"aucs": [0.0725806154921147, 0.07986729015272753, 0.06865920511947898]}}
{"id": "b27753de-c4fd-48e8-8666-b408a78e229b", "fitness": 0.06853728497020857, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introducing Adaptive Quantum Levy Flight with Dynamic Attraction and Randomized Reinforcement: Enhancing exploration-exploitation balance by adding occasional random perturbations to reinvigorate diversity and avoid local optima.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.reinforcement_probability = 0.05\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.01 * (1 - progress_factor)  # More influence early on\n\n            # Randomized reinforcement\n            if np.random.rand() < self.reinforcement_probability:\n                random_perturbation = np.random.uniform(lb, ub, self.dim) * 0.1\n            else:\n                random_perturbation = 0\n            \n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel + random_perturbation)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06854 with standard deviation 0.00419.", "error": "", "parent_ids": ["9bbbbd28-f1c7-4485-a3d7-9172f4cd76b1"], "operator": null, "metadata": {"aucs": [0.07092929134488035, 0.07204268622785004, 0.06263987733789533]}}
{"id": "7c7bc5ce-d334-4c85-88eb-34c4e91ff69c", "fitness": 0.04825918275715176, "name": "MultiSwarmQuantumLevyOptimizer", "description": "Introducing Multi-Swarm Quantum Levy Flight with Dynamic Hierarchical Attraction: Utilizing multiple swarms with hierarchical communication to enhance global and local search balance based on optimization progress.", "code": "import numpy as np\n\nclass MultiSwarmQuantumLevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.swarms = [self.initialize_swarm() for _ in range(self.num_swarms)]\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n    def initialize_swarm(self):\n        return {\n            'positions': None,\n            'velocities': None,\n            'best_positions': None,\n            'best_scores': None,\n            'inertia_weight': 0.9,\n            'cognitive_const': 1.4,\n            'social_const': 1.6,\n        }\n        \n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        for swarm in self.swarms:\n            swarm['positions'] = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n            swarm['velocities'] = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n            swarm['best_positions'] = np.copy(swarm['positions'])\n            swarm['best_scores'] = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for swarm in self.swarms:\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = swarm['cognitive_const'] * r1 * (swarm['best_positions'][i] - swarm['positions'][i])\n                social_velocity = swarm['social_const'] * r2 * (self.global_best_position - swarm['positions'][i])\n                levy_vel = self.levy_flight(self.dim)\n                quantum_weight = 0.01 * (1 - progress_factor)  # More influence early on\n                swarm['velocities'][i] = (swarm['inertia_weight'] * swarm['velocities'][i] +\n                                          cognitive_velocity + social_velocity +\n                                          quantum_weight * levy_vel)\n                swarm['positions'][i] = np.clip(swarm['positions'][i] + swarm['velocities'][i], lb, ub)\n            swarm['inertia_weight'] = max(0.4, swarm['inertia_weight'] - (0.45 / self.budget) * self.population_size)\n            swarm['cognitive_const'] = 1.0 + (0.4 * (1 - progress_factor))\n            swarm['social_const'] = 2.0 - (0.4 * (1 - progress_factor))\n\n    def evaluate_and_update_best(self, func):\n        for swarm in self.swarms:\n            for i in range(self.population_size):\n                score = func(swarm['positions'][i])\n                if score < swarm['best_scores'][i]:\n                    swarm['best_scores'][i] = score\n                    swarm['best_positions'][i] = swarm['positions'][i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = swarm['positions'][i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size * self.num_swarms\n\n        return self.global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm MultiSwarmQuantumLevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04826 with standard deviation 0.00634.", "error": "", "parent_ids": ["9bbbbd28-f1c7-4485-a3d7-9172f4cd76b1"], "operator": null, "metadata": {"aucs": [0.04791023458357724, 0.04067330156488702, 0.05619401212299102]}}
{"id": "b1941f7b-8df1-43f1-ad05-43a05baaa7ac", "fitness": 0.07370237025477373, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Introducing a dynamic cognitive and social coefficient adjustment to better fine-tune the exploration-exploitation balance based on individual particle performance.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.01 * (1 - progress_factor)  # More influence early on\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07370 with standard deviation 0.00464.", "error": "", "parent_ids": ["9bbbbd28-f1c7-4485-a3d7-9172f4cd76b1"], "operator": null, "metadata": {"aucs": [0.0725806154921147, 0.07986729015272753, 0.06865920511947898]}}
{"id": "5d4b4f47-02e6-46bf-a8e4-32f564498e9c", "fitness": 0.09265996096249784, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Incorporating adaptive velocity clamping to the Adaptive Quantum Levy Swarm Optimizer to enhance convergence by dynamically adjusting particle velocities based on progress.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1  # New line to introduce velocity clamping\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.01 * (1 - progress_factor)  # More influence early on\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)  # New line to define max velocity\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)  # Modified line for velocity clamping\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09266 with standard deviation 0.00119.", "error": "", "parent_ids": ["9bbbbd28-f1c7-4485-a3d7-9172f4cd76b1"], "operator": null, "metadata": {"aucs": [0.09430620661429467, 0.09216637975381647, 0.09150729651938239]}}
{"id": "c37c8e92-2120-4363-a53d-1212e1649475", "fitness": 0.09265712964476114, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introducing a dynamic levy flight scale and chaotic perturbations to enhance exploration and exploitation balance in the Adaptive Quantum Levy Swarm Optimizer, improving convergence on diverse optimization tasks.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size, scale):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = scale * u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        chaotic_factor = 0.5 * (1 + np.cos(np.pi * progress_factor))\n        levy_scale = 0.1 * (1 - progress_factor)\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim, levy_scale)\n            quantum_weight = 0.01 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  chaotic_factor * quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09266 with standard deviation 0.00131.", "error": "", "parent_ids": ["5d4b4f47-02e6-46bf-a8e4-32f564498e9c"], "operator": null, "metadata": {"aucs": [0.09449269936081472, 0.09196171404410802, 0.09151697552936067]}}
{"id": "5ede96db-a5d7-491c-be92-115a8da9fc07", "fitness": -Infinity, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Enhanced AdaptiveQuantumLevySwarmOptimizer with dynamic population size adjustment and improved inertia weight decay for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.35 / self.budget) * self.population_size  # Adjusted line for inertia decay\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.01 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            if evaluations % (self.budget // 10) == 0:  # New: Dynamic population adjustment\n                self.population_size = max(5, int(self.population_size * 1.1))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.3, self.inertia_weight - self.inertia_decay)  # Adjusted decay\n\n        return self.global_best_position", "configspace": "", "generation": 20, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_ids": ["5d4b4f47-02e6-46bf-a8e4-32f564498e9c"], "operator": null, "metadata": {}}
{"id": "1f23fec2-b056-45c7-a27d-cfa835f91ec6", "fitness": 0.09332228587589046, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Introduce dynamic quantum weight to enhance global search in initial stages while preserving exploitation in later stages.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 * (1 - progress_factor)  # Modified line to increase quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09332 with standard deviation 0.00092.", "error": "", "parent_ids": ["5d4b4f47-02e6-46bf-a8e4-32f564498e9c"], "operator": null, "metadata": {"aucs": [0.09448654009162905, 0.09224812293059359, 0.09323219460544874]}}
{"id": "f72713db-040d-4b08-bece-eeb34b0cdeba", "fitness": 0.09229757119458944, "name": "RefinedAdaptiveQuantumLevySwarmOptimizer", "description": "Integrate adaptive quantum weights with dynamic inertia adjustments to balance exploration and exploitation across different stages of optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 + 0.4 * (1 - progress_factor)  # Enhanced adaptive quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm RefinedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09230 with standard deviation 0.00109.", "error": "", "parent_ids": ["1f23fec2-b056-45c7-a27d-cfa835f91ec6"], "operator": null, "metadata": {"aucs": [0.09380871708997607, 0.09182400795936485, 0.0912599885344274]}}
{"id": "09fa2779-87e2-4fa0-94d3-bdc4f874be1e", "fitness": 0.09301563301459843, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Enhance global search by introducing stochastic quantum weight and dynamic neighborhood adaptation.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = np.random.uniform(0.05, 0.15) * (1 - progress_factor)  # Stochastic quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09302 with standard deviation 0.00037.", "error": "", "parent_ids": ["1f23fec2-b056-45c7-a27d-cfa835f91ec6"], "operator": null, "metadata": {"aucs": [0.09348690313497698, 0.09298656991172616, 0.09257342599709217]}}
{"id": "b77e970d-d712-4169-b623-83c5e091726c", "fitness": 0.09327673547095501, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Introduce adaptive mutation to enhance exploration and escape local minima during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.mutation_probability = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def mutate_position(self, position, bounds):\n        if np.random.rand() < self.mutation_probability:\n            lb, ub = bounds.lb, bounds.ub\n            mutation_strength = 0.1 * (ub - lb)\n            noise = np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n            position = np.clip(position + noise, lb, ub)\n        return position\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            new_position = self.positions[i] + self.velocities[i]\n            self.positions[i] = self.mutate_position(new_position, bounds)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09328 with standard deviation 0.00076.", "error": "", "parent_ids": ["1f23fec2-b056-45c7-a27d-cfa835f91ec6"], "operator": null, "metadata": {"aucs": [0.0926693726295098, 0.09434848045907474, 0.0928123533242805]}}
{"id": "34633def-8836-43c5-ab01-bf6a1d7fa587", "fitness": 0.09332228587589046, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Integrate dynamic regrouping by reinitializing a portion of the population when stagnation is detected, enhancing global exploration and preventing premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.stagnation_threshold = 20\n        self.stagnation_counter = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel)\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        improvement = False\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n                improvement = True\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n        if improvement:\n            self.stagnation_counter = 0\n        else:\n            self.stagnation_counter += 1\n\n    def regroup_population(self, bounds):\n        if self.stagnation_counter >= self.stagnation_threshold:\n            lb, ub = bounds.lb, bounds.ub\n            num_reinit = int(self.population_size * 0.3)  # Reinitialize 30% of the population\n            indices = np.random.choice(self.population_size, num_reinit, replace=False)\n            center = (lb + ub) / 2\n            quantum_range = (ub - lb) / 2\n            self.positions[indices] = np.random.uniform(center - quantum_range, center + quantum_range, (num_reinit, self.dim))\n            self.stagnation_counter = 0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            self.regroup_population(bounds)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09332 with standard deviation 0.00092.", "error": "", "parent_ids": ["1f23fec2-b056-45c7-a27d-cfa835f91ec6"], "operator": null, "metadata": {"aucs": [0.09448654009162905, 0.09224812293059359, 0.09323219460544874]}}
{"id": "2a82eeda-8853-4e5e-bdfe-3cec1765a5be", "fitness": 0.09365078270705814, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Integrate adaptive mutation based on population diversity to prevent premature convergence and enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09365 with standard deviation 0.00013.", "error": "", "parent_ids": ["1f23fec2-b056-45c7-a27d-cfa835f91ec6"], "operator": null, "metadata": {"aucs": [0.09382297526095285, 0.09351547396412185, 0.09361389889609972]}}
{"id": "dca86f1e-1a7d-46c1-afb7-78aa71d78435", "fitness": 0.09382970875802528, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introduce dynamic adaptation of velocity clamping and quantum weighting based on optimization progress to improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09383 with standard deviation 0.00040.", "error": "", "parent_ids": ["2a82eeda-8853-4e5e-bdfe-3cec1765a5be"], "operator": null, "metadata": {"aucs": [0.09411980893566285, 0.09410763851170201, 0.09326167882671099]}}
{"id": "6bb8eed7-c40e-4357-8140-f575c924b27b", "fitness": 0.09354059912853596, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introduce adaptive mutation strength scaling based on progress to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.2 * diversity * (1 - progress_factor)  # Adaptive mutation strength based on progress\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09354 with standard deviation 0.00110.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09464552029604634, 0.09394160900625537, 0.09203466808330618]}}
{"id": "76e145d6-8649-4b3a-9a19-76cc12dccfc0", "fitness": 0.08984097912749267, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introduce stochastic inertia adjustment based on population diversity to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            diversity_factor = 1 + np.random.uniform(-0.1, 0.1) * np.std(self.positions, axis=0).mean()  # Stochastic inertia adjustment\n            self.inertia_weight = max(0.4, (self.inertia_weight - self.inertia_decay) * diversity_factor)\n\n        return self.global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08984 with standard deviation 0.00195.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.08708848278951031, 0.091019590775262, 0.0914148638177057]}}
{"id": "032c1932-1d8d-4cfe-be4a-7816cd554e1a", "fitness": 0.09162378882097492, "name": "AdaptiveNeighborhoodQuantumLevySwarmOptimizer", "description": "Introduce adaptive swarm intelligence by integrating self-adaptive parameters and neighborhood-based learning to enhance convergence precision and stability.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.neighborhood_radius = 0.1\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            local_best = self.get_local_best(i)\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            r3 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            neighborhood_velocity = 1.5 * r3 * (local_best - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  neighborhood_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def get_local_best(self, idx):\n        distances = np.linalg.norm(self.positions - self.positions[idx], axis=1)\n        within_radius = distances < self.neighborhood_radius\n        local_best_idx = np.argmin(self.best_scores[within_radius])\n        return self.best_positions[within_radius][local_best_idx]\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveNeighborhoodQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09162 with standard deviation 0.00050.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09091768857922233, 0.09193501997618647, 0.09201865790751595]}}
{"id": "95be5ba4-c298-41a7-b63a-a8ffea4ea05d", "fitness": 0.0889893248590647, "name": "AdaptiveHierarchicalSwarmOptimizer", "description": "Implement an adaptive hierarchical swarm strategy with local exploitation and global exploration to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveHierarchicalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        local_exploitation_factor = 0.5 + 0.5 * progress_factor\n        \n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = local_exploitation_factor * self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = (1 - local_exploitation_factor) * self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            \n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveHierarchicalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08899 with standard deviation 0.00479.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09371127185102202, 0.08241800783552045, 0.09083869489065166]}}
{"id": "f3b29143-fef7-4001-987d-14f599877390", "fitness": 0.09370983877589374, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Enhance convergence by adjusting mutation strength and incorporating dynamic scaling of the cognitive and social constants.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.15 * diversity  # Adaptive mutation based on diversity, adjusted value\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.2 + (0.3 * (1 - progress_factor))  # Adjusted scaling of cognitive constant\n            self.social_const = 1.8 - (0.3 * (1 - progress_factor))  # Adjusted scaling of social constant\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09371 with standard deviation 0.00079.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09419412579812558, 0.09434095402557141, 0.09259443650398425]}}
{"id": "0b06c323-1b2c-4008-b356-ee0040295458", "fitness": 0.09344742862454392, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introduce dynamic inertia weight based on progress to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.inertia_weight = 0.9 - (0.5 * progress_factor)  # Dynamic inertia weight adjustment\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09345 with standard deviation 0.00034.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09390399810721028, 0.09308051282461438, 0.09335777494180708]}}
{"id": "936efd1f-a010-40f4-99fd-f161146bd261", "fitness": 0.09164906366458965, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Introduce adaptive inertia weight adjustment based on convergence speed to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)  # Increased quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        last_global_best_score = float('inf')  # Initialize last best score history\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n            # Adapt inertia weight based on the change in the global best score\n            score_improvement = last_global_best_score - self.global_best_score\n            self.inertia_weight = max(0.4, 0.9 - 0.5 * score_improvement)\n            last_global_best_score = self.global_best_score\n\n        return self.global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09165 with standard deviation 0.00173.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09277170322898032, 0.09296945337050833, 0.08920603439428032]}}
{"id": "e7ca120b-a866-4247-9b8a-05a18abedbee", "fitness": 0.09378845810023984, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Enhance quantum weight adaptation for improved exploration-exploitation balance based on progress factor.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()  # Calculate population diversity\n        mutation_strength = 0.1 * diversity  # Adaptive mutation based on diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.3 * (1 - progress_factor)  # Enhanced quantum weight\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))  # Apply mutation\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)  # Adaptive velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09379 with standard deviation 0.00051.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09358515121146971, 0.09449432664997859, 0.09328589643927121]}}
{"id": "384a4eaa-0f93-42b4-801d-f8f49b45246f", "fitness": 0.08859169654652965, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Enhance swarm collaboration via adaptive neighborhood topology and stochastic velocity refreshment to boost exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            neighborhood_best = self.get_neighborhood_best(i)\n            social_velocity = self.social_const * r2 * (neighborhood_best - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            stochastic_refreshment = np.random.rand(self.dim) < 0.05\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) +\n                                  stochastic_refreshment * np.random.uniform(-0.5, 0.5, self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def get_neighborhood_best(self, index):\n        neighbors = (index - 1) % self.population_size, (index + 1) % self.population_size\n        neighbor_scores = [self.best_scores[n] for n in neighbors]\n        best_neighbor = neighbors[np.argmin(neighbor_scores)]\n        return self.best_positions[best_neighbor]\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08859 with standard deviation 0.00146.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.08714924334052976, 0.08803525929165223, 0.09059058700740696]}}
{"id": "9552eb1d-0c15-4460-9d87-415184ef3aac", "fitness": 0.08357361817100932, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Enhance global exploration and local exploitation balance by introducing a chaotic initialization and adaptive neighborhood search strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        chaotic_sequence = np.random.rand(self.population_size, self.dim) ** 2  # Chaotic initialization\n        self.positions = lb + (ub - lb) * chaotic_sequence\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            if np.random.rand() < 0.1:  # Adaptive local search\n                self.positions[i] += np.random.normal(0, 0.1, self.dim) * (self.global_best_position - self.positions[i])\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08357 with standard deviation 0.00994.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09336012728041632, 0.08742418210095004, 0.06993654513166159]}}
{"id": "8d381f5d-c31f-43c9-8a42-77ae65f8e236", "fitness": 0.09432290726510661, "name": "EnhancedAdaptiveQuantumLevySwarmOptimizer", "description": "Integrate adaptive inertia weight scaling and dynamic population clustering to enhance convergence precision and stability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09432 with standard deviation 0.00070.", "error": "", "parent_ids": ["dca86f1e-1a7d-46c1-afb7-78aa71d78435"], "operator": null, "metadata": {"aucs": [0.09460049261259407, 0.09500586264200561, 0.09336236654072017]}}
{"id": "4c73cc41-e57b-4c20-ab32-6ef33e262af2", "fitness": 0.09321291018180959, "name": "HybridQuantumDiversitySwarmOptimizer", "description": "A hybrid swarm optimizer that combines adaptive quantum dynamics and diversity-driven mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridQuantumDiversitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            velocity_update = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                               cognitive_velocity + social_velocity +\n                               quantum_weight * levy_vel +\n                               mutation_strength * np.random.randn(self.dim))\n            if np.random.rand() < self.mutation_prob:\n                mutation_factor = np.random.randn(self.dim) * mutation_strength\n                velocity_update += mutation_factor\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(velocity_update, -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.4 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.4 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm HybridQuantumDiversitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09321 with standard deviation 0.00088.", "error": "", "parent_ids": ["8d381f5d-c31f-43c9-8a42-77ae65f8e236"], "operator": null, "metadata": {"aucs": [0.09372093329775244, 0.09196987798677148, 0.09394791926090484]}}
{"id": "f5218ebf-df83-46b4-a083-86fc7678b2e5", "fitness": 0.09417004374343758, "name": "RefinedAdaptiveQuantumLevySwarmOptimizer", "description": "Integrate adaptive quantum perturbations and dynamic diversity control to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.5\n        self.social_const = 1.7\n        self.inertia_decay = (0.5 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.15\n        self.diversity_threshold = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        adaptive_quantum_weight = 0.3 if diversity < self.diversity_threshold else 0.1\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            self.velocities[i] = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  adaptive_quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = self.velocity_clamp_factor * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.cognitive_const = 1.0 + (0.5 * (1 - progress_factor))\n            self.social_const = 2.0 - (0.5 * (1 - progress_factor))\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09417 with standard deviation 0.00079.", "error": "", "parent_ids": ["8d381f5d-c31f-43c9-8a42-77ae65f8e236"], "operator": null, "metadata": {"aucs": [0.09343982537409468, 0.0952735730904426, 0.09379673276577549]}}
{"id": "7ab4f98c-3768-4b0b-a344-fd3c21218f87", "fitness": 0.09434125427666344, "name": "EnhancedQuantumLevySwarmOptimizerV2", "description": "Introduce adaptive personal and social influence scaling with multi-phase exploration-exploitation cycles to improve convergence robustness and precision.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09434 with standard deviation 0.00030.", "error": "", "parent_ids": ["8d381f5d-c31f-43c9-8a42-77ae65f8e236"], "operator": null, "metadata": {"aucs": [0.09392508099896624, 0.09457533394125595, 0.09452334788976813]}}
{"id": "f604bdc4-d95d-48bd-af1f-ee1d0d1d9a0a", "fitness": 0.09412090855124655, "name": "EnhancedQuantumLevySwarmOptimizerV2", "description": "Refine adaptive parameter tuning by adjusting inertia decay and cognitive-social balance to enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.4 / self.budget) * self.population_size # Adjusted\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.6, 'social': 1.3}, # Adjusted\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.1}] # Adjusted\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09412 with standard deviation 0.00031.", "error": "", "parent_ids": ["7ab4f98c-3768-4b0b-a344-fd3c21218f87"], "operator": null, "metadata": {"aucs": [0.09368986098565801, 0.0943787199674847, 0.09429414470059694]}}
{"id": "3fe4bd76-e687-429c-9bbf-93313f9bd0d5", "fitness": 0.08938307156497101, "name": "EnhancedQuantumLevySwarmOptimizerV3", "description": "Incorporate dynamic topological influence with an adaptive neighborhood-based interaction to enhance global exploration and local exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.topology_radius = int(np.sqrt(self.population_size))\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            neighborhood_indices = (np.arange(i-self.topology_radius, i+self.topology_radius+1) % self.population_size)\n            neighborhood_best_score = np.min(self.best_scores[neighborhood_indices])\n            neighborhood_best_position = self.best_positions[neighborhood_indices[np.argmin(self.best_scores[neighborhood_indices])]]\n            \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (neighborhood_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08938 with standard deviation 0.00545.", "error": "", "parent_ids": ["7ab4f98c-3768-4b0b-a344-fd3c21218f87"], "operator": null, "metadata": {"aucs": [0.0944595909140864, 0.08182461960779885, 0.09186500417302779]}}
{"id": "8b512cf3-0246-4641-88a5-64de1e745b4e", "fitness": 0.09466967228802832, "name": "EnhancedQuantumLevySwarmOptimizerV3", "description": "Introduce dynamic inertia weight adaptation and adjust cognitive-social influence balancing to enhance convergence efficiency and precision.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09467 with standard deviation 0.00014.", "error": "", "parent_ids": ["7ab4f98c-3768-4b0b-a344-fd3c21218f87"], "operator": null, "metadata": {"aucs": [0.0945182529121874, 0.09463407879986885, 0.09485668515202872]}}
{"id": "35aa65f2-d17b-4f60-8887-a63369c3a789", "fitness": 0.09398857257184794, "name": "AdaptiveChaosDrivenQuantumOptimizer", "description": "Integrate adaptive phase transition dynamics and a chaos-driven initialization to enhance exploration and exploitation balance for improved convergence precision.", "code": "import numpy as np\n\nclass AdaptiveChaosDrivenQuantumOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n    \n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n    \n    def chaos_init(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        chaos_map = np.random.rand(self.population_size)\n        for i in range(100):\n            chaos_map = np.sin(np.pi * chaos_map)\n        return lb + chaos_map[:, None] * (ub - lb)\n    \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = self.chaos_init(bounds)\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptiveChaosDrivenQuantumOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.00080.", "error": "", "parent_ids": ["8b512cf3-0246-4641-88a5-64de1e745b4e"], "operator": null, "metadata": {"aucs": [0.0941426446571374, 0.09488446517473159, 0.0929386078836748]}}
{"id": "bfc4a497-edc1-45ba-8695-34156743ed2e", "fitness": 0.09367666106140822, "name": "EnhancedQuantumLevySwarmOptimizerV4", "description": "Introduce adaptive mutation strength based on population diversity and incorporate a non-linear deceleration factor for velocity to enhance convergence precision and robustness.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 + np.tanh(diversity))\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor)\n            velocity_decay = 1 - (progress_factor ** 2)\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim)) * velocity_decay\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09368 with standard deviation 0.00097.", "error": "", "parent_ids": ["8b512cf3-0246-4641-88a5-64de1e745b4e"], "operator": null, "metadata": {"aucs": [0.0937129417733491, 0.09484131351011482, 0.09247572790076075]}}
{"id": "72c4552d-b0f5-4ef3-ae09-851c2cde334d", "fitness": 0.09468830842818103, "name": "EnhancedQuantumLevySwarmOptimizerV4", "description": "Enhance exploration-exploitation balance by integrating adaptive mutation strengths and dynamic quantum weighting to improve convergence speed and precision.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09469 with standard deviation 0.00013.", "error": "", "parent_ids": ["8b512cf3-0246-4641-88a5-64de1e745b4e"], "operator": null, "metadata": {"aucs": [0.0946859472018372, 0.09452620249758747, 0.0948527755851184]}}
{"id": "0f5a5565-bf6d-419e-bfe4-27d1613d0fda", "fitness": 0.09384748360127078, "name": "EnhancedQuantumLevySwarmOptimizerV5", "description": "Further enhance exploitation by incorporating a hybrid mutation strategy and fine-tuning velocity clamping.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * (np.random.randn(self.dim) + levy_vel))  # Hybrid mutation\n            max_velocity = (0.12 - 0.03 * progress_factor) * (ub - lb)  # Fine-tuned velocity clamp\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09385 with standard deviation 0.00101.", "error": "", "parent_ids": ["72c4552d-b0f5-4ef3-ae09-851c2cde334d"], "operator": null, "metadata": {"aucs": [0.09511321744267331, 0.09263894936979133, 0.0937902839913477]}}
{"id": "a9412a21-40a3-4d80-8dba-0e8875b3fc4d", "fitness": 0.09512673866707999, "name": "EnhancedQuantumLevySwarmOptimizerV5", "description": "Introduce diversity through stochastic reinitialization to enhance convergence and avoid local optima.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09513 with standard deviation 0.00040.", "error": "", "parent_ids": ["72c4552d-b0f5-4ef3-ae09-851c2cde334d"], "operator": null, "metadata": {"aucs": [0.09543861356500416, 0.09537936637624156, 0.09456223605999425]}}
{"id": "4cb7819d-0685-433f-9a30-9d36ad9617ba", "fitness": 0.09341382433074441, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Implement adaptive inertia and neighborhood influence to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.neighborhood_size = max(2, int(0.1 * self.population_size))\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            r3 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            neighborhood_best = self.get_neighborhood_best(i)\n            neighborhood_velocity = r3 * (neighborhood_best - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity + neighborhood_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def get_neighborhood_best(self, index):\n        neighbors = np.random.choice(np.delete(np.arange(self.population_size), index), self.neighborhood_size, replace=False)\n        neighbor_scores = self.best_scores[neighbors]\n        best_neighbor_index = neighbors[np.argmin(neighbor_scores)]\n        return self.best_positions[best_neighbor_index]\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09341 with standard deviation 0.00311.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09588190347078684, 0.08902881360442771, 0.09533075591701867]}}
{"id": "fbb32951-b6c0-4954-bb94-7822d7f695f7", "fitness": 0.09408072014991646, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance global exploration by varying quantum weight non-linearly and introducing a controlled random jump mechanism.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            # Adjusted quantum weight for enhanced exploration\n            quantum_weight = 0.3 * ((1 - progress_factor) ** 2) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Controlled random jump for diversity\n            if np.random.rand() < 0.02 * (1.5 - progress_factor):\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09408 with standard deviation 0.00106.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09493285310922728, 0.09258608590349171, 0.09472322143703038]}}
{"id": "f43171d5-f5f6-4490-87f3-9447f89b23ad", "fitness": 0.09496871069516939, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Integrate adaptive mutation scaling based on population diversity to refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.15 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09497 with standard deviation 0.00039.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09550450719186632, 0.09479642728149873, 0.09460519761214314]}}
{"id": "dbb52b26-5605-4d49-aaa2-19b93dbcea37", "fitness": 0.09512334639516933, "name": "EnhancedQuantumLevySwarmOptimizerV5", "description": "Introduce adaptive diversity reinitialization to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce adaptive diversity through reinitialization if stuck\n            if np.random.rand() < 0.01 + 0.01 * progress_factor:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09512 with standard deviation 0.00040.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09543620793981078, 0.09537159518570293, 0.09456223605999425]}}
{"id": "635de9b0-0d10-443b-9465-1f3b5599eac6", "fitness": 0.0907321777414637, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce adaptive velocity control and dynamic mutation strategies to further enhance convergence and robustness against local optima.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.05 * (1 - progress_factor) * diversity  # Reduced mutation strength for better stability\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.1 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Reduced quantum weight\n            # Introducing adaptive control for velocity\n            velocity_control = 0.5 * np.random.rand(self.dim)\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) +\n                                  velocity_control)\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Improved stochastic reinitialization\n            if np.random.rand() < 0.02:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09073 with standard deviation 0.00336.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09031534482412029, 0.08684524115185721, 0.09503594724841358]}}
{"id": "446cefba-b05d-4b85-b83b-6629c2b6333a", "fitness": 0.0900222603707201, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Integrate adaptive inertia weight and differential evolution-inspired crossover for robust swarm convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = max(0.4, 0.9 - progress_factor * 0.5)  # Adaptive inertia weight\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            r3 = np.random.rand(self.dim)\n            crossover_mask = np.random.rand(self.dim) < 0.5\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            trial_position = np.where(crossover_mask, self.positions[i] + self.velocities[i], self.positions[i])\n            self.positions[i] = np.clip(trial_position, lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09002 with standard deviation 0.00104.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09121324332615521, 0.09017057685197483, 0.08868296093403027]}}
{"id": "71331649-7298-4678-b2b4-483f4d125a80", "fitness": 0.0847272273130838, "name": "EnhancedQuantumLevySwarmOptimizerV5", "description": "Enhance convergence by dynamically adjusting velocity clamp factors based on diversity and progress.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = ((0.15 - 0.05 * progress_factor) * (ub - lb)) * (1 + diversity)  # Dynamic velocity clamp\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08473 with standard deviation 0.00668.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.07552707738052455, 0.08744319415228319, 0.09121141040644365]}}
{"id": "11fc3e66-15e9-4ba4-9b3b-ea0795b25840", "fitness": 0.09373504892957092, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance exploration through adaptive step sizes and dynamic adjustment of swarm diversity to improve convergence efficiency and escape local optima.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.2 * (1 - progress_factor) * diversity  # Increased adaptive mutation\n        adaptive_step_size = 0.1 + 0.4 * np.random.rand()  # Adaptive step size\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.3 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Enhanced dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) * adaptive_step_size)\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.02:  # Increased probability for diversity\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09374 with standard deviation 0.00158.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09580227925274687, 0.0919745367640924, 0.09342833077187351]}}
{"id": "fa9a8f29-f81d-437a-8dc2-07b2f2207cc4", "fitness": 0.0949111890108512, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce adaptive chaotic maps to enhance exploration and exploitation balance and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.chaos_control_param = 0.7  # Initial value\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        \n        # Update chaos control parameter using a chaotic map (e.g., Logistic Map)\n        self.chaos_control_param = 4 * self.chaos_control_param * (1 - self.chaos_control_param)\n        \n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01 * self.chaos_control_param:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09491 with standard deviation 0.00032.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09529050135212858, 0.09493085285696556, 0.09451221282345945]}}
{"id": "32c40c16-4d0d-44b1-9d03-887763865932", "fitness": 0.09476212625644864, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce chaos-inspired perturbations and adaptive component integration to enhance exploration and improve convergence precision.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.chaotic_map = self.initialize_chaos_map()\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def initialize_chaos_map(self):\n        return np.random.rand(self.dim)\n\n    def update_chaos_map(self):\n        r = 4.0\n        self.chaotic_map = r * self.chaotic_map * (1 - self.chaotic_map)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n\n        self.update_chaos_map()\n        chaos_factor = 0.1 * self.chaotic_map\n\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) +\n                                  chaos_factor)\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09476 with standard deviation 0.00061.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.0948371947813823, 0.09546547066914479, 0.09398371331881883]}}
{"id": "51199eb0-7981-4fdd-9f1c-8afe16980784", "fitness": 0.09119249081885798, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance exploration and exploitation balance by dynamically adjusting inertia and introducing guided random walks for diversification.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 1 - progress_factor  \n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_steps = self.levy_flight(self.dim)\n            random_walk = np.random.normal(0, 1, self.dim) * mutation_strength\n\n            self.velocities[i] = (inertia_scale * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  0.2 * levy_steps +\n                                  random_walk)\n\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n            if np.random.rand() < 0.02:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            if progress_factor < 0.5:\n                self.cognitive_const = 1.5\n                self.social_const = 1.5\n            else:\n                self.cognitive_const = 1.2\n                self.social_const = 1.8\n\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09119 with standard deviation 0.00057.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09075016671761771, 0.09082770194328305, 0.09199960379567318]}}
{"id": "296613b9-1b35-47e6-8661-169c0933466f", "fitness": 0.0941786349695171, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce an adaptive mutation strategy and reinitialization threshold to further enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.15 * (1 - progress_factor) * diversity  # Adjusted mutation strength\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.015:  # Adjusted reinitialization threshold\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09418 with standard deviation 0.00041.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09430851550637909, 0.09362219179002906, 0.09460519761214314]}}
{"id": "0061a05b-522b-43ea-acb1-3da03b494dc7", "fitness": -Infinity, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce periodic reinitialization based on stagnation detection to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce periodic reinitialization based on stagnation\n            if evaluations % (self.population_size * 5) == 0:  # New reinitialization strategy\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 62, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {}}
{"id": "3c9b6a0b-738b-4a0f-8f3d-dbe0fb8b45c1", "fitness": 0.09366938091681802, "name": "DynamicAdaptiveSwarmOptimizer", "description": "Enhance exploration through dynamic parameter adjustments and adaptive swarm behavior for improved optimization performance.", "code": "import numpy as np\n\nclass DynamicAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.6, 'social': 1.2},\n                       {'start': 0.3, 'end': 0.6, 'cognitive': 1.3, 'social': 1.7},\n                       {'start': 0.6, 'end': 1.0, 'cognitive': 1.0, 'social': 2.1}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.3 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.02 * (1 - progress_factor):\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm DynamicAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09367 with standard deviation 0.00042.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09338625675392065, 0.09336343797412328, 0.09425844802241012]}}
{"id": "b3c84506-c905-4ea0-825a-cb2885318f37", "fitness": -Infinity, "name": "HybridChaosMemorySwarmOptimizer", "description": "Enhance swarm diversity and convergence by introducing hybrid dynamic adaptive strategies using chaotic maps and dynamic memory.", "code": "import numpy as np\n\nclass HybridChaosMemorySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.memory = []\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_sequence(self, size):\n        return 4.0 * np.random.rand(size) * (1.0 - np.random.rand(size))\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.memory = [np.copy(self.positions)]  # Initialize memory with the first positions\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        chaos_factor = self.chaotic_sequence(self.dim)  # Introduce chaos\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            memory_effect = 0.1 * (np.mean(self.memory, axis=0) - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity + memory_effect +\n                                  quantum_weight * levy_vel + chaos_factor * mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Enhance diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n        self.memory.append(np.copy(self.positions))\n        if len(self.memory) > 10:\n            self.memory.pop(0)  # Keep memory size limited\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 64, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (16,10) into shape (10,)').", "error": "ValueError('could not broadcast input array from shape (16,10) into shape (10,)')", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {}}
{"id": "a69a54bb-1215-44d0-82ea-403f06667df4", "fitness": 0.09512673866707999, "name": "EnhancedQuantumLevySwarmOptimizerV5", "description": "Adaptively adjust the velocity clamping factor to balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.velocity_clamp_factor = 0.1 + 0.05 * progress_factor  # Adjust the velocity clamp factor\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09513 with standard deviation 0.00040.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09543861356500416, 0.09537936637624156, 0.09456223605999425]}}
{"id": "00558d2e-254f-4308-ad30-fa90f2fa5fc1", "fitness": 0.09360516014784366, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance swarm intelligence through dynamic adaptation of cognitive and social parameters and adaptive mutation strength to improve convergence and escape local optima.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight = 0.9\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.inertia_decay = (0.45 / self.budget) * self.population_size\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * \n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_scale = 0.5 + 0.5 * np.cos(np.pi * progress_factor)\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            self.velocities[i] = (inertia_scale * (0.5 + 0.4 * np.sin(np.pi * progress_factor)) * self.velocities[i] +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.02:  # Slightly increase reinitialization frequency\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_decay)\n\n        return self.global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09361 with standard deviation 0.00139.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.09416430094779393, 0.09169352043507173, 0.09495765906066533]}}
{"id": "555db816-fcd9-43a8-bc6b-c84882c22f72", "fitness": 0.09528817177024791, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance exploration by implementing an adaptive inertia weight and incorporating an elite preservation strategy to maintain promising solutions.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09529 with standard deviation 0.00035.", "error": "", "parent_ids": ["a9412a21-40a3-4d80-8dba-0e8875b3fc4d"], "operator": null, "metadata": {"aucs": [0.0956875415950561, 0.09534062795549125, 0.0948363457601964]}}
{"id": "7bc4413c-5430-4421-82df-d10dfc767e75", "fitness": 0.09528624844910345, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce dynamic elite preservation by adjusting elite_fraction based on progress_factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        self.elite_fraction = 0.1 * (1 - progress_factor)  # Dynamic elite fraction\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09529 with standard deviation 0.00034.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09567886897025246, 0.09533691108277487, 0.09484296529428304]}}
{"id": "8f6fbf68-67aa-43a0-8bcd-db0b57f604ee", "fitness": 0.09227333061389746, "name": "RefinedQuantumLevySwarmOptimizer", "description": "Introduce a multi-phase dynamic adaptation of the cognitive and social coefficients, enhance diversity with stochastic reinitialization, and integrate elite-guided Levy flights for improved convergence.", "code": "import numpy as np\n\nclass RefinedQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.6, 'cognitive': 1.0, 'social': 1.5},\n                       {'start': 0.6, 'end': 1.0, 'cognitive': 0.7, 'social': 1.9}]\n        self.elite_fraction = 0.2\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.25 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n                levy_vel *= 0.5\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.2 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.02:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09227 with standard deviation 0.00185.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09273088931332019, 0.09427444090315462, 0.08981466162521756]}}
{"id": "5c74f39b-3367-4db3-bcf1-63050dd5cc28", "fitness": 0.09437033967410853, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Improve convergence speed and solution quality through dynamic elite reinitialization and neighborhood exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.reinit_chance = 0.05\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < self.reinit_chance:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09437 with standard deviation 0.00039.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09458755941670527, 0.09382042812007352, 0.09470303148554682]}}
{"id": "eccf2ac6-cdb7-49cd-9204-85b4116e8f13", "fitness": 0.09133574656344627, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Introduce multi-phase adaptation of dynamic parameters with chaotic maps and an enhanced diversity-preserving reinitialization strategy for robust convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def chaotic_map(self, x, a=3.99):\n        return a * x * (1 - x)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.chaotic_state = np.random.rand()\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            \n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            \n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            \n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n        \n        self.chaotic_state = self.chaotic_map(self.chaotic_state)\n        if self.chaotic_state < 0.05:\n            self.positions += np.random.uniform(-diversity, diversity, self.positions.shape)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09134 with standard deviation 0.00263.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.093481410802145, 0.08762559295801398, 0.09290023593017982]}}
{"id": "a633ecf4-497a-4f96-83af-0d05a6d0a453", "fitness": 0.08803980992808895, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance exploration by introducing random selection of swarm leaders to reduce premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        leader_idx = np.random.choice(elite_indices)  # Random leader selection\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.positions[leader_idx] - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08804 with standard deviation 0.00293.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.090067423653034, 0.09016209257296215, 0.08388991355827069]}}
{"id": "fd3566ca-6175-49fa-9b52-9e2a27718a3b", "fitness": 0.09505701796766126, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhance exploration by adding a dynamic exploration factor based on diversity to the inertia weight calculation.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        diversity = np.std(self.positions, axis=0).mean()\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final + 0.1 * diversity  # Modified line\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09506 with standard deviation 0.00016.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.0952137236883761, 0.09512676361413741, 0.09483056660047029]}}
{"id": "9f428d64-d418-4dd0-9c60-04d9adf68bcf", "fitness": 0.09502387176836591, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Introduce adaptive phase transitions and stochastic perturbations to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.2, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.2, 'end': 0.5, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.5, 'end': 0.8, 'cognitive': 1.1, 'social': 2.0},\n                       {'start': 0.8, 'end': 1.0, 'cognitive': 1.0, 'social': 2.5}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor ** 2) * diversity\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        \n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.cos(np.pi * progress_factor))\n            \n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            \n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            \n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            \n            # Stochastic perturbation for exploration\n            if np.random.rand() < 0.05:\n                self.positions[i] += 0.05 * np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09502 with standard deviation 0.00020.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09524485647925351, 0.09506813367739109, 0.09475862514845312]}}
{"id": "f0061b15-cc58-4964-86b7-c93a12f4603a", "fitness": 0.09443384878956473, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduce a dynamic mutation strategy and adaptive elite selection criteria to enhance convergence while maintaining diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.05 * (1 - progress_factor) * diversity  # Adjusted mutation strength\n        elite_size = int(self.elite_fraction * self.population_size * (1 + 0.5 * np.sin(np.pi * progress_factor)))  # Adaptive elite selection\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))  # Dynamic quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09443 with standard deviation 0.00119.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09275018421930492, 0.09539354242048692, 0.09515781972890236]}}
{"id": "6d0f7007-bccc-4587-bf7d-4b95939381f9", "fitness": 0.09447029168134964, "name": "DynamicNeighborhoodAdaptiveSwarmOptimizer", "description": "Introduce a dynamic neighborhood strategy and adaptive local search mechanism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass DynamicNeighborhoodAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.neighborhood_size = int(0.2 * self.population_size)\n        self.local_search_rate = 0.05\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def dynamic_neighborhood(self, index):\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighborhood_indices = np.argsort(distances)[:self.neighborhood_size]\n        local_best_index = neighborhood_indices[np.argmin(self.best_scores[neighborhood_indices])]\n        return self.best_positions[local_best_index]\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            local_best_position = self.dynamic_neighborhood(i)\n            local_velocity = self.cognitive_const * r2 * (local_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.5 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity + local_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < self.local_search_rate:\n                self.positions[i] += np.random.normal(0, 0.1 * (ub - lb), self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm DynamicNeighborhoodAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09447 with standard deviation 0.00052.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09501023301946543, 0.09464155226595006, 0.09375908975863345]}}
{"id": "9ace7ec9-8197-4a38-a703-93d3b65ef84d", "fitness": 0.09531761787416122, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduced adaptive elite preservation and dynamic quantum weight adjustment to enhance solution diversity and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.00038.", "error": "", "parent_ids": ["555db816-fcd9-43a8-bc6b-c84882c22f72"], "operator": null, "metadata": {"aucs": [0.09571417520684722, 0.09542873953094055, 0.09480993888469591]}}
{"id": "c68bf401-b3c7-426b-83cb-9fb9b141f3d7", "fitness": 0.04101960605695376, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Integrate a dynamic inertia weight adjustment based on performance feedback to enhance convergence stability.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        \n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        # Modified inertia weight adjustment for dynamic feedback\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor * (self.global_best_score / self.best_scores.mean())) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04102 with standard deviation 0.00548.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.03989912636874271, 0.048223654060705945, 0.03493603774141263]}}
{"id": "fc9bf9bb-5c51-4559-8f7a-a111f3693367", "fitness": 0.09523360291666909, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduced a probability of dynamic reinitialization for stagnant solutions to promote exploration and limit premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < (0.01 + progress_factor * 0.04):  # Increased dynamic reinitialization probability\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09523 with standard deviation 0.00032.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09563066091866057, 0.0952267771925327, 0.09484337063881398]}}
{"id": "2649bf6c-6fa5-4df4-a5b2-25f0839954b2", "fitness": 0.09354797175513722, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Enhanced convergence by incorporating variable neighborhood search and adaptive updating of cognitive and social components.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.elite_fraction = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  \n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            if np.random.rand() < 0.05:  # Adaptive neighborhood search \n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n            else:\n                self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub) \n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09355 with standard deviation 0.00056.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09347047303325606, 0.0942675901574277, 0.0929058520747279]}}
{"id": "f387bece-5bb0-4972-9741-28ce4c125750", "fitness": 0.095312588456872, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduced a slight increase in the elite fraction to further enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.12  # Slightly increased from 0.1 to 0.12\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09531 with standard deviation 0.00038.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09571552418047691, 0.09542062809226248, 0.0948016130978766]}}
{"id": "fbd94fe6-64ca-4660-87e6-33d047ad3794", "fitness": 0.09531761787416122, "name": "DynamicSwarmOptimizerV1", "description": "Integrate dynamic diversity control and adaptive mutation scaling to improve exploration and convergence balance in the swarm.", "code": "import numpy as np\n\nclass DynamicSwarmOptimizerV1:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.mutation_scale = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = self.mutation_scale * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 82, "feedback": "The algorithm DynamicSwarmOptimizerV1 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.00038.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09571417520684722, 0.09542873953094055, 0.09480993888469591]}}
{"id": "dcad79fd-d2ba-4ace-9c6e-bf025a19bc28", "fitness": 0.09472994620654034, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Introduced phase-specific mutation strength adjustment to further enhance solution exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity * (0.5 + 0.5 * np.sin(2 * np.pi * progress_factor))  # Phase-specific mutation strength\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09473 with standard deviation 0.00101.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09342544762605776, 0.09588921269829709, 0.09487517829526615]}}
{"id": "90c05bb5-ec9d-4c42-b175-f8cb22c3f736", "fitness": 0.09531763147078383, "name": "EnhancedQuantumLevySwarmOptimizerV6", "description": "Enhanced adaptive elite preservation by introducing a dynamic elite expansion during the final phase.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity  # Adaptive mutation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))  # Adaptive elite size\n        if progress_factor > 0.9:  # Dynamic expansion of elite size in the final phase\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))  # Adjusted quantum weight\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            # Introduce diversity through reinitialization if stuck\n            if np.random.rand() < 0.01:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.00038.", "error": "", "parent_ids": ["9ace7ec9-8197-4a38-a703-93d3b65ef84d"], "operator": null, "metadata": {"aucs": [0.09571419405022918, 0.09542875293339093, 0.09480994742873139]}}
{"id": "3cbbb19a-8d66-4d16-b852-18b6eb97c6fb", "fitness": 0.095370933464478, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Enhanced elite adaptation with dynamic inertia weight adjustment and chaos-induced diversity for improved convergence in Levy Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09537 with standard deviation 0.00024.", "error": "", "parent_ids": ["90c05bb5-ec9d-4c42-b175-f8cb22c3f736"], "operator": null, "metadata": {"aucs": [0.09567719795618035, 0.09533740586707229, 0.09509819657018137]}}
{"id": "8cd9a735-b886-4b31-abf1-f0751efd2444", "fitness": 0.09460617157844235, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Introduced adaptive quantum range to further enhance search space exploration in Enhanced Quantum Levy Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2  # Original line\n        quantum_range += 0.1 * quantum_range * np.sin(np.pi / 4)  # Adaptive quantum range adjustment\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09461 with standard deviation 0.00067.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09531969870176094, 0.09478811593592174, 0.09371070009764437]}}
{"id": "afc106e0-4009-48d0-9c3d-f039b2deb52e", "fitness": 0.0953072834072795, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Enhanced adaptive mutation strength for dynamic exploration and exploitation balance in Levy Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor ** 2) * diversity  # Enhanced mutation strength adaptation\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09531 with standard deviation 0.00024.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09564386627417976, 0.09514351531714527, 0.09513446863051345]}}
{"id": "0f108a80-ae15-43cd-a069-294eb33bee3b", "fitness": 0.07762406090179592, "name": "AdaptiveQuantumLevySwarmOptimizer", "description": "Adaptive Quantum-Levy Swarm with Self-Learning Mechanism for Enhanced Dynamic Performance in Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n        self.self_learning_rate = 0.05  # New parameter for self-learning\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        \n        # Adaptive self-learning rate mechanism\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n            self.self_learning_rate = 0.1 * (1 + progress_factor)\n            \n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n\n            # Integrate self-learning rate into velocity update\n            self.velocities[i] = (inertia_component +\n                                  self.self_learning_rate * cognitive_velocity + self.self_learning_rate * social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            \n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07762 with standard deviation 0.00461.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.07992519870332282, 0.08174996365818354, 0.07119702034388142]}}
{"id": "70dab886-e134-4185-8240-bdac2ef156bf", "fitness": 0.09501536012430216, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Introduced a dynamic mutation strength influenced by the cosine of the progress factor for enhanced diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity * (1 + 0.5 * np.cos(np.pi * progress_factor))  # Modified mutation strength\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09502 with standard deviation 0.00067.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09595426351242986, 0.09465658786581987, 0.09443522899465673]}}
{"id": "5486cdc4-92e9-4f3e-a1df-18034008e713", "fitness": 0.09438301909173681, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Adaptive dynamic elite selection with non-linear chaotic scaling and hybrid mutation strategies for robust global optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - np.sqrt(progress_factor)))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            hybrid_mutation = (mutation_strength * np.random.randn(self.dim) +\n                               np.random.uniform(-mutation_strength, mutation_strength, self.dim))\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  hybrid_mutation)\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09438 with standard deviation 0.00080.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09532280223579548, 0.09444789220246785, 0.09337836283694712]}}
{"id": "7daafa17-f50c-474b-ac5c-4cae53d37750", "fitness": 0.09437199128799283, "name": "AdvancedAdaptiveQuantumLevySwarmOptimizer", "description": "Advanced Adaptive Quantum Levy Swarm Optimizer with multi-phase dynamic elite reintegration and stochastic velocity perturbation for enhanced global exploration.", "code": "import numpy as np\n\nclass AdvancedAdaptiveQuantumLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.7, 'social': 1.2},\n                       {'start': 0.3, 'end': 0.6, 'cognitive': 1.3, 'social': 1.7},\n                       {'start': 0.6, 'end': 0.9, 'cognitive': 1.1, 'social': 1.8},\n                       {'start': 0.9, 'end': 1.0, 'cognitive': 0.9, 'social': 2.1}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            \n            stochastic_perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) +\n                                  stochastic_perturbation)\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm AdvancedAdaptiveQuantumLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09437 with standard deviation 0.00052.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09392888001550626, 0.09408766277922043, 0.09509943106925178]}}
{"id": "3bdefbd2-308f-496e-9f14-41425a8d3582", "fitness": 0.0936148874025446, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Introduce adaptive phase transitions and energy-based mutation for enhanced exploration and convergence in Enhanced Quantum Levy Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.velocity_clamp_factor = 0.1\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n        self.energy_threshold = 0.8\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n\n        cognitive_const, social_const = self.dynamic_phase_switch(progress_factor)\n\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        energy_adjustment = self.energy_based_mutation(progress_factor)\n\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        \n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim) +\n                                  energy_adjustment * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def dynamic_phase_switch(self, progress_factor):\n        if progress_factor < 0.3:\n            return 1.5, 1.3\n        elif progress_factor < 0.7:\n            return 1.2, 1.8\n        else:\n            return 1.0, 2.0\n\n    def energy_based_mutation(self, progress_factor):\n        if progress_factor < self.energy_threshold:\n            return 0.1 * (1 - progress_factor)\n        else:\n            return 0.05 * (progress_factor - self.energy_threshold)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09361 with standard deviation 0.00022.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.0933826465876858, 0.09390802695691258, 0.09355398866303544]}}
{"id": "c72c5362-44e3-485d-b295-43914d4e15eb", "fitness": 0.09433243690991788, "name": "AdaptiveQuantumLevySwarmOptimizerV8", "description": "Adaptive Quantum-Levy Swarm Optimizer with Dynamic Elite Strategy and Enhanced Chaotic Inertia for Optimized Convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.cos(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.02 + 0.005 * progress_factor:\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09433 with standard deviation 0.00081.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09510868717380849, 0.09320784735493726, 0.0946807762010079]}}
{"id": "72cd0109-a8d2-4ab8-b1b2-4af3909f1e6c", "fitness": 0.09298468024628263, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Enhanced exploration and exploitation using adaptive quantum perturbation and elite-driven chaotic mutation in Levy Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.3  # Adjusted for better convergence\n        self.cognitive_const = 1.6  # Slightly increased for better exploration\n        self.social_const = 1.4  # Balanced by reducing social influence\n        self.velocity_clamp_factor = 0.12  # Adjusted for exploration\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.6, 'social': 1.2},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.3, 'social': 1.7},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.1, 'social': 1.9}]\n        self.elite_fraction = 0.15  # Increased elite fraction\n        self.chaos_factor = 0.12  # Enhanced chaotic influence\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.12 * (1 - progress_factor) * diversity  # Adjusted mutation strength\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.25 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.45 * self.velocities[i]  # Refined inertia for non-elites\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.12 - 0.04 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.015 + 0.005 * progress_factor:  # Enhanced diversity and mutation\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09298 with standard deviation 0.00100.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09213840646614913, 0.09438369198700769, 0.09243194228569107]}}
{"id": "5ce6a2da-3e03-43e6-b051-4a955706095c", "fitness": 0.0945293457678676, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Incorporate adaptive quantum-inspired shifts and dual mutation strategy into Enhanced Quantum Levy Swarm Optimization for faster and more robust convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n            # Dual mutation strategy: Add Gaussian mutation for additional diversity\n            if np.random.rand() < 0.1 * (1 - progress_factor):\n                self.positions[i] += 0.05 * np.random.randn(self.dim) * (ub - lb)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09453 with standard deviation 0.00020.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09480978499308113, 0.094408757870442, 0.0943694944400797]}}
{"id": "2203e7cf-6c32-47dd-8b77-310af2617d22", "fitness": 0.09533800213679855, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Enhanced exploration-exploitation balance by introducing adaptive mutation scaling and a refined chaos-induced inertia strategy.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor * 2))  # Refined chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor**2) * diversity  # Adaptive mutation scaling\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor))\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09534 with standard deviation 0.00017.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09556131320288319, 0.09530317127128196, 0.0951495219362305]}}
{"id": "3eba630a-cdd8-4fcf-832f-6c8a1d652749", "fitness": 0.09539005971432017, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Introduced adaptive quantum weight scaling to better balance exploration and exploitation in Levy Flight.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor * 2))  # Adaptive scaling\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09539 with standard deviation 0.00024.", "error": "", "parent_ids": ["3cbbb19a-8d66-4d16-b852-18b6eb97c6fb"], "operator": null, "metadata": {"aucs": [0.09568750291602046, 0.09538427547836825, 0.09509840074857179]}}
{"id": "5b9493c9-8f5e-4545-b22a-bf1a0103d341", "fitness": 0.09379119254230832, "name": "EnhancedQuantumLevySwarmOptimizerV7", "description": "Adjusted the elite fraction to enhance exploration dynamics by modifying the formula for better performance.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.15  # Modified elite fraction for enhanced exploration\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor * 2))  # Adaptive scaling\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                self.positions[i] = np.random.uniform(lb, ub, self.dim)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedQuantumLevySwarmOptimizerV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09379 with standard deviation 0.00174.", "error": "", "parent_ids": ["3eba630a-cdd8-4fcf-832f-6c8a1d652749"], "operator": null, "metadata": {"aucs": [0.09526766065852943, 0.09135134278517176, 0.09475457418322375]}}
{"id": "5e5b153b-6b3b-48e0-9135-865c86c21110", "fitness": -Infinity, "name": "EnhancedQuantumLevySwarmOptimizerV8", "description": "Introduced a novel adaptive multi-phase chaos-driven diversity mechanism to enhance solution convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedQuantumLevySwarmOptimizerV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.positions = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_const = 1.4\n        self.social_const = 1.6\n        self.velocity_clamp_factor = 0.1\n        self.phases = [{'start': 0.0, 'end': 0.3, 'cognitive': 1.5, 'social': 1.3},\n                       {'start': 0.3, 'end': 0.7, 'cognitive': 1.2, 'social': 1.8},\n                       {'start': 0.7, 'end': 1.0, 'cognitive': 1.0, 'social': 2.0}]\n        self.elite_fraction = 0.1\n        self.chaos_factor = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        quantum_range = (ub - lb) / 2\n        self.positions = np.random.uniform(center - quantum_range, center + quantum_range, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-quantum_range, quantum_range, (self.population_size, self.dim))\n        self.best_positions = np.copy(self.positions)\n        self.best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_positions_and_velocities(self, bounds, progress_factor):\n        lb, ub = bounds.lb, bounds.ub\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * (1 - progress_factor) + self.inertia_weight_final\n        inertia_weight *= (1 + self.chaos_factor * np.sin(np.pi * progress_factor))  # Chaos-induced inertia adjustment\n        diversity = np.std(self.positions, axis=0).mean()\n        mutation_strength = 0.1 * (1 - progress_factor) * diversity\n        elite_size = int(self.elite_fraction * self.population_size * (1.0 - progress_factor))\n        if progress_factor > 0.9:\n            elite_size = int(self.elite_fraction * self.population_size * (1.0 + 0.5 * progress_factor))\n        elite_indices = np.argsort(self.best_scores)[:elite_size]\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_const * r1 * (self.best_positions[i] - self.positions[i])\n            social_velocity = self.social_const * r2 * (self.global_best_position - self.positions[i])\n            levy_vel = self.levy_flight(self.dim)\n            quantum_weight = 0.2 * (1 - progress_factor) * (1 + 0.8 * np.sin(np.pi * progress_factor * 2))  # Adaptive scaling\n            if i in elite_indices:\n                inertia_component = inertia_weight * self.velocities[i]\n            else:\n                inertia_component = 0.5 * self.velocities[i]\n            self.velocities[i] = (inertia_component +\n                                  cognitive_velocity + social_velocity +\n                                  quantum_weight * levy_vel +\n                                  mutation_strength * np.random.randn(self.dim))\n            max_velocity = (0.15 - 0.05 * progress_factor) * (ub - lb)\n            self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n            self.positions[i] = np.clip(self.positions[i] + self.velocities[i], lb, ub)\n            if np.random.rand() < 0.01 + 0.005 * progress_factor:  # Enhanced diversity induction\n                chaos_angle = np.pi * (i / self.population_size)\n                self.positions[i] += quantum_weight * np.array([np.sin(chaos_angle), np.cos(chaos_angle)])[:self.dim] * (ub - lb)\n\n    def evaluate_and_update_best(self, func):\n        for i in range(self.population_size):\n            score = func(self.positions[i])\n            if score < self.best_scores[i]:\n                self.best_scores[i] = score\n                self.best_positions[i] = self.positions[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            progress_factor = evaluations / self.budget\n            for phase in self.phases:\n                if phase['start'] <= progress_factor < phase['end']:\n                    self.cognitive_const = phase['cognitive']\n                    self.social_const = phase['social']\n                    break\n            self.update_positions_and_velocities(bounds, progress_factor)\n            self.evaluate_and_update_best(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "configspace": "", "generation": 99, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (2,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (2,) (10,) ')", "parent_ids": ["3eba630a-cdd8-4fcf-832f-6c8a1d652749"], "operator": null, "metadata": {}}
