{"id": "77297fdf-2956-4900-b78a-1ee0af248eef", "fitness": 0.05305086342246712, "name": "AdaptiveParticleSwarmOptimization", "description": "An Adaptive Particle Swarm Optimization (APSO) algorithm that dynamically adjusts its search strategy using feedback from particle diversity and convergence rate to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        c1, c2 = 2.05, 2.05  # Cognitive and social coefficients\n        w = 0.5  # initial inertia weight\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.00495.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05605981198735288, 0.058195907362013966, 0.054917860750959835, 0.046019093715074844, 0.04775305105332717, 0.04509867050593186, 0.056139217834515476, 0.058278850434921314, 0.05499530715810674]}}
{"id": "cb44f61d-2c7c-449e-b935-b11b4eeea5a6", "fitness": 0.05318041527143026, "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Enhanced Adaptive Particle Swarm Optimization (EAPSO) integrates adaptive inertia weight and dynamic social/cognitive factors based on swarm diversity and convergence rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05318 with standard deviation 0.00492.", "error": "", "parent_ids": ["77297fdf-2956-4900-b78a-1ee0af248eef"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.0554021110430033, 0.04596060219348774, 0.04775305105332717, 0.04549737584197222, 0.05606741430860951, 0.058278850434921314, 0.05548030099408474]}}
{"id": "a9156ce0-df1b-4139-9702-26a0c3191fe1", "fitness": 0.052930835654598524, "name": "DiversifiedEnhancedParticleSwarmOptimization", "description": "The Diversified Enhanced Particle Swarm Optimization (DEPSO) incorporates strategic diversity enhancement through random reinitialization of stagnated particles and adaptive parameter tuning to improve exploration and convergence for black box optimization.", "code": "import numpy as np\n\nclass DiversifiedEnhancedParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        reinit_prob = 0.1  # Probability of reinitialization for stagnant particles\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        stagnation_counts = np.zeros(num_particles)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    stagnation_counts[i] = 0  # Reset stagnation counter\n                else:\n                    stagnation_counts[i] += 1\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Reinitialize stagnated particles with a probability\n            for i in range(num_particles):\n                if np.random.rand() < reinit_prob * stagnation_counts[i] / self.budget:\n                    positions[i] = np.random.uniform(lb, ub, self.dim)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                    stagnation_counts[i] = 0\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm DiversifiedEnhancedParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05293 with standard deviation 0.00497.", "error": "", "parent_ids": ["cb44f61d-2c7c-449e-b935-b11b4eeea5a6"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.05460673533258731, 0.04596060219348774, 0.04775305105332717, 0.0448431386376964, 0.05606741430860951, 0.058278850434921314, 0.05468369735729095]}}
{"id": "81a308fb-d5a3-446f-8cbd-cfe7903c1769", "fitness": 0.05318041527143026, "name": "EnhancedMultiStrategyParticleSwarmOptimization", "description": "Enhanced Multi-Strategy Particle Swarm Optimization (EMSPSO) employs adaptive inertia weight, diversity-based cognitive/social coefficients, and periodic reinitialization to enhance exploration-exploitation balance and avoid local optima.", "code": "import numpy as np\n\nclass EnhancedMultiStrategyParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        reinit_frequency = 0.3  # Percentage of budget after which to consider reinitialization\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n            # Periodic reinitialization of a subset of particles\n            if evaluations / self.budget > reinit_frequency:\n                worst_indices = np.argsort(personal_best_scores)[-int(num_particles * 0.1):]\n                positions[worst_indices] = np.random.uniform(lb, ub, (len(worst_indices), self.dim))\n                velocities[worst_indices] = np.random.uniform(-1, 1, (len(worst_indices), self.dim))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedMultiStrategyParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05318 with standard deviation 0.00492.", "error": "", "parent_ids": ["cb44f61d-2c7c-449e-b935-b11b4eeea5a6"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.0554021110430033, 0.04596060219348774, 0.04775305105332717, 0.04549737584197222, 0.05606741430860951, 0.058278850434921314, 0.05548030099408474]}}
{"id": "c23f3174-0406-418b-bfd1-baf9983e1d05", "fitness": 0.05351456302749363, "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Enhanced Dynamic Particle Swarm Optimization (EDPSO) incorporates improved particle velocity updates with non-linear inertia weight reduction for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05351 with standard deviation 0.00491.", "error": "", "parent_ids": ["cb44f61d-2c7c-449e-b935-b11b4eeea5a6"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.05647076487888214, 0.04596060219348774, 0.04775305105332717, 0.04636563252296755, 0.05606741430860951, 0.058278850434921314, 0.056550720281780875]}}
{"id": "49093879-33f6-4faf-9e9b-06a329437432", "fitness": 0.05331367144291769, "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Slightly modify the random factors to potentially improve convergence by enhancing exploration.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim) * 1.1, np.random.rand(num_particles, self.dim) * 1.1 # Slightly modified line\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05331 with standard deviation 0.00491.", "error": "", "parent_ids": ["c23f3174-0406-418b-bfd1-baf9983e1d05"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.05582891492769693, 0.04596060219348774, 0.04775305105332717, 0.04584234949475485, 0.05606741430860951, 0.058278850434921314, 0.05590782899999536]}}
{"id": "e3d36541-bb5c-43c3-850b-00de78b34e41", "fitness": 0.053395118416467505, "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Refined velocity update by introducing a momentum term to improve convergence stability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        momentum = 0.2  # Introduce a momentum term\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (momentum * velocities +  # Apply momentum to velocity update\n                          w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05340 with standard deviation 0.00491.", "error": "", "parent_ids": ["c23f3174-0406-418b-bfd1-baf9983e1d05"], "operator": null, "metadata": {"aucs": [0.056020335689644485, 0.058195907362013966, 0.056055602305963625, 0.04598688360116909, 0.04775305105332717, 0.046030913759134484, 0.056099677803184145, 0.058278850434921314, 0.05613484373884925]}}
{"id": "f3a16fc9-25b0-43bb-866a-3d97feeccdee", "fitness": -Infinity, "name": "EnhancedAdaptiveParticleSwarmOptimization", "description": "Enhanced Dynamic Particle Swarm Optimization (EDPSO) with adaptive population size based on diversity for efficient convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n            \n            # Adjust number of particles based on diversity\n            num_particles = int(50 * (1 + diversity / (ub - lb).mean()))\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (94,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (94,10) (50,10) ')", "parent_ids": ["c23f3174-0406-418b-bfd1-baf9983e1d05"], "operator": null, "metadata": {}}
{"id": "079ec53e-a38a-4d0d-ae21-63955a033d6f", "fitness": 0.05380669987170959, "name": "QuantumInspiredParticleSwarmOptimization", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) incorporates quantum-inspired particle updates with adaptive learning coefficients for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Quantum-inspired update for positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05381 with standard deviation 0.00495.", "error": "", "parent_ids": ["c23f3174-0406-418b-bfd1-baf9983e1d05"], "operator": null, "metadata": {"aucs": [0.05759922465245393, 0.058195907362013966, 0.055794574608514114, 0.0472668482875892, 0.04775305105332717, 0.04581723431324758, 0.057681206081399816, 0.058278850434921314, 0.05587340205191926]}}
{"id": "ad51bf93-9cfb-4d7d-9195-ed6eb7b2947a", "fitness": 0.05332822290867483, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO) integrates adaptive quantum potential and chaotic factor perturbations for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Quantum-inspired update with adaptive quantum potential\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            # Introduce chaotic perturbation to enhance exploration\n            chaos = 0.5 * (np.random.rand(num_particles, self.dim) - 0.5)\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position + chaos)\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05333 with standard deviation 0.00491.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.055873870186268104, 0.04596060219348774, 0.04775305105332717, 0.045883376167918044, 0.05606741430860951, 0.058278850434921314, 0.05595281026007526]}}
{"id": "7417c9b9-cfff-4c86-8989-097654e917be", "fitness": 0.05339337252405279, "name": "AdaptiveQuantumInspiredParticleSwarmOptimization", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) enhances solution diversity and convergence by integrating adaptive diversity control and chaos-based perturbation into quantum-inspired updates.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        beta = 0.5  # Chaos control parameter\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Chaos-based perturbation\n            chaos_sequence = np.random.rand(num_particles, self.dim)\n            chaos_perturbation = beta * (chaos_sequence - 0.5)\n\n            # Quantum-inspired update for positions with chaos perturbation\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position) + chaos_perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05339 with standard deviation 0.00508.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.05772742090574701, 0.058195907362013966, 0.054348504208964865, 0.04737107943878849, 0.04775305105332717, 0.04463085989558091, 0.057809613283427264, 0.058278850434921314, 0.054425066133704125]}}
{"id": "d9603d3d-0924-45f2-ac3c-318afef45a12", "fitness": 0.05321058901215842, "name": "AdaptiveQuantumInspiredParticleSwarmOptimization", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) enhances convergence by introducing time-varying quantum factors and adaptive inertia based on particle clustering behavior.", "code": "import numpy as np\nfrom scipy.spatial.distance import cdist\n\nclass AdaptiveQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate clustering-based diversity\n            diversity = np.mean(np.min(cdist(positions, positions), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (diversity / (ub - lb).mean())\n\n            # Quantum-inspired update for positions with time-varying quantum factor\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim)) * (1 - evaluations / self.budget)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05321 with standard deviation 0.00492.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.05604639601840844, 0.058195907362013966, 0.05544089093668969, 0.046008108252406754, 0.04775305105332717, 0.04552715299781085, 0.056125780625171484, 0.058278850434921314, 0.05551916342867613]}}
{"id": "9991a6d2-7319-48c2-ad4e-71109272ff48", "fitness": 0.05349213414459223, "name": "AdaptiveQuantumInspiredParticleSwarmOptimization", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) augments exploration and convergence by integrating adaptive quantum factors and dynamically adjusted coefficients based on population diversity and convergence trends.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Enhanced Quantum-inspired update for positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.7, 1.3, (num_particles, self.dim)) * (1.0 - (evaluations / self.budget))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05349 with standard deviation 0.00506.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.056980386861863686, 0.05880171418116609, 0.05480437640870195, 0.04676594122988886, 0.04824219835872523, 0.04500593223175964, 0.05706132540725828, 0.058885691415590746, 0.05488164120637562]}}
{"id": "0c080e07-2601-4fe4-a256-94eb9123e8d0", "fitness": 0.053427996383859276, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO) introduces adaptive diversity-based reinitialization and dynamic quantum factors for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        diversity_threshold = 0.1  # Threshold for reinitialization\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Quantum-inspired update for positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim)) * (1 + diversity / (ub - lb).mean())\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n            # Diversity-based reinitialization\n            if diversity < diversity_threshold:\n                positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n                velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05343 with standard deviation 0.00540.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.06029159805390394, 0.054109132640998925, 0.04596060219348774, 0.049438008499913866, 0.04443356007829602, 0.05606741430860951, 0.06037819818003254, 0.05418532928803854]}}
{"id": "5cd67ddf-4e8f-43e6-9ae9-85fce65b186d", "fitness": 0.05380669987170959, "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive Particle Swarm Optimizer (QEAPSO) leverages adaptive quantum particle updates with nonlinear diversity control and mutation strategy for robust exploration and convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n        mutation_probability = 0.1\n        mutation_scale = 0.1\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n            \n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - diversity / (ub - lb).mean())\n\n            # Quantum-inspired update for positions\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n            # Apply mutation to introduce robustness\n            for i in range(num_particles):\n                if np.random.rand() < mutation_probability:\n                    mutation_vector = mutation_scale * (ub - lb) * np.random.randn(self.dim)\n                    positions[i] += mutation_vector\n                    positions[i] = np.clip(positions[i], lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05381 with standard deviation 0.00495.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.05759922465245393, 0.058195907362013966, 0.055794574608514114, 0.0472668482875892, 0.04775305105332717, 0.04581723431324758, 0.057681206081399816, 0.058278850434921314, 0.05587340205191926]}}
{"id": "034595b9-48a4-417b-bc78-e6ec99c740a2", "fitness": 0.05380679083804632, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO) uses adaptive chaos-driven perturbations and a self-adaptive learning mechanism to improve exploration and exploitational balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.5 + 0.5 * np.sin(3.14 * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05381 with standard deviation 0.00495.", "error": "", "parent_ids": ["079ec53e-a38a-4d0d-ae21-63955a033d6f"], "operator": null, "metadata": {"aucs": [0.057600008835548944, 0.058195907362013966, 0.05579408379942419, 0.04726747977366552, 0.04775305105332717, 0.04581683421536087, 0.057681991621722384, 0.058278850434921314, 0.0558729104464325]}}
{"id": "52ab4c4e-d4b4-4c01-8aef-d326c535ebd3", "fitness": 0.05335257336566858, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "The Enhanced Quantum-Inspired Particle Swarm Optimization algorithm integrates adaptive inertia and mutation based on Lvy flights to enhance exploration capabilities and convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.5 + 0.5 * np.sin(3.14 * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n\n            # Integrate Lvy flights for enhanced exploration\n            levy_flights = self.levy_flight(positions, global_best_position, lb, ub)\n            positions += quantum_factor * perturbation + levy_flights\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score\n\n    def levy_flight(self, positions, global_best_position, lb, ub):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n\n        u = np.random.normal(0, sigma, positions.shape)\n        v = np.random.normal(0, 1, positions.shape)\n        step = u / np.abs(v)**(1 / beta)\n\n        step_size = 0.01 * (positions - global_best_position)\n        return step_size * step", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05335 with standard deviation 0.00491.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.05595243603511524, 0.04596060219348774, 0.04775305105332717, 0.045945247859681904, 0.05606741430860951, 0.058278850434921314, 0.056031526832407974]}}
{"id": "2bfb0966-705a-4cf5-82ad-a0e1ceadcfcb", "fitness": 0.05380679083804632, "name": "EnhancedQuantumInspiredParticleSwarmOptimizationPlus", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO+) introduces adaptive random restarts and diversity-based velocity updates to further balance exploration and exploitation, enhancing convergence on diverse problem landscapes.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        restart_threshold = self.budget * 0.1\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight using non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.5 + 0.5 * np.sin(3.14 * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n\n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions) +\n                          np.random.uniform(-0.1, 0.1, (num_particles, self.dim)) * (diversity / (ub - lb).mean()))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Adaptive random restart\n            if evaluations % restart_threshold == 0 and diversity < 0.1:\n                restart_indices = np.random.choice(num_particles, num_particles // 5, replace=False)\n                positions[restart_indices] = np.random.uniform(lb, ub, (len(restart_indices), self.dim))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05381 with standard deviation 0.00495.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.057600008835548944, 0.058195907362013966, 0.05579408379942419, 0.04726747977366552, 0.04775305105332717, 0.04581683421536087, 0.057681991621722384, 0.058278850434921314, 0.0558729104464325]}}
{"id": "015a48b9-c004-4fe7-8eab-bcdf91bdae50", "fitness": 0.05371999403237667, "name": "QuantumEnhancedParticleSwarmOptimization", "description": "Quantum-Enhanced Particle Swarm Optimization with Adaptive Hyperparameters (QEPSO-AH) leverages an adaptive quantum factor and dynamic hyperparameter tuning for improved convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Adaptive quantum factor based on evaluations\n            quantum_factor = 0.5 + (1.5 - 0.5) * (1 - (evaluations / self.budget)**2)\n            \n            # Self-adaptive learning\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm QuantumEnhancedParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05372 with standard deviation 0.00492.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.057130251170871005, 0.04596060219348774, 0.04775305105332717, 0.046894372590547295, 0.05606741430860951, 0.058278850434921314, 0.057211372966159635]}}
{"id": "6ba98471-f2e6-493e-b197-844ad48093b1", "fitness": 0.053563970758704685, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Refined EQIPSO with increased perturbation randomness for improved exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.5 + 0.5 * np.sin(3.14 * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += np.random.uniform(0.5, 1.5, (num_particles, self.dim)) * perturbation  # Increased randomness\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05356 with standard deviation 0.00508.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.058035047233542136, 0.058195907362013966, 0.0545886842864326, 0.04761170679103255, 0.04775305105332717, 0.044829028623767364, 0.05811785045974427, 0.058278850434921314, 0.054665610583560786]}}
{"id": "25cb36ef-fe37-47a3-958e-c5909176c714", "fitness": 0.05380677274884868, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO) is refined with adaptive chaos dynamics and non-linear velocity scaling for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.6)  # Adjust line\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.6 + 0.4 * np.sin(3.14 * evaluations / self.budget)  # Adjust line\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05381 with standard deviation 0.00495.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.05759985205910123, 0.058195907362013966, 0.05579418223362642, 0.04726735352524569, 0.04775305105332717, 0.04581691445711544, 0.05768183457392839, 0.058278850434921314, 0.05587300904035852]}}
{"id": "c77172ef-887c-4925-b09b-71e0b40a4e5c", "fitness": 0.05334823046661182, "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Adaptive Quantum Particle Swarm Optimization (AQPSO) utilizes a nonlinear dynamic inertia weight strategy, enhanced chaotic perturbations, and a variable neighborhood search to accelerate convergence and improve solution quality.", "code": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((1 - evaluations / self.budget) ** 2)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            chaos_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            neighborhood_search = np.random.uniform(-0.1, 0.1, (num_particles, self.dim))\n            \n            positions += quantum_factor * perturbation + neighborhood_search\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05335 with standard deviation 0.00493.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.05651632858152167, 0.058195907362013966, 0.05541235150907198, 0.04638709317807832, 0.04775305105332717, 0.04550338861436354, 0.0565965204987553, 0.058278850434921314, 0.05549058296745313]}}
{"id": "d458de6a-ea93-484d-9f2f-bd344c90acc7", "fitness": 0.052774663507905065, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "A refined Enhanced Quantum-Inspired Particle Swarm Optimization (EQIPSO) incorporating dynamic diversity-driven adjustments with a refined quantum factor for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Chaos-driven perturbation\n            chaos_factor = 0.5 + 0.5 * np.sin(3.14 * evaluations / self.budget)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.6, 1.4, (num_particles, self.dim))  # Modified line\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = chaos_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05277 with standard deviation 0.00501.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.058195907362013966, 0.054109132640998925, 0.04596060219348774, 0.04775305105332717, 0.04443356007829602, 0.05606741430860951, 0.058278850434921314, 0.05418532928803854]}}
{"id": "5ae8dd46-4c3b-484e-9fd0-f91af4805217", "fitness": 0.05810706973379222, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improved initialization and convergence strategy by incorporating Gaussian perturbation and adaptive convergence checking.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.00540.", "error": "", "parent_ids": ["034595b9-48a4-417b-bc78-e6ec99c740a2"], "operator": null, "metadata": {"aucs": [0.06168482680110832, 0.060273327114491626, 0.06338930946487564, 0.05059777789963704, 0.049432205405762764, 0.05197205298828966, 0.061773441004163154, 0.060359823171001636, 0.06348086375480011]}}
{"id": "6d3b01a7-ae47-4a9c-af34-c84eddbff077", "fitness": -Infinity, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced convergence through dynamic particle allocation based on past performance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Dynamically adjust number of particles based on global convergence\n            num_particles = max(10, min(100, int(50 + 50 * (1 - global_best_score / np.max(personal_best_scores)))))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {}}
{"id": "8aa40d30-5887-46ce-b70a-3be37886d734", "fitness": 0.05810706973379222, "name": "AdaptiveInertiaQIPSO", "description": "Introduce a multi-phase adaptive inertia weight and exploratory mechanism to enhance convergence and diversity management in Quantum-Inspired Particle Swarm Optimization.", "code": "import numpy as np\n\nclass AdaptiveInertiaQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.2, 0.2  # Increased range for more flexibility\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and control inertia weight with a multi-phase strategy\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            phase = evaluations / self.budget\n            if phase < 0.5:\n                w = max_w - (max_w - min_w) * ((phase / 0.5) ** 0.5)  # Aggressive decrease\n            else:\n                w = min_w + (max_w - min_w) * ((phase - 0.5) / 0.5)  # Recovery phase\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveInertiaQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.00540.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.06168482680110832, 0.060273327114491626, 0.06338930946487564, 0.05059777789963704, 0.049432205405762764, 0.05197205298828966, 0.061773441004163154, 0.060359823171001636, 0.06348086375480011]}}
{"id": "abd5573b-9b17-4d03-8032-05749dab23dd", "fitness": 0.057178381529221584, "name": "ImprovedParticleSwarmOptimizationWithLevyFlight", "description": "Integrate Levy flight for enhanced exploration and incorporate adaptive Gaussian mutation for improved exploitation.", "code": "import numpy as np\n\nclass ImprovedParticleSwarmOptimizationWithLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) / \n                    (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, self.dim)\n            v = np.random.normal(0, sigma2, self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            levy_steps = np.array([levy_flight(1.5) for _ in range(num_particles)])\n            adaptive_mutation = np.random.normal(0, 0.1 / (1 + evaluations/self.budget), (num_particles, self.dim))\n\n            positions += velocities + levy_steps * adaptive_mutation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm ImprovedParticleSwarmOptimizationWithLevyFlight got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00557.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057970801885530276, 0.06338930946487564, 0.05005018657943394, 0.04759909180529087, 0.05197205298828966, 0.06108872676156096, 0.058053073643802855, 0.06348086375480011]}}
{"id": "0a30d181-4bce-41c4-8450-49ef65de9e68", "fitness": 0.05425510741856343, "name": "EnhancedLevyInspiredPSO", "description": "Introducing Lvy flights for enhanced exploration and adaptive neighborhood radius to balance exploration and exploitation in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedLevyInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities\n        positions = np.random.rand(num_particles, self.dim) * (ub - lb) + lb\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, size=self.dim)\n            v = np.random.normal(0, sigma2, size=self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return 0.01 * step\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Lvy flight perturbation for exploration\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            levy_step = levy_flight(1.5)\n            positions += velocities + levy_step\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedLevyInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05426 with standard deviation 0.00508.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.05736256064214995, 0.059574337981354586, 0.05609251299864615, 0.04706957498221587, 0.0488642361253554, 0.046057026747769236, 0.05744420618848267, 0.05965965407852214, 0.05617185702257488]}}
{"id": "aed0850a-48c9-478a-a364-ea636f13df40", "fitness": 0.05810706973379222, "name": "AdvancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced dynamic adaptation and learning strategies by introducing a self-adaptive mutation operator and elite learning mechanism to improve global and local exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation with elite learning\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning with mutation\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            mutation = np.random.normal(0, 0.1, (num_particles, self.dim))\n            velocities += mutation * np.sign(velocities)\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm AdvancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.00540.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.06168482680110832, 0.060273327114491626, 0.06338930946487564, 0.05059777789963704, 0.049432205405762764, 0.05197205298828966, 0.061773441004163154, 0.060359823171001636, 0.06348086375480011]}}
{"id": "4fc6c768-15bd-411a-ab20-6b3459cdede6", "fitness": 0.05734327311734276, "name": "AdaptiveQuantumParticleSwarm", "description": "Introduce adaptive quantum particles with diversity-based mutation and reinforcement learning inspired update mechanisms for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Applied reinforcement learning-inspired update for diversity maintenance\n            exploration_factor = 0.5 + 0.5 * np.tanh(diversity)\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            \n            # Adaptive quantum factor based on current evaluations\n            quantum_factor = np.clip(1 + np.log(1 + evaluations / self.budget), 0.5, 2.0)\n\n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            # Diversity-based mutation\n            mutation_factor = exploration_factor * np.random.normal(0, 0.1, (num_particles, self.dim))\n            mutation = mutation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n\n            positions += quantum_factor * mutation\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveQuantumParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05734 with standard deviation 0.00562.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.06120009911330815, 0.05803283189496422, 0.06365818430085357, 0.05021003807693358, 0.04764948153669446, 0.05218553348054811, 0.061287845408522945, 0.05811520620916111, 0.06375023803509872]}}
{"id": "306398cd-3230-4e94-b552-602b3168d38f", "fitness": 0.05810706973379222, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhanced learning mechanism by introducing a mutation strategy on global best for improved diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Mutation strategy for global best\n            mutation = np.random.normal(0, 0.1, self.dim) \n            global_best_position = np.clip(global_best_position + mutation, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.00540.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.06168482680110832, 0.060273327114491626, 0.06338930946487564, 0.05059777789963704, 0.049432205405762764, 0.05197205298828966, 0.061773441004163154, 0.060359823171001636, 0.06348086375480011]}}
{"id": "4c4b51a0-af08-4e59-bf4c-86f8c76a64d0", "fitness": 0.05740260001315277, "name": "EnhancedHybridQuantumInspiredPSO", "description": "Introduce a hybrid adaptive levy-flight-based exploration to enhance global search efficiency and maintain diversity.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Initialize particles' positions and velocities with Gaussian distribution\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        def levy_flight(Lambda):\n            # Levy flight implementation\n            sigma_u = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                       (np.math.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.normal(0, sigma_u, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            # Calculate diversity and adapt inertia weight with non-linear reduction\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Gaussian-driven perturbation\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            # Self-adaptive learning and levy flight for exploration\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            levy_steps = np.array([levy_flight(1.5) for _ in range(num_particles)])\n            \n            exploration_update = quantum_factor * perturbation + levy_steps\n            positions += exploration_update\n            positions = np.clip(positions, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05740 with standard deviation 0.00561.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.06172199038151893, 0.057970801885530276, 0.06338930946487564, 0.05062552273323051, 0.04759909180529087, 0.05197205298828966, 0.06181069346103607, 0.058053073643802855, 0.06348086375480011]}}
{"id": "2f869a47-a214-42f4-ab0b-a3438f949f9e", "fitness": 0.05903148341848151, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Incorporate Lvy flight and adaptive inertia for enhanced exploration-exploitation balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05903 with standard deviation 0.00557.", "error": "", "parent_ids": ["5ae8dd46-4c3b-484e-9fd0-f91af4805217"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.060570298263751265, 0.06341622291378501, 0.05270024285960029, 0.049662382587872256, 0.05199348250389657, 0.06443455318284674, 0.06065741136249936, 0.0635078265053538]}}
{"id": "f98449ce-bd0e-4062-8dda-1b8c70c052df", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a dynamic quantum factor based on convergence rate for adaptive exploration in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for dynamic quantum factor\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["2f869a47-a214-42f4-ab0b-a3438f949f9e"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "2947b542-8e3f-4d7f-85b2-9f81107df131", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a self-adaptive control mechanism for dynamically tuning inertia weight and acceleration coefficients based on population diversity to enhance convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            diversity_factor = diversity / (ub - lb).mean()\n\n            # Self-adaptive inertia weight\n            w = max_w - (max_w - min_w) * (diversity_factor ** (1.0 / 3))\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - diversity_factor)\n            c2 = max_c2 - (max_c2 - min_c2) * diversity_factor\n            \n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Enhanced dynamic quantum factor\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.clip(np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim)), 0.5, 1.5)\n\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "ca2cf6a5-7772-4b5a-8b3b-4b6a2aac435f", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance the balance between exploration and exploitation by introducing adaptive inertia weight scaling based on swarm diversity and convergence rate to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3.0))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Adaptive inertia weight adjustment based on diversity\n            inertia_scaling = 1 + 0.5 * np.tanh((diversity / self.dim) - 1)\n            velocities *= inertia_scaling\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "861f9996-3bd7-4724-a33a-3bfaa22b5646", "fitness": 0.05755031189512025, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight and hybrid crossover-mutation strategy to enhance diversity and convergence in quantum-inspired particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget) ** 2\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Hybrid crossover-mutation\n            crossover_rate = 0.7\n            mutation_rate = 0.1\n            for i in range(num_particles):\n                if np.random.rand() < crossover_rate:\n                    partner_idx = np.random.randint(num_particles)\n                    crossover_mask = np.random.rand(self.dim) < 0.5\n                    positions[i][crossover_mask] = positions[partner_idx][crossover_mask]\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation_vector\n                    positions[i] = np.clip(positions[i], lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05755 with standard deviation 0.00579.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.05798133912052772, 0.06457666325624212, 0.05005018657943394, 0.04760766742088762, 0.05291282338836456, 0.06108872676156096, 0.05806362812938948, 0.0646704455202659]}}
{"id": "f5446afa-e770-4040-8eb1-2095d6965091", "fitness": 0.05730680168365179, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a random inertia weight scaling factor for enhanced dynamic adaptability in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for random inertia weight scaling factor\n            random_w_scale = np.random.uniform(0.8, 1.2)\n            quantum_factor = np.random.uniform(0.5, 1.5 * ((self.budget - evaluations) / self.budget), (num_particles, self.dim))\n\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += random_w_scale * quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05731 with standard deviation 0.00552.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.05838242506611835, 0.06338930946487564, 0.05005018657943394, 0.04793091822071882, 0.05197205298828966, 0.06108872676156096, 0.05846540543765866, 0.06348086375480011]}}
{"id": "89dec4ff-0067-48e4-8574-b74d581e13c5", "fitness": 0.05753752163820089, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce dynamic memory and adaptive perturbation based on population diversity for enhanced adaptive exploration in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        # Dynamic memory for adaptive exploration\n        memory_positions = np.copy(positions)\n        memory_scores = np.full(num_particles, np.inf)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                    \n                # Update memory positions\n                if score < memory_scores[i]:\n                    memory_scores[i] = score\n                    memory_positions[i] = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            # Adaptive perturbation based on diversity\n            adaptive_perturbation = perturbation_factor * (1 + diversity / (ub - lb).mean())\n            perturbation = adaptive_perturbation * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n            \n            # Lvy flight perturbation with dynamic memory\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * 0.01 * (memory_positions - positions) + adaptive_perturbation * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00545.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.0591202589980202, 0.06338930946487564, 0.05005018657943394, 0.04853051265561792, 0.05197205298828966, 0.06108872676156096, 0.05920445666179963, 0.06348086375480011]}}
{"id": "fcac0485-cca6-4808-9ce5-505398f8a849", "fitness": 0.05787128967754689, "name": "EnhancedOppositionQuantumInspiredPSO", "description": "Integrate opposition-based learning into the particle swarm to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedOppositionQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        def opposition_position(pos, lb, ub):\n            return lb + ub - pos\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Dynamic quantum factor based on convergence rate\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Opposition-based learning component\n            opposite_positions = opposition_position(positions, lb, ub)\n            opposite_scores = np.array([func(op) for op in opposite_positions])\n            evaluations += num_particles\n\n            for i in range(num_particles):\n                if opposite_scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = opposite_scores[i]\n                    personal_best_positions[i] = opposite_positions[i]\n                if opposite_scores[i] < global_best_score:\n                    global_best_score = opposite_scores[i]\n                    global_best_position = opposite_positions[i]\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedOppositionQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05787 with standard deviation 0.00542.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06147690111993942, 0.05971701034058141, 0.06338930946487564, 0.05042946951800986, 0.04900856607992765, 0.05197205298828966, 0.06156516539507639, 0.05980226843642189, 0.06348086375480011]}}
{"id": "61ecc188-d438-4d8d-9382-a75203f0b3e2", "fitness": 0.05829692598713311, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight and hybrid local-global search to enhance convergence and exploration balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((1 - evaluations / self.budget) ** (1.0 / 2))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Adaptive quantum factor based on convergence rate\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = 1.0 + convergence_rate * np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Hybrid local-global search with Lvy flight\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01 * convergence_rate\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05830 with standard deviation 0.00584.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06299080659990708, 0.05834948678437346, 0.06462065847691478, 0.051638203287112217, 0.0479046040254556, 0.052939744426291346, 0.0630818071635878, 0.05843240780374925, 0.06471461531680645]}}
{"id": "cea8c270-be30-465c-8e43-838c611fa834", "fitness": 0.058189848582573395, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Modify the random perturbation factor to adapt dynamically to the diversity of the swarm for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            # Modified line for dynamic perturbation factor\n            perturbation_factor = np.random.normal(0, diversity / (ub - lb).mean(), (num_particles, self.dim))\n            \n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05819 with standard deviation 0.00612.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061609787442190034, 0.057970801885530276, 0.066042806834397, 0.05053856162664505, 0.04759909180529087, 0.054056709380053025, 0.06169825824348718, 0.058053073643802855, 0.06613954638176422]}}
{"id": "e240d431-8475-4457-a662-ce118ad3a358", "fitness": 0.059139888852519716, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive Levy flight perturbation and momentum-based dynamic update for enhanced exploration and exploitation in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        momentum = 0.9\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (momentum * velocities +\n                          w * (c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions)))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            adaptive_levy_factor = 0.01 * (1 + evaluations / self.budget)\n            positions += levy * perturbation_factor * adaptive_levy_factor\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05914 with standard deviation 0.00538.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06299294942728972, 0.062281460607640615, 0.06338930946487564, 0.05163989906914179, 0.051047053530677955, 0.05197205298828966, 0.06308395403491118, 0.06237145679505074, 0.06348086375480011]}}
{"id": "24054853-3b56-4533-b4bb-73ca6d8454f0", "fitness": -Infinity, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight based on personal best improvement to enhance convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for adaptive inertia weight based on improvement\n            w = max_w - (max_w - min_w) * ((np.min(personal_best_scores) / global_best_score) ** (1.0 / 3))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "An exception occurred: NameError(\"name 'quantum_factor' is not defined\").", "error": "NameError(\"name 'quantum_factor' is not defined\")", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {}}
{"id": "eb073130-9acf-4170-8fe2-5134f32f3a3a", "fitness": 0.053376214512019175, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight and multi-swarm strategy to enhance exploration and exploitation balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        num_swarms = 3\n        swarm_size = num_particles // num_swarms\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Multi-swarm strategy\n            for s in range(num_swarms):\n                swarm_slice = slice(s * swarm_size, (s + 1) * swarm_size)\n                velocities[swarm_slice] = (\n                    w * velocities[swarm_slice] +\n                    c1 * r1[swarm_slice] * (personal_best_positions[swarm_slice] - positions[swarm_slice]) +\n                    c2 * r2[swarm_slice] * (global_best_position - positions[swarm_slice])\n                )\n                perturbation = perturbation_factor[swarm_slice] * np.sign(velocities[swarm_slice]) * np.abs(positions[swarm_slice] - global_best_position)\n                quantum_factor = np.random.uniform(0.5, 1.5, (swarm_size, self.dim))\n                positions[swarm_slice] += quantum_factor * perturbation\n                positions[swarm_slice] = np.clip(positions[swarm_slice], lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05338 with standard deviation 0.00495.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.05629978980974348, 0.058398553041185464, 0.05551585319791352, 0.046214474372671344, 0.04791726581524014, 0.04558428075704857, 0.056379587691716915, 0.05848183554449027, 0.05559429037816288]}}
{"id": "c00aa8c1-7779-4cde-aea8-519d536fc34e", "fitness": 0.05850145196729658, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Adjust quantum factor to be directly influenced by both convergence rate and diversity for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Refined dynamic quantum factor\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate * np.exp(-diversity), (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05850 with standard deviation 0.00576.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.05885993535627987, 0.06341622291378501, 0.05270024285960029, 0.04831613914128152, 0.05199348250389657, 0.06443455318284674, 0.058943734655897084, 0.0635078265053538]}}
{"id": "5ec2e100-6f90-4b45-8b6d-7d9eb5efa35c", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight adjustment based on particle convergence to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for dynamic quantum factor\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            # Updated adaptive inertia weight adjustment\n            w = min_w + (max_w - min_w) * (1 - convergence_rate)\n\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "beb0cd57-2483-472c-a6e9-95b030506bd4", "fitness": 0.05907075479115287, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive scaling for Lvy flight perturbation to improve exploration capabilities dynamically.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for dynamic quantum factor\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Adjusted line for adaptive scaling of Lvy flight\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01 * (1 - convergence_rate)\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05907 with standard deviation 0.00538.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06299080659990708, 0.06206044028454727, 0.06338930946487564, 0.051638203287112217, 0.05087330359204689, 0.05197205298828966, 0.0630818071635878, 0.062150005985209145, 0.06348086375480011]}}
{"id": "0c512d19-31ea-4b89-a4d7-3541fcdf9b71", "fitness": 0.059139888852519716, "name": "RefinedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive learning rates and a mutation mechanism based on evolution strategy principles to enhance convergence stability and precision.", "code": "import numpy as np\n\nclass RefinedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with adaptive scale\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            levy_scale = 0.01 * (1 + evaluations / self.budget)\n            positions += levy * perturbation_factor * levy_scale\n            \n            # Mutation step based on Evolution Strategy\n            if evaluations / self.budget > 0.5:\n                mutation_strength = (ub - lb) * 0.1 * (1 - evaluations / self.budget)\n                mutations = np.random.normal(0, mutation_strength, (num_particles, self.dim))\n                positions += mutations\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05914 with standard deviation 0.00538.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06299294942728972, 0.062281460607640615, 0.06338930946487564, 0.05163989906914179, 0.051047053530677955, 0.05197205298828966, 0.06308395403491118, 0.06237145679505074, 0.06348086375480011]}}
{"id": "81f98d9a-591c-4ebb-a563-2ed72712734c", "fitness": 0.058192499205306954, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive velocity scaling and enhanced Lvy flight using a dynamically adjusted scaling factor based on performance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            scaling_factor = np.maximum(0.01, convergence_rate * (global_best_score / (personal_best_scores.mean() + 1e-9)))\n            positions += scaling_factor * quantum_factor * perturbation  # Changed line\n\n            positions = np.clip(positions, lb, ub)\n\n            # Enhanced Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.1 * scaling_factor  # Changed line\n         \n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05819 with standard deviation 0.00527.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06130699861715927, 0.05834885914184407, 0.06338930946487564, 0.0533393585466585, 0.04792205677938999, 0.05390223557342477, 0.06138213190700381, 0.05846652655421747, 0.06567501626318906]}}
{"id": "baba8b05-4eb8-40bd-b316-9f57d8724584", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight based on particle's historical performance to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * np.mean(personal_best_scores) / np.mean([max(personal_best_scores), 1.0]) # Adaptive inertia weight\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "844a48b0-eeb0-4288-90f5-76e56b51abfe", "fitness": 0.05907075479115287, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a decay factor to the Lvy flight perturbation for more controlled exploration as evaluations progress.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Modified line for decay factor in Lvy flight\n            levy_decay = (self.budget - evaluations) / self.budget\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01 * levy_decay\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05907 with standard deviation 0.00538.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06299080659990708, 0.06206044028454727, 0.06338930946487564, 0.051638203287112217, 0.05087330359204689, 0.05197205298828966, 0.0630818071635878, 0.062150005985209145, 0.06348086375480011]}}
{"id": "64509db1-fc4d-456d-b2a8-aeb15df4dfc4", "fitness": 0.057916960460977815, "name": "RefinedQuantumInspiredParticleSwarmOptimization", "description": "Integrate adaptive velocity scaling and adaptive dimensional perturbation to enhance convergence and exploration balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass RefinedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Dynamic quantum factor with adaptive scaling\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n\n            adaptive_velocity_scale = (1 + np.log(1 + evaluations / self.budget))\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions)) * adaptive_velocity_scale\n            \n            # Adaptive dimensional perturbation\n            perturbation = perturbation_factor * (np.sign(velocities) * np.abs(positions - global_best_position) *\n                                                  np.random.uniform(0.5, 1.0, size=(self.dim,)))\n\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm RefinedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05792 with standard deviation 0.00538.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.060343336741026654, 0.06338930946487564, 0.05005018657943394, 0.0494969830268428, 0.05197205298828966, 0.06108872676156096, 0.06042985795256062, 0.06348086375480011]}}
{"id": "3edbe24b-cf64-4f80-9e6d-148286adb167", "fitness": 0.05903148341848151, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a multi-phase approach with adaptive chaotic maps to enhance exploration and exploitation balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Dynamic quantum factor with chaotic map\n            chaotic_multiplier = 0.5 * (1 - np.cos(2 * np.pi * evaluations / self.budget))\n            quantum_factor = np.random.uniform(0.5, 1.5 * chaotic_multiplier, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05903 with standard deviation 0.00557.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.060570298263751265, 0.06341622291378501, 0.05270024285960029, 0.049662382587872256, 0.05199348250389657, 0.06443455318284674, 0.06065741136249936, 0.0635078265053538]}}
{"id": "493b1457-86bb-4b73-9f44-0fe6a5352c99", "fitness": 0.05825288798408474, "name": "EnhancedAdaptiveQuantumLevyPSO", "description": "Enhance PSO with adaptive inertia weight and hybrid quantum-Levy perturbation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = min_w + (max_w - min_w) * np.exp(-diversity / (ub - lb).mean())\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.7, 1.3 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Enhanced Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim)) * 0.01\n            positions += levy * perturbation_factor\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveQuantumLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05825 with standard deviation 0.00588.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.05806311974880429, 0.06341622291378501, 0.05270024285960029, 0.04767406923782436, 0.05199348250389657, 0.06443455318284674, 0.05814554431792329, 0.0635078265053538]}}
{"id": "2c59b7a5-15b7-4c99-925d-9d0b8ffb9669", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce an adaptive inertia weight adjustment based on current performance to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            \n            # Changed line for adaptive inertia weight\n            w = max_w - (max_w - min_w) * (global_best_score / (np.min(personal_best_scores) + 1e-9))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "aa2a940b-9557-46cf-b47f-b91aa9c81f23", "fitness": -Infinity, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance convergence by incorporating adaptive inertia weight based on diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for adaptive inertia weight\n            w = min_w + (max_w - min_w) * np.exp(-diversity / (ub - lb).mean())\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "An exception occurred: NameError(\"name 'quantum_factor' is not defined\").", "error": "NameError(\"name 'quantum_factor' is not defined\")", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {}}
{"id": "fec94d13-4304-4897-9cd0-2d8c6c0a135a", "fitness": 0.05836027151394317, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce dual-randomness perturbations in velocity update for enhanced search efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Changed line for dual-randomness perturbations\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions) +\n                          np.random.rand(num_particles, self.dim) * perturbation_factor)\n\n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05836 with standard deviation 0.00537.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.061765164551663476, 0.06338930946487564, 0.05005018657943394, 0.05064065139383389, 0.05197205298828966, 0.06108872676156096, 0.06185416125162091, 0.06348086375480011]}}
{"id": "b02e6c2a-4ee7-4787-8c22-c40aa3f5f222", "fitness": 0.059531377095154596, "name": "RefinedQuantumInspiredParticleSwarmOptimization", "description": "Introduce an adaptive inertia weight and a non-linear decrease of cognitive and social coefficients in the enhanced quantum particle swarm optimization for improved convergence and diversity.", "code": "import numpy as np\n\nclass RefinedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        alpha = 0.01  # Levy flight scaling factor\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            non_linear_ratio = (1 - (evaluations / self.budget)) ** 2\n            w = min_w + (max_w - min_w) * non_linear_ratio\n\n            c1 = max_c1 - (max_c1 - min_c1) * non_linear_ratio\n            c2 = max_c2 - (max_c2 - min_c2) * non_linear_ratio\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * alpha\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm RefinedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "488a018c-c2f9-4b0d-bf0e-b9fb5dcef46d", "fitness": 0.05755602451320138, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a self-adaptive inertia weight and a dynamic neighborhood-based update mechanism to enhance convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((global_best_score / np.mean(personal_best_scores)) ** 2)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Dynamic neighborhood-based update\n            neighborhood_size = int(num_particles * 0.1)\n            for i in range(num_particles):\n                neighbors = np.random.choice(num_particles, neighborhood_size, replace=False)\n                local_best_index = neighbors[np.argmin(personal_best_scores[neighbors])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1[i] * (personal_best_positions[i] - positions[i]) +\n                                 c2 * r2[i] * (local_best_position - positions[i]))\n\n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += velocities + perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05756 with standard deviation 0.00554.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.05938642494046187, 0.06338930946487564, 0.05005018657943394, 0.04816376960367619, 0.05197205298828966, 0.06108872676156096, 0.05947155964630413, 0.06348086375480011]}}
{"id": "09c15110-bce4-433d-b287-f4de3767ed82", "fitness": 0.05833344185326504, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce an adaptive neighborhood search strategy by integrating local best positions to enhance convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            \n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Adaptive neighborhood search strategy\n            neighborhood_size = max(1, int(num_particles * 0.1))\n            for i in range(num_particles):\n                neighborhood_idx = np.argsort(np.linalg.norm(positions - positions[i], axis=1))[:neighborhood_size]\n                local_best = personal_best_positions[neighborhood_idx[np.argmin(personal_best_scores[neighborhood_idx])]]\n                positions[i] += np.random.uniform(0.5, 1.0) * (local_best - positions[i])\n\n            # Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05833 with standard deviation 0.00599.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06302458664721, 0.057970801885530276, 0.06508583353549835, 0.05166493227633073, 0.04759909180529087, 0.05330631959441834, 0.06311565100326832, 0.058053073643802855, 0.06518068628803564]}}
{"id": "438bf2fb-bde0-49c4-bc6c-43ebc8898bbd", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Incorporate adaptive momentum and resilience factors to enhance exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["f98449ce-bd0e-4062-8dda-1b8c70c052df"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "c9755c9c-f173-4333-8bff-44faf217aec1", "fitness": 0.05728884311023451, "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Adaptive Quantum Particle Swarm Optimization with Dynamic Swarm Intelligence and Enhanced Lvy Flights.", "code": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.std(positions, axis=0).mean()\n            w = max_w - (max_w - min_w) * (evaluations / self.budget)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Adaptive quantum factor and enhanced dynamic swarm intelligence\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n            adaptive_momentum = 0.9 + 0.1 * (1 - evaluations / self.budget)\n\n            velocities = adaptive_momentum * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            new_positions = positions + velocities * quantum_factor\n            positions = np.clip(new_positions, lb, ub)\n\n            # Enhanced Lvy flight with self-adaptive resilience factor\n            levy_step = np.random.standard_cauchy((num_particles, self.dim))\n            adaptive_resilience = 1.0 + 0.1 * np.sin(evaluations / self.budget * np.pi)\n            positions += adaptive_resilience * levy_step * quantum_factor * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05729 with standard deviation 0.00563.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057970801885530276, 0.06374475674450397, 0.05005018657943394, 0.04759909180529087, 0.05225465680347485, 0.06108872676156096, 0.058053073643802855, 0.0638369668891029]}}
{"id": "d13de0aa-e9a7-4865-8823-59a8235e42d6", "fitness": 0.05879588597958907, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance the adaptation of momentum and resilience factors using dynamic scaling of quantum and Lvy perturbations.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate * 1.2, (num_particles, self.dim))  # Adjusted scaling\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.012  # Adjusted scaling\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05880 with standard deviation 0.00614.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06444910881666066, 0.057970801885530276, 0.06515233569157541, 0.052784775692554686, 0.04759909180529087, 0.05336357823501492, 0.06454294805719596, 0.058053073643802855, 0.06524725998867598]}}
{"id": "0f0d1871-6cba-441d-a9a7-1d92a3003f72", "fitness": -Infinity, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate adaptive cooling schedules and chaotic maps to enhance exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Integrate chaotic maps for better exploration\n            chaos_factor = np.random.uniform(0.7, 1.3)\n            positions += chaos_factor * (np.tanh(levy) - 0.5)\n\n            # Adaptive cooling schedule for resilience factor\n            cooling_rate = 0.95\n            resilience_factor = np.random.uniform(0.9, 1.1) * cooling_rate\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'levy' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'levy' referenced before assignment\")", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {}}
{"id": "e193d1ab-fb24-42a0-be07-b7f6c1a1cae8", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a cosine-based modulation in the convergence rate to enhance stability in late-stage iterations.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate * np.cos(np.pi * evaluations / self.budget)  # Modified line\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "d7462b2a-6093-49af-bf87-57ea9d2cde6c", "fitness": 0.05812369040673003, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight and a dynamic neighborhood topology to enhance exploration and exploitation balance in quantum particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** 0.5)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            quantum_factor = np.random.uniform(0.5, 1.5, (num_particles, self.dim))\n\n            velocities = w * velocities + c1 * r1 * (personal_best_positions - positions) + c2 * r2 * (global_best_position - positions)\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Dynamic neighborhood topology\n            for i in range(num_particles):\n                neighborhood_best_position = personal_best_positions[i]\n                neighborhood_best_score = personal_best_scores[i]\n                \n                neighbors = np.random.choice(num_particles, 5, replace=False)\n                for neighbor in neighbors:\n                    if personal_best_scores[neighbor] < neighborhood_best_score:\n                        neighborhood_best_score = personal_best_scores[neighbor]\n                        neighborhood_best_position = personal_best_positions[neighbor]\n                \n                if neighborhood_best_score < global_best_score:\n                    global_best_score = neighborhood_best_score\n                    global_best_position = neighborhood_best_position\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05812 with standard deviation 0.00540.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06178585902626077, 0.06022508438864693, 0.06338930946487564, 0.05067924248617761, 0.04939467277572274, 0.05197205298828966, 0.061874646895056284, 0.060311481880740536, 0.06348086375480011]}}
{"id": "dce2c367-6478-4368-895e-18d2f5fcb531", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance adaptive dynamics by integrating cosine annealing for parameter tuning and introduce selective perturbation to refine exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = min_w + 0.5 * (max_w - min_w) * (1 + np.cos(np.pi * evaluations / self.budget))  # Cosine annealing\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            if evaluations % 2 == 0:  # Selective perturbation\n                positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "3e0a63dd-3b14-4975-8d2d-afbf43cf7c17", "fitness": 0.057178381529221584, "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV2", "description": "Enhance dynamic adaptability and diversity maintenance in quantum swarm optimization through chaotic maps and self-adaptive perturbation mechanisms.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        # Initial chaotic sequence generation\n        chaotic_seq = np.random.rand(num_particles, self.dim)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Chaotic map for diversity maintenance\n            chaotic_seq = 4 * chaotic_seq * (1 - chaotic_seq)\n            positions += chaotic_seq * (ub - lb) * 0.1\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00557.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057970801885530276, 0.06338930946487564, 0.05005018657943394, 0.04759909180529087, 0.05197205298828966, 0.06108872676156096, 0.058053073643802855, 0.06348086375480011]}}
{"id": "a640a206-918c-477a-aa8e-7afccdab84f6", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Leverage chaotic maps for dynamic parameter adjustment and incorporate a self-adaptive inertia weight to improve exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            chaos_param = np.mod(evaluations, 4) / 3.0\n            w = min_w + (max_w - min_w) * chaos_param\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "3c347f7c-3cbc-45ab-a108-5e00e0aa3f5a", "fitness": 0.05953722666793553, "name": "AdaptiveQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive density-aware exploration and local exploitation with dynamic perturbation methods to enhance global search efficiency in quantum swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Enhanced Lvy flight perturbation with density-aware resilience\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            density_factor = np.std(positions, axis=0) / (ub - lb).mean()\n            resilience_factor = np.random.uniform(0.9, 1.1) * (1 + density_factor)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptiveQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05954 with standard deviation 0.00547.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06431694413896027, 0.06223980688358732, 0.06338930946487564, 0.052681487896673374, 0.0510143344123446, 0.05197205298828966, 0.06441051883254079, 0.062329721639348024, 0.06348086375480011]}}
{"id": "ed26abb1-35fd-407f-be2e-9a1c384d726e", "fitness": 0.05971935304589271, "name": "LearningEnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate a learning-based parameter adjustment strategy to dynamically adapt swarm behavior for improved convergence and exploration in quantum swarm optimization.", "code": "import numpy as np\n\nclass LearningEnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            # Learning-based parameter adjustment\n            c1 = min_c1 + (max_c1 - min_c1) * np.tanh(diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.tanh(diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm LearningEnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "dadd7e75-1d29-4e54-bd51-dee00dd48460", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance particle swarm optimization by adjusting inertia, introducing adaptive crossover, and refining quantum perturbation for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Adjusted dynamic quantum factor with adaptive crossover\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            crossover_rate = 0.7 + 0.3 * convergence_rate\n\n            velocities = crossover_rate * (w * velocities +\n                                           c1 * r1 * (personal_best_positions - positions) +\n                                           c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Refined Lvy flight perturbation\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "775a5a42-4c89-41a2-ad35-10eaf85980f0", "fitness": 0.058372939525455254, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a dynamic inertia weight and random forest-based guidance to enhance exploration and exploitation in quantum swarm optimization.", "code": "import numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        rf_model = RandomForestRegressor(n_estimators=10, random_state=0)\n        samples, scores = [], []\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n                samples.append(positions[i])\n                scores.append(score)\n\n            if len(samples) >= 10:\n                rf_model.fit(samples, scores)\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max(1.0 - evaluations / self.budget, 0.4)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n\n            # Apply random forest predictions\n            if len(samples) >= 10:\n                predictions = rf_model.predict(positions)\n                guides = positions[np.argsort(predictions)[:5]]  # Top 5 predicted positions\n                for i in range(num_particles):\n                    positions[i] += np.random.uniform(0.1, 0.5) * (guides[np.random.randint(0, 5)] - positions[i])\n                    positions = np.clip(positions, lb, ub)\n                    \n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05837 with standard deviation 0.00588.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.0582619341403674, 0.06338930946487564, 0.05286757911457274, 0.047835618847036576, 0.05197205298828966, 0.06464923155485569, 0.05834468693781858, 0.06348086375480011]}}
{"id": "6dbfae2f-dc19-43a7-a3c5-b9bf509a7b94", "fitness": 0.057455184507477566, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Improve exploration and convergence by adjusting perturbation and resilience in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.15, (num_particles, self.dim))  # Adjusted\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.95, 1.1)  # Adjusted\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05746 with standard deviation 0.00561.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061827268535640245, 0.05803310663754413, 0.06338930946487564, 0.05071272320720088, 0.04764972827833247, 0.05197205298828966, 0.06191612655070178, 0.05811548114991316, 0.06348086375480011]}}
{"id": "9f5370da-ec29-4697-9df4-eea5463051f3", "fitness": 0.05846644452946684, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce dynamic subpopulation strategies and adaptive inertia damping to enhance diversity and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 2))  # Adjust damping rate\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Introduce dynamic subpopulation strategy\n            if evaluations % (self.budget // 10) == 0:\n                subpop_size = num_particles // 5\n                subpop_indices = np.random.choice(num_particles, subpop_size, replace=False)\n                sub_best_score = np.inf\n                for idx in subpop_indices:\n                    if personal_best_scores[idx] < sub_best_score:\n                        sub_best_score = personal_best_scores[idx]\n                        sub_best_position = personal_best_positions[idx]\n                positions[subpop_indices] += 0.05 * (sub_best_position - positions[subpop_indices])\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05847 with standard deviation 0.00537.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.06210769737702082, 0.06338930946487564, 0.05005018657943394, 0.05091048216926597, 0.05197205298828966, 0.06108872676156096, 0.062197354790544446, 0.06348086375480011]}}
{"id": "396d6f0c-79df-442a-90dc-16654840577d", "fitness": 0.05854800042597495, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a small adaptive scaling factor to the Lvy flight perturbation to enhance diversity during exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            adaptive_scale = 0.01 * (1 + diversity / (ub - lb).mean())  # Small change here\n            positions += resilience_factor * levy * perturbation_factor * adaptive_scale\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05855 with standard deviation 0.00538.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.062371007056435834, 0.06338930946487564, 0.05005018657943394, 0.05111735156837094, 0.05197205298828966, 0.06108872676156096, 0.06246117878059754, 0.06348086375480011]}}
{"id": "f44ff0bc-57f8-4b8d-ab1c-9bd4bef28202", "fitness": 0.057178381529221584, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive variance control and elite strategy in quantum-enhanced PSO for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            elite_particles = np.argsort(personal_best_scores)[:int(0.1 * num_particles)]\n            variance_control = np.var(positions, axis=0) * 0.1\n            positions += quantum_factor * np.random.normal(0, variance_control, positions.shape)\n            positions[elite_particles] += velocities[elite_particles]  # Elite strategy\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.95, 1.05)  # Adjusted resilience factor\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00557.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057970801885530276, 0.06338930946487564, 0.05005018657943394, 0.04759909180529087, 0.05197205298828966, 0.06108872676156096, 0.058053073643802855, 0.06348086375480011]}}
{"id": "6feb4ce9-143d-41d0-8f91-acdce5ca5725", "fitness": 0.057700881457344165, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive chaos-driven perturbation and crowding distance to enhance diversity and convergence in quantum swarm optimization.  ", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n\n            # Introduce chaos-driven perturbation to enhance exploration\n            chaos_factor = 0.5 * (1 - (evaluations / self.budget))\n            chaotic_sequence = np.sin(np.pi * (positions - lb) / (ub - lb))\n            positions += chaos_factor * chaotic_sequence * perturbation_factor\n\n            # Crowding distance based adjustment to maintain diversity\n            crowding_distance = np.min(np.linalg.norm(positions - personal_best_positions, axis=1))\n            positions += crowding_distance * np.random.uniform(-1, 1, positions.shape) * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05770 with standard deviation 0.00553.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06192293600248733, 0.05872393193410341, 0.06338930946487564, 0.05078916102680653, 0.048210255849527206, 0.05197205298828966, 0.062011966294130305, 0.05880745580107727, 0.06348086375480011]}}
{"id": "535f09ed-2910-4816-86c5-11be97de096b", "fitness": 0.057187418704785414, "name": "AdvancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce non-linear dynamic inertia and social-cognitive balancing with adaptive opposition-based learning to enhance exploration and exploitation in quantum swarm optimization.  ", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.3\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * np.sin(np.pi * evaluations / (2 * self.budget))\n\n            c1 = min_c1 + (max_c1 - min_c1) * (1 - np.exp(-diversity / (ub - lb).mean()))\n            c2 = max_c2 - (max_c2 - min_c2) * (1 - np.exp(-diversity / (ub - lb).mean()))\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(1.0, 2.0 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.8 + 0.2 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor and adaptive opposition-based learning\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            opposition_positions = lb + ub - positions\n            enhanced_positions = resilience_factor * levy * perturbation_factor * 0.01 + opposition_positions * 0.05\n            positions = np.clip(positions + enhanced_positions, lb, ub)\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm AdvancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05719 with standard deviation 0.00557.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057999694742881025, 0.06338930946487564, 0.05005018657943394, 0.047622593232224064, 0.05197205298828966, 0.06108872676156096, 0.058082013939593335, 0.06348086375480011]}}
{"id": "740fa96c-c394-40a7-a751-17f87f738d02", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive inertia weight and hierarchical velocity components to refine exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * np.sin(np.pi * (evaluations / self.budget))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            # Hierarchical velocity components\n            inertia_component = w * velocities\n            cognitive_component = c1 * r1 * (personal_best_positions - positions)\n            social_component = c2 * r2 * (global_best_position - positions)\n            velocities = inertia_component + cognitive_component + social_component\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "59ee4ddc-c642-4a1c-b6bd-9bd89f7cda82", "fitness": -Infinity, "name": "EnhancedLvyQuantumSwarmOptimization", "description": "Integrate adaptively sampled Lvy flights and dynamic learning rates to enhance exploration and convergence within quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedLvyQuantumSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1/beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1/beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Adjusted quantum factor with dynamic learning rates\n            convergence_rate = np.tanh((self.budget - evaluations) / self.budget)\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            velocities = w * velocities + c1 * r1 * (personal_best_positions - positions) + c2 * r2 * (global_best_position - positions)\n\n            positions += quantum_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with adaptively sampled step sizes\n            levy_steps = self.levy_flight((num_particles, self.dim))\n            positions += levy_steps * 0.01 * quantum_factor\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {}}
{"id": "c48e4eb1-9e3c-46ac-916a-98888305c72b", "fitness": 0.054767714258638515, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce chaotic maps for particle initialization and adaptive inertia weight for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n        \n        # Using logistic map for chaotic initialization\n        chaotic_seq = np.random.rand(num_particles, self.dim)\n        positions = lb + (ub - lb) * (np.sin(np.pi * chaotic_seq)**2)\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            # Adaptive inertia weight with diversity factor\n            w = max_w - (max_w - min_w) * np.exp(-diversity)\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05477 with standard deviation 0.00516.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.05760425539721936, 0.06038406973361288, 0.05667753408714693, 0.047260468051888105, 0.04954340592961304, 0.04652491706788364, 0.05768634991341426, 0.060470505375239014, 0.05675792277172942]}}
{"id": "b72069d9-c964-408c-8430-645ad017ca37", "fitness": 0.059241562818529166, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce a dynamic resilience factor for the Lvy flight perturbation to enhance adaptability and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with dynamic resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            dynamic_resilience_factor = 0.5 + 0.5 * (1 - convergence_rate)\n            positions += dynamic_resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05924 with standard deviation 0.00541.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06348708778304057, 0.062114902915548775, 0.06338930946487564, 0.052030089719742434, 0.050916149621982765, 0.05197205298828966, 0.06357903478969096, 0.06220457432879156, 0.06348086375480011]}}
{"id": "8baab2a6-94d2-49f1-9bc5-1045623603d7", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate dynamic inertia weight adjustment for improved exploration and convergence balance in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3)) * (1 + 0.1 * (np.std(personal_best_scores)/global_best_score))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "ee176ab4-7dcb-40ce-abd2-28dc60e27d95", "fitness": 0.057378014952577744, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce elite selection and adaptive diversity control to enhance exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        elite_particle_indices = np.random.choice(num_particles, size=int(num_particles * 0.1), replace=False)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n            \n            diversity_control = 1 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Adaptive diversity control\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean()) * diversity_control\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean()) * diversity_control\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions[elite_particle_indices] += quantum_factor[elite_particle_indices] * perturbation[elite_particle_indices]\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05738 with standard deviation 0.00560.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06160350997363706, 0.05800909133871468, 0.06338930946487564, 0.05053368557081539, 0.047630227506977874, 0.05197205298828966, 0.061691967915030954, 0.05809142606005835, 0.06348086375480011]}}
{"id": "37fe130b-ea72-423a-bc29-9d4502f03716", "fitness": 0.057178381529221584, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive learning rates and differential mutation to enhance exploration and exploitation in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = velocities * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Differential mutation for exploration enhancement\n            scale_factor = 0.8\n            for p in range(num_particles):\n                indices = np.random.choice(num_particles, 3, replace=False)\n                mutant_vector = positions[indices[0]] + scale_factor * (positions[indices[1]] - positions[indices[2]])\n                new_position = np.where(np.random.rand(self.dim) < 0.5, mutant_vector, positions[p])\n                positions[p] = np.clip(new_position, lb, ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00557.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.057970801885530276, 0.06338930946487564, 0.05005018657943394, 0.04759909180529087, 0.05197205298828966, 0.06108872676156096, 0.058053073643802855, 0.06348086375480011]}}
{"id": "af6d0236-c569-4dfc-857b-15c3d97d5830", "fitness": 0.059531377095154596, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Enhance convergence by dynamically adjusting the resilience factor based on evaluation ratio.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with dynamic resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = 0.9 + 0.2 * (1 - evaluations / self.budget)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05953 with standard deviation 0.00547.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.0643409305867283, 0.06216995799078073, 0.06341622291378501, 0.05270024285960029, 0.05095944080419068, 0.05199348250389657, 0.06443455318284674, 0.06225973650920924, 0.0635078265053538]}}
{"id": "90c8fc11-c09e-4d2d-9bd0-dd96b424a5cd", "fitness": 0.05827608626135594, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Incorporate a dynamic velocity damping factor to fine-tune convergence behavior in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0.1, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05828 with standard deviation 0.00602.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06249925583274407, 0.057970801885530276, 0.06542614913745692, 0.05124802124971306, 0.04759909180529087, 0.05357741735409827, 0.06258934218588563, 0.058053073643802855, 0.06552162325768152]}}
{"id": "626ed794-587c-4ac4-b2fd-1b1618a7dff2", "fitness": 0.05840621240748171, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate adaptive learning factors and chaotic perturbation for enhanced exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            # Introduce chaotic perturbation\n            chaotic_sequence = 0.7 * np.sin(positions) - positions * np.cos(positions)\n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation * chaotic_sequence\n            positions = np.clip(positions, lb, ub)\n\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05841 with standard deviation 0.00597.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.057970801885530276, 0.06378933953688781, 0.05286757911457274, 0.04759909180529087, 0.0522899818796031, 0.06464923155485569, 0.058053073643802855, 0.06388163332031116]}}
{"id": "f3d1a9c4-6ec2-4745-b0c4-88f8805aabf7", "fitness": 0.052753356006055845, "name": "EnhancedQuantumInspiredParticleSwarmOptimizationV2", "description": "Improve exploration and convergence by integrating a chaotic initialization and adaptive mutation strategy in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimizationV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        # Using chaotic initialization for better distribution\n        positions = lb + (ub - lb) * np.random.rand(num_particles, self.dim) ** 2\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = np.random.normal(0, 0.1, (num_particles, self.dim)) * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Use adaptive mutation strategy for resilience\n            mutation_strength = np.random.uniform(0.9, 1.1) * (1 - (evaluations / self.budget))\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += mutation_strength * levy * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimizationV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05275 with standard deviation 0.00529.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.05831110198466005, 0.057250016333432074, 0.0526818221631562, 0.0478468465465014, 0.046971605509438796, 0.043236973443428584, 0.0583942527486323, 0.05733153969327498, 0.05275604563197822]}}
{"id": "288cc707-556c-4173-91b0-1d8e9935fdef", "fitness": 0.05971935304589271, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive boundary reflection and stochastic reseeding to enhance exploration and prevent premature convergence in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Adaptive boundary reflection\n            for i in range(num_particles):\n                for d in range(self.dim):\n                    if positions[i, d] < lb[d] or positions[i, d] > ub[d]:\n                        velocities[i, d] *= -1  # Reflect velocity\n                        positions[i, d] = np.random.uniform(lb[d], ub[d])  # Stochastic reseeding\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05972 with standard deviation 0.00551.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06455517892648088, 0.062188644308827756, 0.06378933953688781, 0.05286757911457274, 0.05097412953597369, 0.0522899818796031, 0.06464923155485569, 0.062278459235521555, 0.06388163332031116]}}
{"id": "665efc1e-0119-4d65-b604-93ded2bb8d7e", "fitness": 0.0581031853380187, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Modify particle update strategy to incorporate direction-based adjustment and adaptive neighborhood for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            direction_adjustment = np.sign(velocities) * (personal_best_positions - global_best_position)\n            positions += quantum_factor * direction_adjustment\n            positions = np.clip(positions, lb, ub)\n\n            # Adaptive neighborhood perturbation\n            neighborhood_factor = np.random.uniform(0.8, 1.2)\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01 * neighborhood_factor\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05810 with standard deviation 0.00602.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06134496293995173, 0.058196746255253506, 0.06580069191090498, 0.050326030471578354, 0.047782031736940955, 0.053868909130944775, 0.06143296732886794, 0.05827939818079486, 0.0658969300869312]}}
{"id": "cc813d1e-3336-4d79-a902-13bdc3221093", "fitness": 0.054247434047708785, "name": "AdaptiveQuantumInspiredPSO", "description": "Introduce adaptive inertia weight adjustments and a chaotic dynamic perturbation mechanism to boost exploration and exploitation balance in quantum-inspired particle swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 2))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Improved dynamic quantum factor with adaptive momentum\n            convergence_progress = evaluations / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * (1 - convergence_progress), (num_particles, self.dim))\n            momentum_factor = 0.8 + 0.2 * (1 - convergence_progress)\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n\n            chaotic_factor = np.sin(np.pi * convergence_progress)\n            positions += quantum_factor * velocities + chaotic_factor * perturbation_factor\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.95, 1.05)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05425 with standard deviation 0.00502.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.05844597128249163, 0.05857490928419962, 0.04596060219348774, 0.047953485317362765, 0.04804840591512105, 0.05606741430860951, 0.05852935767187828, 0.058658636244776075]}}
{"id": "75901cfe-d544-4d69-a97c-aaafdecbf9fe", "fitness": 0.05776748789061324, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Integrate self-adaptive control parameters and employ chaotic maps for enhanced exploration and exploitation in quantum swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        # Helper function for chaotic map\n        def chaotic_map(x):\n            return 4 * x * (1 - x)\n\n        chaos_factor = np.random.rand(num_particles)\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n\n            # Apply chaotic map to positions for better exploration\n            chaos_factor = chaotic_map(chaos_factor)\n            chaotic_perturbation = (positions - global_best_position) * (chaos_factor[:, None] - 0.5) * 0.1\n            positions += chaotic_perturbation\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05777 with standard deviation 0.00542.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061231354987755005, 0.05962762095324392, 0.06338930946487564, 0.05023516443470355, 0.048939172843151524, 0.05197205298828966, 0.06131915585929193, 0.05971269572940785, 0.06348086375480011]}}
{"id": "b0b512c1-f254-478c-8c11-3f61e68bc3ad", "fitness": 0.052855823952936566, "name": "ClusteredQuantumSwarmOptimization", "description": "Integrate adaptive particle clustering and strategic dimensional reduction to boost exploration and convergence in quantum swarm optimization.", "code": "import numpy as np\n\nclass ClusteredQuantumSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            # Dynamic clustering by dimensional reduction\n            cluster_center = np.mean(positions, axis=0)\n            reduced_dim_positions = positions - cluster_center\n            positions += quantum_factor * perturbation_factor * reduced_dim_positions\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm ClusteredQuantumSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05286 with standard deviation 0.00502.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.05624757971226979, 0.058195907362013966, 0.054109132640998925, 0.04617170992043951, 0.04775305105332717, 0.04443356007829602, 0.056327295086123885, 0.058278850434921314, 0.05418532928803854]}}
{"id": "8d3ba61e-d6f2-4dcf-8c0e-0b126eef064e", "fitness": 0.059105122884117005, "name": "EnhancedQuantumInspiredParticleSwarmOptimization", "description": "Introduce adaptive learning coefficients and hybrid dynamic perturbations to improve convergence and robustness in quantum-inspired swarm optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            adaptive_c1 = min_c1 + (max_c1 - min_c1) * (1 - (global_best_score / (np.abs(global_best_score) + np.finfo(float).eps)))\n            adaptive_c2 = max_c2 - (max_c2 - min_c2) * (global_best_score / (np.abs(global_best_score) + np.finfo(float).eps))\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # New dynamic quantum factor with adaptive momentum\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5 * convergence_rate, (num_particles, self.dim))\n            momentum_factor = 0.9 + 0.1 * convergence_rate\n\n            velocities = momentum_factor * (w * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - positions) +\n                          adaptive_c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Hybrid dynamic perturbation: Combination of Lvy flight and Gaussian noise\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            gaussian_noise = np.random.normal(0, 0.1, (num_particles, self.dim))\n            dynamic_factor = np.random.uniform(0.9, 1.1)\n            positions += dynamic_factor * (0.5 * levy + 0.5 * gaussian_noise) * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05911 with standard deviation 0.00539.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.06309932339125968, 0.06206267660517484, 0.06338930946487564, 0.05172404057946012, 0.05087506332192304, 0.05197205298828966, 0.06319052920940604, 0.06215224664186392, 0.06348086375480011]}}
{"id": "57db320a-bb1a-451b-bd76-f39134819d92", "fitness": 0.05750579631755388, "name": "EnhancedDynamicQuantumPSO", "description": "Introduce dynamic inertia weights and stochastic local search to enhance the convergence efficiency of quantum-inspired particle swarms.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = min_w + (max_w - min_w) * (1 - evaluations / self.budget) ** 2\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n            velocities = w * velocities + c1 * r1 * (personal_best_positions - positions) + c2 * r2 * (global_best_position - positions)\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n            # Stochastic local search with perturbation for enhanced exploration\n            if evaluations / self.budget < 0.3:\n                perturbation = np.random.uniform(-0.01, 0.01, (num_particles, self.dim))\n                positions += perturbation\n\n            # Lvy flight perturbation with dynamic factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            positions += levy * 0.01 * (1 - evaluations / self.budget)\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDynamicQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05751 with standard deviation 0.00546.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.059019548805888555, 0.06338930946487564, 0.05005018657943394, 0.048446547973347354, 0.05197205298828966, 0.06108872676156096, 0.0591036036503787, 0.06348086375480011]}}
{"id": "76da17e5-a13a-4d6f-92d1-737835fc51d1", "fitness": 0.05315816413450612, "name": "RefinedQuantumInspiredParticleSwarmOptimization", "description": "Integrate an adaptive convergence and exploration strategy using diversity-aware momentum and stochastic quantum factors to enhance performance in quantum swarm optimization.", "code": "import numpy as np\n\nclass RefinedQuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 0.9, 0.4\n\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Improved dynamic quantum factor and adaptive momentum using a stochastic approach\n            convergence_rate = (self.budget - evaluations) / self.budget\n            quantum_factor = np.random.uniform(0.5, 1.5) * convergence_rate\n            stochastic_factor = np.random.uniform(0.8, 1.2)\n\n            velocities = stochastic_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Enhanced Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.95, 1.05)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm RefinedQuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05316 with standard deviation 0.00496.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.055988124211452384, 0.05837864476937271, 0.05515537182247887, 0.04596060219348774, 0.04790108656858971, 0.045276967112454436, 0.05606741430860951, 0.058461894434577166, 0.05523337178953258]}}
{"id": "0b633f69-e11e-4466-ae3f-c783fda39963", "fitness": 0.05772865792583837, "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduce adaptive quantum tunneling with chaotic maps for enhanced exploration and convergence in particle swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        num_particles = 50\n        max_c1, max_c2 = 2.5, 2.5\n        min_c1, min_c2 = 0.5, 0.5\n        max_w, min_w = 1.0, 0.4\n\n        positions = np.random.normal((lb + ub) / 2, (ub - lb) / 4, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(num_particles, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(num_particles):\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n            diversity = np.mean(np.linalg.norm(positions - np.mean(positions, axis=0), axis=1))\n            w = max_w - (max_w - min_w) * ((evaluations / self.budget) ** (1.0 / 3))\n\n            c1 = min_c1 + (max_c1 - min_c1) * np.exp(-diversity / (ub - lb).mean())\n            c2 = max_c2 - (max_c2 - min_c2) * np.exp(-diversity / (ub - lb).mean())\n\n            perturbation_factor = np.random.normal(0, 0.1, (num_particles, self.dim))\n            r1, r2 = np.random.rand(num_particles, self.dim), np.random.rand(num_particles, self.dim)\n\n            # Chaotic map for quantum factor adaptation\n            chaos = np.mod(np.sin(evaluations + 1), 1)\n            quantum_factor = 0.5 + 0.5 * chaos\n            momentum_factor = 0.9 + 0.1 * chaos\n\n            velocities = momentum_factor * (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            \n            perturbation = perturbation_factor * np.sign(velocities) * np.abs(positions - global_best_position)\n            positions += quantum_factor * perturbation\n            positions = np.clip(positions, lb, ub)\n\n            # Lvy flight perturbation with resilience factor\n            levy = np.random.standard_cauchy((num_particles, self.dim))\n            resilience_factor = np.random.uniform(0.9, 1.1)\n            positions += resilience_factor * levy * perturbation_factor * 0.01\n            \n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05773 with standard deviation 0.00541.", "error": "", "parent_ids": ["438bf2fb-bde0-49c4-bc6c-43ebc8898bbd"], "operator": null, "metadata": {"aucs": [0.061001326879409956, 0.05973661221861293, 0.06338930946487564, 0.05005018657943394, 0.04901685480562035, 0.05197205298828966, 0.06108872676156096, 0.05982198787994175, 0.06348086375480011]}}
