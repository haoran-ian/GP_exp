{"id": "fcaa62a6-b79b-4fac-a1d6-3d69349d8e53", "fitness": 0.07675812498482404, "name": "AdaptiveSwarmMutation", "description": "Adaptive Swarm Mutation (ASM) leverages swarm intelligence and adaptive mutation strategies for efficient exploration and exploitation of search spaces in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveSwarmMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Heuristic population size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n\n                # Mutation step: Adaptive mutation rate based on proximity to global best\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation rate\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (np.linalg.norm(global_best_position - population[i]) / np.linalg.norm(ub - lb))\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSwarmMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07676 with standard deviation 0.00357.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08048071088438113, 0.07193490867695762, 0.07785875539313336]}}
{"id": "f75ac4c4-822e-48a1-a4a7-8769791b0602", "fitness": 0.08141847159713007, "name": "DynamicVelocitySwarmMutation", "description": "Dynamic Velocity Swarm Mutation (DVSM) enhances exploration and exploitation by using dynamic velocity scaling and adaptive mutation influenced by particle diversity in black box optimization.", "code": "import numpy as np\n\nclass DynamicVelocitySwarmMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Heuristic population size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.velocity_scale = 0.1  # Initial velocity scale factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Mutation step: Adaptive mutation rate based on proximity to global best\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation rate and velocity scale dynamically\n                diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1))\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (diversity / np.linalg.norm(ub - lb))\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicVelocitySwarmMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08142 with standard deviation 0.00067.", "error": "", "parent_ids": ["fcaa62a6-b79b-4fac-a1d6-3d69349d8e53"], "operator": null, "metadata": {"aucs": [0.08131757495636904, 0.08228546765958378, 0.08065237217543741]}}
{"id": "3d2eb2ec-77c3-4fb2-9a42-081cd97edf10", "fitness": 0.06619845571842346, "name": "AdaptiveMultiSwarmDynamicMutation", "description": "Adaptive Multi-Swarm Dynamic Mutation (AMSDM) improves exploration and exploitation by employing an adaptive multi-swarm strategy with dynamic velocity scaling and mutation influenced by inter-swarm communication for robust black box optimization.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarmDynamicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_count = 3  # Number of sub-swarms\n        self.swarm_size = 10 * dim  # Heuristic size for each swarm\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.c3 = 0.5  # Communication coefficient between swarms\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.velocity_scale = 0.1  # Initial velocity scale factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        total_population_size = self.swarm_count * self.swarm_size\n        population = np.random.uniform(lb, ub, (total_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (total_population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_position = np.copy(personal_best_positions[np.argmin(personal_best_scores)])\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = total_population_size\n\n        while evaluations < self.budget:\n            for swarm_id in range(self.swarm_count):\n                start_idx = swarm_id * self.swarm_size\n                end_idx = start_idx + self.swarm_size\n                swarm_population = population[start_idx:end_idx]\n                swarm_velocities = velocities[start_idx:end_idx]\n                swarm_personal_best_positions = personal_best_positions[start_idx:end_idx]\n                swarm_personal_best_scores = personal_best_scores[start_idx:end_idx]\n                swarm_global_best_index = np.argmin(swarm_personal_best_scores)\n                swarm_global_best_position = np.copy(swarm_personal_best_positions[swarm_global_best_index])\n\n                for i in range(self.swarm_size):\n                    velocities[start_idx + i] = (\n                        self.w * swarm_velocities[i]\n                        + self.c1 * np.random.rand(self.dim) * (swarm_personal_best_positions[i] - swarm_population[i])\n                        + self.c2 * np.random.rand(self.dim) * (swarm_global_best_position - swarm_population[i])\n                        + self.c3 * np.random.rand(self.dim) * (global_best_position - swarm_population[i])\n                    )\n                    population[start_idx + i] += velocities[start_idx + i] * self.velocity_scale\n\n                    # Mutation step: Adaptive mutation rate based on proximity to global best\n                    if np.random.rand() < self.mutation_rate:\n                        mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                        population[start_idx + i] += mutation_vector\n\n                    # Ensure within bounds\n                    population[start_idx + i] = np.clip(population[start_idx + i], lb, ub)\n\n                    # Evaluate new position\n                    score = func(population[start_idx + i])\n                    evaluations += 1\n\n                    # Update personal and global bests\n                    if score < swarm_personal_best_scores[i]:\n                        swarm_personal_best_scores[i] = score\n                        swarm_personal_best_positions[i] = population[start_idx + i]\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = population[start_idx + i]\n\n                # Adjust mutation rate and velocity scale dynamically per swarm\n                diversity = np.mean(np.linalg.norm(swarm_population - swarm_global_best_position, axis=1))\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (diversity / np.linalg.norm(ub - lb))\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveMultiSwarmDynamicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06620 with standard deviation 0.00500.", "error": "", "parent_ids": ["f75ac4c4-822e-48a1-a4a7-8769791b0602"], "operator": null, "metadata": {"aucs": [0.05966726482642393, 0.06712756107915951, 0.07180054124968693]}}
{"id": "b33c6af3-4f71-4115-9aa0-47705ad2e891", "fitness": 0.08102114232300639, "name": "DynamicVelocitySwarmMutationDiversityPreservation", "description": "Dynamic Velocity Swarm Mutation with Diversity Preservation (DVSM-DP) combines dynamic velocity scaling, adaptive mutation, and diversity preservation to enhance exploration, maintain particle diversity, and improve convergence in black box optimization.", "code": "import numpy as np\n\nclass DynamicVelocitySwarmMutationDiversityPreservation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Heuristic population size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.velocity_scale = 0.1  # Initial velocity scale factor\n        self.diversity_threshold = 0.1  # Threshold to trigger diversity preservation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Mutation step: Adaptive mutation rate based on proximity to global best\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation rate and velocity scale dynamically\n                diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1))\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (diversity / np.linalg.norm(ub - lb))\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n                # Implement diversity preservation strategy\n                if diversity < self.diversity_threshold * np.linalg.norm(ub - lb):\n                    # Randomly reinitialize a portion of the population to enhance diversity\n                    num_to_reinitialize = max(1, int(self.population_size * 0.1))\n                    reinitialize_indices = np.random.choice(self.population_size, num_to_reinitialize, replace=False)\n                    population[reinitialize_indices] = np.random.uniform(lb, ub, (num_to_reinitialize, self.dim))\n                    velocities[reinitialize_indices] = np.random.uniform(-1, 1, (num_to_reinitialize, self.dim)) * self.velocity_scale\n                    # Re-evaluate reinitialized individuals\n                    for idx in reinitialize_indices:\n                        score = func(population[idx])\n                        evaluations += 1\n                        personal_best_scores[idx] = score\n                        personal_best_positions[idx] = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicVelocitySwarmMutationDiversityPreservation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08102 with standard deviation 0.00050.", "error": "", "parent_ids": ["f75ac4c4-822e-48a1-a4a7-8769791b0602"], "operator": null, "metadata": {"aucs": [0.08073569459230656, 0.08172717436191423, 0.08060055801479837]}}
{"id": "ae8bfd8b-5958-4245-b714-6596badb5a8d", "fitness": 0.07307096480303903, "name": "EnhancedDynamicVelocitySwarmMutation", "description": "Enhanced Dynamic Velocity Swarm Mutation (E-DVSM) improves convergence by introducing a diversity-driven adaptive inertia weight and momentum preservation for optimized exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicVelocitySwarmMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Heuristic population size\n        self.base_inertia = 0.9  # Base inertia weight\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.velocity_scale = 0.1  # Initial velocity scale factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1))\n            inertia_weight = self.min_inertia + (self.base_inertia - self.min_inertia) * (diversity / np.linalg.norm(ub - lb))\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                # Momentum preservation: retain a fraction of previous velocity\n                velocities[i] = 0.9 * velocities[i] + 0.1 * np.random.uniform(-1, 1, self.dim)\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Mutation step: Adaptive mutation rate based on proximity to global best\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation rate dynamically\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (diversity / np.linalg.norm(ub - lb))\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedDynamicVelocitySwarmMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07307 with standard deviation 0.00239.", "error": "", "parent_ids": ["f75ac4c4-822e-48a1-a4a7-8769791b0602"], "operator": null, "metadata": {"aucs": [0.07492973549890514, 0.06970187519290505, 0.07458128371730688]}}
{"id": "005c1b57-c39a-4eef-b89f-706597f2c83c", "fitness": 0.08049024368881923, "name": "EnhancedVelocitySwarmMutation", "description": "Enhanced Velocity Swarm Mutation (EVSM) improves convergence speed and solution quality by integrating an adaptive neighborhood search strategy with velocity control and diversity-aware mutation.", "code": "import numpy as np\n\nclass EnhancedVelocitySwarmMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Heuristic population size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.velocity_scale = 0.1  # Initial velocity scale factor\n        self.neighborhood_size = int(0.1 * self.population_size)  # Neighborhood size for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Select neighborhood\n                neighbors_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best_index = neighbors_indices[np.argmin(personal_best_scores[neighbors_indices])]\n                local_best_position = personal_best_positions[local_best_index]\n\n                # Velocity update with neighborhood influence\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (local_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Mutation step: Adaptive mutation rate based on proximity to global and local best\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, (ub - lb) * 0.1, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation rate and velocity scale dynamically\n                diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1))\n                self.mutation_rate = 0.05 + 0.45 * (1 - evaluations / self.budget) * (diversity / np.linalg.norm(ub - lb))\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedVelocitySwarmMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08049 with standard deviation 0.00136.", "error": "", "parent_ids": ["f75ac4c4-822e-48a1-a4a7-8769791b0602"], "operator": null, "metadata": {"aucs": [0.07924928173571233, 0.07984035127430933, 0.08238109805643601]}}
{"id": "f98b6fd4-2bc4-4d2a-beb2-0be2e5607064", "fitness": 0.08213592447711815, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation (EPS-DCM) introduces a covariance-based mutation strategy to adaptively adjust exploration and exploitation based on particle spread and convergence speed in black box optimization.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08214 with standard deviation 0.00156.", "error": "", "parent_ids": ["f75ac4c4-822e-48a1-a4a7-8769791b0602"], "operator": null, "metadata": {"aucs": [0.08095103041378982, 0.08433951396106709, 0.08111722905649754]}}
{"id": "e4c9ab5d-f4e3-4d30-8f44-45bcca304a59", "fitness": 0.07587132771172804, "name": "HybridAdaptiveParticleSwarm", "description": "Hybrid Adaptive Particle Swarm integrates opposition-based learning and adaptive inertia weight to enhance exploration and convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                # Update velocity and position with adaptive inertia weight\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Opposition-based learning\n                if np.random.rand() < 0.1:\n                    opposite_position = lb + ub - population[i]\n                    opposite_position = np.clip(opposite_position, lb, ub)\n                    opposite_score = func(opposite_position)\n                    evaluations += 1\n                    if opposite_score < personal_best_scores[i]:\n                        personal_best_scores[i] = opposite_score\n                        personal_best_positions[i] = opposite_position\n                        if opposite_score < global_best_score:\n                            global_best_score = opposite_score\n                            global_best_position = opposite_position\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07587 with standard deviation 0.00271.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07230509533789098, 0.07886771348482924, 0.07644117431246389]}}
{"id": "826ccc6e-34f4-441a-85ff-9164a0e03017", "fitness": 0.07628357750587311, "name": "AdaptiveQuantumParticleSwarm", "description": "Adaptive Quantum Particle Swarm Optimization (AQPSO) combines quantum-inspired particles with adaptive shrinking hyper-spheres for enhanced global exploration and local exploitation, dynamically balancing exploration-exploitation trade-offs for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.hyper_sphere_shrink_factor = 0.99\n        self.init_velocity_scale = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.init_velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n\n                # Quantum-inspired mutation within a shrinking hyper-sphere\n                if np.random.rand() < 0.1:\n                    mutation_radius = np.linalg.norm(global_best_position - population.mean(axis=0)) * self.hyper_sphere_shrink_factor\n                    mutation_vector = np.random.randn(self.dim)\n                    mutation_vector /= np.linalg.norm(mutation_vector)\n                    population[i] = global_best_position + mutation_radius * mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            # Adaptive inertia weight to improve convergence\n            self.w = 0.9 - 0.7 * (evaluations / self.budget)\n        \n        return global_best_score, global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveQuantumParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07628 with standard deviation 0.00062.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07715150656086067, 0.07597343813561996, 0.0757257878211387]}}
{"id": "dad97f7f-f9ae-4181-a7fa-6270a7504ec7", "fitness": 0.0721166306622955, "name": "QuantumInspiredParticleSwarmAM", "description": "Quantum-inspired Particle Swarm with Adaptive Mutation (QPS-AM) leverages quantum superposition principles for diverse particle exploration and dynamically adjusts mutation intensity based on swarm convergence and fitness landscape roughness.", "code": "import numpy as np\n\nclass QuantumInspiredParticleSwarmAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.mutation_probability = 0.1\n        self.mutation_intensity = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + 1e-3 * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position using quantum-inspired superposition\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Adaptive mutation based on fitness landscape roughness\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.normal(0, self.mutation_intensity, self.dim)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust mutation intensity based on swarm convergence\n                self.mutation_intensity = 0.1 * (1 - evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm QuantumInspiredParticleSwarmAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07212 with standard deviation 0.00265.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.06921421719814191, 0.07152294598906961, 0.07561272879967496]}}
{"id": "35e23dbe-0833-4f9b-99cb-6b763320e904", "fitness": 0.08163125757992751, "name": "AdaptiveCovarianceSwarmOptimization", "description": "Adaptive Covariance Swarm Optimization (ACSO) leverages adaptive covariance scaling based on individual and global convergence rates to enhance exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveCovarianceSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            # Dynamically scale mutation probability based on progress\n            scaled_mutation_probability = self.mutation_probability * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step with adaptive probability\n                if np.random.rand() < scaled_mutation_probability:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveCovarianceSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08163 with standard deviation 0.00035.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.08131115988364357, 0.08211696193352158, 0.08146565092261737]}}
{"id": "1bfb1766-cd68-49a4-86cd-5f16cadd61a1", "fitness": 0.07102344080902685, "name": "AdaptiveParticleSwarmSCM", "description": "Adaptive Particle Swarm Optimization with Stochastic Covariance Mutation (APSO-SCM) enhances exploration and exploitation by dynamically adjusting velocity scales and introducing stochastic covariance-based perturbations to maintain diversity and improve convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmSCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            # Update inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - population[i])\n                    + self.c2 * r2 * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Stochastic Covariance-based mutation step\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (1 - (evaluations / self.budget))\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveParticleSwarmSCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07102 with standard deviation 0.00394.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.06547608911678116, 0.07422182587215931, 0.07337240743814011]}}
{"id": "2ee3d3cf-44c5-4a7c-8181-f4148f94000d", "fitness": 0.06937697684144732, "name": "AdaptiveParticleSwarmSGC", "description": "Adaptive Particle Swarm Optimization with Stochastic Gradient Correction (APSO-SGC) integrates stochastic gradient estimates in particle updates to enhance convergence speed and solution accuracy in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmSGC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.1\n        self.gradient_step_size = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Stochastic Gradient Correction\n                gradient_estimate = (func(population[i]) - func(personal_best_positions[i])) / (np.linalg.norm(population[i] - personal_best_positions[i]) + 1e-8)\n                population[i] -= self.gradient_step_size * gradient_estimate * (population[i] - personal_best_positions[i])\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveParticleSwarmSGC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06938 with standard deviation 0.00244.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.06593974558804205, 0.07130349765280508, 0.07088768728349482]}}
{"id": "d2eec601-dcf1-4e87-9a22-bfa318c7647f", "fitness": 0.06973479447989876, "name": "AdaptiveParticleSwarmGCM", "description": "Adaptive Particle Swarm with Gradient-Based Covariance Mutation (APSO-GCM) leverages adaptive gradients and covariance matrices to enhance exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmGCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.2  # Increased mutation probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            # Gradient approximation step for better direction\n            gradients = np.zeros_like(population)\n            for i, individual in enumerate(population):\n                perturbed = individual + self.velocity_scale * velocities[i]\n                gradients[i] = (func(perturbed) - personal_best_scores[i]) / self.velocity_scale\n\n            for i in range(self.population_size):\n                # Update velocity and position using gradient information\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                    - 0.01 * gradients[i]  # Incorporate gradient to adjust search direction\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step with adaptive probability\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveParticleSwarmGCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06973 with standard deviation 0.00200.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07122854134091261, 0.07106891112983338, 0.06690693096895028]}}
{"id": "642568f2-f244-46b0-a991-e9f85b0bfd89", "fitness": 0.08206331775688391, "name": "HybridEnhancedParticleSwarmACGR", "description": "Hybrid Enhanced Particle Swarm with Adaptive Covariance and Gradient Reflection (H-EPS-ACGR) incorporates adaptive covariance scaling and gradient reflection to balance exploration-exploitation and enhance convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridEnhancedParticleSwarmACGR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < self.mutation_probability:\n                    mutation_strength = 1.0 - (evaluations / self.budget)\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix * mutation_strength)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                if evaluations % (self.population_size // 2) == 0:\n                    gradient = (population[i] - personal_best_positions[i]) / (evaluations + 1)\n                    population[i] -= gradient * self.velocity_scale\n\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm HybridEnhancedParticleSwarmACGR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08206 with standard deviation 0.00139.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.0807353449879703, 0.0839805778885786, 0.08147403039410284]}}
{"id": "161c162b-a49d-4a89-83eb-4a8aae431d93", "fitness": 0.06039357621219055, "name": "AdaptiveParticleSwarmPCM", "description": "Adaptive Particle Swarm with Progressive Covariance Mutation (APS-PCM) dynamically adjusts mutation intensity and velocity decay based on solution diversity and evaluation progression to enhance exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmPCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_velocity_scale = 0.1\n        self.final_velocity_scale = 0.001\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.initial_velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                current_velocity_scale = (\n                    self.initial_velocity_scale + (self.final_velocity_scale - self.initial_velocity_scale) * (evaluations / self.budget)\n                )\n                population[i] += velocities[i] * current_velocity_scale\n\n                # Progressive Covariance-based mutation step\n                if np.random.rand() < self.mutation_probability * (1 - evaluations / self.budget):\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveParticleSwarmPCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06039 with standard deviation 0.00137.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.06088791932292448, 0.06176526093563994, 0.05852754837800722]}}
{"id": "4e1be8bc-ff42-4b8e-87da-ffd96591853b", "fitness": 0.0771837901027838, "name": "AdaptiveParticleSwarmDL", "description": "Adaptive Particle Swarm Optimization with Directional Learning (APSO-DL) integrates directional learning to prioritize promising search directions for particles, balancing exploration and exploitation dynamically in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.7  # Increased inertia weight\n        self.c1 = 1.4\n        self.c2 = 1.4\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.directional_learning_rate = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Apply directional learning\n                if np.random.rand() < self.directional_learning_rate:\n                    optimal_direction = global_best_position - population[i]\n                    norm_optimal_direction = np.linalg.norm(optimal_direction)\n                    if norm_optimal_direction > 0:\n                        optimal_direction = optimal_direction / norm_optimal_direction\n                    population[i] += optimal_direction * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveParticleSwarmDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07718 with standard deviation 0.00347.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07545033091237052, 0.07407343788084297, 0.08202760151513788]}}
{"id": "aec0a76b-bfd9-4df5-a873-cda54747c659", "fitness": 0.08002627280987003, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation (EPS-DCM) introduces adaptive inertia weight to balance exploration and exploitation, dynamically adjusting based on convergence.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08003 with standard deviation 0.00231.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07693321222416538, 0.08248966553603865, 0.08065594066940607]}}
{"id": "9e830327-44c5-4341-8cd2-fe5ad1af5385", "fitness": 0.06256270836553017, "name": "AdaptiveParticleSwarmCGE", "description": "Adaptive Particle Swarm with Covariance-Guided Exploration (APS-CGE) enhances convergence by dynamically adjusting the velocity scale and incorporating a more frequent covariance-based mutation to improve exploration in diverse regions of the search space for black box optimization.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmCGE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.base_velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_probability = 0.3  # Increased probability\n        self.velocity_decay = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.base_velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.base_velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            # Adjust velocity scale dynamically based on convergence\n            self.base_velocity_scale *= self.velocity_decay ** (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveParticleSwarmCGE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06256 with standard deviation 0.00646.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.062243715364970975, 0.05481303090155898, 0.07063137883006054]}}
{"id": "fb3d6a32-97fd-4ba8-b5eb-aac3b1837917", "fitness": 0.07247037180798595, "name": "AdaptiveQuantumPSODCM", "description": "Adaptive Quantum-Inspired Particle Swarm with Dynamic Covariance Mutation (AQPS-DCM) combines quantum-inspired position updates and adaptive inertia weight control with enhanced covariance-based mutation to improve convergence and diversity in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumPSODCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.qdelta = 0.001  # Quantum delta for position update\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Quantum position update\n                if np.random.rand() < 0.5:\n                    quantum_jump = np.random.uniform(-self.qdelta, self.qdelta, self.dim)\n                    quantum_position = population[i] + quantum_jump\n                    quantum_position = np.clip(quantum_position, lb, ub)\n                    quantum_score = func(quantum_position)\n                    evaluations += 1\n\n                    # Accept quantum move if better\n                    if quantum_score < personal_best_scores[i]:\n                        population[i] = quantum_position\n                        personal_best_scores[i] = quantum_score\n                        personal_best_positions[i] = quantum_position\n                        if quantum_score < global_best_score:\n                            global_best_score = quantum_score\n                            global_best_position = quantum_position\n\n                # Update velocity and position\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveQuantumPSODCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07247 with standard deviation 0.00175.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07006462697335714, 0.07415891174531264, 0.07318757670528808]}}
{"id": "9b6780fd-df1d-4da0-97e5-a97694a0fe35", "fitness": 0.07519361597728917, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Variable Inertia (EPS-DVI) introduces a novel dynamic inertia weight adjustment based on the convergence rate to improve particle exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Dynamic adjustment of inertia weight\n                self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07519 with standard deviation 0.00264.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.0714624906928909, 0.0769682152484975, 0.07715014199047909]}}
{"id": "c102d69a-d0e7-47f6-81f5-9d7968fa5c3e", "fitness": 0.0819924288413546, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation (EPS-DCM) with adaptive inertia weight dynamically adjusting based on iteration progress to improve convergence speed and stability.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Adaptive inertia weight adjustment\n                self.w = 0.9 - 0.8 * (evaluations / self.budget)\n\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08199 with standard deviation 0.00127.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.08020907148478029, 0.08303800389065574, 0.08273021114862777]}}
{"id": "ba15b10a-f5c1-4e69-bd6d-727b52852442", "fitness": 0.07804529529503734, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation and Adaptive Learning Rate adjusts exploration based on convergence speed and particle fitness diversity in black box optimization.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget) * (np.std(personal_best_scores)/np.mean(personal_best_scores))  # Changed line\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07805 with standard deviation 0.00248.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.07459163170617655, 0.07922226265736287, 0.0803219915215726]}}
{"id": "425537b7-8227-4ae9-8410-9b86f0aa95fb", "fitness": 0.08250189768286391, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation (EPS-DCM) introduces adaptive velocity scaling based on convergence rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)  # Adjusted change\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08250 with standard deviation 0.00140.", "error": "", "parent_ids": ["f98b6fd4-2bc4-4d2a-beb2-0be2e5607064"], "operator": null, "metadata": {"aucs": [0.08053565245853278, 0.08367402744196839, 0.08329601314809054]}}
{"id": "204752a1-f934-4ac3-bb87-5540ac8757f6", "fitness": 0.07676105178540775, "name": "EnhancedParticleSwarmAVDCM", "description": "The Enhanced Particle Swarm with Adaptive Velocity and Dynamic Covariance Mutation (EPS-AVDCM) introduces adaptive population size and inertial weight based on convergence rate, alongside dynamic covariance mutation, to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmAVDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(10 * dim)\n        self.initial_population_size = self.population_size\n        self.w = 0.9  # Start with higher inertia weight\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            # Adjust velocity scale and inertia weight dynamically based on convergence\n            progress = evaluations / self.budget\n            self.velocity_scale = 0.1 + 0.8 * progress\n            self.w = 0.9 - 0.5 * progress  # Decrease inertia weight as iterations progress\n\n            # Dynamically adjust population size\n            self.population_size = max(self.initial_population_size - int(progress * self.initial_population_size / 2), int(self.initial_population_size / 2))\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedParticleSwarmAVDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07676 with standard deviation 0.00432.", "error": "", "parent_ids": ["425537b7-8227-4ae9-8410-9b86f0aa95fb"], "operator": null, "metadata": {"aucs": [0.07068185024594886, 0.07930517746754528, 0.08029612764272909]}}
{"id": "29aa660d-bfcc-42f6-a960-f0a6a44ab16b", "fitness": 0.08249064165370046, "name": "EnhancedParticleSwarmDCM", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation now includes a refined dynamic velocity scaling formula for improved convergence.  ", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n                \n                # Covariance-based mutation step\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.7 * (evaluations / self.budget)  # Adjusted change\n        \n        return global_best_score, global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedParticleSwarmDCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08249 with standard deviation 0.00127.", "error": "", "parent_ids": ["425537b7-8227-4ae9-8410-9b86f0aa95fb"], "operator": null, "metadata": {"aucs": [0.08072821010274722, 0.08366404994436183, 0.08307966491399232]}}
{"id": "dabc560d-3b74-487c-8280-65c49eeca736", "fitness": 0.07082642701490242, "name": "EnhancedParticleSwarmDCMAIW", "description": "Enhanced Particle Swarm with Dynamic Covariance Mutation and Adaptive Inertia Weight (EPS-DCMAIW) introduces adaptive inertia weight and diversity-based mutation rate to improve convergence.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDCMAIW:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            \n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            # Diversity-based mutation rate\n            diversity = np.mean(np.std(population, axis=0))\n            mutation_rate = min(0.5, max(0.05, diversity / (ub - lb).mean()))\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Covariance-based mutation step\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedParticleSwarmDCMAIW got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07083 with standard deviation 0.00160.", "error": "", "parent_ids": ["425537b7-8227-4ae9-8410-9b86f0aa95fb"], "operator": null, "metadata": {"aucs": [0.07260054964566975, 0.07115528345738797, 0.06872344794164953]}}
{"id": "6bdfe294-4cdb-4b69-a8b1-d0a1b9032005", "fitness": 0.08101355758159472, "name": "AdaptiveParticleSwarmCovarianceMutation", "description": "Adaptive Particle Swarm with Covariance-Guided Mutation (APSCM) enhances exploration by dynamically adjusting mutation rates using personal best distance and increasing diversity through adaptive velocity perturbations.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmCovarianceMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate population covariance for mutation adaptation\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Dynamic mutation rate based on distance to personal best\n                distance_to_pb = np.linalg.norm(personal_best_positions[i] - population[i])\n                adaptive_mutation_rate = self.mutation_rate + 0.2 * (distance_to_pb / np.linalg.norm(ub - lb))\n\n                # Covariance-based mutation step\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                # Ensure within bounds\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate new position\n                score = func(population[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale dynamically based on convergence\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveParticleSwarmCovarianceMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08101 with standard deviation 0.00120.", "error": "", "parent_ids": ["425537b7-8227-4ae9-8410-9b86f0aa95fb"], "operator": null, "metadata": {"aucs": [0.08059369963613772, 0.07980212825938204, 0.08264484484926438]}}
{"id": "7d5b0616-fe7b-49fe-b7d0-f537b620b4c6", "fitness": 0.08287704201131736, "name": "AdaptiveParticleSwarmLS", "description": "Adaptive Particle Swarm Optimization with Local Search (APSO-LS) introduces a local search strategy when the population stagnates to enhance diversification and convergence speed.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08288 with standard deviation 0.00140.", "error": "", "parent_ids": ["425537b7-8227-4ae9-8410-9b86f0aa95fb"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08205434651895682, 0.0848522599415984]}}
{"id": "0acf66fd-5f61-4e7b-b4d4-d26766894850", "fitness": 0.08273394528425244, "name": "EnhancedAdaptiveParticleSwarmDM", "description": "Enhanced Adaptive Particle Swarm Optimization with Differential Mutation (APSO-DM) incorporates differential mutation to balance exploration and exploitation while accelerating convergence. ", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.differential_weight = 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                for idx in np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False):\n                    a, b, c = population[np.random.choice(self.population_size, 3, replace=False)]\n                    differential_mutation = a + self.differential_weight * (b - c)\n                    differential_mutation = np.clip(differential_mutation, lb, ub)\n                    \n                    if func(differential_mutation) < personal_best_scores[idx]:\n                        personal_best_scores[idx] = func(differential_mutation)\n                        personal_best_positions[idx] = differential_mutation\n                    if func(differential_mutation) < global_best_score:\n                        global_best_score = func(differential_mutation)\n                        global_best_position = differential_mutation\n                    evaluations += 1\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08273 with standard deviation 0.00150.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08162505633776207, 0.0848522599415984]}}
{"id": "7be5a49e-2db8-4818-920e-38f7bcd07e57", "fitness": 0.08284957230591816, "name": "AdaptiveParticleSwarmLS", "description": "Introduced adaptive velocity scaling based on stagnation detection to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n        prev_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust velocity scale based on improvement\n                if global_best_score < prev_global_best_score:\n                    self.velocity_scale = 0.1 + 0.8 * ((evaluations / self.budget) ** 0.5) # Stagnation improvement\n                else:\n                    self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n                prev_global_best_score = global_best_score\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08285 with standard deviation 0.00105.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08207559129163822, 0.0821453935350488, 0.08432773209106748]}}
{"id": "e5b4ba1b-7378-4d04-b07c-17ef5cc68fbe", "fitness": 0.04926812966734954, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Parameter Tuning and Adaptive Mutation (EAPSO-DPTAM) incorporates dynamic inertia weight adjustment and adaptive Gaussian mutation based on population diversity to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.vel_limit = 0.2\n        self.local_search_probability = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.vel_limit\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        def calculate_diversity(pop):\n            mean_position = np.mean(pop, axis=0)\n            return np.mean(np.linalg.norm(pop - mean_position, axis=1))\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            diversity = calculate_diversity(population)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                velocities[i] = np.clip(velocities[i], -self.vel_limit, self.vel_limit)\n                population[i] += velocities[i]\n\n                mutation_strength = 0.1 / (1 + np.exp(-diversity + 2))\n                if np.random.rand() < mutation_strength:\n                    mutation_vector = np.random.normal(0, mutation_strength, self.dim)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04927 with standard deviation 0.00034.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.04907966891787441, 0.048976265884859815, 0.049748454199314396]}}
{"id": "8a01cfd6-affe-4b8b-ade7-9697203b70f1", "fitness": 0.07370647276778523, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced APSO-LS with adaptive inertia weight adjustment to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adaptive inertia weight adjustment\n                self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07371 with standard deviation 0.00154.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.0729051002315505, 0.07235073146643711, 0.07586358660536807]}}
{"id": "34a5292a-781c-4fe1-b8d4-01214ff8e99b", "fitness": 0.08197960418964616, "name": "EnhancedAdaptiveParticleSwarmILS", "description": "Enhanced Adaptive Particle Swarm with Intelligent Local Search (EAPSO-ILS) integrates adaptive learning rates and a dynamic local search based on success history to improve convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmILS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.success_count = 0\n        self.failure_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                    self.success_count += 1\n                    self.failure_count = 0\n                elif np.random.rand() < 0.05:  # add stochastic acceptance for exploration\n                    personal_best_scores[i] *= 1.01  # artificially inflate score for variety\n                    self.failure_count += 1\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                # Adjust the velocity scale based on the success history\n                if self.success_count > self.failure_count:\n                    self.velocity_scale = min(0.5, self.velocity_scale * 1.1)\n                else:\n                    self.velocity_scale *= 0.9\n\n            # Dynamic local search probability based on success rate\n            if self.success_count > 5:\n                if np.random.rand() < self.local_search_probability:\n                    local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                    for idx in local_search_indices:\n                        local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                        population[idx] += local_mutation_vector\n                        population[idx] = np.clip(population[idx], lb, ub)\n                        local_score = func(population[idx])\n                        evaluations += 1\n\n                        if local_score < personal_best_scores[idx]:\n                            personal_best_scores[idx] = local_score\n                            personal_best_positions[idx] = population[idx]\n                        if local_score < global_best_score:\n                            global_best_score = local_score\n                            global_best_position = population[idx]\n\n                self.success_count = 0\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmILS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08198 with standard deviation 0.00155.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08048543571611877, 0.08133249042287216, 0.08412088642994753]}}
{"id": "2dc54304-1df3-483a-a5e0-220bb6173fbb", "fitness": 0.07800625816842092, "name": "EnhancedParticleSwarmDEEB", "description": "Enhanced Particle Swarm Optimization with Dynamic Exploration-Exploitation Balance (EPSO-DEEB) improves convergence by dynamically adjusting the exploration and exploitation phases, utilizing an adaptive velocity scale and an intelligent mutation strategy during stagnation.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDEEB:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.mutation_strength = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.normal(0, self.mutation_strength, self.dim)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if evaluations / self.budget > 0.5:\n                self.w = 0.3\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedParticleSwarmDEEB got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07801 with standard deviation 0.00088.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07712511158419899, 0.07767730883099067, 0.0792163540900731]}}
{"id": "dd0b12a4-8355-4aac-ac28-7b3982056779", "fitness": 0.08217749350226027, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced APSO-LS by adjusting the local search probability dynamically based on convergence to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            # Changed for dynamic local search probability\n            self.local_search_probability = 0.2 + 0.3 * (1 - evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08218 with standard deviation 0.00067.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08168050006158267, 0.08312746087180123]}}
{"id": "d0ef8477-6239-4c9e-b9bb-805c2404276e", "fitness": 0.08217749350226027, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced Adaptive Particle Swarm Optimization with Local Search (APSO-LS) by dynamically adjusting local search frequency based on convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            self.local_search_probability = 0.2 + 0.3 * (1 - evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08218 with standard deviation 0.00067.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08168050006158267, 0.08312746087180123]}}
{"id": "6a2005f2-1199-4e07-8844-abe6f355e0a0", "fitness": 0.08287704201131736, "name": "EnhancedAdaptiveParticleSwarmDLS", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Local Search (EAPSO-DLS) introduces adaptive velocity scaling and dynamic local search probability based on convergence rate to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.base_local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n        prev_global_best_score = global_best_score\n        convergence_count = 0\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if global_best_score < prev_global_best_score:\n                convergence_count = max(convergence_count - 1, 0)\n            else:\n                convergence_count += 1\n\n            prev_global_best_score = global_best_score\n\n            dynamic_local_search_prob = self.base_local_search_probability + 0.1 * (convergence_count / (evaluations / self.population_size))\n\n            if np.random.rand() < dynamic_local_search_prob:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08288 with standard deviation 0.00140.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08205434651895682, 0.0848522599415984]}}
{"id": "50fb6399-df62-43f1-a078-b15661acafc1", "fitness": 0.07204768309765246, "name": "EnhancedParticleSwarmAM", "description": "Enhanced Particle Swarm Optimization with Adaptive Mutation (EPSO-AM) incorporates adaptive mutation based on population diversity to improve exploration and convergence in solving black box optimization problems.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.adaptive_mutation_scale = 0.2\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + 1e-3 * np.eye(self.dim)\n\n            # Calculate population diversity\n            diversity = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n            adaptive_mutation_scale = self.adaptive_mutation_scale * (1 - (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Introduce adaptive mutation\n                if np.random.rand() < diversity:\n                    mutation_vector = np.random.normal(0, adaptive_mutation_scale, self.dim)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            # Local search with adaptive probability\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedParticleSwarmAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07205 with standard deviation 0.00442.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.06671434647959729, 0.07188865551753443, 0.07754004729582564]}}
{"id": "263e135c-7005-4aa6-8930-ef664b439309", "fitness": 0.07034055136680746, "name": "EnhancedAdaptiveParticleSwarmDL", "description": "Enhanced Adaptive Particle Swarm with Dynamic Learning (EAPSO-DL) improves convergence by dynamically adjusting cognitive and social components based on performance feedback and introducing an adaptive local search radius.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                current_score = func(population[i])\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = population[i]\n                if current_score < global_best_score:\n                    global_best_score = current_score\n                    global_best_position = population[i]\n\n                learning_factor = 1 - (current_score - global_best_score) / (np.abs(global_best_score) + 1e-10)\n                self.c1 = 1.5 * learning_factor\n                self.c2 = 1.5 * (1 - learning_factor)\n\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    radius = np.linalg.norm(population[idx] - global_best_position) / 2\n                    local_mutation_vector = np.random.normal(0, radius, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07034 with standard deviation 0.00369.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07140404171110581, 0.06538123416818864, 0.07423637822112794]}}
{"id": "3a4ab3d1-e78d-4f87-b513-4a0ba2dbb5dd", "fitness": 0.07649791071805205, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm Optimization incorporates adaptive inertia weight and a dynamic local search strategy to improve performance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if evaluations % int(0.2 * self.budget) == 0:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07650 with standard deviation 0.00120.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07492075679338839, 0.0767298086224748, 0.07784316673829295]}}
{"id": "268689e7-8826-4c34-8c19-1c040870d1d6", "fitness": 0.08217749350226027, "name": "AdaptiveParticleSwarmLS", "description": "Introduce dynamic adjustment of the local search probability based on progress to enhance exploration when needed.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            progress_ratio = evaluations / self.budget  # Adjust local search probability based on progress\n            self.local_search_probability = 0.2 + 0.3 * (1 - progress_ratio)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08218 with standard deviation 0.00067.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08168050006158267, 0.08312746087180123]}}
{"id": "d99d6116-c611-4f19-b435-cd70643053c2", "fitness": 0.08251475352391317, "name": "AdaptiveParticleSwarmLS", "description": "Improved Adaptive Particle Swarm Optimization with Dynamic Local Search Probability (IAPSO-DLSP) adjusts the local search probability dynamically based on convergence rate.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            # Dynamically adjust local search probability based on convergence rate\n            convergence_rate = 1 - (global_best_score / (np.mean(personal_best_scores) + 1e-10))\n            self.local_search_probability = 0.1 + 0.9 * (1 - convergence_rate)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08251 with standard deviation 0.00078.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08168067893740849, 0.08231454061653831, 0.0835490410177927]}}
{"id": "d6a084b3-5794-4615-bb63-4a0244544b7d", "fitness": 0.08250189768286391, "name": "EnhancedAdaptiveParticleSwarmDRLS", "description": "Enhanced Adaptive Particle Swarm Optimization with Diversity-Regulated Local Search (EAPSO-DRLS) introduces a diversity metric to adaptively trigger local searches, improving exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDRLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.diversity_threshold = 0.1  # New parameter for diversity regulation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            # Calculate population diversity\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n            \n            # Trigger local search based on diversity\n            if diversity < self.diversity_threshold:\n                if np.random.rand() < self.local_search_probability:\n                    local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.3), replace=False)\n                    for idx in local_search_indices:\n                        local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                        population[idx] += local_mutation_vector\n                        population[idx] = np.clip(population[idx], lb, ub)\n                        local_score = func(population[idx])\n                        evaluations += 1\n\n                        if local_score < personal_best_scores[idx]:\n                            personal_best_scores[idx] = local_score\n                            personal_best_positions[idx] = population[idx]\n                        if local_score < global_best_score:\n                            global_best_score = local_score\n                            global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDRLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08250 with standard deviation 0.00140.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08053565245853278, 0.08367402744196839, 0.08329601314809054]}}
{"id": "31d75b87-ae58-48a5-baa4-97bcbed4aeab", "fitness": 0.06453670302337515, "name": "AdaptiveParticleSwarmLS", "description": "Introduce adaptive velocity scaling based on population diversity to enhance convergence in Adaptive Particle Swarm Optimization with Local Search (APSO-LS).", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget) * np.std(velocities)  # Modified line\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06454 with standard deviation 0.00447.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.06820181140645576, 0.06716634832254331, 0.058241949341126364]}}
{"id": "ca466463-ac47-4f23-a873-e04e9094a3b3", "fitness": 0.08287704201131736, "name": "EnhancedAdaptiveParticleSwarmDLS", "description": "Enhanced Adaptive Particle Swarm with Dynamic Local Search (EAPSO-DLS) utilizes a dynamically adjusted local search frequency based on swarm diversity to improve convergence stability and speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.base_local_search_probability = 0.2\n        self.dynamic_search_scaling = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            # Calculate diversity\n            diversity = np.mean(np.linalg.norm(population - global_best_position, axis=1))\n            dynamic_local_search_probability = self.base_local_search_probability * (1 + self.dynamic_search_scaling * diversity / np.max([1, np.linalg.norm(ub - lb)]))\n\n            if np.random.rand() < dynamic_local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08288 with standard deviation 0.00140.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08172451957339688, 0.08205434651895682, 0.0848522599415984]}}
{"id": "c1e9bd9a-c62c-41a7-bd84-bc7090da502b", "fitness": 0.08231237467045678, "name": "AdaptiveParticleSwarmLS", "description": "Adaptive Particle Swarm LS with Dynamic Local Search introduces a dynamic local search probability adjustment based on iteration progress to enhance convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            # Change: Dynamic adjustment of local search probability\n            self.local_search_probability = 0.2 + 0.5 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08231 with standard deviation 0.00087.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08171064722942145, 0.08168050006158267, 0.08354597672036623]}}
{"id": "f327da3f-0ed1-47ed-ab27-27ae203c57c1", "fitness": 0.06823438425364821, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm Optimization (EAPSO) integrates a dynamic inertia weight adjustment based on population diversity and a selective local search mechanism to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            # Dynamic inertia weight calculation\n            diversity = np.mean(np.std(population, axis=0))\n            w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + 1))\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06823 with standard deviation 0.00190.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.0676650236728018, 0.06624286066911977, 0.07079526841902306]}}
{"id": "15a2afc1-2d83-47bd-9fc2-09cc8f76dd3d", "fitness": 0.07985402951033915, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced velocity update mechanism in APSO-LS to increase exploration capability.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                    + 0.05 * np.random.randn(self.dim)  # Added extra randomness to velocities\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07985 with standard deviation 0.00124.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07856987057375009, 0.07945325422525029, 0.08153896373201708]}}
{"id": "7cc29fac-e1f5-4032-ab2d-9479f88e02d3", "fitness": 0.08064034616445033, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced APSO-LS incorporates adaptive inertia weight and a dynamic local search probability to improve convergence speed and precision.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.9  # Changed from 0.5 to 0.9 for higher initial exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n                self.w = 0.9 - (0.5 * (evaluations / self.budget))  # Adaptive inertia weight\n\n            if np.random.rand() < self.local_search_probability:\n                self.local_search_probability = 0.2 + 0.3 * (1 - evaluations / self.budget)  # Dynamic local search probability\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08064 with standard deviation 0.00230.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07929218746791744, 0.0787549168749353, 0.08387393415049826]}}
{"id": "d84fc2d1-45bb-4dc0-b240-6162a82d5f1c", "fitness": 0.07755961472985407, "name": "EnhancedParticleSwarmDIALS", "description": "Enhanced Particle Swarm Optimization with Dynamic Inertia and Adaptive Local Search (EPSO-DIALS) uses dynamic inertia weight adjustment and adaptive local search frequency based on convergence rate for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmDIALS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_frequency = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n        prev_global_best = global_best_score\n\n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            convergence_rate = (prev_global_best - global_best_score) / prev_global_best if prev_global_best > 0 else 0\n            prev_global_best = global_best_score\n\n            if np.random.rand() < self.local_search_frequency * (1 + convergence_rate):\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedParticleSwarmDIALS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07756 with standard deviation 0.00140.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07600822275414765, 0.079397614010145, 0.07727300742526955]}}
{"id": "87127bcc-eca1-42c2-9b65-6cf52bbb176a", "fitness": 0.08241841963986345, "name": "QuantumAdaptiveParticleSwarmELS", "description": "Quantum-inspired Adaptive Particle Swarm Optimization with Enhanced Local Search (QAPSO-ELS) leverages quantum mechanics concepts and dynamic local search to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumAdaptiveParticleSwarmELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3\n        self.q_delta = 0.05  # Quantum jump factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            for i in range(self.population_size):\n                random_vector = np.random.rand(self.dim)\n                quantum_jump = self.q_delta * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * random_vector * (personal_best_positions[i] - population[i])\n                    + self.c2 * random_vector * (global_best_position - population[i])\n                    + quantum_jump\n                )\n                population[i] += velocities[i] * self.velocity_scale\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n                \n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm QuantumAdaptiveParticleSwarmELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08242 with standard deviation 0.00057.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.0817642028462281, 0.08233139613320373, 0.0831596599401585]}}
{"id": "dd0739dd-dee7-4982-b96f-048e5d5a7915", "fitness": 0.08103031739768289, "name": "EnhancedAdaptiveParticleSwarmDSA", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Strategy Adjustment (EAPSO-DSA) introduces dynamic inertia and learning factor adjustments, alongside adaptive mutation to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmDSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.9  # Initial inertia weight, dynamically adjusted\n        self.c1 = 2.0  # Cognitive learning factor\n        self.c2 = 2.0  # Social learning factor\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.epsilon = 1e-8  # Small constant to avoid division by zero\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            # Dynamically adjust inertia weight and learning factors\n            progress_ratio = evaluations / self.budget\n            self.w = 0.4 + 0.5 * (1 - progress_ratio)  # Decrease inertia over time to focus on exploitation\n            self.c1 = 2.5 - 1.5 * progress_ratio\n            self.c2 = 1.5 + 1.5 * progress_ratio\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1 * progress_ratio, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmDSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08103 with standard deviation 0.00259.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07738493873959407, 0.08249490900391565, 0.08321110444953894]}}
{"id": "4cf53797-bdce-4c54-8eab-a3ec4306aefd", "fitness": 0.08043308594049459, "name": "EnhancedAdaptiveParticleSwarmLS", "description": "Enhanced Adaptive Particle Swarm with Dynamic Inertia and Global Perturbation (E-APSO-LS) dynamically adjusts inertia weights and perturbs the global best position to balance exploration and exploitation, improving convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n            # Perturb the global best position occasionally\n            if evaluations % int(self.budget * 0.1) == 0:\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                global_best_position += perturbation\n                global_best_position = np.clip(global_best_position, lb, ub)\n                global_best_score = func(global_best_position)\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08043 with standard deviation 0.00222.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07940576057566884, 0.07837370188533965, 0.08351979536047527]}}
{"id": "f492e42c-e744-461b-941d-8458c47b5792", "fitness": 0.0761134024441692, "name": "EnhancedAdaptiveParticleSwarmALS", "description": "Enhanced Adaptive Particle Swarm Optimization with Adaptive Local Search (EAPSO-ALS) dynamically adjusts local search intensity and uses non-linear inertia weight to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmALS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.local_search_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * progress ** 2\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim) * (1 - progress)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n            self.local_search_probability *= self.local_search_decay\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmALS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07611 with standard deviation 0.00165.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.0740440120144722, 0.07809399649984738, 0.07620219881818802]}}
{"id": "f7605129-7c5e-4b27-a611-18878bd72587", "fitness": 0.07377188201032332, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Inertia Weight and Adaptive Mutation (EAPSO-DIW-AM) adjusts inertia weight dynamically and introduces adaptive mutation for better exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.9  # Line 7: Initialize w with a larger value for dynamic adjustment\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            # Line 31: Dynamically adjust inertia weight\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                # Line 42: Adaptive mutation probability based on convergence\n                adaptive_mutation_prob = 0.1 + 0.4 * (1 - evaluations / self.budget)\n                if np.random.rand() < adaptive_mutation_prob:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07377 with standard deviation 0.00460.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.0743308764022409, 0.06787393091767435, 0.07911083871105473]}}
{"id": "0a1cff50-4101-4ac1-8bba-6804b9525be3", "fitness": 0.07407429672702259, "name": "AdaptiveParticleSwarmLS", "description": "Introduce a momentum factor to enhance the convergence velocity while maintaining exploration, improving the efficiency of Adaptive Particle Swarm Optimization with Local Search (APSO-LS).", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.momentum_factor = 0.9  # Newly introduced momentum factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.momentum_factor * velocities[i]  # Apply momentum to the velocity update\n                    + self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07407 with standard deviation 0.00162.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.07179679942650485, 0.07501455173199789, 0.07541153902256503]}}
{"id": "e47414f4-4497-4f7d-a666-ed9f34e25a78", "fitness": 0.07177795277917505, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced Adaptive Particle Swarm Optimization (EAPSO-LS) modifies the velocity update with dynamic adjustment of `c1` and `c2` to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * (1 - evaluations / self.budget) * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * (evaluations / self.budget) * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07178 with standard deviation 0.00182.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.06920960401807119, 0.07312030425535543, 0.07300395006409854]}}
{"id": "34b711d2-8f6a-4d1d-8a8f-2170520254d5", "fitness": 0.08439641738829488, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced APSO-LS modifies the velocity update with dynamic scaling to improve convergence precision.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)  # Change made here\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08440 with standard deviation 0.00092.", "error": "", "parent_ids": ["7d5b0616-fe7b-49fe-b7d0-f537b620b4c6"], "operator": null, "metadata": {"aucs": [0.08538763057358956, 0.08463303899430508, 0.08316858259699]}}
{"id": "c4d4d142-ec45-4de8-8053-7b4c1cce3e8c", "fitness": 0.07474999499413452, "name": "AdaptiveParticleSwarmLS", "description": "AdaptiveParticleSwarmLS enhances convergence by adjusting mutation probability based on exploration progress.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)  # Change made here\n\n                mutation_prob = 0.1 + 0.5 * (1 - evaluations / self.budget)  # Change made here\n                if np.random.rand() < mutation_prob:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07475 with standard deviation 0.00488.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.07705340328096211, 0.06795992979361598, 0.07923665190782547]}}
{"id": "4a7f6bc8-10af-4a48-9ef5-fd6bd054254a", "fitness": 0.08316717073650992, "name": "AdaptiveParticleSwarmLS", "description": "Further improved APSO-LS by modifying dynamic velocity scaling and enhancing mutation for better convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.4 + 0.6)  # Change made here\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix * 0.9)  # Change made here\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08317 with standard deviation 0.00344.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.07883929130158263, 0.08726758235955911, 0.08339463854838802]}}
{"id": "0b90fb48-7682-4376-a806-3a790523f783", "fitness": 0.08361348391471528, "name": "AdaptiveParticleSwarmLS", "description": "Introducing dynamic inertia weight adjustment based on function evaluations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                self.w = 0.9 - 0.8 * (evaluations / self.budget)  # Change made here\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08361 with standard deviation 0.00093.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08459454489484952, 0.08387794837703211, 0.08236795847226419]}}
{"id": "bc91ee10-2afb-47cc-991e-9746aa3fec12", "fitness": 0.0821352148034199, "name": "HybridAdaptivePSO", "description": "Hybrid APSO with Adaptive Covariance Mutation integrates adaptive velocity control and covariance-based mutation to enhance convergence and exploration.", "code": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            \n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (0.5 + 0.5 * np.random.rand())  # Adaptive scaling of velocity\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector * (0.5 + 0.5 * (evaluations / self.budget))  # Adaptive mutation scaling\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08214 with standard deviation 0.00086.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08239480973265512, 0.08097757718707199, 0.08303325749053259]}}
{"id": "332e440a-d890-4c0b-bf0f-6412f7c856a8", "fitness": 0.07239321378260932, "name": "ImprovedAdaptiveParticleSwarmLS", "description": "Improved APSO-LS uses adaptive inertia weight and fitness-based local search intensity to enhance convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            fitness_gain = (global_best_score - np.min(personal_best_scores)) / (global_best_score + 1e-10)\n            local_search_prob = self.local_search_probability * (1 + fitness_gain)\n            \n            if np.random.rand() < local_search_prob:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm ImprovedAdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07239 with standard deviation 0.00112.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.07250187693717247, 0.073702582451866, 0.07097518195878949]}}
{"id": "ccf712a2-acbc-4c8e-886b-3601c796914b", "fitness": 0.08335159896395354, "name": "ImprovedAdaptiveParticleSwarmLS", "description": "Enhanced APSO-LS with adaptive inertia and dynamic local search radius for improved convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.local_search_probability = 0.2\n        self.local_search_radius = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    # Dynamic local search radius\n                    dynamic_radius = self.local_search_radius * (1 - evaluations / self.budget)\n                    local_mutation_vector = np.random.normal(0, dynamic_radius, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 64, "feedback": "The algorithm ImprovedAdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08335 with standard deviation 0.00171.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08118949001189213, 0.08536085086203571, 0.08350445601793277]}}
{"id": "99202dd1-9dca-4bbd-803f-7f5cff00082b", "fitness": 0.08439641738829488, "name": "DynamicCovariancePSO", "description": "\"DynamicCovariancePSO enhances APSO-LS by adapting covariance matrix updates based on velocity convergence to better handle diverse search spaces.\"", "code": "import numpy as np\n\nclass DynamicCovariancePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.local_search_probability = 0.2\n        self.covariance_inflation = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n        prev_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            velocity_converged = np.linalg.norm(velocities.mean(axis=0)) < 0.01\n            if velocity_converged:\n                self.covariance_inflation *= 0.99\n\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm DynamicCovariancePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08440 with standard deviation 0.00092.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08538763057358956, 0.08463303899430508, 0.08316858259699]}}
{"id": "87f20ef6-c577-4c28-91a1-84aeaa92cd4b", "fitness": 0.07915295605993933, "name": "AdaptiveParticleSwarmLSPlusPlus", "description": "AdaptiveParticleSwarmLS++ integrates an adaptive inertia weight and elite selection mechanism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLSPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            elite_size = max(1, int(self.population_size * self.elite_fraction))\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(elite_indices, size=int(self.population_size * 0.2), replace=True)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveParticleSwarmLSPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07915 with standard deviation 0.00249.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08043125200940882, 0.08135162142648245, 0.07567599474392672]}}
{"id": "4d78d98a-5e28-47ca-97ac-fb82f673e81d", "fitness": 0.06815035409124685, "name": "StochasticAdaptiveParticleSwarmLS", "description": "Stochastic Adaptive Particle Swarm LS integrates Gaussian perturbations and adaptive inertia weights for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass StochasticAdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.local_search_probability = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.w_start - (self.w_start - self.w_end) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n                if np.random.rand() < 0.2:  # increase perturbation likelihood\n                    mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm StochasticAdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06815 with standard deviation 0.00571.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.06858600675553295, 0.0609535791038216, 0.074911476414386]}}
{"id": "7784d973-4239-4d92-a392-2d4463549873", "fitness": 0.0693894350746443, "name": "AdaptiveCooperativePSO", "description": "Introducing an Adaptive Inertia and Cooperative Particle Swarm Optimization (ACPSO) using adaptive inertia weight and cooperative local search to enhance convergence precision and robustness.", "code": "import numpy as np\n\nclass AdaptiveCooperativePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Increased local search probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)  # Adaptive inertia weight\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n\n                if np.random.rand() < 0.15:  # Increased mutation probability\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveCooperativePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06939 with standard deviation 0.00488.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.07384831510312029, 0.0625984390834976, 0.07172155103731503]}}
{"id": "b32660bb-c2e1-43de-93f6-ebfb79fddbd7", "fitness": 0.08323738452328981, "name": "AdaptiveParticleSwarmLS", "description": "Introduced adaptive local search probability and non-uniform mutation scaling to enhance exploration and convergence.  ", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector * (1 - evaluations / self.budget)  # Change here\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), size=self.dim)  # Change here\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n            self.local_search_probability = 0.2 + 0.3 * (evaluations / self.budget)  # Change here\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08324 with standard deviation 0.00080.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08256612832895582, 0.08436142476789743, 0.08278460047301617]}}
{"id": "ed52a5be-0e3d-4be2-8990-5f792330af34", "fitness": 0.07846694526911009, "name": "AdaptiveParticleSwarmLS", "description": "Introduce random inertia weight adaptation to foster exploration and exploitation in the search space.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                w = np.random.uniform(0.4, 0.9)  # Change made here\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07847 with standard deviation 0.00261.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.07882285198975736, 0.0814678151839191, 0.07511016863365383]}}
{"id": "c538c493-1c66-42e1-afe6-f23460412f2f", "fitness": 0.08022795832150693, "name": "AdaptiveParticleSwarmLS", "description": "Improved dynamic velocity scaling and mutation for better exploration in Enhanced APSO-LS.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)  # Change made here\n\n                if np.random.rand() < 0.15:  # Change made here\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08023 with standard deviation 0.00546.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08564556642877996, 0.08228365995370757, 0.07275464858203329]}}
{"id": "1f1c94dd-0921-4f67-b434-d25b81030cb8", "fitness": 0.08194989103720378, "name": "AdaptiveParticleSwarmLSLevy", "description": "Enhanced APSO-LS with Lvy flight disturbance for improved exploration and convergence precision.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLSLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.2\n        self.levy_alpha = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                if np.random.rand() < 0.1:  # Apply Lvy flight disturbance\n                    levy_step = self.levy_flight()\n                    population[i] += levy_step * (ub - lb)\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position\n\n    def levy_flight(self):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / self.levy_alpha))\n        return step", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveParticleSwarmLSLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08195 with standard deviation 0.00387.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08739601258159191, 0.07974526949007044, 0.07870839103994898]}}
{"id": "9a43441b-530a-4c47-8ab2-5e2da15d265f", "fitness": 0.08592318102316594, "name": "AdaptiveParticleSwarmLS", "description": "Modified velocity scaling and increased local search probability to boost exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08592 with standard deviation 0.00089.", "error": "", "parent_ids": ["34b711d2-8f6a-4d1d-8a8f-2170520254d5"], "operator": null, "metadata": {"aucs": [0.08489181266366197, 0.08706772379468852, 0.08581000661114735]}}
{"id": "920b899e-ec46-45e0-ba0b-20b31dd0b9f7", "fitness": 0.08407751462614343, "name": "AdaptiveParticleSwarmLS", "description": "Integrated adaptive inertia weight to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08408 with standard deviation 0.00254.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08187773244052732, 0.08763521483525094, 0.08271959660265205]}}
{"id": "cc10835e-9869-4e9a-8d94-0028f892591b", "fitness": 0.06653239712707548, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Particle Swarm Optimization with dynamic inertia, adaptive local search, and mutation diversity to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Further increased to enhance exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia weight\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.2:  # Increased mutation probability\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06653 with standard deviation 0.00645.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.05885926435111799, 0.07464715439574676, 0.0660907726343617]}}
{"id": "2a26cb7d-7378-480c-96c9-0cc47ccef942", "fitness": 0.08253639110965956, "name": "AdaptiveParticleSwarmLS", "description": "Fine-tuned exploration by adjusting mutation probability and local search intensity.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.15:  # Adjusted from 0.1 for mutation probability\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.1), replace=False)  # Decreased intensity from 0.2\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08254 with standard deviation 0.00376.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08476223816311645, 0.08560592343780571, 0.07724101172805653]}}
{"id": "262bc3d4-c0ba-4b40-8aec-fb96e298e82d", "fitness": 0.08455668304049213, "name": "AdaptiveParticleSwarmAdvanced", "description": "Introduce adaptive inertia weight and elitist learning mechanism to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmAdvanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n        self.elitist_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n            # Elitist learning mechanism\n            elite_count = int(self.population_size * self.elitist_rate)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elite_positions = personal_best_positions[elite_indices]\n            for idx in elite_indices:\n                elite_mutation_vector = np.mean(elite_positions, axis=0) - personal_best_positions[idx]\n                population[idx] += elite_mutation_vector * np.random.rand(self.dim)\n                population[idx] = np.clip(population[idx], lb, ub)\n                elite_score = func(population[idx])\n                evaluations += 1\n                \n                if elite_score < personal_best_scores[idx]:\n                    personal_best_scores[idx] = elite_score\n                    personal_best_positions[idx] = population[idx]\n                if elite_score < global_best_score:\n                    global_best_score = elite_score\n                    global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveParticleSwarmAdvanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08456 with standard deviation 0.00115.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08507721393154832, 0.08562996116034505, 0.08296287402958302]}}
{"id": "88b12f0a-5c98-47c0-b5e2-64c6934f2fac", "fitness": 0.05978209026745925, "name": "ImprovedAdaptiveParticleSwarmLS", "description": "Integrate adaptive inertia weight and dynamic local search to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Increased from 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i]\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.3), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm ImprovedAdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05978 with standard deviation 0.00779.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.0707672843872087, 0.0550596478948171, 0.053519338520351956]}}
{"id": "f9894637-70af-4a43-9d9d-292caa0e53ff", "fitness": 0.07884632762394066, "name": "EnhancedAdaptivePSO", "description": "Enhanced particle swarm optimization with dynamic inertia, adaptive velocity scaling, and intensified local search to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.2\n        self.local_search_probability = 0.3  # Increased from 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * self.velocity_scale\n\n                if np.random.rand() < 0.2:  # Increase diversity with mutation\n                    mutation_vector = np.random.normal(0, 0.2, size=self.dim)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.2 + 0.5 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.25), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07885 with standard deviation 0.00333.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07425129866968505, 0.08204861055225321, 0.0802390736498837]}}
{"id": "790ebe9b-3834-4f9e-85cc-b42d00cb545f", "fitness": 0.08338011675025536, "name": "AdaptiveParticleSwarmDE", "description": "Incorporate adaptive learning strategies and differential evolution to enhance convergence and solution diversity.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Slightly increased for more local exploitation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.5 + 0.5)  # Adjusted scaling\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.3), replace=False)\n                for idx in local_search_indices:\n                    crossover_idx = np.random.choice(range(self.population_size), size=3, replace=False)\n                    x1, x2, x3 = population[crossover_idx[0]], population[crossover_idx[1]], population[crossover_idx[2]]\n                    mutant = x1 + 0.8 * (x2 - x3)\n                    trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant, population[idx])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    local_score = func(trial_vector)\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = trial_vector\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = trial_vector\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveParticleSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08338 with standard deviation 0.00077.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08321437087675909, 0.08439673505359324, 0.08252924432041375]}}
{"id": "086cd7ff-1473-4430-979b-9540c56d11b2", "fitness": 0.07822994566206531, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Particle Swarm Optimization with Adaptive Velocity Scaling and Diversified Local Search for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_velocity_scale = 0.1\n        self.final_velocity_scale = 0.5\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Increased from 0.25 for more frequent local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.initial_velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                velocity_scale = self.initial_velocity_scale + (self.final_velocity_scale - self.initial_velocity_scale) * (evaluations / self.budget)\n                population[i] += velocities[i] * velocity_scale\n\n                # Apply a small probability of large mutation to escape local optima\n                if np.random.rand() < 0.15:\n                    cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            # Diversified local search with adaptive mutation step\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    scale = np.random.rand() * 0.2 + 0.05  # Adaptive mutation scale\n                    local_mutation_vector = np.random.normal(0, scale, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07823 with standard deviation 0.00375.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.0734276972121608, 0.08258376214144392, 0.07867837763259122]}}
{"id": "4dca29be-cd7c-48a3-8eb4-0a097f6e64f2", "fitness": 0.08466309923210398, "name": "AdaptiveParticleSwarmLS", "description": "Introduce adaptive inertia weight and dynamic velocity scaling to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n            self.w = 0.9 - 0.8 * (evaluations / self.budget)  # Adaptive inertia weight\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08466 with standard deviation 0.00268.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08189167096634786, 0.0882841331026718, 0.08381349362729229]}}
{"id": "dd63a5d8-d10b-45e5-8a8a-61c234a0e6cb", "fitness": 0.08172406076264493, "name": "DynamicAdaptivePSO", "description": "Introduce dynamic population resizing and adaptive inertia weight to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.min_population_size = 4 * dim\n        self.w = 0.9  # Start with a high inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight adjustment\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(population_size), size=int(population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n            if evaluations % (self.budget // 10) == 0 and population_size > self.min_population_size:\n                population_size = max(self.min_population_size, int(population_size * 0.9))\n                population = population[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm DynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.00395.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07835751587940964, 0.08727413178327026, 0.0795405346252549]}}
{"id": "01b91928-78ee-42f4-8f9a-12c6f89b711d", "fitness": 0.08200598609997767, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced the exploration phase using a dynamically adjusted mutation strategy based on early convergence indications.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.15:  # Adjusted probability from 0.1\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix * (0.5 + 0.5 * (evaluations/self.budget)))\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08201 with standard deviation 0.00329.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08393001826195667, 0.08471371518292192, 0.07737422485505441]}}
{"id": "9dec3458-b20f-4f9b-b967-58a1a962b4c8", "fitness": 0.083840638857961, "name": "AdaptiveParticleSwarmLSImproved", "description": "Introducing a dynamic adaptation of the inertia weight and local search intensification based on convergence speed to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLSImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.initial_w - (self.initial_w - self.final_w) * (evaluations / self.budget)\n\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveParticleSwarmLSImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08384 with standard deviation 0.00278.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08289102431572903, 0.08761689131812234, 0.08101400094003164]}}
{"id": "9e0c643e-b548-4c4f-b160-f87b4d11f74f", "fitness": 0.08479722237724352, "name": "AdaptiveParticleSwarmLS", "description": "Fine-tuned velocity update formula for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.8 + 0.2)  # Modified scaling from 0.6+0.4\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08480 with standard deviation 0.00213.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08192692483336561, 0.08703517452356868, 0.08542956777479627]}}
{"id": "8b1826f5-94b4-45e2-b74b-05855f59eaa2", "fitness": 0.07366648465070787, "name": "EnhancedAdaptivePSO", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Learning Rates and Adaptive Local Search to improve global exploration and local exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 1.2\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.initial_w - (self.initial_w - self.final_w) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07367 with standard deviation 0.00366.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07117145223109855, 0.0788468022114932, 0.07098119950953186]}}
{"id": "32a208e3-e4f5-4fe4-ac36-858fd5c1e666", "fitness": 0.08421792876131735, "name": "AdaptiveParticleSwarmLS", "description": "Introduce gradual velocity scale reduction to improve convergence towards the end of the optimization process.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.35)  # Modified scaling to 0.35\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08422 with standard deviation 0.00247.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08137949278089296, 0.08739084463008917, 0.08388344887296995]}}
{"id": "2c1d1545-d444-45ba-ab47-171d1506db7b", "fitness": 0.08346336029947599, "name": "AdaptiveParticleSwarmLS", "description": "Introduce dynamic inertia weight adjustment based on the iteration progress to enhance convergence speed.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Updated inertia weight dynamically\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08346 with standard deviation 0.00370.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07903324414614654, 0.08808146491687163, 0.08327537183540978]}}
{"id": "14fd594e-b5ee-4b84-aefb-329c3541bcab", "fitness": 0.056110449366534275, "name": "HybridParticleSwarmDE", "description": "Introduce adaptive learning coefficients and hybridize with differential evolution to enhance convergence and exploration.", "code": "import numpy as np\n\nclass HybridParticleSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Increased from 0.25\n        self.de_mutation_factor = 0.8\n        self.de_crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                # Adaptive learning coefficients\n                c1 = self.c1_min + (self.c1_max - self.c1_min) * evaluations / self.budget\n                c2 = self.c2_min + (self.c2_max - self.c2_min) * evaluations / self.budget\n\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                # Differential Evolution mutation and crossover\n                if np.random.rand() < self.de_crossover_rate:\n                    idxs = np.random.choice(range(self.population_size), 3, replace=False)\n                    a, b, c = population[idxs]\n                    mutant_vector = a + self.de_mutation_factor * (b - c)\n                    population[i] = np.where(np.random.rand(self.dim) < self.de_crossover_rate, mutant_vector, population[i])\n\n                population[i] = np.clip(population[i], lb, ub)\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm HybridParticleSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05611 with standard deviation 0.00527.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.06233589250544369, 0.05655235891639754, 0.04944309667776159]}}
{"id": "d64fbb9a-ce41-409c-b2b2-3638f29d3500", "fitness": 0.08398854223190544, "name": "AdaptiveParticleSwarmDynamicLS", "description": "Introduced adaptive inertia and dynamic local search intensity for enhanced exploration and convergence in PSO.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmDynamicLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.initial_local_search_probability = 0.3  # Increased from 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            local_search_probability = self.initial_local_search_probability * (1 - evaluations / self.budget)\n\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptiveParticleSwarmDynamicLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08399 with standard deviation 0.00278.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08175041366781, 0.08790394441728999, 0.08231126861061633]}}
{"id": "8f96b2fb-cc4f-43fe-b27b-e50d1a3914e7", "fitness": 0.07860201246424237, "name": "EnhancedAdaptivePSO", "description": "An enhanced particle swarm optimization incorporating adaptive inertia weight, dynamic velocity scaling, and targeted local search to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.local_search_probability = 0.3  # Increased local search probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly decreasing inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (0.5 + 0.5 * (evaluations / self.budget))  # Dynamic velocity scaling\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.05, size=self.dim)  # Smaller mutation for refined local search\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07860 with standard deviation 0.00307.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07457714142819805, 0.0792102863605908, 0.08201860960393825]}}
{"id": "8acc7df0-dcc6-4c49-8201-40181c15c612", "fitness": 0.0811211348717555, "name": "AdaptiveParticleSwarmLS", "description": "Introducing adaptive inertia weight and mutation scaling to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.9  # Changed from 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.30  # Increased from 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix) * (0.5 + 0.5 * np.random.rand())  # Scaled mutation\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08112 with standard deviation 0.00174.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08049611375689303, 0.08349320102212088, 0.0793740898362526]}}
{"id": "9ce39596-9951-4438-9c8b-07d3a871d797", "fitness": 0.07719736617211008, "name": "EnhancedAdaptiveParticleSwarm", "description": "Enhanced Adaptive Particle Swarm with Dynamic Inertia and Stochastic Local Search for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07720 with standard deviation 0.00406.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.07156995661636867, 0.07901391749601905, 0.08100822440394251]}}
{"id": "e1bd723e-1989-41f3-bc35-02c338b3091c", "fitness": 0.08318598994023274, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced global best influence by adjusting c2 for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.7  # Increased from 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08319 with standard deviation 0.00013.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08336637169777872, 0.08304622173056841, 0.08314537639235109]}}
{"id": "913c28ca-af31-4d2b-9983-ee2301b86314", "fitness": 0.08592318102316594, "name": "AdaptiveParticleSwarmLS", "description": "Adjusted local search probability to enhance exploration while staying within the 1.4% modification limit.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Increased from 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08592 with standard deviation 0.00089.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08489181266366197, 0.08706772379468852, 0.08581000661114735]}}
{"id": "f53c1dbc-1003-40cf-85dd-5fe017807f2e", "fitness": 0.07996118099054923, "name": "AdaptiveParticleSwarmLS", "description": "Enhanced exploration and convergence in AdaptiveParticleSwarmLS by dynamic inertia and increased mutation diversity.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.9  # Increased initial inertia weight for exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.3  # Further increased for enhanced local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            dynamic_inertia = self.w * (1 - evaluations / self.budget)  # Dynamic inertia weight\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    dynamic_inertia * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)  # Modified scaling from 0.5+0.5\n\n                if np.random.rand() < 0.2:  # Increased mutation chance\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07996 with standard deviation 0.00145.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08200818003554255, 0.07879847389055439, 0.07907688904555077]}}
{"id": "8b7bfb39-4a61-4582-9c45-293c6063b58a", "fitness": 0.08415611107540899, "name": "AdaptiveParticleSwarmLS", "description": "Adjusted velocity calculation and mutation probability to enhance convergence and robustness.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25  # Increased from 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.65 + 0.35)  # Modified scaling from 0.6+0.4\n\n                if np.random.rand() < 0.15:  # Increased mutation probability from 0.1\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08416 with standard deviation 0.00025.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08424741359173771, 0.08440965373337161, 0.08381126590111765]}}
{"id": "d192943e-0167-450f-8367-7681b107ff79", "fitness": 0.08573129948818563, "name": "AdaptiveParticleSwarmLS", "description": "Adjusted inertia weight decay and introduced dynamic local search probability based on diversity to enhance exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_scale = 0.1\n        self.covariance_inflation = 1e-3\n        self.local_search_probability = 0.25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * self.velocity_scale\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cov_matrix = np.cov(population, rowvar=False) + self.covariance_inflation * np.eye(self.dim)\n\n            for i in range(self.population_size):\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    + self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                )\n                population[i] += velocities[i] * (self.velocity_scale * 0.6 + 0.4)\n\n                if np.random.rand() < 0.1:\n                    mutation_vector = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    population[i] += mutation_vector\n\n                population[i] = np.clip(population[i], lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = population[i]\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = population[i]\n\n                self.velocity_scale = 0.1 + 0.8 * (evaluations / self.budget)\n\n            diversity = np.mean(np.std(population, axis=0))\n            self.w = 0.5 * (1 - evaluations / self.budget)  # Adjusted inertia weight decay\n            self.local_search_probability = 0.25 + 0.25 * (diversity / np.max([diversity, 1e-9]))  # Dynamic probability\n\n            if np.random.rand() < self.local_search_probability:\n                local_search_indices = np.random.choice(range(self.population_size), size=int(self.population_size * 0.2), replace=False)\n                for idx in local_search_indices:\n                    local_mutation_vector = np.random.normal(0, 0.1, size=self.dim)\n                    population[idx] += local_mutation_vector\n                    population[idx] = np.clip(population[idx], lb, ub)\n                    local_score = func(population[idx])\n                    evaluations += 1\n\n                    if local_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = local_score\n                        personal_best_positions[idx] = population[idx]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = population[idx]\n\n        return global_best_score, global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveParticleSwarmLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08573 with standard deviation 0.00154.", "error": "", "parent_ids": ["9a43441b-530a-4c47-8ab2-5e2da15d265f"], "operator": null, "metadata": {"aucs": [0.08593785387237962, 0.08750853852062368, 0.08374750607155357]}}
