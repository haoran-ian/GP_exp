{"id": "55b13c06-132f-4f53-ba24-3588882656ed", "fitness": 0.04740906052133282, "name": "AdaptiveBiasedRandomWalk", "description": "\"Adaptive Biased Random Walk (ABRW) - A novel metaheuristic that adaptively balances exploration and exploitation using biased random walks based on historical performance within defined bounds.\"", "code": "import numpy as np\n\nclass AdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction and biased step size\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.9\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.1\n            \n            # Adaptive mechanism to reset position if stuck\n            if evaluations % (self.budget // 10) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04741 with standard deviation 0.00189.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.04694096529624292, 0.04404388748802279, 0.045266967647855316, 0.04969801536610585, 0.04664660547430266, 0.0479330876664702, 0.050342506527153885, 0.04725388183256529, 0.04855562739327646]}}
{"id": "2cb18c31-443c-40ef-8521-e9a5eb7e17a9", "fitness": 0.046473310590981, "name": "AdaptiveBiasedRandomWalk", "description": "Adaptive Biased Random Walk (ABRW) with Momentum - Introduces momentum to enhance convergence by adjusting steps based on previous movements, balancing exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n        momentum = np.zeros(self.dim)  # Momentum initialization\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction with momentum\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * (direction + 0.5 * momentum)\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                momentum = direction  # Update momentum\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.9\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.1\n            \n            # Adaptive mechanism to reset position if stuck\n            if evaluations % (self.budget // 10) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04647 with standard deviation 0.00447.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.05026153026915037, 0.041228149996149765, 0.042041874562524506, 0.05320692287386575, 0.04368893354061265, 0.04454495838542549, 0.05389701386359824, 0.04426210235817429, 0.04512830946932789]}}
{"id": "ac73fb92-08ef-41f1-a5f2-1e692845a76d", "fitness": 0.04740906052133282, "name": "AdaptiveBiasedRandomWalk", "description": "Refined Adaptive Biased Random Walk (R-ABRW) - Introduces dynamic step size adaptation based on a differential comparison to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction and biased step size\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.9 * (1 - (proposed_value - best_value) / (current_value - proposed_value + 1e-10))\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.1\n            \n            # Adaptive mechanism to reset position if stuck\n            if evaluations % (self.budget // 10) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04741 with standard deviation 0.00189.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.04694096529624292, 0.04404388748802279, 0.045266967647855316, 0.04969801536610585, 0.04664660547430266, 0.0479330876664702, 0.050342506527153885, 0.04725388183256529, 0.04855562739327646]}}
{"id": "cd422b4f-f1ae-4e35-bcdc-03481322806b", "fitness": -Infinity, "name": "EnhancedAdaptiveBiasedRandomWalk", "description": "Enhanced Adaptive Biased Random Walk (EABRW) - Introduces adaptive restart and dynamic learning rate adjustment to improve convergence speed and solution quality through better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        success_counter = 0  # Track consecutive successful steps\n\n        while evaluations < self.budget:\n            # Random direction with bias for exploration-exploitation\n            direction = np.random.normal(size=self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n                success_counter += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size to fine-tune solutions\n                step_size *= 0.85\n            else:\n                # Increase step size for broader exploration\n                step_size *= 1.2\n                success_counter = 0\n\n            # Adaptive restart if stuck in local optimum\n            if success_counter > 10 and evaluations < self.budget:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n                step_size = 0.1 * (ub - lb)  # Reset step size\n\n            # Dynamic adjustment of step-size based on success rate\n            if evaluations % (self.budget // 10) == 0:\n                step_size = min(step_size * (1 + success_counter / 10), 0.2 * (ub - lb))\n\n        return best_position, best_value", "configspace": "", "generation": 3, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {}}
{"id": "f95c0a23-027f-48fa-8a74-6b203f2eaee4", "fitness": 0.04330662824213887, "name": "EnhancedAdaptiveBiasedRandomWalk", "description": "Enhanced Adaptive Biased Random Walk (E-ABRW) â€“ An improved metaheuristic incorporating adaptive learning rate modulation and dynamic boundary reflection to effectively balance exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n        learning_rate = 0.05  # Initial learning rate\n\n        best_position = current_position\n        best_value = current_value\n        \n        while evaluations < self.budget:\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                step_size *= 1.0 - learning_rate  # Reduce step size\n                learning_rate *= 0.95  # Reduce learning rate for stability\n            else:\n                step_size *= 1.0 + learning_rate  # Increase step size\n                learning_rate *= 1.05  # Increase learning rate for exploration\n            \n            if evaluations % (self.budget // 10) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n            # Reflective boundary adjustment\n            for i in range(self.dim):\n                if current_position[i] < lb[i]:\n                    current_position[i] = lb[i] + abs(current_position[i] - lb[i])\n                elif current_position[i] > ub[i]:\n                    current_position[i] = ub[i] - abs(current_position[i] - ub[i])\n\n        return best_position, best_value", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04331 with standard deviation 0.00342.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.04456969109332809, 0.037326600055947345, 0.04249119320124417, 0.047200043882579146, 0.03960456055980244, 0.04501557752928842, 0.04781398021539929, 0.04013397831588683, 0.04560402932577412]}}
{"id": "4f415cf5-4ae4-45a9-b51a-96a68b49ef48", "fitness": 0.045841167717765884, "name": "DynamicStepSizeRandomWalk", "description": "\"Dynamic Step Size Random Walk (DSSRW) - An enhanced metaheuristic that dynamically adjusts step sizes using a momentum-inspired mechanism and resets based on diversity check to improve convergence in black box optimization tasks.\"", "code": "import numpy as np\n\nclass DynamicStepSizeRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n        momentum = np.zeros(self.dim)  # Momentum for direction persistence\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction with momentum influence\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction = 0.8 * momentum + 0.2 * direction\n            direction /= np.linalg.norm(direction)\n\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n                momentum = direction  # Update momentum\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.9\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.1\n                momentum = np.zeros(self.dim)  # Reset momentum on failure\n\n            # Adaptive mechanism to reset position if diversity is low\n            if evaluations % (self.budget // 10) == 0:\n                diversity_check = np.std(current_position)\n                if diversity_check < 0.01 * (ub - lb).mean():\n                    current_position = np.random.uniform(lb, ub, self.dim)\n                    current_value = func(current_position)\n                    evaluations += 1\n                    step_size = 0.1 * (ub - lb)  # Reset step size\n                    momentum = np.zeros(self.dim)  # Reset momentum\n\n        return best_position, best_value", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicStepSizeRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04584 with standard deviation 0.00244.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.04662632645164644, 0.04280549006512768, 0.042290201393710425, 0.04936586505731655, 0.04534495296607399, 0.044804281701704585, 0.050006122440080736, 0.045937016597226266, 0.04539025278700626]}}
{"id": "f68d288f-ff34-431b-b12c-803fff8f1c3f", "fitness": 0.044846499353079654, "name": "AdaptiveDirectionalSearch", "description": "Adaptive Directional Search (ADS) - An enhanced metaheuristic leveraging adaptive step size and directional memory to improve convergence rates and robustness in solving black box optimization problems.", "code": "import numpy as np\n\nclass AdaptiveDirectionalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n        directional_memory = np.zeros(self.dim)\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Compute new search direction based on past successes\n            direction = np.random.uniform(-1.0, 1.0, self.dim) + directional_memory\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Successful move; update position and directional memory\n                current_position = proposed_position\n                current_value = proposed_value\n                directional_memory = 0.5 * directional_memory + 0.5 * direction\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for fine-grained exploration\n                step_size *= 0.9\n            else:\n                # Unsuccessful move; increase step size for exploration\n                step_size *= 1.1\n                directional_memory = 0.9 * directional_memory  # Decay directional memory\n            \n            # Adaptive restart mechanism to escape local optima\n            if evaluations % (self.budget // 20) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n                directional_memory = np.zeros(self.dim)\n\n        return best_position, best_value", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDirectionalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04485 with standard deviation 0.00159.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.042017734080091795, 0.04393411064501296, 0.042896405466435694, 0.044522188440758614, 0.046530932340647535, 0.0454406107465688, 0.04510590774460632, 0.0471367870343411, 0.046033817679254074]}}
{"id": "bc30e8f5-85ed-494c-8ef9-9f5a0b5edb75", "fitness": 0.05000619973182157, "name": "AdaptiveBiasedRandomWalk", "description": "\"Enhanced ABRW - An improved metaheuristic using a dynamic adaptive strategy for faster convergence by adjusting random restarts and step size scaling more effectively.\"", "code": "import numpy as np\n\nclass AdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction and biased step size\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.9\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.05\n            \n            # Adaptive mechanism to reset position if stuck\n            if evaluations % (self.budget // 20) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05001 with standard deviation 0.00231.", "error": "", "parent_ids": ["55b13c06-132f-4f53-ba24-3588882656ed"], "operator": null, "metadata": {"aucs": [0.04750379197179666, 0.04609427133351773, 0.05013683513189726, 0.05029118131682053, 0.04880669532905224, 0.05307555819597587, 0.05094299461285612, 0.049440429582346734, 0.053764040112130984]}}
{"id": "d7da022f-3005-4443-88cb-11cc2d407217", "fitness": 0.047763548300091364, "name": "DynamicStepStrategy", "description": "\"Dynamic Step Strategy - A refined Adaptive Biased Random Walk using a dynamic step size adjustment and periodic diversification to enhance exploration and convergence speed.\"", "code": "import numpy as np\n\nclass DynamicStepStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        stagnation_counter = 0\n        stagnation_limit = self.budget // 10  # Trigger diversification after a certain number of stagnant evaluations\n\n        while evaluations < self.budget:\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                step_size *= 0.9\n                stagnation_counter = 0  # Reset stagnation counter\n            else:\n                step_size *= 1.1  # Increase more aggressively for better exploration\n                stagnation_counter += 1\n\n            if stagnation_counter > stagnation_limit:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n                stagnation_counter = 0  # Reset after diversification\n\n        return best_position, best_value", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicStepStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04776 with standard deviation 0.00193.", "error": "", "parent_ids": ["bc30e8f5-85ed-494c-8ef9-9f5a0b5edb75"], "operator": null, "metadata": {"aucs": [0.04694096529624292, 0.04404388748802279, 0.04628948716889014, 0.04969801536610585, 0.04664660547430266, 0.04901041296617903, 0.050342506527153885, 0.04725388183256529, 0.04964617258135973]}}
{"id": "d4a60eaf-5c22-43f1-9499-1c77b5a97375", "fitness": 0.05057749852811496, "name": "AdaptiveBiasedRandomWalk", "description": "Fine-tuned step size adaptation by adjusting exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveBiasedRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)  # Initial step size\n\n        best_position = current_position\n        best_value = current_value\n\n        while evaluations < self.budget:\n            # Random direction and biased step size\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n            \n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                # Move to better position\n                current_position = proposed_position\n                current_value = proposed_value\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Decrease step size for finer exploration (exploitation)\n                step_size *= 0.85  # Adjusted from 0.9\n            else:\n                # Increase step size for wider exploration\n                step_size *= 1.05\n            \n            # Adaptive mechanism to reset position if stuck\n            if evaluations % (self.budget // 20) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveBiasedRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05058 with standard deviation 0.00246.", "error": "", "parent_ids": ["bc30e8f5-85ed-494c-8ef9-9f5a0b5edb75"], "operator": null, "metadata": {"aucs": [0.05099765981934845, 0.046602392849946384, 0.04777816289547787, 0.0539884911279751, 0.04934142699135957, 0.050581260195624145, 0.05468964243406704, 0.04998157296654204, 0.05123687747269401]}}
{"id": "24793694-f21f-4276-a1a8-7d2f61e75849", "fitness": 0.06294132322773423, "name": "EnhancedAdaptiveRandomWalk", "description": "Enhanced exploration-exploitation balance using adaptive dynamic step size scaling based on success ratio.", "code": "import numpy as np\n\nclass EnhancedAdaptiveRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb) \n        best_position = current_position\n        best_value = current_value\n\n        success_count = 0\n        adapt_interval = 10  # Interval for adapting step size\n\n        while evaluations < self.budget:\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + (success_ratio - 0.5))\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06294 with standard deviation 0.00476.", "error": "", "parent_ids": ["d4a60eaf-5c22-43f1-9499-1c77b5a97375"], "operator": null, "metadata": {"aucs": [0.06302845447778638, 0.054420468890365226, 0.06325606891993596, 0.06685961814124486, 0.057625020830323725, 0.06711127125365013, 0.0677674720038195, 0.058378264496642296, 0.06802527003584002]}}
{"id": "6cacfeef-d274-4ae9-aa76-45907b5bcb07", "fitness": 0.07071957210902419, "name": "EnhancedAdaptiveRandomWalk", "description": "Introduce a dynamic adaptive mechanism leveraging both exploration and exploitation through a memory-based improvement strategy and adaptive mutation control.", "code": "import numpy as np\n\nclass EnhancedAdaptiveRandomWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb) \n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10  # Interval for adapting step size\n\n        while evaluations < self.budget:\n            direction = np.random.uniform(-1.0, 1.0, self.dim)\n            direction /= np.linalg.norm(direction)\n\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + (success_ratio - 0.5))\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveRandomWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07072 with standard deviation 0.01107.", "error": "", "parent_ids": ["24793694-f21f-4276-a1a8-7d2f61e75849"], "operator": null, "metadata": {"aucs": [0.07963950851126333, 0.06804073184622139, 0.054828538582740394, 0.08509085801683036, 0.07228971040758614, 0.058057472222782125, 0.08641071689794466, 0.07330196430529279, 0.05881664819055643]}}
{"id": "43ab637f-9264-4793-a177-7d30c0197f5d", "fitness": 0.07789753083243106, "name": "EnhancedNonlinearAdaptiveWalk", "description": "Introduce a novel multi-phase adaptive strategy incorporating nonlinear convergence and diversity maintenance to enhance exploration-exploitation balance and escape local optima.", "code": "import numpy as np\n\nclass EnhancedNonlinearAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with nonlinear convergence\n                direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Exploitation with focused exploration\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.5 * (success_ratio - 0.5))\n                \n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedNonlinearAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07790 with standard deviation 0.01060.", "error": "", "parent_ids": ["6cacfeef-d274-4ae9-aa76-45907b5bcb07"], "operator": null, "metadata": {"aucs": [0.08509630678839641, 0.07530351964759885, 0.06200705809466067, 0.09137884471228974, 0.08035699597832402, 0.06577286572774887, 0.09292138510824277, 0.08157600596878356, 0.06666479546583459]}}
{"id": "659c676b-c4da-46d2-90e8-1345675de2e7", "fitness": 0.07789753083243106, "name": "EnhancedNonlinearAdaptiveWalk", "description": "Introduce a memory-based dynamic phase adjustment to improve convergence by adapting between exploration and exploitation based on historical progress.", "code": "import numpy as np\n\nclass EnhancedNonlinearAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            # Dynamic adjustment based on memory value improvement\n            if memory_value < best_value:\n                phase_switch = min(phase_switch + 0.1, 0.9)\n\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with nonlinear convergence\n                direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Exploitation with focused exploration\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.5 * (success_ratio - 0.5))\n                \n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedNonlinearAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07790 with standard deviation 0.01060.", "error": "", "parent_ids": ["43ab637f-9264-4793-a177-7d30c0197f5d"], "operator": null, "metadata": {"aucs": [0.08509630678839641, 0.07530351964759885, 0.06200705809466067, 0.09137884471228974, 0.08035699597832402, 0.06577286572774887, 0.09292138510824277, 0.08157600596878356, 0.06666479546583459]}}
{"id": "bc8ffabe-6395-4509-8e30-c8a2ba1c51b0", "fitness": 0.07789245117983745, "name": "RefinedAdaptiveWalk", "description": "Introduce an adaptive step size strategy with memory-enhanced local intensification and dynamic phase transition to improve convergence and efficiency.", "code": "import numpy as np\n\nclass RefinedAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch_ratio = 0.5\n        dynamic_threshold = 0.1\n\n        while evaluations < self.budget:\n            # Dynamic phase transition based on performance improvement\n            if best_value - current_value > dynamic_threshold:\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n            else:\n                direction = np.random.normal(size=self.dim)\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.5 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 14, "feedback": "The algorithm RefinedAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07789 with standard deviation 0.01060.", "error": "", "parent_ids": ["43ab637f-9264-4793-a177-7d30c0197f5d"], "operator": null, "metadata": {"aucs": [0.08508829531168494, 0.07530347629110778, 0.06200112219034459, 0.09136967105056104, 0.08035694751053846, 0.06576644181689317, 0.09291190042668596, 0.08157595617330027, 0.06665824984742086]}}
{"id": "b338f275-775e-4797-b3eb-b3a9abdef514", "fitness": -Infinity, "name": "EnhancedNonlinearAdaptiveWalkV2", "description": "Implement a dynamic diversity-driven adaptive strategy utilizing multi-phase exploration-exploitation balance with strategic restarts and adaptive step-sizing to enhance convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedNonlinearAdaptiveWalkV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        restart_threshold = 0.01 * (ub - lb)\n        \n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with dynamic adaptation\n                direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Exploitation with fine-tuned search\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            \n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.5 * (success_ratio - 0.5))\n                \n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            # Strategic Restart\n            if np.linalg.norm(current_position - memory_position) < restart_threshold and evaluations / self.budget > phase_switch:\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 15, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["43ab637f-9264-4793-a177-7d30c0197f5d"], "operator": null, "metadata": {}}
{"id": "cbea3487-305a-4a07-9f6d-0313ef99bdf5", "fitness": 0.07845056689198229, "name": "EnhancedDynamicAdaptiveWalk", "description": "Implement a dynamic adaptive step-size and multi-directional search mechanism to enhance exploration and convergence in diverse landscapes of black-box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07845 with standard deviation 0.00458.", "error": "", "parent_ids": ["43ab637f-9264-4793-a177-7d30c0197f5d"], "operator": null, "metadata": {"aucs": [0.06996649292554158, 0.07637860285695308, 0.07789019434136368, 0.0744026926957927, 0.0815584044220824, 0.08315675364306607, 0.07546249896541568, 0.08281003551953292, 0.0844294266580925]}}
{"id": "ce296287-4750-41dc-9f93-c61e844493df", "fitness": 0.07845056689198229, "name": "EnhancedDynamicAdaptiveWalk", "description": "Incorporate a memory-based reinitialization strategy to prevent stagnation and enhance exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            if evaluations % (self.budget // 5) == 0 and best_value == memory_value:  # New: Reinitialization strategy\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07845 with standard deviation 0.00458.", "error": "", "parent_ids": ["cbea3487-305a-4a07-9f6d-0313ef99bdf5"], "operator": null, "metadata": {"aucs": [0.06996649292554158, 0.07637860285695308, 0.07789019434136368, 0.0744026926957927, 0.0815584044220824, 0.08315675364306607, 0.07546249896541568, 0.08281003551953292, 0.0844294266580925]}}
{"id": "cc7fe518-6408-42f2-93c5-61548e361720", "fitness": 0.07845056689198229, "name": "EnhancedDynamicAdaptiveReinforcedWalk", "description": "Integrate memory-based reinforcement and hybrid step-size control to improve adaptability and convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveReinforcedWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        reinforcement_factor = 0.05\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            # Reinforce memory-based exploration\n            if evaluations % (self.budget // 10) == 0:\n                memory_attempt_position = memory_position + reinforcement_factor * step_size * np.random.normal(size=self.dim)\n                memory_attempt_position = np.clip(memory_attempt_position, lb, ub)\n                memory_attempt_value = func(memory_attempt_position)\n                evaluations += 1\n                if memory_attempt_value < memory_value:\n                    memory_position = memory_attempt_position\n                    memory_value = memory_attempt_value\n\n        return best_position, best_value", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedDynamicAdaptiveReinforcedWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07845 with standard deviation 0.00458.", "error": "", "parent_ids": ["cbea3487-305a-4a07-9f6d-0313ef99bdf5"], "operator": null, "metadata": {"aucs": [0.06996649292554158, 0.07637860285695308, 0.07789019434136368, 0.0744026926957927, 0.0815584044220824, 0.08315675364306607, 0.07546249896541568, 0.08281003551953292, 0.0844294266580925]}}
{"id": "e2b3dafe-ecb7-49bd-ae4c-e92400181d5e", "fitness": 0.06474724419800865, "name": "MemoryAdaptiveDynamicWalk", "description": "Introduce a memory-based adaptive strategy with dynamic exploration-exploitation balance and stochastic perturbations to improve search efficiency and robustness in black-box optimization.", "code": "import numpy as np\n\nclass MemoryAdaptiveDynamicWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        perturbation_strength = 0.01\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n                if success_count < adapt_interval / 2:\n                    direction += np.random.normal(scale=0.5, size=self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                direction = np.random.normal(size=self.dim)\n                if success_count < adapt_interval / 2:\n                    direction += np.random.uniform(-0.5, 0.5, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                memory_position = proposed_position\n                memory_value = proposed_value\n            elif np.random.rand() < perturbation_strength:\n                # Stochastic perturbations to escape local minima\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 19, "feedback": "The algorithm MemoryAdaptiveDynamicWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06475 with standard deviation 0.00645.", "error": "", "parent_ids": ["cbea3487-305a-4a07-9f6d-0313ef99bdf5"], "operator": null, "metadata": {"aucs": [0.05742702051506532, 0.07004585700752763, 0.058303671615774544, 0.06084213220122359, 0.07451629667807658, 0.0617701000163442, 0.061647170374385274, 0.07558540347962095, 0.06258754589405979]}}
{"id": "b6175ffd-a585-4cfb-a39e-6bfbbf0bcdb0", "fitness": 0.07845056689198229, "name": "EnhancedDynamicAdaptiveWalk", "description": "Integrate a variable adapt interval to dynamically adjust exploration and exploitation based on success history in adaptive walk.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = max(5, self.budget // 100)\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07845 with standard deviation 0.00458.", "error": "", "parent_ids": ["cbea3487-305a-4a07-9f6d-0313ef99bdf5"], "operator": null, "metadata": {"aucs": [0.06996649292554158, 0.07637860285695308, 0.07789019434136368, 0.0744026926957927, 0.0815584044220824, 0.08315675364306607, 0.07546249896541568, 0.08281003551953292, 0.0844294266580925]}}
{"id": "468124d6-b9a1-4205-b78d-5bd02f523462", "fitness": 0.08006279976566742, "name": "EnhancedDynamicAdaptiveWalk", "description": "Fine-tune adaptive step-size scaling factor to improve search efficiency and convergence rate in the black-box optimization process.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.7 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08006 with standard deviation 0.00995.", "error": "", "parent_ids": ["cbea3487-305a-4a07-9f6d-0313ef99bdf5"], "operator": null, "metadata": {"aucs": [0.08853112098161664, 0.06976503159042902, 0.07023571613146751, 0.09522740057526535, 0.07420185240248289, 0.07469849330748612, 0.0968785298012862, 0.07526207294012377, 0.07576498016084932]}}
{"id": "a16470df-5d6a-4782-8fa1-1a1a644cafd2", "fitness": 0.07105576683125364, "name": "MemoryEnhancedAdaptiveWalk", "description": "Introduce dynamic memory-based perturbation and multi-scale exploration to enhance adaptation and convergence speed in black-box optimization.", "code": "import numpy as np\n\nclass MemoryEnhancedAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly with memory-based perturbation\n                    direction = np.random.normal(size=self.dim) + 0.1 * (memory_position - current_position)\n                else:\n                    # Adaptive directional focus with multi-scale exploration\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima with memory-based perturbation\n                    direction = np.random.uniform(-1.0, 1.0, self.dim) + 0.1 * (memory_position - current_position)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.8 * (success_ratio - 0.5))  # Further adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 22, "feedback": "The algorithm MemoryEnhancedAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07106 with standard deviation 0.00515.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.07085817304869702, 0.0617438712272782, 0.07103179603905663, 0.07537728251014453, 0.0654828742209137, 0.07555080114498336, 0.07645795915738074, 0.0663679807172699, 0.07663116341555876]}}
{"id": "4247dfa4-e26b-491d-941c-cbd37476fffe", "fitness": 0.08006279976566742, "name": "MemoryEnhancedAdaptiveWalk", "description": "Integrate a memory-based restart mechanism and adaptive local search loop to enhance exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass MemoryEnhancedAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n        restart_memory = current_position\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        local_search_counter = 0\n        local_search_limit = 5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n                local_search_counter = 0\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n                    restart_memory = proposed_position\n\n            else:\n                local_search_counter += 1\n                if local_search_counter >= local_search_limit:\n                    current_position = restart_memory\n                    local_search_counter = 0\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.7 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n                    restart_memory = random_checkpoint_position\n\n        return best_position, best_value", "configspace": "", "generation": 23, "feedback": "The algorithm MemoryEnhancedAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08006 with standard deviation 0.00995.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.08853112098161664, 0.06976503159042902, 0.07023571613146751, 0.09522740057526535, 0.07420185240248289, 0.07469849330748612, 0.0968785298012862, 0.07526207294012377, 0.07576498016084932]}}
{"id": "3ab39ce5-7aff-4ffb-a738-0ea75550ca23", "fitness": 0.07612299068904567, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve exploration by introducing a dynamic perturbation factor and refine the adaptive interval for better convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 8  # Changed from 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            perturbation_factor = np.random.uniform(0.9, 1.1)  # New line\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim) * perturbation_factor  # Modified line\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim) * perturbation_factor  # Modified line\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.7 * (success_ratio - 0.5)) \n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07612 with standard deviation 0.00541.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.07103426445798211, 0.07864911354373261, 0.0681077341750218, 0.07556139577056342, 0.08398431408228424, 0.07241232842796297, 0.07664395310707939, 0.08527422837204968, 0.07343958426473485]}}
{"id": "66099eeb-11ca-4639-914f-fff3aa9ca20a", "fitness": 0.07699158827656086, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce a dynamic memory reset mechanism and adaptive interval adjustments to improve exploration-exploitation balance and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        dynamic_reset_threshold = self.budget // 4\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.7 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                    adapt_interval = max(5, adapt_interval - 1)\n                else:\n                    adapt_interval = min(20, adapt_interval + 1)\n                success_count = 0\n\n            if evaluations % dynamic_reset_threshold == 0:\n                dynamic_reset_threshold *= 2\n                if memory_value < best_value:\n                    best_position = memory_position\n                    best_value = memory_value\n\n        return best_position, best_value", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07699 with standard deviation 0.01035.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.07971505137077317, 0.06015835634638467, 0.08028183842184622, 0.0851133441084051, 0.06376730917216478, 0.08576191216728801, 0.08641819414661489, 0.06462003301954322, 0.08708825573602763]}}
{"id": "13e2495e-e3e7-4e11-a6fa-9acb091c2afd", "fitness": 0.07209524522136784, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce a dynamic exploration-exploitation balance and random memory utilization to enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.6 * (success_ratio - 0.5))  # Slightly adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n                # Utilize random memory for potential escape\n                if np.random.rand() < 0.1:\n                    current_position = memory_position\n\n        return best_position, best_value", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07210 with standard deviation 0.00896.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.06989140551567963, 0.05840700634256757, 0.07812301210695882, 0.07432163207177356, 0.061902189034361954, 0.0834131278354806, 0.07537994503511514, 0.06272708996048149, 0.08469179908989188]}}
{"id": "a5e2a558-e0b1-49fb-9b63-313f08b776b4", "fitness": 0.08181570128764643, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adjustment based on success ratio and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08182 with standard deviation 0.00686.", "error": "", "parent_ids": ["468124d6-b9a1-4205-b78d-5bd02f523462"], "operator": null, "metadata": {"aucs": [0.07106004442037928, 0.07742560808382182, 0.08501981726728802, 0.07558029598486737, 0.0826873543083555, 0.09121536312811163, 0.07666097719562104, 0.08395942270705103, 0.09273242849332208]}}
{"id": "f76e3748-3576-49a7-a2b8-9887a9010df6", "fitness": 0.05829719793394997, "name": "EnhancedDynamicMemoryWalk", "description": "Enhance convergence by incorporating dynamic memory-based restart mechanisms and diversified directional search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicMemoryWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        memory_reset_factor = 0.25\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with diverse directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n                else:\n                    direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))\n\n                if success_ratio < 0.3:\n                    # Dynamic memory reset mechanism\n                    current_position = memory_position + memory_reset_factor * np.random.normal(size=self.dim)\n                    current_position = np.clip(current_position, lb, ub)\n                    current_value = func(current_position)\n                    evaluations += 1\n\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedDynamicMemoryWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05830 with standard deviation 0.00668.", "error": "", "parent_ids": ["a5e2a558-e0b1-49fb-9b63-313f08b776b4"], "operator": null, "metadata": {"aucs": [0.06398197501260783, 0.049312043021188745, 0.054131131029219626, 0.06791027330298915, 0.052212437328041816, 0.057321303697991155, 0.06884274370176657, 0.05289176506916193, 0.05807110924258285]}}
{"id": "85b441e3-8d51-4b16-ba55-e391aa6b44a7", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve adaptive search by modifying direction vector scaling and success ratio impact on step size.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.7, 0.7, self.dim)  # Changed from (-0.5, 0.5) to (-0.7, 0.7)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor from 0.75 to 0.9\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["a5e2a558-e0b1-49fb-9b63-313f08b776b4"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "58b4c1bb-b05a-49d6-af53-a44b2e33c290", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adjustment and exploration-exploitation balance with memory retention.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["a5e2a558-e0b1-49fb-9b63-313f08b776b4"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "91eea0bc-5add-4ee3-9029-f3161b384dd7", "fitness": 0.07962702348538936, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adjustment based on success ratio and exploration-exploitation balance, with a more aggressive adaptation.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 1.0 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07963 with standard deviation 0.00486.", "error": "", "parent_ids": ["a5e2a558-e0b1-49fb-9b63-313f08b776b4"], "operator": null, "metadata": {"aucs": [0.07918759775503081, 0.07774069762225355, 0.07064134713708037, 0.08458631842887243, 0.08298832744108631, 0.07513787731320842, 0.08589268108767689, 0.08425554714757244, 0.07621281743572306]}}
{"id": "bff436f9-cf92-4e90-a8e9-1298a151da1c", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and memory-based exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["a5e2a558-e0b1-49fb-9b63-313f08b776b4"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "c64025f9-9dc8-4317-a4f5-c9bfc6e76ecd", "fitness": 0.07753953317633398, "name": "EnhancedDynamicAdaptiveWalk", "description": "Integrate a dynamic learning rate and memory-driven phase transition for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = np.random.uniform(0.4, 0.6)  # Dynamic phase_switch\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07754 with standard deviation 0.00538.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07054373920866663, 0.07114568931069098, 0.08010935709145228, 0.07503729040294804, 0.07568012609959707, 0.08557090956324742, 0.07611156052578127, 0.07676445481949157, 0.08689267156513059]}}
{"id": "61a2f26f-b399-4828-95ee-a2d077e94a4e", "fitness": 0.05934783436538054, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and memory-based exploration with dynamic adapt_interval adjustment.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10  # This interval will now become dynamic\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n                adapt_interval = max(5, int(adapt_interval * (1 + 0.2 * (0.5 - success_ratio))))  # Dynamic adaptation\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05935 with standard deviation 0.00278.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.05956424890371814, 0.05616069966773485, 0.0547918401273364, 0.06312107734280681, 0.05947921111428034, 0.05801702806212472, 0.06396081231624862, 0.060260327093650146, 0.05877526466052485]}}
{"id": "d0f3d098-ec8b-4da2-9d40-a5181715a66d", "fitness": 0.0736477212237827, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and dynamic memory updates.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.45))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07365 with standard deviation 0.01190.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06311893958005488, 0.062078568931939526, 0.08539237701289915, 0.06696154882519456, 0.06585537076663561, 0.09163533756975073, 0.06787236071340419, 0.06675006697256403, 0.09316492064160165]}}
{"id": "3669c054-b896-4066-a873-5003f068ea31", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation, memory-based exploration, and integrating dynamic diversification.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly with enhanced randomness\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "f779c4a9-a01b-4af1-8df1-bfe2a845d6bc", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Refine step-size adaptation by adjusting the scaling factor for enhanced convergence stability.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "2f8e71ab-6ba1-45f1-806e-a4a9d085dd41", "fitness": 0.07511443028001032, "name": "AdvancedDynamicAdaptiveWalk", "description": "Further enhance convergence by introducing a dynamic balance between exploration and exploitation with a memory-triggered adaptive step-size mechanism.", "code": "import numpy as np\n\nclass AdvancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.3, 0.3, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n                else:\n                    direction = np.random.normal(size=self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Further increased scaling factor\n\n                if success_ratio < 0.4:  # Adjusted success ratio threshold for memory recall\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 38, "feedback": "The algorithm AdvancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328786312207, 0.056737313860647065, 0.07784251804675202, 0.08573308203082186, 0.06009893777134978, 0.0830787380577721, 0.08706240808445942, 0.06089069395712843, 0.08434289284804009]}}
{"id": "0a531d08-c8a2-423f-a183-d4a2cd6d6a2e", "fitness": 0.08469429188843368, "name": "EnhancedDynamicAdaptiveWalk", "description": "Strengthen convergence by refining step-size bounds and adaptive memory usage.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= np.clip(1 + 0.85 * (success_ratio - 0.5), 0.01, 1.0)  # Added bound to step-size scaling\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08469 with standard deviation 0.00841.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.0703635801113538, 0.08643708716699305, 0.08455823789360106, 0.07484332631053703, 0.09289563683744217, 0.09063421130895111, 0.07591417535115375, 0.0944841307555172, 0.09211824126035395]}}
{"id": "d3d87625-a00b-4afc-9edc-ee9f74845ba7", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalkV2", "description": "Improve convergence by integrating a dynamic memory mechanism with adaptive step-size scaling for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalkV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        dynamic_memory = []\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n                dynamic_memory.append((proposed_position, proposed_value))\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor for responsiveness\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n                if success_ratio > 0.65 and dynamic_memory:\n                    memory_position, memory_value = min(dynamic_memory, key=lambda x: x[1])\n                    dynamic_memory.clear()\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedDynamicAdaptiveWalkV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "3a7a7504-6106-432d-ab07-c7d28641198c", "fitness": 0.0833147985754954, "name": "AdaptiveMemoryGuidedDynamicWalk", "description": "Adaptive Memory-Guided Dynamic Walk: Enhance convergence by utilizing adaptive memory-driven exploration and position reinforcement.", "code": "import numpy as np\n\nclass AdaptiveMemoryGuidedDynamicWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        memory_factor = 0.2\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive memory influence\n                memory_influence = np.random.rand(self.dim) < memory_factor\n                direction = np.random.normal(size=self.dim) * (1 - memory_influence) + memory_influence * (memory_position - current_position)\n            else:\n                # Phase 2: Memory-Guided Intensification\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveMemoryGuidedDynamicWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08331 with standard deviation 0.00796.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.0797780808857278, 0.08721487965730568, 0.07066370954442314, 0.08521453496362819, 0.0937096383228686, 0.07516915563864612, 0.08652997287932906, 0.09530678201546183, 0.07624643327206815]}}
{"id": "fa3c73e2-aadf-48ac-922b-473b035755d6", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve local exploitation by modifying the step size scaling factor.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Changed scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "55e228f0-8de9-471a-94dc-7ce4d7ca2f31", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce a dynamic phase switch based on success ratio for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            # Dynamic phase switch based on success ratio\n            phase_switch = 0.5 + 0.1 * (success_count / adapt_interval - 0.5)\n\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "0b59885c-763d-4c7d-bf66-6c7f78cc66e2", "fitness": 0.07511459029552442, "name": "EnhancedDynamicNeighborhoodWalk", "description": "Leverage dynamic neighborhood search with adaptive memory reinforcement to enhance convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedDynamicNeighborhoodWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_positions = [current_position]\n        memory_values = [current_value]\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive neighborhood search\n                if success_count < adapt_interval / 2:\n                    # Explore using larger neighborhoods\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Focused exploration\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Diversified search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                # Update memory\n                memory_positions.append(proposed_position)\n                memory_values.append(proposed_value)\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor for dynamic adaptation\n\n                if success_ratio < 0.35:\n                    best_memory_idx = np.argmin(memory_values)\n                    current_position = memory_positions[best_memory_idx]\n\n                # Maintain recent memories\n                memory_positions = memory_positions[-5:]\n                memory_values = memory_values[-5:]\n\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < best_value:\n                    best_position = random_checkpoint_position\n                    best_value = random_checkpoint_value\n                    memory_positions.append(random_checkpoint_position)\n                    memory_values.append(random_checkpoint_value)\n\n        return best_position, best_value", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedDynamicNeighborhoodWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "26172884-c9c1-41e8-9e63-51120bb5327a", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve convergence by introducing dynamic neighborhood scaling and multi-phase adaptive memory utilization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        neighborhood_factor = 1.0\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with dynamic neighborhood scaling\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-neighborhood_factor, neighborhood_factor, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with adaptive memory utilization\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-neighborhood_factor * 2, neighborhood_factor * 2, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n                neighborhood_factor *= 1.1  # Increase neighborhood on success\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                    neighborhood_factor = max(0.1, neighborhood_factor * 0.5)  # Reset neighborhood factor on failure to explore other regions\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "66d9ae86-ff93-4cae-a8ff-bb1a8be1f529", "fitness": 0.0817964378005309, "name": "EnhancedDynamicAdaptiveWalkV2", "description": "Integrate dynamic multi-phase adaptation with intelligent selection and diverse memory exploitation to enhance global convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalkV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.4  # Adjusted for earlier phase switching\n\n        while evaluations < self.budget:\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 1.0 * (success_ratio - 0.5))  # Further enhanced scaling factor\n\n                if success_ratio < 0.4:  # Optimized success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 15) == 0:  # More frequent checkpoints\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedDynamicAdaptiveWalkV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08180 with standard deviation 0.00617.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08034664629636323, 0.08239476048313965, 0.07082077902024098, 0.08585241652310038, 0.08822181638722504, 0.075315478409128, 0.08718586709093823, 0.08964061175031834, 0.0763895642443243]}}
{"id": "321a86a5-c46f-494b-a974-92ea9f2e8af3", "fitness": 0.08181570128764643, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by incorporating a dynamic memory-based adaptive step-size control and a multi-directional search strategy.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with multi-directional search strategy\n                if success_count < adapt_interval / 2:\n                    # Explore with varied directionality\n                    direction = np.random.multivariate_normal(mean=np.zeros(self.dim), cov=np.eye(self.dim))\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08182 with standard deviation 0.00686.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07106004442037928, 0.07742560808382182, 0.08501981726728802, 0.07558029598486737, 0.0826873543083555, 0.09121536312811163, 0.07666097719562104, 0.08395942270705103, 0.09273242849332208]}}
{"id": "a3136516-c153-403d-a7c8-2dd8c2ddfa17", "fitness": 0.07061679835175722, "name": "AdaptiveQuantumInspiredWalk", "description": "Adaptive Quantum-Inspired Walk: Integrate quantum-inspired superposition with dynamic step-size and stochastic tunneling for enhanced global exploration and local exploitation.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Quantum-inspired superposition phase\n                amplitude = np.random.uniform(-1, 1, self.dim)\n                quantum_direction = (np.random.choice([-1, 1], self.dim) * amplitude) / np.linalg.norm(amplitude)\n            else:\n                # Stochastic tunneling phase\n                quantum_direction = np.random.normal(size=self.dim)\n                quantum_direction /= np.linalg.norm(quantum_direction)\n\n            proposed_position = current_position + step_size * quantum_direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveQuantumInspiredWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07062 with standard deviation 0.00646.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.0713194426591991, 0.059431531210677346, 0.07163022635786365, 0.07586123015708346, 0.06298517820069427, 0.076225972291599, 0.07694723033357376, 0.0638242361820528, 0.07732613777307162]}}
{"id": "f3353682-8bcf-417f-87fe-f58451010445", "fitness": 0.08159105010745604, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by integrating adaptive diversification using LÃ©vy flights and refined step-size adjustments.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with LÃ©vy flight\n                direction = np.random.standard_cauchy(size=self.dim)\n                direction /= np.linalg.norm(direction)\n                direction *= np.random.normal(0, step_size, size=self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            proposed_position = current_position + direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08159 with standard deviation 0.00632.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07853070160664355, 0.07088699693346756, 0.0835529715596427, 0.08382634978006664, 0.0754211880229605, 0.08951765979883874, 0.08510534368209144, 0.07650579356195342, 0.09097244602143983]}}
{"id": "f7002fdc-2c66-493a-965a-c85c0a8aa876", "fitness": 0.0621969153413261, "name": "AdaptiveMomentumWalk", "description": "Introduce dual-phase search strategy with adaptive momentum to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMomentumWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n        momentum = np.zeros(self.dim)\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search and momentum\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with adaptive momentum\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            momentum = 0.9 * momentum + direction\n            proposed_position = current_position + step_size * momentum\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveMomentumWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06220 with standard deviation 0.00581.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06680657737957063, 0.056462066828652624, 0.05529856256721677, 0.07096562071479795, 0.05980094312140494, 0.05856378602528778, 0.07195569934120738, 0.06058705893558525, 0.059331923158211564]}}
{"id": "9a2f9f3b-868c-4e73-9ec6-643e7b039ec0", "fitness": 0.0728773443288315, "name": "EnhancedDynamicAdaptiveWalk", "description": "Optimize convergence by refining adaptive techniques and introducing strategic exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                else:\n                    current_position = best_position  # Strategic shift to best known position\n                success_count = 0\n\n            if evaluations % (self.budget // 15) == 0:  # More frequent checkpointing\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07288 with standard deviation 0.00292.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07134232637315774, 0.06743384798156382, 0.06999066987392977, 0.0758857515800585, 0.07166119402004567, 0.0744392032158987, 0.07697221873376847, 0.07266863723700667, 0.07550224994405419]}}
{"id": "998cb7a5-5d0a-40be-918a-431ecc927961", "fitness": 0.0621969153413261, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve step-size adaptation with momentum-based direction refinement.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        momentum = np.zeros(self.dim)  # Added momentum for direction refinement\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            momentum = 0.9 * momentum + direction  # Refine direction with momentum\n            proposed_position = current_position + step_size * momentum\n\n            proposed_position = np.clip(proposed_position, lb, ub)\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06220 with standard deviation 0.00581.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06680657737957063, 0.056462066828652624, 0.05529856256721677, 0.07096562071479795, 0.05980094312140494, 0.05856378602528778, 0.07195569934120738, 0.06058705893558525, 0.059331923158211564]}}
{"id": "f3a3d11b-5f0d-485f-bbc9-2c1ce2562a4c", "fitness": 0.08464969198296324, "name": "RefinedAdaptiveMemoryExploration", "description": "Enhance global exploration and local exploitation via adaptive memory-based deviations and dynamic feedback.", "code": "import numpy as np\n\nclass RefinedAdaptiveMemoryExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with enhanced adaptive search\n                if success_count < adapt_interval / 2:\n                    # Broad exploration\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Memory-based focused exploration\n                    direction = memory_position - current_position\n            else:\n                # Phase 2: Exploitation with adaptive deviations\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Memory-based deviation to escape local minima\n                    direction = memory_position - current_position\n\n            if np.linalg.norm(direction) > 0:\n                direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 53, "feedback": "The algorithm RefinedAdaptiveMemoryExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08465 with standard deviation 0.00839.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07035624832919407, 0.08641639669606171, 0.08446518720861895, 0.07483527481743901, 0.09287141717983738, 0.09052856224419714, 0.0759059410530345, 0.09445894558106205, 0.09200925473722432]}}
{"id": "98abd160-22cb-4205-8a38-83885d0380da", "fitness": 0.05616122281612238, "name": "StochasticTunnelingAdaptiveWalk", "description": "Utilize stochastic tunneling and adaptive memory management to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass StochasticTunnelingAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        tunnel_intensity = 0.1\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with stochastic tunneling\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with adaptive memory use\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            # Stochastic tunneling acceptance criteria\n            tunneling_factor = np.exp(-tunnel_intensity * max(0, proposed_value - current_value))\n            acceptance_probability = min(1, tunneling_factor)\n\n            if proposed_value < current_value or np.random.rand() < acceptance_probability:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 54, "feedback": "The algorithm StochasticTunnelingAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05616 with standard deviation 0.00515.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.049901191566736225, 0.05117274965673446, 0.060307680351069926, 0.0528268299732223, 0.05417498877477367, 0.06391251434115519, 0.053512150213296805, 0.05487892230397051, 0.06476397816414237]}}
{"id": "87243b08-11a8-40ed-b4d5-e65347158c38", "fitness": 0.08098762856359355, "name": "EnhancedDynamicAdaptiveWalk", "description": "Boost performance by optimizing adaptive directional search and memory-based exploration through refined step-size scaling.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.95 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08099 with standard deviation 0.01261.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.09099146714000794, 0.06324975227200524, 0.07682127847110154, 0.09791390316976589, 0.06711447813833504, 0.08195339163142668, 0.09962267501748845, 0.06803093380873837, 0.0831907774234728]}}
{"id": "211d5f5b-a02c-41b9-88f8-77c56daa1c0f", "fitness": 0.07037771730050918, "name": "EnhancedDynamicAdaptiveWalk", "description": "Fine-tune convergence by leveraging adaptive memory-based search and refined step-size control with hybrid exploration strategies.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 15\n        phase_switch = 0.6\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Diverse exploration with dynamic adaptation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n                else:\n                    direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Focused exploitation and escape strategy\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Further refined scaling factor\n\n                if success_ratio < 0.3:  # Refined success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07038 with standard deviation 0.00482.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06200131550782484, 0.07165825972582884, 0.06804254918560615, 0.06575597642106479, 0.07627133367135941, 0.07231511290735582, 0.06664493223538026, 0.07737616126730962, 0.07333381478285284]}}
{"id": "c9f79fb1-4ae3-4fc4-b976-08df1c2ccdda", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Incorporate dynamic boundary adjustments and progressive memory-guided exploration for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "d6f1a5d5-8d63-4f78-878f-db1bfd81080f", "fitness": 0.07583102271895432, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by integrating adaptive memory retention and dynamic phase-switching.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.3  # Changed phase_switch threshold\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim) * (1 + (phase_switch / 2))  # Modified direction\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim) * (1 + (phase_switch / 2))  # Modified direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 2  # Adjusted success count increment\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 5:  # Adjusted adaptation condition\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.3))  # Modified scaling\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07583 with standard deviation 0.00501.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07661092907912992, 0.07330610302957352, 0.06693556286232294, 0.08175687749542393, 0.07819985725869671, 0.07114428895357128, 0.0829989697500052, 0.07937901282943083, 0.07214760321243463]}}
{"id": "646aa6e3-0107-494d-8b09-93e72b725710", "fitness": 0.06168959715774135, "name": "InertiaAdaptiveRestartWalk", "description": "Improve convergence by integrating adaptive inertia and strategic restart mechanisms.", "code": "import numpy as np\n\nclass InertiaAdaptiveRestartWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        velocity = np.zeros(self.dim)\n        inertia_weight = 0.9\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        restart_interval = self.budget // 4\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive inertia\n                direction = np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with inertia and restart\n                direction = np.random.uniform(-0.5, 0.5, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            velocity = inertia_weight * velocity + step_size * direction\n            proposed_position = current_position + velocity\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % restart_interval == 0:\n                random_restart_position = np.random.uniform(lb, ub, self.dim)\n                random_restart_value = func(random_restart_position)\n                evaluations += 1\n                if random_restart_value < memory_value:\n                    memory_position = random_restart_position\n                    memory_value = random_restart_value\n\n        return best_position, best_value", "configspace": "", "generation": 59, "feedback": "The algorithm InertiaAdaptiveRestartWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06169 with standard deviation 0.00861.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07020205249985345, 0.05372473811459011, 0.05311953472170283, 0.074671376259833, 0.05688820530794414, 0.05624733474428212, 0.07573973320755645, 0.05763147124105916, 0.05698192832285087]}}
{"id": "0bd355c1-bd77-43e5-90e1-f333464d7a56", "fitness": 0.07138823662289502, "name": "EnhancedDynamicAdaptiveWalk", "description": "Integrate a multi-scale directional search and adaptive memory reset for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with multi-scale search\n                if success_count < adapt_interval / 2:\n                    # Wider exploration\n                    direction = np.random.normal(size=self.dim) + np.random.uniform(-1, 1, self.dim)\n                else:\n                    # Focused adaptive search\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation and escape\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim) * 0.5\n                else:\n                    # Escape strategy\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07139 with standard deviation 0.00373.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06432365111588223, 0.07022950838135378, 0.0700132027389665, 0.06824653810779813, 0.07470293744622258, 0.07448053291223988, 0.06917704111792755, 0.07577220115198213, 0.07554851663368245]}}
{"id": "ade17e19-bfdd-48c7-868a-1aaa721e9c21", "fitness": 0.07423663389714306, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence using multi-layered adaptive step-size and dynamic memory-based search for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.4  # More time for exploitation phase\n        inertia_weight = 0.9  # Inertia for momentum-based search\n        velocity = np.zeros(self.dim)\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            velocity = inertia_weight * velocity + step_size * direction\n            proposed_position = current_position + velocity\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                inertia_weight *= 0.95  # Gradually reduce inertia weight\n                success_count = 0\n\n            if evaluations % (self.budget // 15) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07424 with standard deviation 0.00413.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06917765755960381, 0.07515388392604061, 0.06817603810671025, 0.07357241226869804, 0.08015113609143976, 0.07245121652165143, 0.0746222423532632, 0.08135471173064457, 0.07347040651623593]}}
{"id": "ea6814a8-a8e5-46b6-9f34-45b9932d3c84", "fitness": 0.08128816267388674, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and memory-based exploration with strategic checkpoint adjustments.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 10) == 0:  # Changed checkpoint frequency\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08129 with standard deviation 0.00699.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07059154789316324, 0.08486343445844435, 0.07660529295128393, 0.07509178872396083, 0.0910522168999115, 0.08171150917168568, 0.0761677960525694, 0.09256766861433552, 0.08294220929962615]}}
{"id": "e8873ddd-676a-4680-8c34-4fe37a229a38", "fitness": 0.07499292988687534, "name": "EnhancedDynamicAdaptiveWalk", "description": "A novel stochastic step strategy with improved exploration-exploitation trade-off using dynamic feedback loops.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            exploration_factor = np.exp(-evaluations / self.budget)\n            exploitation_factor = 1.0 - exploration_factor\n\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Improved Exploration with stochastic step strategy\n                direction = np.random.normal(size=self.dim) * exploration_factor\n            else:\n                # Phase 2: Enhanced Exploitation with adaptive feedback\n                direction = np.random.uniform(-1.0, 1.0, self.dim) * exploitation_factor\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Further adjusted scaling factor\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold for feedback\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07499 with standard deviation 0.01149.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024329447288714, 0.056737304923502596, 0.07750689618427375, 0.0857330894331172, 0.06009892821878138, 0.08270476143197825, 0.08706241569309303, 0.06089068425343813, 0.08395899437080656]}}
{"id": "9e7ad70d-1395-4a31-851a-980a36a77dca", "fitness": 0.08493081275154812, "name": "ImprovedAdaptiveMemoryWalk", "description": "Improve convergence by integrating dynamic multi-phase step-size adaptation with diversity-enhancing memory mechanism.", "code": "import numpy as np\n\nclass ImprovedAdaptiveMemoryWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_positions = [current_position]\n        memory_values = [current_value]\n        \n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        memory_rate = 0.1\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < min(memory_values):\n                    memory_positions.append(proposed_position)\n                    memory_values.append(proposed_value)\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35 and memory_positions:\n                    current_position = memory_positions[np.argmin(memory_values)]\n                    memory_positions = memory_positions[-int(memory_rate * len(memory_positions)):]\n                    memory_values = memory_values[-int(memory_rate * len(memory_values)):]\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < min(memory_values):\n                    memory_positions.append(random_checkpoint_position)\n                    memory_values.append(random_checkpoint_value)\n\n        return best_position, best_value", "configspace": "", "generation": 64, "feedback": "The algorithm ImprovedAdaptiveMemoryWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "a03f1147-23f6-49f0-a995-ae55e85a97ac", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by introducing dynamic memory adjustment and random perturbations during stagnation.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        memory_update_interval = 25  # New parameter for dynamic memory adjustment\n        perturbation_factor = 0.05  # New parameter for random perturbations\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % memory_update_interval == 0:  # Dynamic memory adjustment\n                if evaluations % (self.budget // 20) == 0:\n                    random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                    random_checkpoint_value = func(random_checkpoint_position)\n                    evaluations += 1\n                    if random_checkpoint_value < memory_value:\n                        memory_position = random_checkpoint_position\n                        memory_value = random_checkpoint_value\n\n            if evaluations % (self.budget // 10) == 0:  # Introduce random perturbations\n                perturbation = np.random.uniform(-perturbation_factor, perturbation_factor, self.dim)\n                current_position = np.clip(current_position + perturbation, lb, ub)\n\n        return best_position, best_value", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "a59717d3-33a4-4a25-9fb4-0b2830ada133", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Adaptive Multi-Phase Search with Enhanced Memory Utilization for Robust Convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Adaptive Exploration\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Memory-Driven Exploitation\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Increased scaling factor for step size\n\n                if success_ratio < 0.35:\n                    current_position = memory_position  # Return to best memory position if convergence slows\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                # Random checkpoint for potential memory update\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "c904945e-f680-4b8e-a2c5-973b805bb330", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve phase-switch strategy by dynamically adjusting based on performance metrics.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5  # Changed line: phase_switch = 1 - (best_value / current_value)\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "44e111ed-a944-45ec-b8cc-3ebbeee6f05d", "fitness": 0.07511459029552442, "name": "ImprovedDynamicAdaptiveWalk", "description": "Incorporate dynamic memory-based exploration and exploitative strategies with localized neighborhood search to enhance convergence.", "code": "import numpy as np\n\nclass ImprovedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.3, 0.3, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.7, 0.7, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))\n\n                if success_ratio < 0.25:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 68, "feedback": "The algorithm ImprovedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "71e843d0-4e91-42f2-ae15-75c878f2520f", "fitness": 0.06305611649048028, "name": "MultiScaleAdaptiveWalk", "description": "Introduce multi-scale search and adaptive memory to balance exploration and exploitation for enhanced convergence.", "code": "import numpy as np\n\nclass MultiScaleAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Enhanced Exploration with multi-scale search\n                scale_factor = 1.0 if success_count < adapt_interval / 2 else 0.5\n                direction = np.random.uniform(-scale_factor, scale_factor, self.dim)\n            else:\n                # Phase 2: Adaptive Exploitation\n                scale_factor = 0.5 if success_count < adapt_interval / 2 else 1.0\n                direction = np.random.uniform(-scale_factor, scale_factor, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 69, "feedback": "The algorithm MultiScaleAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06306 with standard deviation 0.00662.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.05717578171897286, 0.06865553927462897, 0.05513945975279089, 0.06057428684501642, 0.07300231152158065, 0.05838912519555661, 0.06137522283822716, 0.07403994250237533, 0.05915337876517357]}}
{"id": "dec19811-8b77-4ceb-9124-e597e45cd18e", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Incorporate adaptive escape strategies and historical memory for enhanced convergence in dynamic environments.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            # Normalize and propose new position\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "7c598c69-afa2-4f91-af43-300793905b4b", "fitness": 0.07511459029552442, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and memory-based exploration with fine-tuned adaptation parameters.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08024328621180932, 0.05673732942556686, 0.07784294597695351, 0.0857330801815015, 0.060098954408077554, 0.083079215846944, 0.08706240618359251, 0.06089071085705766, 0.08434338356821691]}}
{"id": "d9625fed-33ce-4f40-92e3-f0a11c835c9a", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation and memory-based exploration with a slightly stricter success ratio threshold.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold to be stricter\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "014f7619-ccdf-4381-a995-5fa7779a91d2", "fitness": 0.07851033283242118, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence with adaptive direction scaling and memory recall mechanism for improved exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.4  # Adjusted phase switch\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction *= np.random.uniform(0.8, 1.2)  # Adaptive scaling\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:  # New threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07851 with standard deviation 0.00831.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08481661606823865, 0.0681273765210707, 0.07140513596138987, 0.0909807503664053, 0.07237838636779692, 0.07595741343633222, 0.09249012668476653, 0.07339106207045853, 0.07704612801533184]}}
{"id": "42c72f22-01e3-4f39-91dd-284a8aefd593", "fitness": 0.08001417114570909, "name": "GradientInformedAdaptiveMemoryWalk", "description": "Integrate gradient-informed exploration and dynamic adaptive memory to enhance convergence and robustness.", "code": "import numpy as np\n\nclass GradientInformedAdaptiveMemoryWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with gradient-informed search\n                direction = np.random.normal(size=self.dim)\n                if success_count >= adapt_interval / 2:\n                    gradient_estimate = (current_value - memory_value) / np.linalg.norm(current_position - memory_position)\n                    direction = direction * gradient_estimate\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.95 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 74, "feedback": "The algorithm GradientInformedAdaptiveMemoryWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08001 with standard deviation 0.01262.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.09008676966975215, 0.06233966626169385, 0.07571671659650248, 0.09701668595340873, 0.0662104580324342, 0.08083403243101439, 0.09872731070145913, 0.06712837778146519, 0.08206752288365171]}}
{"id": "55a29b18-7a12-46c7-a029-cb47fc488bb2", "fitness": 0.08322409271304998, "name": "EnhancedDynamicAdaptiveWalkV2", "description": "Introduce multi-scale directional search and adaptive memory reset to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalkV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with multi-scale directional search\n                scale_modifier = 1.0 if success_count < adapt_interval / 2 else 0.5\n                direction = np.random.normal(size=self.dim) if np.random.rand() < 0.7 else np.random.uniform(-1.0, 1.0, self.dim)\n            else:\n                # Phase 2: Exploitation with enhanced local search\n                scale_modifier = 0.5 if success_count < adapt_interval / 2 else 1.0\n                direction = np.random.normal(size=self.dim) if np.random.rand() < 0.3 else np.random.uniform(-0.5, 0.5, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + scale_modifier * step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            # Adaptive memory reset\n            if evaluations % (self.budget // 10) == 0:\n                if np.random.rand() < 0.1:\n                    memory_position = np.random.uniform(lb, ub, self.dim)\n                    memory_value = func(memory_position)\n                    evaluations += 1\n\n        return best_position, best_value", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedDynamicAdaptiveWalkV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08322 with standard deviation 0.00316.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.0792027740354262, 0.07775326493586765, 0.08061919473425494, 0.08461074683263314, 0.0830135905024284, 0.08613825710731104, 0.0859196279604012, 0.08428460565370233, 0.08747477265542491]}}
{"id": "b72bc190-e4bb-48ef-8243-ee51193c0d4e", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Incorporate random restart with adaptive memory to escape deep local minima.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            if evaluations % (self.budget // 5) == 0:  # New restart logic\n                current_position = np.random.uniform(lb, ub, self.dim)  # Restart strategy applied\n\n        return best_position, best_value", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "546b5eaa-a788-435d-b853-f7021a239a55", "fitness": 0.0809822133135274, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by refining step-size adaptation, introducing directional memory, and balanced exploration-exploitation phases.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n        direction_memory = np.zeros(self.dim)  # Added directional memory\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim)\n                if success_count > adapt_interval / 3:\n                    # Use directional memory\n                    direction += 0.3 * direction_memory\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                direction_memory = direction  # Update directional memory\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.95 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.3:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08098 with standard deviation 0.01260.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.09099155297364647, 0.06327233757608608, 0.07678409737621628, 0.0979140023480064, 0.06713890697639158, 0.08191205448676608, 0.09962277781014761, 0.06805582210893246, 0.0831483681655536]}}
{"id": "ae5bef31-6751-4136-8a20-923fe1fd27ad", "fitness": 0.07494554773140832, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by improving diversification steps and balancing exploration-exploitation with better adaptive strategies.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.15 * (ub - lb)  # Adjusted initial step size\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 8  # Adjusted adaptation interval\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusted scaling factor\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07495 with standard deviation 0.00744.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07984702007326627, 0.06394255155023454, 0.07070028688106655, 0.08531019451261013, 0.06784011422392155, 0.07519862914251219, 0.08663289906902971, 0.0687643642145539, 0.07627386991548013]}}
{"id": "aee974ee-2bcd-453b-b657-6630a55f749c", "fitness": 0.08098762856359355, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance convergence by implementing a more dynamic step-size adjustment and emphasizing memory utilization in the search process.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.95 * (success_ratio - 0.5))  # Slightly increased scaling factor and adjusted to 0.95\n\n                if success_ratio < 0.3:  # Adjusted success ratio threshold for memory utilization\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08099 with standard deviation 0.01261.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.09099146714000794, 0.06324975227200524, 0.07682127847110154, 0.09791390316976589, 0.06711447813833504, 0.08195339163142668, 0.09962267501748845, 0.06803093380873837, 0.0831907774234728]}}
{"id": "404d1a91-f870-429c-b012-7e61212caf9a", "fitness": 0.08486851287957534, "name": "EnhancedDynamicAdaptiveWalk", "description": "Adjust the exploitation phase to include a memory-enhanced focus for improved convergence.  ", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim) + memory_position  # Memory-enhanced focus\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08487 with standard deviation 0.00850.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036346907004443, 0.08635213603798109, 0.08511651541916176, 0.07484320443383863, 0.09279839968617754, 0.09127025765811547, 0.07591405072400481, 0.09438360432968285, 0.09277497855717143]}}
{"id": "f1d6b1c7-2012-4b57-9b61-b0967a36fcad", "fitness": 0.08493081275154812, "name": "EnhancedDualMemoryAdaptiveWalk", "description": "Integrate a dual-memory approach with diversified directional search to enhance convergence and escape local optima.", "code": "import numpy as np\n\nclass EnhancedDualMemoryAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n        secondary_memory_position = current_position\n        secondary_memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with diversified directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    secondary_memory_position = memory_position\n                    secondary_memory_value = memory_value\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    if memory_value < secondary_memory_value:\n                        current_position = memory_position\n                    else:\n                        current_position = secondary_memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    secondary_memory_position = memory_position\n                    secondary_memory_value = memory_value\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedDualMemoryAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "85947aa6-9aff-41c8-91ad-ee51a4e6428a", "fitness": 0.08043298117227217, "name": "MultiPhaseDynamicAdaptiveWalk", "description": "Introduce multi-phase exploration with dynamic step-size modulation and adaptive search radius to improve convergence efficiency.", "code": "import numpy as np\n\nclass MultiPhaseDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch1, phase_switch2 = 0.3, 0.6\n\n        while evaluations < self.budget:\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < phase_switch1:\n                # Phase 1: Broad exploration\n                direction = np.random.normal(size=self.dim)\n            elif phase_ratio < phase_switch2:\n                # Phase 2: Focused adaptive search\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 3: Intensive exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.95 * (success_ratio - 0.5))  # Fine-tuned scaling factor\n\n                if success_ratio < 0.3:  # Lower success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 15) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 82, "feedback": "The algorithm MultiPhaseDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08043 with standard deviation 0.00632.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08048658975626888, 0.069126180578861, 0.08019715376944503, 0.08598822372922965, 0.07351205617954137, 0.08568853283197186, 0.0873202692245928, 0.07455951418829154, 0.08701831029224738]}}
{"id": "c7cde28c-4812-4b33-a30b-ebdb7f64b5a3", "fitness": 0.08490986395621497, "name": "DynamicMultiPhaseOptimization", "description": "Introduce dynamic multi-phase exploration and exploitation with adaptive memory reset for improved convergence.", "code": "import numpy as np\n\nclass DynamicMultiPhaseOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch1 = 0.3\n        phase_switch2 = 0.7\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch1:\n                # Phase 1: Broad Exploration\n                direction = np.random.normal(size=self.dim)\n            elif evaluations / self.budget < phase_switch2:\n                # Phase 2: Focused Exploration\n                direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 3: Intensive Exploitation\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.25:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 83, "feedback": "The algorithm DynamicMultiPhaseOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08491 with standard deviation 0.00853.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07037323061219503, 0.08650141514668641, 0.0850693244856412, 0.07485390024786798, 0.09296878547563325, 0.09121716703620264, 0.07592498318929564, 0.09455962352872127, 0.09272034588369138]}}
{"id": "164a5a19-6330-49cc-bbf0-fbba9cd26d20", "fitness": 0.08493081275154812, "name": "EnhancedPhaseAwareAdaptiveWalk", "description": "Introduce a phase-aware memory reinforcement strategy to optimize exploratory and exploitative transitions.", "code": "import numpy as np\n\nclass EnhancedPhaseAwareAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        phase_memory = {'explore': current_position, 'exploit': current_position}\n        phase_memory_value = {'explore': current_value, 'exploit': current_value}\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive reinforcement\n                phase = 'explore'\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Exploitation with enhanced reinforcement\n                phase = 'exploit'\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < phase_memory_value[phase]:\n                    phase_memory[phase] = proposed_position\n                    phase_memory_value[phase] = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = phase_memory[phase]\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < phase_memory_value[phase]:\n                    phase_memory[phase] = random_checkpoint_position\n                    phase_memory_value[phase] = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedPhaseAwareAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "e537ee43-5997-4f32-8707-447426f817a8", "fitness": 0.06809273007040087, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce probabilistic phase switching and dynamic memory updates for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = np.random.uniform(0.4, 0.6)  # Probabilistic phase switching\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim)\n                if success_count >= adapt_interval / 2:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n                if success_count >= adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06809 with standard deviation 0.01339.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07077394468931997, 0.047696432845626746, 0.07658352328330453, 0.07527648994621372, 0.05049696532473502, 0.0816423848758685, 0.0763528373321204, 0.05115199103771417, 0.08286000129870474]}}
{"id": "decc1955-e8bb-4f70-b1be-1cde755f62a2", "fitness": 0.08181570128764643, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance exploration-exploitation balance with dynamic switching between strategies and incorporate a guided mutation mechanism.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with guided mutation\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Guided mutation\n                    direction = np.random.uniform(-0.75, 0.75, self.dim)\n            else:\n                # Phase 2: Exploitation with enhanced escape\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search with guided direction\n                    direction = np.random.uniform(-1.25, 1.25, self.dim)\n                \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.75 * (success_ratio - 0.5))  # Adjusted scaling factor\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08182 with standard deviation 0.00686.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07106004442037928, 0.07742560808382182, 0.08501981726728802, 0.07558029598486737, 0.0826873543083555, 0.09121536312811163, 0.07666097719562104, 0.08395942270705103, 0.09273242849332208]}}
{"id": "09d79918-e5e3-4769-a0fd-c8656359ac25", "fitness": 0.06599009704302754, "name": "ImprovedAdaptiveWalk", "description": "Utilize a multi-phase exploration-exploitation strategy with dynamic adaptivity to enhance convergence and robustness.", "code": "import numpy as np\n\nclass ImprovedAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = [0.3, 0.7]  # Multi-phase: exploration, hybrid, exploitation\n\n        while evaluations < self.budget:\n            phase_ratio = evaluations / self.budget\n\n            if phase_ratio < phase_switch[0]:\n                direction = np.random.normal(size=self.dim)  # Broad exploration\n            elif phase_ratio < phase_switch[1]:\n                direction = np.random.uniform(-0.5, 0.5, self.dim)  # Hybrid search\n            else:\n                direction = np.random.uniform(-1.0, 1.0, self.dim)  # Intensified exploitation\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.5 * (success_ratio - 0.2))  # Adjusted scaling factor for better stability\n                success_count = 0\n\n            if evaluations % (self.budget // 30) == 0:  # More frequent random restart\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < best_value:\n                    best_position = random_checkpoint_position\n                    best_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 87, "feedback": "The algorithm ImprovedAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06599 with standard deviation 0.00604.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.06996576856110981, 0.05729842832758869, 0.06171723903839432, 0.07466874910472043, 0.060773046378624684, 0.0655846017961007, 0.0758041167055421, 0.06159407107338033, 0.06650485240178672]}}
{"id": "83c90215-8b68-4f9a-99a0-67c7abb7b174", "fitness": 0.08493081275154812, "name": "EnhancedDynamicAdaptiveWalk", "description": "Integrate momentum-based memory enhancement to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n        momentum = 0.9  # Added momentum term\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                if success_count < adapt_interval / 2:\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction + momentum * (current_position - memory_position)  # Added momentum influence\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08493 with standard deviation 0.00854.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358016186661, 0.08638549645036753, 0.08525165651909394, 0.07484332636597313, 0.09283682120141712, 0.09142452307470772, 0.07591417540785195, 0.09442339099186614, 0.09293434459078898]}}
{"id": "224889ea-5512-42b5-8c97-3ccad50187a1", "fitness": 0.06571876031088875, "name": "EnhancedDynamicAdaptiveWalkV2", "description": "Enhance convergence by incorporating multi-phase adaptation with memory reset and dynamic step-size modulation.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalkV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.3\n        reset_interval = self.budget // 5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count < adapt_interval / 2 else np.random.normal(size=self.dim)\n            else:\n                # Phase 2: Exploitation\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Dynamic step-size modulation\n\n                if success_ratio < 0.3:  # Lower threshold for more frequent memory resets\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % reset_interval == 0:\n                # Periodic memory reset to explore fresh regions\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedDynamicAdaptiveWalkV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06572 with standard deviation 0.01025.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.05746429675433917, 0.0760175747242029, 0.0549192471465163, 0.06088031439188424, 0.08109960245896763, 0.058157976080005724, 0.061685512996191294, 0.08232470803275171, 0.05891961021313974]}}
{"id": "7fba23c3-f598-4834-85df-f89fc1488811", "fitness": 0.08305894557751332, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve convergence by enhancing step-size adaptation dynamics and adding a strategic random reinitialization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))  # Slightly increased scaling factor\n\n                if success_ratio < 0.35:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                if np.random.rand() < 0.1:  # Random reinitialization with 10% probability\n                    random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                    random_checkpoint_value = func(random_checkpoint_position)\n                    evaluations += 1\n                    if random_checkpoint_value < memory_value:\n                        memory_position = random_checkpoint_position\n                        memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08306 with standard deviation 0.01336.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.08886971626905893, 0.08577276836302339, 0.06198793215705889, 0.0955964477446597, 0.09207501953557684, 0.06573343629618045, 0.09725527298259518, 0.09361994332071988, 0.06661997352874671]}}
{"id": "28bce83c-74cf-4e8c-9fc6-47f2d2beeea3", "fitness": 0.08026173419808275, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improve convergence by fine-tuning step-size scaling and checkpoint intervention.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                if success_count < adapt_interval / 2:\n                    # Explore more broadly\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Adaptive directional focus\n                    direction = np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation\n                if success_count < adapt_interval / 2:\n                    # Intensified local search\n                    direction = np.random.normal(size=self.dim)\n                else:\n                    # Broader search to escape local minima\n                    direction = np.random.uniform(-1.0, 1.0, self.dim)\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))  # Adjusting scaling factor\n\n                if success_ratio < 0.4:  # Adjusted success ratio threshold\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 25) == 0:  # Adjusted checkpoint frequency\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08026 with standard deviation 0.00333.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07477883448377909, 0.07884124967133954, 0.07573895498905525, 0.07968971822754334, 0.08422672844427703, 0.08073831954926991, 0.08087050512570759, 0.08552998446634508, 0.08194131282542794]}}
{"id": "d88879f0-679f-4d6c-892f-7f2d1f93d97c", "fitness": 0.08494159000312917, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce a memory-enhanced adaptive exploitation phase and dynamic perturbation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with Memory-Enhanced Search\n                perturbation_factor = 0.1 if success_count < adapt_interval / 2 else 0.2\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08494 with standard deviation 0.00855.", "error": "", "parent_ids": ["bff436f9-cf92-4e90-a8e9-1298a151da1c"], "operator": null, "metadata": {"aucs": [0.07036358043530067, 0.08640589962467471, 0.08526030264118711, 0.07484332666608817, 0.09286032377682452, 0.09143440923469692, 0.07591417571473713, 0.0944477297607893, 0.09294456217386404]}}
{"id": "0028c2d8-ebeb-4531-9cf2-02d800da1e9a", "fitness": 0.05476106976518965, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce an adaptive memory mechanism and stochastic phase transitions for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if np.random.rand() < phase_switch - (success_count / adapt_interval):\n                # Phase 1: Exploration with dynamic directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Exploitation with stochastic memory enhancement\n                perturbation_factor = 0.1 if success_count < adapt_interval / 2 else 0.2\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n            \n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                memory_position = (memory_position + proposed_position) / 2\n                memory_value = min(memory_value, proposed_value)\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05476 with standard deviation 0.00398.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.05560875958025557, 0.05414498914913546, 0.04763209737666252, 0.058886076238646945, 0.05733191501461976, 0.05042711553261581, 0.059657046118233414, 0.0580808496651154, 0.051080779211421956]}}
{"id": "b67c2ba7-a9ff-4620-9965-835dea972d71", "fitness": 0.08494159000312917, "name": "EnhancedDynamicAdaptiveWalk", "description": "Introduce periodic global re-initialization to prevent stagnation and explore new regions.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with Memory-Enhanced Search\n                perturbation_factor = 0.1 if success_count < adapt_interval / 2 else 0.2\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n            if evaluations % (self.budget // 5) == 0:  # Periodic global re-initialization\n                current_position = np.random.uniform(lb, ub, self.dim)\n                current_value = func(current_position)\n                evaluations += 1\n                if current_value < best_value:\n                    best_position = current_position\n                    best_value = current_value\n\n        return best_position, best_value", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08494 with standard deviation 0.00855.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.07036358043530067, 0.08640589962467471, 0.08526030264118711, 0.07484332666608817, 0.09286032377682452, 0.09143440923469692, 0.07591417571473713, 0.0944477297607893, 0.09294456217386404]}}
{"id": "91f0c377-503a-4816-9d9f-4e4da759a770", "fitness": 0.08494159000312917, "name": "EnhancedDynamicAdaptiveWalk", "description": "Enhance exploitation phase by incorporating dynamic memory reinforcement and adaptive checkpointing.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with Memory-Enhanced Search\n                perturbation_factor = 0.15 if success_count < adapt_interval / 2 else 0.25\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08494 with standard deviation 0.00855.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.07036358043530067, 0.08640589962467471, 0.08526030264118711, 0.07484332666608817, 0.09286032377682452, 0.09143440923469692, 0.07591417571473713, 0.0944477297607893, 0.09294456217386404]}}
{"id": "d2665235-646c-48a9-bc18-397f6928ed03", "fitness": 0.0782558095771266, "name": "EnhancedDynamicAdaptiveWalk", "description": "Incorporate a multi-phase search strategy with adaptive memory-based exploitation and diversity preservation to enhance optimization efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch_1 = 0.4\n        phase_switch_2 = 0.8\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch_1:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            elif evaluations / self.budget < phase_switch_2:\n                # Phase 2: Memory-Enhanced Exploitation\n                perturbation_factor = 0.15 if success_count < adapt_interval / 2 else 0.25\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n            else:\n                # Phase 3: Diversity Preservation with Memory Retrace\n                direction = np.random.uniform(-1.0, 1.0, self.dim)\n                if np.random.rand() < 0.3:\n                    current_position = memory_position\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0 and np.random.rand() < 0.5:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07826 with standard deviation 0.00575.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.07904750548768968, 0.06801884324850427, 0.07666291583650309, 0.08443738096119768, 0.072292601954971, 0.08177840760740829, 0.08574153812608265, 0.07331154157428776, 0.08301155139749505]}}
{"id": "b3ca9d3b-27c6-4b22-ae91-402da3d1a832", "fitness": 0.08494159000312917, "name": "StochasticRefinementGlobalReposition", "description": "Integrate stochastic local refinement with periodic global reposition for enhanced diversity and convergence balance.", "code": "import numpy as np\n\nclass StochasticRefinementGlobalReposition:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with stochastic refinement\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Exploitation with Memory-Enhanced Search and stochastic perturbation\n                perturbation_factor = 0.1 if success_count < adapt_interval / 2 else 0.2\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                # Periodic global reposition to enhance diversity\n                global_reposition_position = np.random.uniform(lb, ub, self.dim)\n                global_reposition_value = func(global_reposition_position)\n                evaluations += 1\n                if global_reposition_value < memory_value:\n                    memory_position = global_reposition_position\n                    memory_value = global_reposition_value\n\n        return best_position, best_value", "configspace": "", "generation": 97, "feedback": "The algorithm StochasticRefinementGlobalReposition got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08494 with standard deviation 0.00855.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.07036358043530067, 0.08640589962467471, 0.08526030264118711, 0.07484332666608817, 0.09286032377682452, 0.09143440923469692, 0.07591417571473713, 0.0944477297607893, 0.09294456217386404]}}
{"id": "5fbbe8bb-5337-4212-9d61-a7d22c955e58", "fitness": 0.07511313201534753, "name": "EnhancedDynamicAdaptiveWalk", "description": "Improved convergence by adjusting the step size modulation and incorporating a more refined directional search.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                # Phase 1: Exploration with adaptive directional search\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                # Phase 2: Enhanced Exploitation with Memory-Enhanced Search\n                perturbation_factor = 0.15 if success_count < adapt_interval / 2 else 0.3\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.9 * (success_ratio - 0.5))\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07511 with standard deviation 0.01156.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.08024328612839182, 0.05673732565103384, 0.07783892732306086, 0.08573308008808056, 0.06009895037362811, 0.08307472962441331, 0.08706240608756954, 0.060890706758783386, 0.08433877610316631]}}
{"id": "fafe5102-fe8b-431e-b9a1-df8856864ad1", "fitness": 0.06648999146964046, "name": "EnhancedDynamicAdaptiveWalk", "description": "Integrate adaptive inertia weight with multi-phase exploration-exploitation for enhanced convergence and stability.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveWalk:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = np.random.uniform(lb, ub, self.dim)\n        current_value = func(current_position)\n        evaluations = 1\n\n        step_size = 0.1 * (ub - lb)\n        best_position = current_position\n        best_value = current_value\n        memory_position = current_position\n        memory_value = current_value\n\n        success_count = 0\n        adapt_interval = 10\n        phase_switch = 0.5\n\n        inertia_weight = 0.9\n        min_inertia = 0.4\n        inertia_decrease_factor = 0.95\n\n        while evaluations < self.budget:\n            if evaluations / self.budget < phase_switch:\n                direction = np.random.normal(size=self.dim) if success_count < adapt_interval / 2 else np.random.uniform(-0.5, 0.5, self.dim)\n            else:\n                perturbation_factor = 0.1 if success_count < adapt_interval / 2 else 0.2\n                direction = (np.random.normal(size=self.dim) + perturbation_factor * (memory_position - current_position))\n                direction = np.random.uniform(-1.0, 1.0, self.dim) if success_count >= adapt_interval / 2 else direction\n\n            direction /= np.linalg.norm(direction)\n            proposed_position = current_position + inertia_weight * step_size * direction\n            proposed_position = np.clip(proposed_position, lb, ub)\n\n            proposed_value = func(proposed_position)\n            evaluations += 1\n\n            if proposed_value < current_value:\n                current_position = proposed_position\n                current_value = proposed_value\n                success_count += 1\n\n                if proposed_value < best_value:\n                    best_position = proposed_position\n                    best_value = proposed_value\n\n                if proposed_value < memory_value:\n                    memory_position = proposed_position\n                    memory_value = proposed_value\n\n            if evaluations % adapt_interval == 0:\n                success_ratio = success_count / adapt_interval\n                step_size *= (1 + 0.85 * (success_ratio - 0.5))\n                inertia_weight = max(min_inertia, inertia_weight * inertia_decrease_factor)\n\n                if success_ratio < 0.35:\n                    current_position = memory_position\n                success_count = 0\n\n            if evaluations % (self.budget // 20) == 0:\n                random_checkpoint_position = np.random.uniform(lb, ub, self.dim)\n                random_checkpoint_value = func(random_checkpoint_position)\n                evaluations += 1\n                if random_checkpoint_value < memory_value:\n                    memory_position = random_checkpoint_position\n                    memory_value = random_checkpoint_value\n\n        return best_position, best_value", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedDynamicAdaptiveWalk got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06649 with standard deviation 0.00552.", "error": "", "parent_ids": ["d88879f0-679f-4d6c-892f-7f2d1f93d97c"], "operator": null, "metadata": {"aucs": [0.05690534004165737, 0.06809102882158535, 0.06574817314689618, 0.0602816283476002, 0.07234781618154362, 0.06981493251714677, 0.06107706010051783, 0.07336214549108766, 0.07078179857872913]}}
