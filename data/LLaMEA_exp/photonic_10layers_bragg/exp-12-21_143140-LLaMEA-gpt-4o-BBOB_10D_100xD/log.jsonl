{"id": "8a4df38d-49f5-40df-8b5d-75bdeb564d37", "fitness": -Infinity, "name": "HybridPSODE", "description": "A hybrid Particle Swarm Optimization (PSO) with Differential Evolution (DE) algorithm that dynamically balances exploration and exploitation by adaptively adjusting the influence of particles' personal and global bests along with DE's mutation and crossover strategies.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = self.population[i]\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = self.population[i]\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial_vector\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = trial_vector\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2  # Each of PSO and DE consumes num_particles evaluations", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 97, in evaluateBBOB\n    budget=budget, dim=dim)\n  File \"<string>\", line 81, in __call__\n  File \"<string>\", line 32, in update_particles\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n.", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 97, in evaluateBBOB\n    budget=budget, dim=dim)\n  File \"<string>\", line 81, in __call__\n  File \"<string>\", line 32, in update_particles\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "54d780e8-efc0-4ba2-b744-9c4c08e82759", "fitness": 0.11118558935684922, "name": "RefinedHybridPSODE", "description": "A robust hybrid optimizer leveraging Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameter tuning for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 1, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11119 with standard deviation 0.03574.", "error": "", "parent_ids": ["8a4df38d-49f5-40df-8b5d-75bdeb564d37"], "operator": null, "metadata": {"aucs": [0.16760130644676108, 0.16134752352996218, 0.14606651012056937, 0.07672925262566799, 0.07512410105031664, 0.0871071240085668, 0.08928878509839944, 0.11766863927478599, 0.07973706205661357]}}
{"id": "6063f691-5f51-4a27-a8f7-a6470409de63", "fitness": 0.09728123640715974, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimizer integrating Particle Swarm Optimization (PSO) with Differential Evolution (DE), augmented by adaptive inertia weight and mutation strategies for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor_min = 0.5\n        self.mutation_factor_max = 0.9\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_inertia_weight(self, eval_count):\n        return self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n    def update_particles(self, func, eval_count):\n        inertia_weight = self.update_inertia_weight(eval_count)\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def adaptive_mutation_factor(self, eval_count):\n        return self.mutation_factor_max - (self.mutation_factor_max - self.mutation_factor_min) * (eval_count / self.budget)\n\n    def differential_evolution(self, func, eval_count):\n        mutation_factor = self.adaptive_mutation_factor(eval_count)\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func, eval_count)\n            self.differential_evolution(func, eval_count)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09728 with standard deviation 0.04629.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.17704305318851077, 0.15511779703734474, 0.14645632444968293, 0.06938274693149471, 0.09148167197260271, 0.07234103451763019, 0.04180775156355476, 0.06295166845834055, 0.058949079545276395]}}
{"id": "ed61e1b5-2f77-444d-a2ea-92df00b4258e", "fitness": 0.10121238078519919, "name": "EnhancedHybridPSODESA", "description": "An enhanced hybrid optimizer combining Particle Swarm Optimization (PSO), Differential Evolution (DE), and Simulated Annealing (SA) for superior exploration, exploitation, and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.temperature = 1000\n        self.cooling_rate = 0.99\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def simulated_annealing(self, func):\n        for i in range(self.num_particles):\n            candidate = self.population[i] + np.random.normal(0, 1, self.dim)\n            candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            candidate_fitness = func(candidate)\n\n            if candidate_fitness < self.personal_best_value[i]:\n                self.population[i] = candidate\n                self.personal_best[i] = candidate\n                self.personal_best_value[i] = candidate_fitness\n\n                if candidate_fitness < self.global_best_value:\n                    self.global_best = candidate\n                    self.global_best_value = candidate_fitness\n            else:\n                acceptance_prob = np.exp((self.personal_best_value[i] - candidate_fitness) / self.temperature)\n                if np.random.rand() < acceptance_prob:\n                    self.population[i] = candidate\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            self.simulated_annealing(func)\n            self.temperature *= self.cooling_rate\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10121 with standard deviation 0.04110.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.1678816830241343, 0.14953088576561147, 0.15649131776906267, 0.06323304328575563, 0.06785696490780524, 0.08609539555402423, 0.06422615395323894, 0.0855616973162957, 0.07003428549086455]}}
{"id": "8d44e5b8-8980-4a0c-bf8d-da0490ad8bcc", "fitness": 0.0990994512486664, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimizer combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with cyclic adaptive inertia weight and dynamic crossover rate for improved performance in diverse black box optimization scenarios.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.initial_w = 0.9\n        self.w = self.initial_w\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.initial_crossover_rate = 0.9\n        self.crossover_rate = self.initial_crossover_rate\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_inertia_and_crossover(self, eval_count):\n        T = self.budget / (self.num_particles * 2)\n        cycle = eval_count // T\n        self.w = self.initial_w * (0.5 + 0.5 * np.cos(2 * np.pi * cycle / 10))\n        self.crossover_rate = 0.5 + 0.4 * np.cos(2 * np.pi * cycle / 10)\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_inertia_and_crossover(eval_count)\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09910 with standard deviation 0.03855.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.14822126594624807, 0.15533673857131491, 0.13702439719798676, 0.09452607137358005, 0.09952314394334383, 0.07145674782679001, 0.032305733965628525, 0.06914272159581336, 0.08435824081729204]}}
{"id": "63cca396-9295-4dff-83ec-32ee407d87f5", "fitness": 0.10832308695780694, "name": "RefinedHybridPSODE", "description": "Enhanced the mutation factor adaptation in the Differential Evolution phase to improve convergence speed.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Mutant vector\n            if np.random.rand() < 0.5:  # Adaptive mutation factor\n                self.mutation_factor = 0.5 * (1 + np.random.rand())\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 5, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10832 with standard deviation 0.03283.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.15767360289239107, 0.1480765575371107, 0.14817263213001874, 0.09564778870325441, 0.07387557694329427, 0.08281067470869652, 0.06403613270132502, 0.10804658734906869, 0.09656822965510303]}}
{"id": "7a5a4aa8-ea93-447a-99ee-024d95b38e44", "fitness": 0.09906048623448009, "name": "EnhancedAdaptivePSODE", "description": "Enhanced Adaptive PSO-DE: A novel hybrid algorithm that leverages adaptation in PSO-DE parameters based on success rates to dynamically balance exploration and exploitation for improved performance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.success_rate_ps = 0.0\n        self.success_rate_de = 0.0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        successes = 0\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n                successes += 1\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n        self.success_rate_ps = successes / self.num_particles\n\n    def differential_evolution(self, func):\n        successes = 0\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                successes += 1\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n        self.success_rate_de = successes / self.num_particles\n\n    def adapt_parameters(self):\n        if self.success_rate_ps > self.success_rate_de:\n            self.w = min(0.9, self.w + 0.05)\n        else:\n            self.mutation_factor = min(1.0, self.mutation_factor + 0.05)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            self.adapt_parameters()\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09906 with standard deviation 0.04104.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.15676055234320407, 0.1475442823224089, 0.16112258694506965, 0.07256451983266343, 0.06646209476120335, 0.08562327102383571, 0.0549067152609487, 0.08742959222203384, 0.059130761398953124]}}
{"id": "0e22fded-ea8e-495f-9886-08db934804c8", "fitness": 0.09968733261805006, "name": "RefinedHybridPSODE", "description": "A robust hybrid optimizer leveraging Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameter tuning for enhanced exploration, exploitation balance, and improved convergence through velocity adaptation.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity with adaptive inertia weight\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = (self.w + np.random.uniform(-0.1, 0.1)) * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09969 with standard deviation 0.04025.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.14994623269754015, 0.1474986057196409, 0.16087448318946895, 0.06968783894363983, 0.10874539747212109, 0.07446792402878388, 0.05945151956331263, 0.07146702828545493, 0.05504696366248818]}}
{"id": "efc36864-2cea-4f84-ac32-1bef481fda2c", "fitness": 0.1047559627621485, "name": "RefinedHybridPSODE", "description": "Enhanced hybrid optimizer integrating a memory-based learning component for improved convergence and diversity management.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.memory = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n        self.memory = [np.copy(self.population)]\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            memory_influence = 0.1 * np.mean(self.memory, axis=0)[i]  # Added memory influence\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social + memory_influence\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            self.memory.append(np.copy(self.population))  # Update memory\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 8, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10476 with standard deviation 0.04679.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.15939904131348792, 0.17088161174048955, 0.17073025722050306, 0.06886873857578246, 0.06617890089221523, 0.09331918573372588, 0.03994478398514856, 0.09769451204925383, 0.07578663334873004]}}
{"id": "b9448224-cc8f-4c8a-945e-c3d35131072b", "fitness": 0.0, "name": "AdaptiveQuantumSwarmDE", "description": "Adaptive Quantum Swarm Differential Evolution (AQSDE) introduces quantum-inspired particle updates and adaptive learning rates to enhance convergence speed and solution quality in hybrid PSO-DE optimization.", "code": "import numpy as np\n\nclass AdaptiveQuantumSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.max_velocity = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.max_velocity = 0.1 * (ub - lb)\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Adaptive learning weights\n            fitness_diff = self.global_best_value - np.min(self.personal_best_value)\n            self.w = 0.4 + 0.5 * (1 - np.exp(-0.1 * fitness_diff))\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Quantum-inspired velocity update\n            quantum_velocity = np.random.normal(0, self.max_velocity, self.dim)\n            self.velocity[i] += quantum_velocity\n            \n            # Clamp velocity\n            self.velocity[i] = np.clip(self.velocity[i], -self.max_velocity, self.max_velocity)\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveQuantumSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00000 with standard deviation 0.00000.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}
{"id": "f76f53c0-72a7-4d5c-95d8-406945c23d93", "fitness": 0.09375133233367444, "name": "EnhancedCooperativePSODE", "description": "An enhanced cooperative co-evolutionary optimizer that integrates dynamic subgrouping with hybrid PSO-DE, leveraging both adaptive learning and local search for balanced global and local exploration.", "code": "import numpy as np\n\nclass EnhancedCooperativePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.subgroup_size = max(2, self.dim // 3)\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def dynamic_subgrouping(self, func):\n        perm = np.random.permutation(self.dim)\n        subgroups = [perm[i:i + self.subgroup_size] for i in range(0, self.dim, self.subgroup_size)]\n        for subgroup in subgroups:\n            for i in range(self.num_particles):\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                subgroup_indices = np.random.choice(subgroup, len(subgroup)//2, replace=False)\n                mutant_vector = np.copy(self.population[i])\n                mutant_vector[subgroup_indices] = (self.population[a][subgroup_indices] +\n                                                   self.mutation_factor * (self.population[b][subgroup_indices] -\n                                                                           self.population[c][subgroup_indices]))\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(mutant_vector)\n                if trial_fitness < self.personal_best_value[i]:\n                    self.population[i][subgroup_indices] = mutant_vector[subgroup_indices]\n                    self.personal_best_value[i] = trial_fitness\n                    self.personal_best[i] = np.copy(self.population[i])\n                    if trial_fitness < self.global_best_value:\n                        self.global_best = np.copy(self.population[i])\n                        self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            self.dynamic_subgrouping(func)\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedCooperativePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09375 with standard deviation 0.04656.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.16492729439871368, 0.15300921398681355, 0.15531547781030097, 0.05613070655302166, 0.06936125069319277, 0.08562327102383571, 0.04630434699097008, 0.051688800562949, 0.061401628983272505]}}
{"id": "e2e58036-9d58-4e38-b5cb-a26dee699935", "fitness": 0.09158929381095209, "name": "EnhancedPSODE", "description": "Enhanced PSO-DE with dynamic inertia weight and self-adaptive mutation strategy for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_count):\n        w = self.w_initial - (self.w_initial - self.w_final) * (eval_count / self.budget)\n        \n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n            eval_count += 1\n\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n        return eval_count\n\n    def differential_evolution(self, func, eval_count):\n        mutation_factor = self.mutation_factor_initial - \\\n                          (self.mutation_factor_initial - self.mutation_factor_final) * (eval_count / self.budget)\n        \n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            eval_count += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n        return eval_count\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            eval_count = self.update_particles(func, eval_count)\n            eval_count = self.differential_evolution(func, eval_count)", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09159 with standard deviation 0.04731.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.15475403292243362, 0.14844071782627688, 0.15240443974004403, 0.06940468831648172, 0.0911404959585217, 0.0925412708229898, 0.03024067476189818, 0.05237585200023598, 0.033001471949686834]}}
{"id": "7c035bed-3b57-44e7-8ac1-48bc2c0f1c81", "fitness": 0.0855737134721606, "name": "RefinedHybridPSODE", "description": "Introduce adaptive inertia weight for improved exploration and exploitation in the RefinedHybridPSODE algorithm.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Start with a higher inertia weight for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 12, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08557 with standard deviation 0.05303.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.15477144628953055, 0.1638365268283425, 0.14261707109913768, 0.07430830909236896, 0.08770838953756088, 0.06931701672785451, 0.020084856184811928, 0.029109091540294507, 0.028410713949543864]}}
{"id": "ef2c80e0-f04f-4d92-b3c9-b8baf8b8f970", "fitness": 0.11036985971106035, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSO-DE with Adaptive Memory: An improved hybrid that dynamically adjusts velocity and DE parameters based on historical performance, enhancing convergence speed and precision.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def adapt_parameters(self):\n        if len(self.history) > 5:\n            improvement = [self.history[i] - self.history[i + 1] for i in range(len(self.history) - 1)]\n            avg_improvement = np.mean(improvement)\n            if avg_improvement < 0.01:  # If improvement is slow\n                self.w *= 0.9\n                self.mutation_factor *= 1.1\n            else:\n                self.w *= 1.1\n                self.mutation_factor *= 0.9\n\n    def update_particles(self, func):\n        self.adapt_parameters()\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2\n            self.history.append(self.global_best_value)\n            if len(self.history) > 10:\n                self.history.pop(0)", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11037 with standard deviation 0.03347.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.16760130644676108, 0.14965240177080774, 0.1496463068735947, 0.0779526242855858, 0.08948425831572238, 0.08934560536799141, 0.08251759567512507, 0.10859554703785168, 0.07853309162610334]}}
{"id": "b2f8f93f-c836-468f-9bc6-461420c2dd67", "fitness": 0.11304185756438812, "name": "RefinedHybridPSODE", "description": "Enhanced parameter tuning for adaptive mutation factor to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.9  # Adjusted mutation factor for improved performance\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 14, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11304 with standard deviation 0.03416.", "error": "", "parent_ids": ["54d780e8-efc0-4ba2-b744-9c4c08e82759"], "operator": null, "metadata": {"aucs": [0.1660298447457076, 0.15571135863717267, 0.15663441144509327, 0.07480347659761044, 0.09011240785822883, 0.09202857013018795, 0.08360229764084548, 0.11133680680896307, 0.08711754421568374]}}
{"id": "4d51581f-e1ca-475f-84bc-b3a92740a80b", "fitness": 0.10853738998700149, "name": "GradientEnhancedHybridPSODE", "description": "Incorporate gradient-based movement for better local search capabilities while maintaining global exploration through hybrid PSO-DE.", "code": "import numpy as np\n\nclass GradientEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8  # Adjusted for better balance\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n\n            # Gradient-based movement: small perturbation for local exploration\n            gradient_step = 0.01 * np.sign(np.random.randn(self.dim))\n            self.velocity[i] = (self.w * self.velocity[i] + cognitive + social + gradient_step)\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 15, "feedback": "The algorithm GradientEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10854 with standard deviation 0.03694.", "error": "", "parent_ids": ["b2f8f93f-c836-468f-9bc6-461420c2dd67"], "operator": null, "metadata": {"aucs": [0.15933196426597318, 0.15970124603297164, 0.15834053519605307, 0.08965002902960895, 0.09546518805675719, 0.09319255584263364, 0.07160419636737658, 0.06485689311996079, 0.08469390197167836]}}
{"id": "6d10ab2d-7770-4af5-9fab-39ee3ac8a464", "fitness": 0.09143712648986295, "name": "RefinedHybridPSODE", "description": "Adaptive multi-strategy optimizer integrating dynamic inertia and self-adaptive crossover to enhance convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.9\n        self.initial_crossover_rate = 0.9\n        self.final_crossover_rate = 0.4\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_count):\n        w = self.initial_w - (self.initial_w - self.final_w) * (eval_count / self.budget)\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_count):\n        current_crossover_rate = self.initial_crossover_rate - (self.initial_crossover_rate - self.final_crossover_rate) * (eval_count / self.budget)\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < current_crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            self.update_particles(func, eval_count)\n            self.differential_evolution(func, eval_count)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09144 with standard deviation 0.04818.", "error": "", "parent_ids": ["b2f8f93f-c836-468f-9bc6-461420c2dd67"], "operator": null, "metadata": {"aucs": [0.15050233735698915, 0.14882741546925116, 0.16574646484465216, 0.063243137938229, 0.08946330248213308, 0.07779893298421803, 0.027131340772623247, 0.04514729247427429, 0.05507391408639639]}}
{"id": "c20a0032-eba3-44f7-b570-c7ede648f727", "fitness": 0.12231107334957418, "name": "AdaptivePSODE", "description": "Adaptive PSO-DE with temporal mutation and crossover rates to dynamically adjust exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5  # Initial mutation factor\n        self.crossover_rate = 0.5  # Initial crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            # Update velocity\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n\n            # Update position\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new position\n            fitness_value = func(self.population[i])\n\n            # Update personal best\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n\n            # Update global best\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            self.mutation_factor = 0.5 + 0.5 * eval_ratio  # Dynamic mutation\n            self.crossover_rate = 0.9 * (1 - eval_ratio)  # Dynamic crossover\n\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget  # Ratio of used evaluations\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12231 with standard deviation 0.03487.", "error": "", "parent_ids": ["b2f8f93f-c836-468f-9bc6-461420c2dd67"], "operator": null, "metadata": {"aucs": [0.14944807427871387, 0.1813814166351836, 0.17269595137082172, 0.0903828248147669, 0.10634276619685945, 0.10333861078478379, 0.11757855304266396, 0.10414367806536806, 0.07548778495700614]}}
{"id": "d1e01775-10c8-4ecd-a311-41ed582b51ae", "fitness": 0.12537987787349894, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with self-adaptive parameter tuning and improved diversity retention for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12538 with standard deviation 0.03719.", "error": "", "parent_ids": ["c20a0032-eba3-44f7-b570-c7ede648f727"], "operator": null, "metadata": {"aucs": [0.16241183764317757, 0.1813814166351836, 0.17269595137082172, 0.07304390719497489, 0.11094337348881167, 0.09739158304258166, 0.13686538004347093, 0.10707770694192509, 0.08660774450054332]}}
{"id": "4ff66e39-e402-451d-988d-84620e98a63f", "fitness": 0.10044060969550887, "name": "QuantumAdaptivePSODE", "description": "Quantum-Inspired Adaptive PSO-DE with dynamic topology and learning strategy enhances convergence by incorporating quantum behaviors and adaptive social structures.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.neighborhood_size = 3\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            neighborhood_indices = np.random.choice(self.num_particles, self.neighborhood_size, replace=False)\n            local_best_index = neighborhood_indices[np.argmin(self.personal_best_value[neighborhood_indices])]\n            local_best = self.personal_best[local_best_index]\n            \n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (local_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 19, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10044 with standard deviation 0.03952.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14388855161627, 0.15930408158909404, 0.15466165189484748, 0.08787017701798838, 0.06444174221714616, 0.0719586115123867, 0.0997480516535314, 0.046939492797150484, 0.07515312696116516]}}
{"id": "e1ce23ef-878b-49be-aa51-b6553da853d6", "fitness": 0.09460834493694581, "name": "HybridPSODER", "description": "Hybrid PSO-DE with Reinforced Exploration and Dynamic Inertia for adaptive exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODER:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        # Dynamic inertia weight\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + 0.3 * np.sin(eval_ratio * np.pi)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSODER got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09461 with standard deviation 0.04814.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16720581395189693, 0.1499716478862878, 0.15495584459130263, 0.07108066817041025, 0.09371272887206494, 0.08374827231145243, 0.03605073203798903, 0.03483991399389652, 0.05990948261721174]}}
{"id": "55a7d22f-0a21-4a3d-ac4a-f83745c67341", "fitness": -Infinity, "name": "AdaptivePSODE", "description": "Introduced dynamic strategy adaptation using a feedback loop based on recent successes to enhance optimization efficiency.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.success_ratio_threshold = 0.1  # New line\n        self.last_improvement_eval = 0  # New line\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n                self.last_improvement_eval = eval_count  # New line\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n                    self.last_improvement_eval = eval_count  # New line\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            success_ratio = (eval_count - self.last_improvement_eval) / eval_count  # New line\n            \n            if success_ratio > self.success_ratio_threshold:  # New line\n                self.w *= 0.9  # New line: Dynamic inertia weight adjustment\n            \n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 21, "feedback": "An exception occurred: ZeroDivisionError('division by zero').", "error": "ZeroDivisionError('division by zero')", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {}}
{"id": "ef4842b1-567d-4922-a76b-0205a0742f2a", "fitness": 0.1009380641700906, "name": "QuantumAdaptivePSODE", "description": "Quantum-Enhanced Adaptive PSO-DE using quantum-inspired particle representation and dynamic parameter adaptation for improved convergence and exploration.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def apply_quantum_effects(self):\n        quantum_bits = np.random.rand(self.num_particles, self.dim)\n        self.population += np.sign(np.random.rand(self.num_particles, self.dim) - 0.5) * quantum_bits * 0.1\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.apply_quantum_effects()\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 22, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10094 with standard deviation 0.04739.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16492391680759788, 0.14684612040628553, 0.1690086432735597, 0.09838478084491509, 0.09513225432796613, 0.08014854987841036, 0.02012997345713008, 0.06130692449121078, 0.07256141404373995]}}
{"id": "35d9e47a-c3b8-452f-8bb9-8854319fef1b", "fitness": 0.12259722145159693, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic step scaling for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = 0.1 * self.w * self.velocity[i] + cognitive + social  # Modified line\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12260 with standard deviation 0.02956.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1608877010629478, 0.15479778962847457, 0.15848613552854984, 0.1391752481031897, 0.08155780527987921, 0.10759843911323885, 0.09178428563838292, 0.11649005259836553, 0.09259753611134403]}}
{"id": "1623f86b-7a4e-4c5d-a5b7-36d2d5880e00", "fitness": 0.10803207693482425, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic local search intensification based on Levy flights for enhanced convergence speed and solution precision.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def levy_flight(self, lam=1.5):\n        u = np.random.normal(0, 1, self.dim) * (0.01 / (abs(np.random.normal(0, 1, self.dim)) ** (1/lam)))\n        return u\n\n    def local_search_intensification(self, func):\n        for i in range(self.num_particles):\n            if np.random.rand() < 0.3:\n                step_size = self.levy_flight()\n                new_pos = np.clip(self.population[i] + step_size, func.bounds.lb, func.bounds.ub)\n                new_fitness = func(new_pos)\n                if new_fitness < self.personal_best_value[i]:\n                    self.population[i] = new_pos\n                    self.personal_best_value[i] = new_fitness\n                    self.personal_best[i] = np.copy(new_pos)\n                    if new_fitness < self.global_best_value:\n                        self.global_best = np.copy(new_pos)\n                        self.global_best_value = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.local_search_intensification(func)\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 24, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10803 with standard deviation 0.04581.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15148495613074764, 0.18041596921459813, 0.1718698259141862, 0.07902993260224833, 0.07155941499005003, 0.06564216275681523, 0.05616500024638027, 0.11835023610287276, 0.07777119445551961]}}
{"id": "a38497bd-fd42-4cd3-b32c-498fb51fa0bc", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Introduced inertia weight decay to adaptively adjust exploration-exploitation balance over time.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.4  # Inertia weight decay for adaptive adjustment\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "5952cfec-d236-43d8-b972-f0eddb4a01b9", "fitness": 0.093428464244315, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic inertia weight and adaptive mutation for enhanced convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Adjusted initial inertia\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.4  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.4 + 0.1 * np.random.rand()  # Adaptive mutation factor\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 26, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09343 with standard deviation 0.04350.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14227663569715954, 0.1477458211346392, 0.14906411233300476, 0.09309937156578973, 0.08647555219168301, 0.08866694340397141, 0.07358200192242192, 0.023552585766493217, 0.03639315418367217]}}
{"id": "bd9c2ea1-c056-4114-9120-4603b8bf5225", "fitness": 0.10834014052150258, "name": "HybridPSODE", "description": "Hybrid Particle Swarm-DE Algorithm with Dynamic Adaptive Parameters and Neighborhood-based Diversity for Enhanced Global Search.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            neighborhood_velocity = self.w * np.mean(self.velocity, axis=0)\n            self.velocity[i] = neighborhood_velocity + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Adding randomness to mutation factor\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10834 with standard deviation 0.03292.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1463596996630242, 0.16747315877295244, 0.14625133774166676, 0.07566307946018025, 0.07884621784121315, 0.0961787182165067, 0.08427120699385893, 0.09417462957578115, 0.08584321642833959]}}
{"id": "68fedd83-3813-459d-b9bd-9a55b3257c8b", "fitness": 0.09882394230258722, "name": "EnhancedAdaptivePSODE", "description": "Hybrid PSO-DE with adaptive inertia weight and dynamic crossover rate adjusted based on evaluation progression for enhanced convergence speed and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_min = 0.2\n        self.w_max = 0.8\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-9)) \n            self.crossover_rate = 0.9 * (1 - eval_ratio) + 0.1 * eval_ratio\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09882 with standard deviation 0.04667.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1591358967405232, 0.16103304934355844, 0.1543482312285125, 0.09230481960906267, 0.09547925783797362, 0.08726741912112146, 0.06729635785887333, 0.0342340394612175, 0.038316409522442196]}}
{"id": "55b18647-b26e-47e9-9462-1f1b10fad0d5", "fitness": 0.09663885633024977, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic inertia weight adjustment and local search enhancement for better convergence and diversity.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9  # Changed from constant w to dynamic w\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = self.w_max - eval_ratio * (self.w_max - self.w_min)  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n            # Local search enhancement\n            if np.random.rand() < 0.1:  # Small probability for a local search\n                perturbed = trial_vector + 0.01 * (np.random.rand(self.dim) - 0.5)\n                perturbed = np.clip(perturbed, func.bounds.lb, func.bounds.ub)\n                perturbed_fitness = func(perturbed)\n                if perturbed_fitness < trial_fitness:\n                    self.population[i] = np.copy(perturbed)\n                    self.personal_best_value[i] = perturbed_fitness\n                    self.personal_best[i] = np.copy(perturbed)\n                    if perturbed_fitness < self.global_best_value:\n                        self.global_best = np.copy(perturbed)\n                        self.global_best_value = perturbed_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09664 with standard deviation 0.04117.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14652015101087346, 0.16301292852996485, 0.1456191213369773, 0.06605327746754908, 0.08707876207654963, 0.08614436307705653, 0.07539208418320187, 0.05296334879127451, 0.04696567049880063]}}
{"id": "b1eb3dc9-abde-497c-b36d-3cec61f8bc55", "fitness": 0.09167643988745039, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE by integrating dynamic inertia weight and adaptive mutation strategy for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Start with higher inertia\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        inertia_weight = self.w - (self.w - self.w_min) * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + 0.3 * eval_ratio  # Adaptive mutation strategy\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09168 with standard deviation 0.04887.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14849643718673444, 0.1509750631118304, 0.07144186410455322, 0.09773020726911319, 0.06586187825926959, 0.02812032795953845, 0.03168105224575213, 0.06604597433164583]}}
{"id": "8efbba9b-f6df-4b29-a072-7c4e2701ca36", "fitness": 0.09611169911995128, "name": "MultiStrategyDynamicPopulation", "description": "Multi-Strategy Dynamic Population Algorithm (MSDPA) combining adaptive PSO, enhanced DE, and natural selection for robust exploration-exploitation balance.", "code": "import numpy as np\n\nclass MultiStrategyDynamicPopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.8 + 0.2 * np.tanh(self.personal_best_value[i] / self.global_best_value)\n            crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def select_survivors(self, func):\n        fitness_values = np.array([func(ind) for ind in self.population])\n        sorted_indices = np.argsort(fitness_values)\n        self.population = self.population[sorted_indices[:self.num_particles]]\n        self.personal_best = self.personal_best[sorted_indices[:self.num_particles]]\n        self.personal_best_value = self.personal_best_value[sorted_indices[:self.num_particles]]\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.select_survivors(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 31, "feedback": "The algorithm MultiStrategyDynamicPopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09611 with standard deviation 0.03876.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15360314653926166, 0.14610758197467122, 0.13828662616709597, 0.07462989160535471, 0.062167672299991095, 0.06718208444019136, 0.051015078814040216, 0.06099246278839077, 0.11102074745056456]}}
{"id": "edaeed73-9122-4fda-817d-ebf8a201d045", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Enhanced parameter adaptation by adjusting inertia weight dynamically based on evaluation ratio for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            # Dynamically adjust inertia weight\n            self.velocity[i] = (0.9 - eval_ratio * 0.4) * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "18c2ea7f-b661-4ca0-9b74-4e87d32925cb", "fitness": 0.08958759085578988, "name": "AdaptivePSODEPlus", "description": "AdaptivePSODE+ uses dynamic inertia weighting and adaptive crossover rates for enhanced optimization efficiency.", "code": "import numpy as np\n\nclass AdaptivePSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9  # Increased maximum inertia weight\n        self.w_min = 0.4  # Reduced minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = self.w_max - (self.w_max - self.w_min) * eval_ratio  # Dynamic inertia weighting\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio) + 0.1  # More aggressive crossover rate adaptation\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptivePSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.05082.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14603585395032725, 0.1644871380071775, 0.14980131831635501, 0.09591564853634471, 0.08970135200441631, 0.06555952204166471, 0.023762330779256158, 0.03235299931940927, 0.038672154747158016]}}
{"id": "5781ce4f-47d2-4afe-86a7-9ce31c3f7ad6", "fitness": 0.09941669299223461, "name": "AdaptivePSODE", "description": "Adaptive PSO-DE with dynamic inertia weight and enhanced mutation for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Changed initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - eval_ratio * 0.5  # Dynamic inertia weight update\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * 0.5  # Enhanced mutation factor calculation\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09942 with standard deviation 0.04751.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16532865484864379, 0.16001440990872384, 0.14852505066927812, 0.0729132735024618, 0.10098282449721485, 0.10542081162970074, 0.03537080315993968, 0.033695976348651846, 0.07249843236549691]}}
{"id": "5bcb40ee-dd15-413b-9e46-2508e8215434", "fitness": 0.0996505089781719, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic adaptive learning rates and mutation strategy to further improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - 0.5 * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            if np.random.rand() < 0.3:  # New mutation strategy\n                mutant_vector = self.global_best + self.mutation_factor * (self.population[b] - self.population[c])\n            else:\n                mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09965 with standard deviation 0.03630.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.13572192172453712, 0.15233615589776017, 0.1532839108719829, 0.09518534809163937, 0.09738347529978919, 0.06504283272935063, 0.07176823189115011, 0.07373633808163538, 0.052396366215702206]}}
{"id": "29931619-73a6-481d-b7f6-75b63c5d08f3", "fitness": 0.09228789702246291, "name": "AdaptivePSODE", "description": "AdaptivePSODE with dynamic inertia weight update for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.5  # Dynamic inertia weight update\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "a7221960-4f49-4416-8d3b-76cb69455ec5", "fitness": 0.07785551473067813, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic parameter adjustment based on particle diversity and convergence speed.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        diversity = np.std(self.population, axis=0).mean()  # Calculate particle diversity\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.velocity[i] *= (1 + diversity)  # Adjust velocity based on diversity\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07786 with standard deviation 0.05547.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15508939874405248, 0.14076874272166928, 0.15430292488791142, 0.0656432747930844, 0.06303310054274691, 0.07428316538420732, 0.01831734330092405, 0.01589181368429826, 0.013369868517209005]}}
{"id": "a247ee6c-56d5-4eb5-a186-ab84a3acf5be", "fitness": 0.09495205911598541, "name": "AdaptivePSODE", "description": "Integrates adaptive inertia and dynamic population strategies to enhance convergence and diversity balance in the optimization process.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - 0.5 * eval_ratio  # Adaptive inertia weight\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            if eval_ratio > 0.5:  # Dynamic population reduction\n                self.num_particles = 10  # Reduce the number of particles after 50% budget\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09495 with standard deviation 0.04955.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.1512357577913298, 0.16303286995954813, 0.07284172213010776, 0.09214331006321108, 0.08201395742909234, 0.030095307400409, 0.03559143009449761, 0.0628790226570567]}}
{"id": "8c15f5e2-d6fb-4406-8daa-8e952370314a", "fitness": 0.09334951411640907, "name": "HybridPSODE", "description": "Hybrid Particle Swarm and Differential Evolution with Adaptive Inertia Weight and Dynamic Crossover for Improved Convergence and Performance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-8))\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09335 with standard deviation 0.04402.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15020140960415862, 0.1514056706042911, 0.15432443215130875, 0.06788637850049106, 0.0764367232364015, 0.09287462830169668, 0.04165454627057841, 0.06271411836698204, 0.04264772001177353]}}
{"id": "72dd0109-9234-42c6-a865-c91670b248f5", "fitness": 0.09066464621831764, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight adjustment and adaptive crossover strategy to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - 0.5 * eval_ratio  # Dynamic inertia weight adjustment\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.8 + 0.1 * eval_ratio  # Adaptive crossover strategy\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09066 with standard deviation 0.04368.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.149027321291737, 0.14493664719333388, 0.14985811255043902, 0.07787444071064509, 0.09610084634694338, 0.05969592363679921, 0.058275841802320594, 0.039991329397576214, 0.040221353035064356]}}
{"id": "b2e9a628-24ec-4f6c-ae62-337570fa9a40", "fitness": 0.09389131804928326, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic inertia and stochastic local search for improved convergence and solution quality.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * eval_ratio\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n                \n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def stochastic_local_search(self, func):\n        for i in range(self.num_particles):\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = self.personal_best[i] + perturbation\n            candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(candidate)\n                self.personal_best_value[i] = candidate_fitness\n                if candidate_fitness < self.global_best_value:\n                    self.global_best = np.copy(candidate)\n                    self.global_best_value = candidate_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.stochastic_local_search(func)\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 41, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09389 with standard deviation 0.04320.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1514671358045585, 0.15414677283386224, 0.1432809448885155, 0.0735823624338049, 0.09889653641706331, 0.08430048521140687, 0.03786564676857318, 0.047868084607549655, 0.05361389347821521]}}
{"id": "4582fdbf-637e-46cf-b911-e6050bf96695", "fitness": 0.11491650087757058, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with stochastic inertia weight and dynamic crossover for better exploration and convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.w = 0.4 + 0.5 * np.random.rand()  # Stochastic inertia weight\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio * 0.5)  # Dynamic crossover\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11492 with standard deviation 0.03960.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15592969079956076, 0.15921983491820468, 0.15534453042518148, 0.0769599441840334, 0.08309957414055502, 0.07358579276425059, 0.09987307254154021, 0.0679834296867643, 0.16225263843804472]}}
{"id": "d94b1bac-caa0-408d-b4b2-1e27378cbe4e", "fitness": 0.0959376647808195, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with hybrid local search to refine exploitation and adaptive parameter adjustments for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-9)) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def local_search(self, func):\n        for i in range(self.num_particles):\n            local_best = np.copy(self.personal_best[i])\n            step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n            for _ in range(5):  # Perform 5 local search steps\n                trial_vector = local_best + np.random.uniform(-step_size, step_size, self.dim)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                if trial_fitness < func(local_best):\n                    local_best = trial_vector\n            if func(local_best) < self.personal_best_value[i]:\n                self.personal_best_value[i] = func(local_best)\n                self.personal_best[i] = local_best\n                if func(local_best) < self.global_best_value:\n                    self.global_best = local_best\n                    self.global_best_value = func(local_best)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            if eval_count % (self.num_particles * 10) == 0:\n                self.local_search(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09594 with standard deviation 0.05036.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.13776131954525683, 0.18123421539987583, 0.17269595137082172, 0.061364925454970964, 0.06577704891336611, 0.06275012629933363, 0.04276861559672951, 0.08501144693196927, 0.05407533351505156]}}
{"id": "9f379b61-9685-4560-921e-554cbbe3e8ba", "fitness": 0.09119045843227847, "name": "EnhancedAdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with a hybrid inertia weight strategy and dynamic crossover adapting to evaluation progress for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - 0.5 * eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09119 with standard deviation 0.05162.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.15345680743804746, 0.1601737265953307, 0.0762853802212825, 0.0889456281449299, 0.06571413936259807, 0.028547196920420403, 0.031902102324648185, 0.05095399036463277]}}
{"id": "b47ae17f-8aaa-47c9-b03b-5fed8e25a564", "fitness": 0.10737835429953146, "name": "AdaptivePSODE", "description": "Improved velocity update mechanism for enhanced convergence speed and accuracy in AdaptivePSODE.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + 0.5 * social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10738 with standard deviation 0.03546.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1570386353145945, 0.14616075724570832, 0.14734444648043055, 0.10335428624020693, 0.08174152157237868, 0.08296835023779403, 0.12242566428963508, 0.07412053641618033, 0.051250990898854765]}}
{"id": "d799a3c9-08ce-41d8-91e6-c8192990c764", "fitness": 0.0878698502447543, "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm-Differential Evolution with adaptive inertia weights and stochastic parameter scaling for enhanced global convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * eval_ratio\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = np.random.uniform(0.5, 1.0)\n            crossover_rate = 0.9\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08787 with standard deviation 0.04968.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14661221296785198, 0.16053210116846184, 0.15800640600718296, 0.06844978865278262, 0.07158439114699666, 0.07418637364380976, 0.03968896278881451, 0.034169688887899174, 0.037598726938989135]}}
{"id": "fddbc061-007f-4335-bec3-ba759e151558", "fitness": 0.09289721971660785, "name": "SynergisticPSODE", "description": "Synergistic PSO-DE with dynamic parameter adaptation and hybrid local-global best strategies to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass SynergisticPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.mutation_factor_min = 0.4\n        self.mutation_factor_max = 0.9\n        self.crossover_rate_min = 0.2\n        self.crossover_rate_max = 0.8\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = self.mutation_factor_min + (self.mutation_factor_max - self.mutation_factor_min) * (1 - eval_ratio)\n            crossover_rate = self.crossover_rate_max - (self.crossover_rate_max - self.crossover_rate_min) * eval_ratio\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 47, "feedback": "The algorithm SynergisticPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09290 with standard deviation 0.04976.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15095397036000724, 0.1662239817787876, 0.14377195221454186, 0.0931084231212852, 0.08911815166064208, 0.09286101477098285, 0.04713857634187446, 0.024553486751705433, 0.028345420449643832]}}
{"id": "0e2357c4-e43e-43ba-9975-0795a9b4b526", "fitness": 0.10513856461981017, "name": "QuantumAdaptivePSODE", "description": "Integrated Quantum-Inspired Swarm Dynamics with Adaptive Differential Evolution for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.quantum_particles = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n        self.quantum_particles = np.copy(self.population)\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n            # Quantum-inspired update\n            self.quantum_particles[i] = self.global_best + np.random.randn(self.dim) * (self.personal_best[i] - self.global_best)\n            self.quantum_particles[i] = np.clip(self.quantum_particles[i], func.bounds.lb, func.bounds.ub)\n            quantum_fitness = func(self.quantum_particles[i])\n            if quantum_fitness < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.quantum_particles[i])\n                self.personal_best_value[i] = quantum_fitness\n                if quantum_fitness < self.global_best_value:\n                    self.global_best = np.copy(self.quantum_particles[i])\n                    self.global_best_value = quantum_fitness\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 3  # Including quantum evaluations", "configspace": "", "generation": 48, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10514 with standard deviation 0.03529.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14849765692996664, 0.14942227276641384, 0.14747339840444929, 0.05908707196740293, 0.08449127278120883, 0.06522289858944397, 0.06850579346630492, 0.11082937259706671, 0.1127173440760344]}}
{"id": "cfca1754-6ec9-4dcd-9c65-c78a6605e66f", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight and diverse mutation strategy for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.4  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "e72ed145-a06c-4100-af9f-87538cd4cd1c", "fitness": 0.09162168431240306, "name": "HybridPSODE", "description": "Hybrid PSO-DE with dynamic adaptive parameters and elite retention for enhanced optimization performance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_init = 0.9\n        self.w_final = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_count, max_budget):\n        w = self.w_init - eval_count * (self.w_init - self.w_final) / max_budget\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_count, max_budget):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.8 + 0.2 * (1 - eval_count / max_budget)  # Decrease mutation factor over time\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover_rate = 0.8 * (0.5 + 0.5 * (self.global_best_value / self.personal_best_value[i]))  # Dynamic crossover\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            self.update_particles(func, eval_count, self.budget)\n            self.differential_evolution(func, eval_count, self.budget)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09162 with standard deviation 0.04494.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1517920172821312, 0.160448335129861, 0.14518541320484524, 0.06715517817045114, 0.09084556821435841, 0.06286131387894311, 0.046614293996932066, 0.0511478591886817, 0.048545179745423606]}}
{"id": "4bd3252c-6f53-40d4-9efb-8885c69765d6", "fitness": 0.12126381584892422, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE by adjusting crossover rate for better diversity and convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio**2)  # Adjusted line for crossover rate\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2\n", "configspace": "", "generation": 51, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12126 with standard deviation 0.03646.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1501351758688928, 0.18123421539987583, 0.17269595137082172, 0.0779493477060107, 0.11015958597519515, 0.09376571852607296, 0.1182993586001242, 0.11078629227992143, 0.07634869691340329]}}
{"id": "a17ed793-1c08-4009-84bc-752955449c5c", "fitness": 0.09228789702246291, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight adjustment to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - eval_ratio * 0.5  # Dynamic inertia weight adjustment\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "0cfee4cf-f5b0-41b0-b17d-aebbfb9b82c6", "fitness": 0.09743900835004558, "name": "ChaoticHybridPSODE", "description": "Hybrid PSO-DE with adaptive chaotic perturbation for enhanced exploration and convergence balance.", "code": "import numpy as np\n\nclass ChaoticHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.chaotic_sequence = self.generate_chaotic_sequence(self.budget)\n\n    def generate_chaotic_sequence(self, size):\n        sequence = np.zeros(size)\n        x = 0.7  # Initial chaotic value\n        for i in range(size):\n            x = 4.0 * x * (1.0 - x)  # Logistic map\n            sequence[i] = x\n        return sequence\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_count):\n        chaotic_factor = self.chaotic_sequence[eval_count]\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social + chaotic_factor * np.random.randn(self.dim)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_count)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 53, "feedback": "The algorithm ChaoticHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09744 with standard deviation 0.04160.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16147783661878257, 0.1524546233080346, 0.14460250784954942, 0.07635085414830944, 0.07902815929474205, 0.06268823816513247, 0.03853929832215419, 0.07044063002547507, 0.09136892741823044]}}
{"id": "7108efaf-dbcc-489f-a74b-503990481f4d", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Introduced dynamic adjustment of inertia weight to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - eval_ratio * 0.4  # Adjusted line for dynamic inertia weight\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "1fed14f3-9a1b-4c8e-b5c9-d41ee5d28ef4", "fitness": 0.09583852798799077, "name": "HybridPSODE", "description": "Hybrid Particle Swarm-Differential Evolution with dynamic parameter adaptation and enhanced mutation strategies for robust global optimization across diverse problem landscapes.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.w = 0.7\n        self.c1 = 1.4\n        self.c2 = 1.4\n        self.mutation_factor_base = 0.6\n        self.crossover_rate_base = 0.7\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            inertia_weight = self.w * (0.9 - eval_ratio * 0.4)\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = self.mutation_factor_base + 0.3 * np.sin(np.pi * eval_ratio)\n            crossover_rate = self.crossover_rate_base * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09584 with standard deviation 0.03707.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14347415330163082, 0.14397224982374146, 0.15002309441800343, 0.06439409609895919, 0.09110600738036445, 0.06788365356080794, 0.05492293635983869, 0.05975900475816176, 0.08701155619040912]}}
{"id": "b26b21c5-8f12-4d1a-8a22-ea5f90c6e3d7", "fitness": -Infinity, "name": "DynamicAdaptivePSODE", "description": "Dynamic Adaptive PSO-DE with chaotic map initialization and opposition-based learning for enhanced convergence and diversity maintenance.", "code": "import numpy as np\n\nclass DynamicAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def chaotic_init(self, size, lower, upper):\n        chaotic_seq = np.zeros(size)\n        chaotic_seq[0] = np.random.uniform(lower, upper)\n        for i in range(1, size):\n            chaotic_seq[i] = 4 * chaotic_seq[i - 1] * (1 - chaotic_seq[i - 1])\n        return lower + chaotic_seq * (upper - lower)\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.array([self.chaotic_init(self.dim, lb, ub) for _ in range(self.num_particles)])\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def opposition_based_learning(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        opposite_population = lb + ub - self.population\n        for i in range(self.num_particles):\n            opposite_fitness = func(opposite_population[i])\n            if opposite_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(opposite_population[i])\n                self.personal_best_value[i] = opposite_fitness\n                self.personal_best[i] = np.copy(opposite_population[i])\n                if opposite_fitness < self.global_best_value:\n                    self.global_best = np.copy(opposite_population[i])\n                    self.global_best_value = opposite_fitness\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.opposition_based_learning(func.bounds)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 56, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {}}
{"id": "f6d904b4-25b4-4a8b-8a3c-42f329a5dda6", "fitness": 0.10223286746276022, "name": "HybridPSODE", "description": "Hybrid PSO-DE with dynamic inertia weight and adaptive parameter scaling for enhanced convergence across varying problem landscapes.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor_min = 0.4\n        self.mutation_factor_max = 0.9\n        self.crossover_rate_min = 0.3\n        self.crossover_rate_max = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        mutation_factor = self.mutation_factor_min + eval_ratio * (self.mutation_factor_max - self.mutation_factor_min)\n        crossover_rate = self.crossover_rate_max - eval_ratio * (self.crossover_rate_max - self.crossover_rate_min)\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 57, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10223 with standard deviation 0.04076.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1566839160961151, 0.15273423570099842, 0.15106729537865116, 0.07115752659840802, 0.09809736316208573, 0.08637486195467436, 0.10211526871467891, 0.034249248009485145, 0.06761609154974524]}}
{"id": "1520c39c-9a03-4d70-89e9-d409defa82e4", "fitness": 0.08906639250588094, "name": "DynamicPSODE", "description": "Enhanced Particle Swarm Optimization with Dynamic Parameter Adjustment and Adaptive Mutation Control for improved convergence handling diverse optimization landscapes.", "code": "import numpy as np\n\nclass DynamicPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_min, self.w_max = 0.3, 0.9\n        self.c1_min, self.c1_max = 0.5, 2.5\n        self.c2_min, self.c2_max = 0.5, 2.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_parameters(self, eval_ratio):\n        self.w = self.w_max - eval_ratio * (self.w_max - self.w_min)\n        self.c1 = self.c1_max - eval_ratio * (self.c1_max - self.c1_min)\n        self.c2 = self.c2_min + eval_ratio * (self.c2_max - self.c2_min)\n\n        # Adjust mutation factor based on convergence\n        if self.global_best_value != np.inf:\n            self.mutation_factor = 0.5 + 0.5 * (1 - eval_ratio) * (self.global_best_value / np.mean(self.personal_best_value))\n\n    def update_particles(self, func):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_parameters(eval_ratio)\n            self.update_particles(func)\n            self.differential_evolution(func)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 58, "feedback": "The algorithm DynamicPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08907 with standard deviation 0.04263.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14702340045747342, 0.14565627625742272, 0.14723535946885025, 0.07681461325475947, 0.07937576315106054, 0.06978214106055347, 0.04541354121304797, 0.04910173461699974, 0.04119470307276085]}}
{"id": "e68582a7-72bf-4966-b499-de8cf277831b", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamically adjusted inertia weight for improved exploration-exploitation balance. ", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - 0.4 * eval_ratio  # Dynamically adjusted inertia weight\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "e97368a5-ddca-45c1-9b77-605017d8e106", "fitness": 0.10234301589276112, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight and adaptive crossover for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9  # Changed for dynamic inertia weight\n        self.w_min = 0.4  # Changed for dynamic inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social  # Updated with dynamic inertia weight\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.5 + 0.4 * eval_ratio  # Adaptive crossover rate\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10234 with standard deviation 0.03900.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14241927756132844, 0.15275143210078113, 0.14677912310452657, 0.09582418165008011, 0.10858313040921974, 0.07808035990539153, 0.025496048177672592, 0.1002664478498867, 0.07088714227596338]}}
{"id": "ac2e11c0-9b1b-41d9-81fb-ca54657fedc8", "fitness": 0.09737669237783245, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with refined crossover strategy for improved solution space exploration.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.95 * (1 - eval_ratio)  # Change made here\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09738 with standard deviation 0.03516.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14939767959084338, 0.1453299867837754, 0.14170584250453022, 0.0648666478185489, 0.08376133121545248, 0.0813089015852011, 0.05549602503071471, 0.07037983645318358, 0.08414398041824223]}}
{"id": "48cb2242-e1df-47f6-abd0-95c43318e5ed", "fitness": 0.09228789702253694, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight and early convergence detection for improved exploration-exploitation balance and efficiency.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = self.w_min + (0.9 - self.w_min) * (1 - eval_ratio)  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2\n            if abs(self.global_best_value - np.mean(self.personal_best_value)) < 1e-5:\n                break  # Early convergence detection", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643818672, 0.0697579885837436, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "c8bf6688-aa87-49dd-ac65-a73a12c01c71", "fitness": 0.09466545596433973, "name": "EnhancedAdaptivePSODE", "description": "Hybrid PSO-DE with adaptive learning rates and dynamic population adjustments for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_init = 0.9\n        self.w_final = 0.4\n        self.c1_init = 2.5\n        self.c1_final = 0.5\n        self.c2_init = 0.5\n        self.c2_final = 2.5\n        self.mutation_factor_init = 0.8\n        self.mutation_factor_final = 0.2\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_init - (self.w_init - self.w_final) * eval_ratio\n        c1 = self.c1_init - (self.c1_init - self.c1_final) * eval_ratio\n        c2 = self.c2_init + (self.c2_final - self.c2_init) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        mutation_factor = self.mutation_factor_init - (self.mutation_factor_init - self.mutation_factor_final) * eval_ratio\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09467 with standard deviation 0.03960.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14673886702774597, 0.1536286201888607, 0.1441930277561636, 0.07620752291424615, 0.0697289705885511, 0.07749795434645079, 0.04858323125133923, 0.08559329822623207, 0.04981761137946794]}}
{"id": "46b6aaa1-e9bb-4179-9e0b-ace9a9828c38", "fitness": 0.11297976026363066, "name": "EnhancedAdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic strategy adaptation and learning-driven parameter control for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def dynamic_adaptation(self, eval_count):\n        # Dynamically adapt parameters based on progress\n        adapt_ratio = eval_count / self.budget\n        self.w = 0.4 + 0.1 * np.cos(adapt_ratio * np.pi)  # Adaptive inertia weight\n        self.c1 = 2.0 - 1.5 * adapt_ratio  # Adaptive cognitive component\n        self.c2 = 1.5 + 0.5 * adapt_ratio  # Adaptive social component\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.dynamic_adaptation(eval_count)\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11298 with standard deviation 0.04386.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15531857372812485, 0.1828002816841865, 0.17312092175031946, 0.07437133627475678, 0.06839755755104837, 0.07653282556356567, 0.08296432508232165, 0.12474229966276917, 0.07856972107558347]}}
{"id": "62f8adfb-dddb-4714-ae98-04b4723a464b", "fitness": 0.09833925114547849, "name": "AdaptivePSODE", "description": "Enhanced PSO-DE with elite selection and adaptive inertia weight for improved convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Changed initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - (eval_ratio * 0.5)  # Adaptive inertia weight\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        elite_indices = np.argsort(self.personal_best_value)[:int(0.2 * self.num_particles)]  # Elite selection\n        for i in elite_indices:\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09834 with standard deviation 0.04080.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16071336820536775, 0.15199639668618237, 0.1406800260542811, 0.08325060515006266, 0.10346901589627755, 0.08293780551702756, 0.05782104324105686, 0.050340598528790026, 0.05384440103026056]}}
{"id": "2465cec7-6e64-411b-a814-0e01a3e59783", "fitness": 0.0962314820492666, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic learning factors and neighborhood-based velocity adjustment to enhance convergence and maintain diversity.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            w = self.w_max - eval_ratio * (self.w_max - self.w_min)\n            c1 = self.c1_max - eval_ratio * (self.c1_max - self.c1_min)\n            c2 = self.c2_min + eval_ratio * (self.c2_max - self.c2_min)\n            \n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = c2 * r2 * (self.global_best - self.population[i])\n            neighborhood_effect = self.get_neighborhood_effect(i)\n            self.velocity[i] = w * self.velocity[i] + cognitive + social + neighborhood_effect\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def get_neighborhood_effect(self, index):\n        neighbor_indices = [(index + offset) % self.num_particles for offset in range(-1, 2) if offset != 0]\n        neighborhood_center = np.mean(self.population[neighbor_indices], axis=0)\n        return 0.1 * (neighborhood_center - self.population[index])\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 66, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09623 with standard deviation 0.04278.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1479229926403267, 0.15083756284931749, 0.15400629701359225, 0.07876132920370427, 0.10230348555330471, 0.07665193159827843, 0.044580618700866936, 0.07516329273413791, 0.03585582814987065]}}
{"id": "96422bff-6f67-41ff-9868-45aa9b12f68a", "fitness": 0.09228789702246291, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic inertia weight and enhanced crossover strategy for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9  # Dynamic inertia weight\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "2b3f2fce-0f69-423d-ad50-0fb83d27b729", "fitness": 0.0982736896901211, "name": "BioInspiredHybrid", "description": "Bio-inspired Hybrid Enhancement combines adaptive swarm intelligence with dynamic learning strategies, enhancing solution accuracy and convergence speed across diverse optimization landscapes.", "code": "import numpy as np\n\nclass BioInspiredHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.exploration_best = None\n        self.exploration_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.exploration_best = np.copy(self.population[0])\n        self.exploration_best_value = np.inf\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            exploration = self.c1 * r1 * (self.exploration_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social + exploration\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n            if fitness_value < self.exploration_best_value:\n                self.exploration_best = np.copy(self.population[i])\n                self.exploration_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n                if trial_fitness < self.exploration_best_value:\n                    self.exploration_best = np.copy(trial_vector)\n                    self.exploration_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 68, "feedback": "The algorithm BioInspiredHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09827 with standard deviation 0.04058.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15184406135743567, 0.14781080372236677, 0.14820654848191106, 0.09729189456798937, 0.0868131198519948, 0.0743089555675992, 0.030935887699898523, 0.09020685888399405, 0.05704507707790041]}}
{"id": "6c482944-0e90-407f-b631-6de5ddeeef40", "fitness": 0.09228789702246291, "name": "AdaptivePSODE", "description": "Enhanced PSO-DE with adaptive inertia weight and elitist selection to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Adjusted for dynamically decreasing inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.5  # Dynamically adjust inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "e74ebcbe-3e99-4d2e-8464-90f3aecba0d4", "fitness": 0.11273987852827677, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with adaptive learning rates and chaotic mutation for improved exploration and convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.c1 = 1.5 + eval_ratio  # Adaptive learning rate for cognitive component\n            self.c2 = 1.5 - eval_ratio  # Adaptive learning rate for social component\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            chaotic_factor = 4 * eval_ratio * (1 - eval_ratio)  # Chaotic mutation factor\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c]) + chaotic_factor\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11274 with standard deviation 0.04112.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15188217623280098, 0.18123421539987583, 0.17269595137082172, 0.10033742785519073, 0.0965464452908521, 0.07780307306189393, 0.06817083468473806, 0.08169407604985168, 0.08429470680846585]}}
{"id": "2b0877a7-35ea-4233-836a-03e6aa867ecf", "fitness": 0.1020226163371985, "name": "QuantumAdaptivePSODE", "description": "Introduce Quantum-Inspired Swarm Dynamics to Adaptive PSO-DE for improved exploration and convergence leveraging quantum superposition and entanglement principles.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.quantum_register = np.random.uniform(0, 1, (self.num_particles, self.dim))\n      \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def quantum_update(self, func):\n        for i in range(self.num_particles):\n            quantum_state = self.quantum_register[i]\n            quantum_position = (quantum_state >= 0.5).astype(float)\n            quantum_position = np.where(quantum_position, self.population[i], self.global_best)\n            trial_fitness = func(quantum_position)\n            if trial_fitness < self.global_best_value:\n                self.global_best = np.copy(quantum_position)\n                self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.quantum_update(func)\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 71, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10202 with standard deviation 0.03706.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1445105056487288, 0.14763721428979404, 0.15462392841356898, 0.09316306677183883, 0.07876745104271332, 0.08947965236786382, 0.10325485444252869, 0.043349080343865976, 0.06341779371388412]}}
{"id": "6cccc4b7-b1fd-402b-9cc6-7963eb2bfe8f", "fitness": 0.09266523914972855, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with adaptive inertia and dynamic population size for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 20\n        self.final_particles = 5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.initial_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.initial_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.initial_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        num_particles = int(self.initial_particles - eval_ratio * (self.initial_particles - self.final_particles))\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        for i in range(num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        num_particles = int(self.initial_particles - eval_ratio * (self.initial_particles - self.final_particles))\n        for i in range(num_particles):\n            indices = [idx for idx in range(num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += 2 * int(self.initial_particles - eval_ratio * (self.initial_particles - self.final_particles))", "configspace": "", "generation": 72, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09267 with standard deviation 0.05044.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14974224132950487, 0.15706103575822328, 0.06649641201835732, 0.10744398324400306, 0.07468192811901064, 0.03215480053001252, 0.045382268159302463, 0.03628932867052659]}}
{"id": "0704e99a-f706-40c7-a861-a75271e43e8b", "fitness": 0.11110698258828369, "name": "AdaptivePSODE", "description": "Further enhance Adaptive PSO-DE with adaptive learning rates for cognitive and social components based on the evaluation ratio to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.c1 = 1.5 * (1 - eval_ratio) + 0.5 * eval_ratio\n            self.c2 = 1.5 * eval_ratio + 0.5 * (1 - eval_ratio)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11111 with standard deviation 0.03784.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.16394502011227208, 0.15567648438853932, 0.1664371315218518, 0.07728898348411906, 0.07219825014127257, 0.08637187012503478, 0.09517554969921993, 0.11080206114679547, 0.07206749267544821]}}
{"id": "d8e40c32-f309-44c9-9b6a-f34f3661e160", "fitness": 0.09482750567937888, "name": "EnhancedAdaptivePSODE", "description": "Enhanced Particle Swarm Optimization with Dynamic Parameter Adjustment and Adaptive Differential Evolution for improved convergence stability and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_min, self.w_max = 0.3, 0.9\n        self.c1_min, self.c1_max = 1.0, 2.5\n        self.c2_min, self.c2_max = 1.0, 2.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - eval_ratio * (self.w_max - self.w_min)\n        c1 = self.c1_max - eval_ratio * (self.c1_max - self.c1_min)\n        c2 = self.c2_min + eval_ratio * (self.c2_max - self.c2_min)\n\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def adaptive_differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.5 + 0.3 * np.sin(eval_ratio * np.pi)\n            crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.adaptive_differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09483 with standard deviation 0.04188.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1475452570779724, 0.14975679398036623, 0.15768936595284255, 0.06617325615021885, 0.0662336838637485, 0.07388840195163304, 0.08512828597315858, 0.06859523609465801, 0.03843727006981179]}}
{"id": "40c8af5d-7b74-4c52-b1f0-16e81fff2eb8", "fitness": 0.0908331757234221, "name": "ImprovedAdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic inertia weight and adaptive crossover strategies for enhanced convergence and exploration capabilities.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_init = 0.9\n        self.w_final = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        inertia_weight = self.w_init - (self.w_init - self.w_final) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + 0.3 * eval_ratio\n            self.crossover_rate = 0.9 * (1 - eval_ratio) + 0.1\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 75, "feedback": "The algorithm ImprovedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09083 with standard deviation 0.05619.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.17879948277630664, 0.16110255479523616, 0.15688123499980466, 0.06834951831318958, 0.07661614616002366, 0.07904838801618164, 0.03244180996424206, 0.021405592839756404, 0.04285385364605809]}}
{"id": "16e3e2a3-90bf-4f7e-b20b-d4f3d637acda", "fitness": 0.09180711576992719, "name": "AdaptivePSODE", "description": "AdaptivePSODE with dynamic inertia weight adjustment and improved crossover strategy for enhancing convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Increased initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.4 + 0.5 * (1 - eval_ratio)  # Dynamic inertia weight adjustment\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.8 * (1 - eval_ratio)  # Improved crossover strategy\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09181 with standard deviation 0.04342.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15176391618641027, 0.14614423794717002, 0.15148285117740812, 0.07095282773954426, 0.09541912443544265, 0.06388139967057715, 0.0465530893107029, 0.04320543539234156, 0.05686116006974773]}}
{"id": "a40848b6-5f66-413f-9138-ef9e33512cb5", "fitness": 0.08958759085578988, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE by adjusting inertia weight dynamically and enhancing crossover operation to boost exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - eval_ratio * 0.5  # Dynamically adjust inertia weight\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < (self.crossover_rate + 0.1)  # Enhance crossover operation\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.05082.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14603585395032725, 0.1644871380071775, 0.14980131831635501, 0.09591564853634471, 0.08970135200441631, 0.06555952204166471, 0.023762330779256158, 0.03235299931940927, 0.038672154747158016]}}
{"id": "7c7f6511-8c1a-4150-b61f-51831ad0654c", "fitness": 0.09284879025424081, "name": "QuantumInspiredAdaptivePSODE", "description": "Hybrid Quantum-Inspired Adaptive PSO-DE with entropy-based diversity control and dynamic parameter adjustment for superior global search capability.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def entropy_control(self):\n        diversity = np.mean(np.std(self.population, axis=0))\n        return 1 - np.exp(-diversity)\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            quantum_jump = self.entropy_control() * np.random.uniform(-1, 1, self.dim) * np.abs(self.global_best - self.personal_best[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social + quantum_jump\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-8))\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 78, "feedback": "The algorithm QuantumInspiredAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09285 with standard deviation 0.04665.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14855915981068435, 0.1495514910941732, 0.16007189272660882, 0.07265410371466696, 0.06336210740553505, 0.06836196702507003, 0.1023969965501551, 0.026250553470723692, 0.04443084049055013]}}
{"id": "8d202a9d-cb83-43b7-91fa-906a4dba8bcf", "fitness": 0.11988882192856727, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with self-adaptive parameter tuning, improved diversity retention, and adaptive mutation factor scaling for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + 0.3 * eval_ratio * (self.personal_best_value[i] / self.global_best_value)  # Updated line: adjusted scaling\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11989 with standard deviation 0.03810.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14912598403660038, 0.1813814166351836, 0.17269595137082172, 0.08602852548201301, 0.10553049505752199, 0.07967160161275832, 0.13455540222063145, 0.0884307310031629, 0.08157928993841201]}}
{"id": "269928dd-a181-479d-9c77-a994ee3c9978", "fitness": 0.0878608384439797, "name": "HybridPSODE", "description": "Hybrid PSO-DE with Adaptive Mutation and Crossover for Dynamic Exploration-Exploitation Balance, incorporating adaptive inertia and feedback-driven mutation and crossover rates to enhance convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30  # Increased population size for better exploration\n        self.w_min = 0.4  # Minimum inertia weight\n        self.w_max = 0.9  # Maximum inertia weight\n        self.c1 = 2.0  # Increased cognitive component\n        self.c2 = 2.0  # Increased social component\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            adaptive_factor = (self.personal_best_value[i] - self.global_best_value) / (self.global_best_value + 1e-9)\n            mutation_factor = 0.5 + adaptive_factor\n            crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08786 with standard deviation 0.04524.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14827433924978917, 0.14331054428052425, 0.1538278543889362, 0.07056511871775717, 0.07093263388204862, 0.0796936954850822, 0.04631791288101461, 0.02958407994570922, 0.04824136716495586]}}
{"id": "15997490-f17e-4e1f-b3c9-5c98b55999c4", "fitness": 0.09939159273322887, "name": "AdaptivePSODE", "description": "Improved Adaptive PSO-DE with dynamic inertia weight and elite selection for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        elite_index = np.argmin(self.personal_best_value)\n        for i in range(self.num_particles):\n            if i == elite_index:\n                continue\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09939 with standard deviation 0.04391.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1519252999236418, 0.16519220822512848, 0.15082365661247898, 0.09311762594457229, 0.09080887723174336, 0.07958459119959682, 0.029954109154190056, 0.07480282472917466, 0.05831514157853335]}}
{"id": "4dfd1bc4-ceeb-4137-8070-b0608dc710ec", "fitness": 0.09228789702246291, "name": "AdaptivePSODE", "description": "Introduced variable inertia weight to enhance exploration in the Adaptive PSO-DE algorithm.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            # Variable inertia weight for enhanced exploration\n            self.w = 0.9 - eval_ratio * 0.5\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "ad4e1012-a443-4ce9-b999-a894a71e5cc1", "fitness": 0.10053135378248934, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with adaptive inertia weight and dynamic mutation strategy for refined convergence.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w *= 0.99  # Dynamic inertia weight adaptation\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            adaptive_mutation = 0.8 * (1 - eval_ratio)  # Adaptive mutation strategy\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + adaptive_mutation * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10053 with standard deviation 0.03964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1516777171944198, 0.14666750213093027, 0.1614312175237641, 0.08428735291027889, 0.07598519707590068, 0.08238644714625598, 0.03977929053737872, 0.08690110137887053, 0.0756663581446051]}}
{"id": "15219d43-4e30-4f68-8ea7-0ed2c7af9d73", "fitness": 0.09252151450195625, "name": "HybridPSODE", "description": "Hybrid PSO-DE with adaptive inertia weight and tournament selection for increased convergence and exploration balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        inertia_weight = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def tournament_selection(self):\n        tournament_size = 3\n        selected_indices = np.random.choice(self.num_particles, tournament_size, replace=False)\n        best_index = selected_indices[np.argmin(self.personal_best_value[selected_indices])]\n        return best_index\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            if eval_count % (self.num_particles * 2) == 0 and eval_count > 0:\n                selected_index = self.tournament_selection()\n                self.global_best = np.copy(self.personal_best[selected_index])\n                self.global_best_value = self.personal_best_value[selected_index]\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 84, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09252 with standard deviation 0.04972.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14951494375001761, 0.1642820219651927, 0.07310078620057037, 0.08324438656065714, 0.07077855395175725, 0.04802162690533296, 0.03240587784933058, 0.046610278816131445]}}
{"id": "de9b1bda-1081-402b-a5ac-da1092424192", "fitness": 0.09187635610093298, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic inertia weight and diversity-enhanced mutation for robust exploration-exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.initial_inertia = 0.9\n        self.final_inertia = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_mutation_factor = 0.8\n        self.final_mutation_factor = 0.2\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        inertia_weight = self.initial_inertia - eval_ratio * (self.initial_inertia - self.final_inertia)\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = inertia_weight * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = self.initial_mutation_factor - eval_ratio * (self.initial_mutation_factor - self.final_mutation_factor)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 85, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09188 with standard deviation 0.04518.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1527842922254079, 0.150563393044314, 0.15215300826857736, 0.06688013320626118, 0.09868796536303459, 0.06766846581547958, 0.041659205031940094, 0.04911721062485208, 0.04737353132852995]}}
{"id": "788683bc-49e5-4613-9f07-dc64d517bf01", "fitness": 0.09158041025933826, "name": "EnhancedAdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic parameter adaptation and elite-guided search for improved convergence and solution precision.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_min, self.w_max = 0.4, 0.9\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio\n        c1 = self.c1_max - (self.c1_max - self.c1_min) * eval_ratio\n        c2 = self.c2_min + (self.c2_max - self.c2_min) * eval_ratio\n\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-8)) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09158 with standard deviation 0.04937.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14897898906237672, 0.14412301618298673, 0.15686738771068154, 0.08059370401886301, 0.11435815649174885, 0.08265560949577155, 0.01939507175369848, 0.03227045352009861, 0.044981304097818864]}}
{"id": "01a0b67e-c461-483d-96d4-7a8684dbc243", "fitness": -Infinity, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic parameter adaptation and chaos-driven perturbation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_init = 0.9\n        self.w_final = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_init - eval_ratio * (self.w_init - self.w_final)  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * 0.5  # Dynamic mutation factor\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def perturbation(self, eval_ratio):\n        chaos_param = 0.7\n        for i in range(self.num_particles):\n            if np.random.rand() < chaos_param * (1 - eval_ratio):\n                perturb = np.random.normal(0, 1, self.dim)\n                self.population[i] += perturb * (func.bounds.ub - func.bounds.lb) * 0.01\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            self.perturbation(eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 87, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {}}
{"id": "e7ce8f3b-1740-42de-a2cf-d011bfb0aeaf", "fitness": 0.10320466493690512, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with adaptive inertia weight adjustment and strategic mutation factor scaling.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.w = 0.9 - eval_ratio * 0.5  # Adaptive inertia weight decreases over time\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * 0.5  # Strategic scaling of mutation factor\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10320 with standard deviation 0.05358.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.19942040235067837, 0.16001440990872384, 0.14852505066927812, 0.0729132735024618, 0.10098282449721485, 0.10542081162970074, 0.03537080315993968, 0.033695976348651846, 0.07249843236549691]}}
{"id": "de3d15bd-a75a-4f6c-ab7a-847cbae87b85", "fitness": 0.09127536630591898, "name": "QuantumInspiredPSODE", "description": "Quantum-inspired PSO-DE with adaptive quantum gates and dynamic topology for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.velocity[i] = self.apply_quantum_gates(self.velocity[i], eval_ratio)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def apply_quantum_gates(self, velocity, eval_ratio):\n        quantum_gate = np.random.rand(self.dim) < (0.5 + eval_ratio * 0.5)\n        return np.where(quantum_gate, -velocity, velocity)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 89, "feedback": "The algorithm QuantumInspiredPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09128 with standard deviation 0.04886.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14562651788380454, 0.16169368001226336, 0.1642975036361154, 0.07981193818780152, 0.06681774882942926, 0.06317108192629028, 0.025998517624251316, 0.0646580840015133, 0.0494032246518018]}}
{"id": "19511b62-8514-465b-b60d-d5a8a5558a83", "fitness": 0.09305519291668417, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with dynamic inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        self.w = 0.9 - eval_ratio * 0.4  # Adjusted line: Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) \n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09306 with standard deviation 0.04964.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.15256556133636157, 0.16225604989276443, 0.15897289023071692, 0.07473860901441842, 0.08822963751030133, 0.07249450456576556, 0.0240713776376823, 0.03465952082301005, 0.06950858523913694]}}
{"id": "9ba43b3c-141f-4eb9-8c9b-57dcd69630b6", "fitness": 0.09531984032351216, "name": "AdaptivePSODE", "description": "AdaptivePSO-DE enhanced with dynamic inertia weight and adaptive mutation factor to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9  # Changed line: added for dynamic inertia weight\n        self.w_min = 0.4  # Changed line: added for dynamic inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            # Changed line: Dynamic inertia weight\n            self.w = self.w_max - eval_ratio * (self.w_max - self.w_min)\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            # Changed line: Adaptive mutation factor\n            self.mutation_factor = 0.5 + 0.3 * (1 - eval_ratio) * (self.personal_best_value[i] / (self.global_best_value + 1e-8))\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.03830.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1469899744037214, 0.14073427721901732, 0.14077862432792032, 0.07081386950083013, 0.09106052373252749, 0.06759194809741109, 0.07257917648734902, 0.028358044513672298, 0.09897212462916039]}}
{"id": "0a9fac29-3269-46de-abba-04e787bd151e", "fitness": 0.09228789428615983, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic inertia weight and adaptive mutation strategy for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * eval_ratio  # Dynamic inertia weight\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / (self.global_best_value + 1e-8))  # Prevent division by zero\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 92, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905417560671, 0.16017372525621376, 0.06902959964344424, 0.08850654806281555, 0.06975798180697601, 0.03052302373613225, 0.03832639878342947, 0.06042956259220422]}}
{"id": "8c62366d-0d11-4426-a064-53ee610aea1b", "fitness": 0.09228789702246291, "name": "EnhancedAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic variation of inertia and crossover rates for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.w_max - eval_ratio * (self.w_max - self.w_min)\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value)\n            crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09229 with standard deviation 0.04932.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.1647351545186162, 0.14910905513569273, 0.1601737265953307, 0.06902960682184478, 0.08850655643761829, 0.06975798858364579, 0.030523023736113597, 0.03832639878263777, 0.06042956259066634]}}
{"id": "fb74c104-2b94-4db0-b3ff-21f61c491bb4", "fitness": -Infinity, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with dynamic parameter adaption and a novel local search mechanism for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_inertia_weight(self, eval_ratio):\n        return self.w_max - (self.w_max - self.w_min) * eval_ratio\n\n    def local_search(self, particle):\n        perturb = np.random.uniform(-0.1, 0.1, self.dim)\n        return np.clip(particle + perturb, func.bounds.lb, func.bounds.ub)\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            w = self.update_inertia_weight(eval_ratio)\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n            # Apply local search to improve exploitation\n            local_candidate = self.local_search(self.population[i])\n            local_fitness = func(local_candidate)\n            if local_fitness < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(local_candidate)\n                self.personal_best_value[i] = local_fitness\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.global_best_value - self.personal_best_value[i]) / (self.global_best_value + 1e-9)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 3", "configspace": "", "generation": 94, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {}}
{"id": "00c626cc-9574-426b-8045-e4f29e235aad", "fitness": 0.125877998181552, "name": "AdaptivePSODE", "description": "Enhanced Adaptive PSO-DE with improved mutation factor dynamics for better convergence speed.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) * 0.95\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12588 with standard deviation 0.03402.", "error": "", "parent_ids": ["d1e01775-10c8-4ecd-a311-41ed582b51ae"], "operator": null, "metadata": {"aucs": [0.14954812602309664, 0.1813814166351836, 0.17269595137082172, 0.09622913552937107, 0.11755329022072603, 0.08251580957624516, 0.13335351560228037, 0.1129051316259918, 0.08671960705025161]}}
{"id": "b8767955-e4a0-40d3-99dc-ab7223bd9d31", "fitness": 0.09852965205080624, "name": "HybridDynamicAdaptivePSODE", "description": "Hybrid Dynamic Adaptive PSO-DE with inertia weight adaptation and diversity-driven mutation factor control for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass HybridDynamicAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        w = self.initial_w - eval_ratio * (self.initial_w - self.final_w)\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = w * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        diversity = np.mean(np.std(self.population, axis=0))\n        adaptive_mutation_factor = 0.8 * (1 - eval_ratio) + diversity * 0.2\n        crossover_rate = 0.9 * (1 - eval_ratio)\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant_vector = self.population[a] + adaptive_mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 96, "feedback": "The algorithm HybridDynamicAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09853 with standard deviation 0.04323.", "error": "", "parent_ids": ["00c626cc-9574-426b-8045-e4f29e235aad"], "operator": null, "metadata": {"aucs": [0.16533537449173408, 0.14980085477270588, 0.14800718486290732, 0.09089744857151205, 0.08876744305547879, 0.07450334413445459, 0.07843139340941907, 0.0293479584672115, 0.06167586669183289]}}
{"id": "25c1ecc7-5820-4611-b223-ceac7aa00500", "fitness": 0.10061681868744675, "name": "AdaptivePSODE", "description": "Dynamic Particle Attraction and Adaptive CR for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            # Dynamic particle attraction\n            attract_factor = np.tanh(1 - eval_ratio)\n            self.velocity[i] = self.w * self.velocity[i] + attract_factor * (cognitive + social)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) * 0.95\n            # Adaptive crossover rate\n            self.crossover_rate = 0.1 + 0.8 * (1 - np.tanh(eval_ratio))\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10062 with standard deviation 0.03932.", "error": "", "parent_ids": ["00c626cc-9574-426b-8045-e4f29e235aad"], "operator": null, "metadata": {"aucs": [0.15986542650227054, 0.13903301915710053, 0.16033249704926666, 0.06410472687891444, 0.07340820108753021, 0.10534284433414975, 0.06325255999876522, 0.0720929325584545, 0.06811916062056889]}}
{"id": "fe50ef47-ecca-48b9-a942-33fe00fdb7ba", "fitness": 0.09807569654295839, "name": "CoalescedPSODE", "description": "Coalesced PSO-DE with adaptive elitism and dynamic inertia for enhanced convergence and exploration balance.", "code": "import numpy as np\n\nclass CoalescedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.6\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            inertia = (0.9 - eval_ratio * (0.9 - 0.4))\n            self.velocity[i] = inertia * self.velocity[i] + cognitive + social\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.8 * (1 - eval_ratio)\n            self.crossover_rate = 0.6 + eval_ratio * 0.4\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 98, "feedback": "The algorithm CoalescedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09808 with standard deviation 0.04325.", "error": "", "parent_ids": ["00c626cc-9574-426b-8045-e4f29e235aad"], "operator": null, "metadata": {"aucs": [0.16436566500530903, 0.14385152953259683, 0.15752497882194205, 0.08006982214614111, 0.08580916430450125, 0.08006104816302517, 0.03189221596340064, 0.0675880961098313, 0.07151874883987808]}}
{"id": "3b7d511d-3187-4cdb-8c1c-d347437cdb0c", "fitness": 0.09606713951135593, "name": "ImprovedCooperativePSODE", "description": "Improved Cooperative Adaptive PSO-DE by integrating fitness diversity and adaptive velocity adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedCooperativePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n        self.population = None\n        self.velocity = None\n        self.personal_best = None\n        self.personal_best_value = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocity = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.num_particles, self.dim))\n        self.personal_best = np.copy(self.population)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best = np.copy(self.population[0])\n        self.global_best_value = np.inf\n\n    def update_particles(self, func, eval_ratio):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocity[i] = self.w * self.velocity[i] + cognitive + social\n            # Adaptive inertia weight adjustment\n            self.w = 0.9 - (0.5 * eval_ratio)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            fitness_value = func(self.population[i])\n            if fitness_value < self.personal_best_value[i]:\n                self.personal_best[i] = np.copy(self.population[i])\n                self.personal_best_value[i] = fitness_value\n            if fitness_value < self.global_best_value:\n                self.global_best = np.copy(self.population[i])\n                self.global_best_value = fitness_value\n\n    def differential_evolution(self, func, eval_ratio):\n        fitness_diversity = np.std(self.personal_best_value)\n        for i in range(self.num_particles):\n            indices = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            self.mutation_factor = 0.5 + eval_ratio * (self.personal_best_value[i] / self.global_best_value) * 0.95\n            self.mutation_factor *= (1 + fitness_diversity / (self.global_best_value + np.finfo(float).eps))\n            self.crossover_rate = 0.9 * (1 - eval_ratio)\n            mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(crossover):\n                crossover[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = np.copy(trial_vector)\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best[i] = np.copy(trial_vector)\n                if trial_fitness < self.global_best_value:\n                    self.global_best = np.copy(trial_vector)\n                    self.global_best_value = trial_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        eval_count = 0\n        while eval_count < self.budget:\n            eval_ratio = eval_count / self.budget\n            self.update_particles(func, eval_ratio)\n            self.differential_evolution(func, eval_ratio)\n            eval_count += self.num_particles * 2", "configspace": "", "generation": 99, "feedback": "The algorithm ImprovedCooperativePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09607 with standard deviation 0.05182.", "error": "", "parent_ids": ["00c626cc-9574-426b-8045-e4f29e235aad"], "operator": null, "metadata": {"aucs": [0.16579054007291916, 0.16301768775997527, 0.1535572950862618, 0.08854551642645725, 0.08917361735435092, 0.09341532987527101, 0.029690084940752648, 0.061604475575026574, 0.019809708511188684]}}
