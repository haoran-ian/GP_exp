{"id": "1da56081-ab02-4bdb-ae07-5adb60d62678", "fitness": 0.06225854638041634, "name": "HybridSwarmOptimizer", "description": "A hybrid swarm-based algorithm combining particle swarm optimization with differential evolution for adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.7\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06226 with standard deviation 0.00270.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05981615343141489, 0.06170678880309566, 0.05728623035365277, 0.06339144468263125, 0.06542066895594745, 0.060684914849403304, 0.06423575165699535, 0.06629918124063883, 0.06148578344996758]}}
{"id": "be0aecc6-7011-481b-9664-da68d22e2020", "fitness": 0.06623960182161774, "name": "HybridSwarmOptimizer", "description": "A hybrid swarm-based algorithm with adaptive differential weight for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.7\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06624 with standard deviation 0.00489.", "error": "", "parent_ids": ["1da56081-ab02-4bdb-ae07-5adb60d62678"], "operator": null, "metadata": {"aucs": [0.06111223339938876, 0.05975094367495626, 0.06919819684542317, 0.0648041693578928, 0.06331626588636985, 0.07355032913846882, 0.06567773406102173, 0.06415800003242211, 0.07458854399861614]}}
{"id": "28f842bd-1b33-488d-9a80-62fa9b70d234", "fitness": 0.06305953585965743, "name": "EnhancedHybridSwarmOptimizer", "description": "Enhanced Hybrid Swarm Optimizer using adaptive inertia weight and elitism for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n        \n        for _ in range(self.budget // self.population_size):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO with adaptive inertia\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06306 with standard deviation 0.00269.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.062092886034119, 0.05794567768933445, 0.061031433634959775, 0.06584149851328969, 0.06138480494874776, 0.0647211052389659, 0.0667287293706118, 0.06219551028686865, 0.0655941770200198]}}
{"id": "36194286-77b3-499f-bcf4-0d52f9e3a81b", "fitness": 0.06489137072565564, "name": "EnhancedHybridSwarmOptimizer", "description": "An enhanced hybrid swarm optimizer incorporating adaptive inertia weights and diversity-promoting mechanisms for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.uniform(0, 1, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, dim))\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n        self.min_inertia = 0.4\n        self.max_inertia = 0.9\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Calculate inertia weight\n            inertia_weight = self.max_inertia - (self.max_inertia - self.min_inertia) * (eval_count / self.budget)\n\n            # Update velocities and positions for PSO with adaptive inertia\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity promotion\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06489 with standard deviation 0.00227.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.06334052409960134, 0.06198601737493692, 0.0609312814154781, 0.06719407076726147, 0.06572789879022845, 0.06462379246162842, 0.06810750378697206, 0.06661348436861214, 0.06549776346618186]}}
{"id": "530afef5-4104-45bd-be01-6fafa9bc6205", "fitness": 0.06148067904716497, "name": "HybridSwarmOptimizer", "description": "Enhance the exploration capabilities of the HybridSwarmOptimizer by increasing the inertia weight for more diverse search patterns.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.8  # Adjusted inertia weight for improved exploration\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 4, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06148 with standard deviation 0.00298.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.05803533362569224, 0.06185558227792698, 0.056686987243874554, 0.06149473509652703, 0.0655908491428645, 0.06004330165085192, 0.06231072149116357, 0.06647486765672572, 0.06083373323885821]}}
{"id": "735a8a4b-9abc-4c78-8eaf-b92e3874cd2f", "fitness": 0.06092306920073429, "name": "EnhancedHybridSwarmOptimizer", "description": "Enhanced Hybrid Swarm Optimizer with Dynamic Adaptive Mechanisms for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia_weight = 0.9  # Initial inertia weight\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n\n            # Update velocities and positions for PSO\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                self.inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06092 with standard deviation 0.00297.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.061263687138159884, 0.05775447328992955, 0.05598653122052266, 0.06494237274027603, 0.06118160823518248, 0.05929885024314174, 0.06581215192730228, 0.06198939186282826, 0.060078556149265716]}}
{"id": "2efa214c-6f7d-408e-ba8c-134269da257a", "fitness": 0.06092306920073429, "name": "HybridSwarmOptimizer", "description": "An improved balance in exploration and exploitation by adjusting the inertia weight adaptively.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Adaptive inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 6, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06092 with standard deviation 0.00297.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.061263687138159884, 0.05775447328992955, 0.05598653122052266, 0.06494237274027603, 0.06118160823518248, 0.05929885024314174, 0.06581215192730228, 0.06198939186282826, 0.060078556149265716]}}
{"id": "b61c9cfc-b807-4be8-8a77-9b5bc3030a90", "fitness": 0.06557888454053984, "name": "HybridSwarmOptimizer", "description": "A hybrid swarm-based algorithm with adaptive differential weight and stochastic inertia for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.7 + 0.1 * np.random.rand()  # Stochastic inertia\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06558 with standard deviation 0.00452.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.05937408041214376, 0.060789305120332315, 0.06801696629815279, 0.06291620848205326, 0.06444051260136119, 0.0722979508197309, 0.06375231679413185, 0.0653036574156407, 0.07331896292131179]}}
{"id": "282daf7c-691d-4bcf-8cdb-597b6456eea3", "fitness": 0.06092306920073429, "name": "HybridSwarmOptimizer", "description": "Introduce a dynamic inertia weight that decreases linearly over the evaluations to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 8, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06092 with standard deviation 0.00297.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.061263687138159884, 0.05775447328992955, 0.05598653122052266, 0.06494237274027603, 0.06118160823518248, 0.05929885024314174, 0.06581215192730228, 0.06198939186282826, 0.060078556149265716]}}
{"id": "25097139-90ea-4137-9a6e-4dff72cbf783", "fitness": 0.0580260474888732, "name": "EnhancedHybridSwarmOptimizer", "description": "Integrate an adaptive inertia weight and swarm diversity monitoring to enhance convergence in the Hybrid Swarm Optimizer.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Adaptive inertia weight based on diversity\n            diversity = np.std(self.particles, axis=0).mean()\n            inertia_weight = 0.9 - 0.5 * (diversity / (upper_bound - lower_bound).mean())\n\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05803 with standard deviation 0.00224.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.0537226816378219, 0.05668267490749501, 0.0563363810699008, 0.05687987252240778, 0.060035906073566236, 0.059672196568588576, 0.05762151783381242, 0.060825537871217694, 0.060457658915048396]}}
{"id": "490932e8-2444-40a7-bdaa-9d3a7bcf6b90", "fitness": 0.06598168653314147, "name": "HybridSwarmOptimizer", "description": "Enhanced Hybrid Swarm Optimizer with reduced inertia weight to improve convergence speed.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.6  # Reduced inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 10, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06598 with standard deviation 0.00328.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.06058303018864042, 0.06241450237937485, 0.06624792148440006, 0.06425962255208151, 0.06618643515979805, 0.07046354342750505, 0.06512997229504058, 0.06707941240142679, 0.071470738910006]}}
{"id": "3e595eca-0ad9-4438-86dc-6ee99814318d", "fitness": 0.06125461156388287, "name": "EnhancedHybridSwarmOptimizer", "description": "Enhanced HybridSwarmOptimizer with adaptive inertia, enhanced mutation strategy, and leader-based crossover for superior exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.initial_inertia = 0.9\n        self.final_inertia = 0.4\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update inertia weight linearly\n            inertia_weight = self.initial_inertia - (eval_count / self.budget) * (self.initial_inertia - self.final_inertia)\n\n            # Update velocities and positions for PSO\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Enhanced Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Use an enhanced mutation strategy\n                f = 0.5 + 0.5 * (np.random.rand() - 0.5)  # Adaptive factor\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                # Leader-based crossover\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06125 with standard deviation 0.00283.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.056130110640713826, 0.06102646544484569, 0.058773208658782106, 0.059443930593350736, 0.06469910849716032, 0.06229750647306487, 0.06022386996529683, 0.06556762569381935, 0.06312967810791215]}}
{"id": "981bf5ee-8b0c-449d-89ec-1440270e290d", "fitness": 0.06092306920073429, "name": "HybridSwarmOptimizer", "description": "Introducing a dynamic inertia weight in PSO to adaptively balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n                \n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 12, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06092 with standard deviation 0.00297.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.061263687138159884, 0.05775447328992955, 0.05598653122052266, 0.06494237274027603, 0.06118160823518248, 0.05929885024314174, 0.06581215192730228, 0.06198939186282826, 0.060078556149265716]}}
{"id": "dd78e204-7e8d-48e9-a4a4-f29677cd3807", "fitness": 0.0870672502641171, "name": "EnhancedSwarmOptimizer", "description": "An enhanced swarm optimizer incorporating chaotic maps and Lvy flights for robust exploration and quick convergence.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.7\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08707 with standard deviation 0.00468.", "error": "", "parent_ids": ["be0aecc6-7011-481b-9664-da68d22e2020"], "operator": null, "metadata": {"aucs": [0.08715466597494115, 0.0815259320206988, 0.07960365284834037, 0.09344646217789976, 0.08712501401981232, 0.08499072137545216, 0.09498433422336805, 0.08848189902342907, 0.08629257071311225]}}
{"id": "b10299d8-95b7-4c8f-8ff5-7ae65d4f6185", "fitness": 0.08738381396434225, "name": "EnhancedSwarmOptimizer", "description": "Introduce dynamic adaptation of inertia weight in PSO for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)  # Dynamic inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08738 with standard deviation 0.00323.", "error": "", "parent_ids": ["dd78e204-7e8d-48e9-a4a4-f29677cd3807"], "operator": null, "metadata": {"aucs": [0.08354716494653813, 0.08368806565947928, 0.08192967278380647, 0.08939507823019321, 0.08954021608558937, 0.08759944850571932, 0.09081691728437447, 0.09096276332847486, 0.08897499885490512]}}
{"id": "c5165f42-3155-4bf9-9b68-a7caf4aa99a7", "fitness": 0.08859856004312791, "name": "EnhancedSwarmOptimizer", "description": "Refine inertia weight adaptation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08860 with standard deviation 0.00372.", "error": "", "parent_ids": ["b10299d8-95b7-4c8f-8ff5-7ae65d4f6185"], "operator": null, "metadata": {"aucs": [0.08218499884504815, 0.08642045410659493, 0.08389243053545292, 0.08785975075545627, 0.09262862851404818, 0.08979219947409134, 0.08923613904785066, 0.09414495600895967, 0.0912274831006491]}}
{"id": "c6a46ad7-718f-45cb-b523-d975732e92ec", "fitness": 0.09013610771641528, "name": "EnhancedSwarmOptimizer", "description": "Introduce adaptive chaos factor to improve exploration dynamics in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        return 4 * x * (1 - x + 0.1 * it / self.budget)  # Modified line: added adaptive chaos factor\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09014 with standard deviation 0.00383.", "error": "", "parent_ids": ["c5165f42-3155-4bf9-9b68-a7caf4aa99a7"], "operator": null, "metadata": {"aucs": [0.08806040347919852, 0.0844477365308628, 0.08417052666181324, 0.09452175216356129, 0.09039720512334981, 0.0901144013382339, 0.09610624970493198, 0.09184520727955914, 0.09156148716622692]}}
{"id": "d968cc89-f887-4884-8ba4-b384dc0f5e29", "fitness": 0.08624061039259633, "name": "EnhancedSwarmOptimizer", "description": "Enhance information sharing dynamics by slightly increasing the influence of the global best in velocity updates.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        return 4 * x * (1 - x + 0.1 * it / self.budget)  # Modified line: added adaptive chaos factor\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim) * 1.05  # Increased global influence\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08624 with standard deviation 0.00363.", "error": "", "parent_ids": ["c6a46ad7-718f-45cb-b523-d975732e92ec"], "operator": null, "metadata": {"aucs": [0.08079690267641981, 0.08452093754412682, 0.08066088839259489, 0.08631369377937459, 0.09052975397479146, 0.08618125124370635, 0.08764918722985271, 0.09199502868375842, 0.0875178500087419]}}
{"id": "099066fa-dc09-460e-93b0-e802c537bb27", "fitness": 0.09033373922440457, "name": "EnhancedSwarmOptimizer", "description": "Enhance the adaptive chaotic map by introducing a nonlinear decay to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        # Modified line: added nonlinear decay factor\n        return 4 * x * (1 - x + 0.1 * (it / self.budget) ** 2)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                # Integrating chaotic map into mutation\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating Lvy flights\n                trial_vector += self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09033 with standard deviation 0.00530.", "error": "", "parent_ids": ["c6a46ad7-718f-45cb-b523-d975732e92ec"], "operator": null, "metadata": {"aucs": [0.08221995744748078, 0.09096480951604768, 0.08403251836324577, 0.08790500262973133, 0.09778862101839236, 0.08995016536788447, 0.0892842740264842, 0.09946816230441924, 0.09139014234595533]}}
{"id": "0c2f1cf5-d0be-4e8f-8ae3-af1128410317", "fitness": 0.09169486177533559, "name": "DynamicEnhancedSwarmOptimizer", "description": "Introduce a dynamic adaptive strategy blending chaotic maps and Lvy flights to enhance global exploration and local exploitation for improved convergence.", "code": "import numpy as np\n\nclass DynamicEnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        # Introducing a more complex decay factor\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 19, "feedback": "The algorithm DynamicEnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09169 with standard deviation 0.00513.", "error": "", "parent_ids": ["099066fa-dc09-460e-93b0-e802c537bb27"], "operator": null, "metadata": {"aucs": [0.08564237842674605, 0.09171773759805857, 0.08355625757614826, 0.09174793951579696, 0.09869939376796433, 0.08940445488131099, 0.09323698979156969, 0.10042259011757915, 0.09082601430284631]}}
{"id": "0ca1a2ac-6ced-4637-9741-949e62fab538", "fitness": 0.09618497942566999, "name": "DynamicEnhancedSwarmOptimizer", "description": "Introduce a dynamic scaling factor for velocity adjustment to improve convergence.", "code": "import numpy as np\n\nclass DynamicEnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        # Introducing a more complex decay factor\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 20, "feedback": "The algorithm DynamicEnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09618 with standard deviation 0.00381.", "error": "", "parent_ids": ["0c2f1cf5-d0be-4e8f-8ae3-af1128410317"], "operator": null, "metadata": {"aucs": [0.09117962936430091, 0.0918403806956608, 0.09003648962418498, 0.09809151145226347, 0.09883147098221978, 0.09682887126226547, 0.09979652460237298, 0.10055700618111574, 0.09850293066664573]}}
{"id": "7f474a88-bdc8-46d2-b6a6-74d354a97691", "fitness": 0.09618497942566999, "name": "DynamicEnhancedSwarmOptimizer", "description": "Slightly adjust the cognitive component scaling factor to improve convergence and exploration.", "code": "import numpy as np\n\nclass DynamicEnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        # Introducing a more complex decay factor\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim) * 1.2  # Slightly increase influence\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 21, "feedback": "The algorithm DynamicEnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09618 with standard deviation 0.00381.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.09117962936430091, 0.0918403806956608, 0.09003648962418498, 0.09809151145226347, 0.09883147098221978, 0.09682887126226547, 0.09979652460237298, 0.10055700618111574, 0.09850293066664573]}}
{"id": "5c7896a2-4251-4537-b764-e936b8d1bb9b", "fitness": 0.09494111996548349, "name": "AdaptiveChaoticSwarmOptimizer", "description": "Introduce adaptive chaotic maps and dynamic Lvy flights to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it, phase):\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        if phase == \"exploration\":\n            return 4 * x * (1 - x + decay_factor)\n        else:  # exploitation phase\n            return 4 * x * (1 - x) + 0.5 * decay_factor\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            phase = \"exploration\" if eval_count < self.budget / 2 else \"exploitation\"\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count, phase) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveChaoticSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09494 with standard deviation 0.00402.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.08985371073412929, 0.0918403806956608, 0.08798194205728205, 0.09655781111761841, 0.09883147098221978, 0.09451728590164243, 0.09820654090864578, 0.10055700618111574, 0.09612393111103712]}}
{"id": "768df92b-5075-4991-b448-2c0d5fe7eaa0", "fitness": 0.08777867690749769, "name": "ImprovedSwarmOptimizer", "description": "Integrate dynamic opposition-based learning and adaptive elitism to enhance exploration and exploitation balance for convergence.", "code": "import numpy as np\n\nclass ImprovedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Opposition-based Learning\n            opposition_particles = lower_bound + upper_bound - self.particles\n            for i in range(self.population_size):\n                opposition_score = func(opposition_particles[i])\n                eval_count += 1\n                if opposition_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = opposition_score\n                    self.personal_best[i] = opposition_particles[i].copy()\n                    if opposition_score < self.global_best_score:\n                        self.global_best_score = opposition_score\n                        self.global_best = opposition_particles[i].copy()\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 23, "feedback": "The algorithm ImprovedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08778 with standard deviation 0.00652.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.09016331217095486, 0.07769302306277215, 0.08212124721266811, 0.09700804399441443, 0.08290434407393821, 0.08792337413297457, 0.09869679856246427, 0.08416214995406457, 0.08933579900322797]}}
{"id": "2afce858-601c-4cc5-8c52-064029e615c2", "fitness": 0.09207080903253023, "name": "AdaptiveMultiStrategySwarmOptimizer", "description": "AdaptiveMultiStrategySwarmOptimizer: Combine differential evolution and particle swarm with adaptive parameters and disruption to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMultiStrategySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        decay_factor = 0.1 * (1 - np.cos(np.pi * it / self.budget))\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * np.sin(np.pi * eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - np.sin(np.pi * eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveMultiStrategySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09207 with standard deviation 0.00625.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.09283778222056704, 0.08777875986803574, 0.08121608874320796, 0.0999657201335874, 0.0941782161140331, 0.0869024229805837, 0.10172775137049328, 0.09574545058314776, 0.08828508927911605]}}
{"id": "90363d7c-48e3-48e7-8e95-368517c2d0de", "fitness": 0.09011286568064143, "name": "ImprovedDynamicSwarmOptimizer", "description": "Integrate stochastic global and local learning strategies with adaptive parameter control to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass ImprovedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        decay_factor = 0.1 * (1 - (it / self.budget)) ** 2\n        return 4 * x * (1 - x + decay_factor)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        for eval_count in range(self.budget):\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.7 + 0.3 * np.random.rand()  # Stochastic inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # Dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles) * np.random.rand()\n                + social_component * (self.global_best - self.particles) * np.random.rand()\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Ensure budget limit\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best", "configspace": "", "generation": 25, "feedback": "The algorithm ImprovedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09011 with standard deviation 0.00551.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.08147729623473354, 0.08414253845501074, 0.0909509356864947, 0.08708193106375905, 0.09005718465348667, 0.09783587955153139, 0.08844048957509187, 0.09149619513899943, 0.09953334076666553]}}
{"id": "a73505d1-bb4d-4481-843e-0fcce598b50b", "fitness": 0.09716382379860412, "name": "EnhancedDynamicSwarmOptimizer", "description": "Combine adaptive chaotic maps and Lvy flights with diversity boosting strategies to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        # Introducing an adaptive chaotic map\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity boost\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights with diversity boost\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09716 with standard deviation 0.00384.", "error": "", "parent_ids": ["0ca1a2ac-6ced-4637-9741-949e62fab538"], "operator": null, "metadata": {"aucs": [0.09187023718449416, 0.0927917254992201, 0.09113643298941931, 0.09883960133287983, 0.09988383773830023, 0.09802975721453622, 0.10055854582085533, 0.1016354043144323, 0.09972887209329961]}}
{"id": "b12574e3-26e7-4ed5-9856-10fd71549e91", "fitness": 0.06340355928489722, "name": "QuantumInspiredSwarmOptimizer", "description": "Integrate quantum-inspired exploration and adaptive elitism strategies into a dynamic swarm framework for enhanced optimization efficiency.", "code": "import numpy as np\n\nclass QuantumInspiredSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def quantum_exploration(self, particles, global_best, step_size):\n        # Quantum-inspired exploration step\n        theta = np.random.uniform(0, 2 * np.pi, size=particles.shape)\n        quantum_step = step_size * np.sin(theta)\n        return particles + quantum_step * (global_best - particles)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            step_size = 0.05 * (1 - eval_count / self.budget)\n            self.particles = self.quantum_exploration(self.particles, self.global_best, step_size)\n\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 27, "feedback": "The algorithm QuantumInspiredSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06340 with standard deviation 0.00315.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.0622049292169613, 0.062459926832990065, 0.05736912490459534, 0.06597395191028321, 0.06623139095927821, 0.06079678430835478, 0.06686649059977057, 0.06712417043331242, 0.06160526439852909]}}
{"id": "e9bac68b-fb7c-47b1-bf90-989397e3f8f9", "fitness": 0.0970853945627917, "name": "EnhancedDynamicSwarmOptimizer", "description": "Incorporate a non-linear decreasing inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        # Introducing an adaptive chaotic map\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * (eval_count / self.budget)**2)  # Adjusted non-linear inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity boost\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights with diversity boost\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09709 with standard deviation 0.00385.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09187023718449416, 0.0927917254992201, 0.09092539152410217, 0.09883960133287983, 0.09988383773830023, 0.09778666916665069, 0.10055854582085533, 0.1016354043144323, 0.09947713848419049]}}
{"id": "9c734d10-caa4-4bcc-8fb0-720c95c1b669", "fitness": 0.09643630003746706, "name": "EnhancedDynamicSwarmOptimizer", "description": "Integrate adaptive chaotic maps with Lvy flights and dynamic swarm intelligence incorporating elite preservation to enhance convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return np.clip(a * 4 * x * (1 - x), 0, 1)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with elite preservation\n            sorted_indices = np.argsort(self.personal_best_scores)\n            elites = sorted_indices[:5] # Preserve top 5 elite solutions\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(set(range(self.population_size)) - {i})\n                if i in elites:\n                    a, b = np.random.choice(indices, 2, replace=False)\n                    c = np.random.choice(elites)\n                else:\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09644 with standard deviation 0.00390.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09057026342566676, 0.0927917254992201, 0.09047480341033476, 0.09734463603143506, 0.09988383773830023, 0.09727089994424232, 0.09901114220856455, 0.1016354043144323, 0.09894398776500746]}}
{"id": "5c60d51a-ff3c-4ddc-96c1-f39f38904edb", "fitness": 0.06495825608275113, "name": "EnhancedDynamicSwarmOptimizer", "description": "Integrate dynamic Gaussian mutation and adaptive inertia weight adjustment to improve exploration and convergence in swarm-based optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def dynamic_gaussian_mutation(self, vector, eval_count):\n        mutation_strength = 0.1 * (1 - eval_count / self.budget)\n        return vector + mutation_strength * np.random.normal(size=self.dim)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.7 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_vector = self.dynamic_gaussian_mutation(trial_vector, eval_count)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06496 with standard deviation 0.00606.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.06811172390536202, 0.06328534570648925, 0.055034687287602635, 0.07235736553145011, 0.06711866040552894, 0.05827906572795982, 0.07336866469061387, 0.0680267419071584, 0.05904204958259507]}}
{"id": "cbae4620-cdf3-4a8b-b20d-5d11b44848d9", "fitness": 0.09591857646122452, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate non-linear dynamic inertia weight and adaptive neighborhood search to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def non_linear_inertia_weight(self, eval_count):\n        return 0.5 + 0.4 * np.cos((np.pi * eval_count) / self.budget)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.non_linear_inertia_weight(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            neighborhood_radius = 0.5 * (1 - eval_count / self.budget)\n\n            for i in range(self.population_size):\n                neighborhood_best = self.personal_best_scores[i]\n                for j in range(self.population_size):\n                    if np.linalg.norm(self.particles[i] - self.particles[j]) < neighborhood_radius:\n                        if self.personal_best_scores[j] < neighborhood_best:\n                            neighborhood_best = self.personal_best_scores[j]\n                            self.global_best = self.personal_best[j]\n\n                self.velocities[i] = (\n                    inertia_weight * self.velocities[i]\n                    + cognitive_component[i] * (self.personal_best[i] - self.particles[i])\n                    + social_component[i] * (self.global_best - self.particles[i])\n                )\n\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lower_bound, upper_bound)\n\n                if eval_count >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 31, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09592 with standard deviation 0.00442.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09191989088104446, 0.0927991388340772, 0.08771372366408892, 0.09889416937466844, 0.09989238529369171, 0.09411137459490759, 0.1006143638251048, 0.10164425824149603, 0.0956778834419415]}}
{"id": "4e2321bf-1207-4c83-b567-ebccea763103", "fitness": 0.0970853945627917, "name": "EnhancedDynamicSwarmOptimizer", "description": "Fine-tune the inertia weight formula to enhance dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        # Introducing an adaptive chaotic map\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.4 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.5 + 0.5 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity boost\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights with diversity boost\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09709 with standard deviation 0.00385.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09187023718449416, 0.0927917254992201, 0.09092539152410217, 0.09883960133287983, 0.09988383773830023, 0.09778666916665069, 0.10055854582085533, 0.1016354043144323, 0.09947713848419049]}}
{"id": "8999f240-ed5b-45ad-a911-9892da7178c9", "fitness": 0.09371099890385431, "name": "EnhancedDynamicSwarmOptimizer", "description": "Adjust the dynamic scaling factor to improve exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        # Introducing an adaptive chaotic map\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.3 + 0.7 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity boost\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights with diversity boost\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09371 with standard deviation 0.00716.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09267860201401457, 0.09289119985770744, 0.08080396871453033, 0.09976456734045713, 0.09999847295440856, 0.0863279909493454, 0.10151477316807578, 0.10175413207166661, 0.08766528306448307]}}
{"id": "e14d7799-574b-4b30-a59f-3c3cd0f03c7a", "fitness": 0.09669155966320123, "name": "EnhancedDynamicSwarmOptimizer", "description": "Refine the strategy by adjusting the dynamic scaling factor to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        # Introducing an adaptive chaotic map\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate particles\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            inertia_weight = 0.85 - (0.8 * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            dynamic_scaling_factor = 0.6 + 0.4 * (eval_count / self.budget)  # New dynamic scaling factor\n            self.velocities = (\n                dynamic_scaling_factor * inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n\n            # Apply boundaries\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Differential Evolution mutation and crossover with diversity boost\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()  # Dynamic differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector, \n                    self.particles[i]\n                )\n\n                # Integrating dynamic Lvy flights with diversity boost\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09669 with standard deviation 0.00401.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09207028998438016, 0.0927917254992201, 0.08966161780562243, 0.09907069986620975, 0.09988383773830023, 0.09633605275603252, 0.1007980291300038, 0.1016354043144323, 0.09797637987460972]}}
{"id": "0b871dcb-c460-48a7-bc15-d0d19d0f517c", "fitness": 0.09799631952566283, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate adaptive inertia weight tuning and dynamic Lvy flight scaling with chaos-boosted mutation strategies for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 35, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09800 with standard deviation 0.00383.", "error": "", "parent_ids": ["a73505d1-bb4d-4481-843e-0fcce598b50b"], "operator": null, "metadata": {"aucs": [0.09244124500746664, 0.0927917254992201, 0.09281258385399338, 0.09949386410785954, 0.09988383773830023, 0.09995363886302089, 0.10123516216729378, 0.1016354043144323, 0.10171941417937858]}}
{"id": "17649898-c666-4a99-924e-caa7d873796f", "fitness": 0.09690085035891215, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce a dynamic learning rate to balance exploration and exploitation in the velocity update for improved performance.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            # Introduce a dynamic learning rate factor to enhance performance\n            learning_rate = 0.5 + 0.5 * (eval_count / self.budget)\n            self.velocities = (\n                learning_rate * (inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles))\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 36, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09690 with standard deviation 0.00412.", "error": "", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {"aucs": [0.09198085850635207, 0.09343913746664911, 0.08966241052195378, 0.09896168498366209, 0.10063055819367317, 0.09634833728580416, 0.10068356322228478, 0.10240896137602229, 0.09799214167380788]}}
{"id": "d5ae3fb3-17b1-4c47-9677-78b92c0141aa", "fitness": -Infinity, "name": "HybridOppositionSpiralOptimizer", "description": "Enhance exploration and exploitation balance using a hybrid opposition-based learning and adaptive spiral dynamics with chaos-enhanced differential mutation.", "code": "import numpy as np\n\nclass HybridOppositionSpiralOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_spiral_dynamics(self, it, particle):\n        theta = np.linspace(0, 4 * np.pi, self.dim)\n        r = 1.0 - 0.5 * (it / self.budget)\n        spiral = r * np.exp(0.1 * theta) * np.array([np.cos(theta), np.sin(theta)])\n        return particle + spiral[:, :self.dim]\n\n    def chaos_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def opposition_based_learning(self, particle, lower_bound, upper_bound):\n        return lower_bound + upper_bound - particle\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                opp_particle = self.opposition_based_learning(self.particles[i], lower_bound, upper_bound)\n                spiral_particle = self.adaptive_spiral_dynamics(eval_count, self.particles[i])\n                trial_particle = np.where(\n                    np.random.rand(self.dim) > 0.5,\n                    spiral_particle,\n                    opp_particle\n                )\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaos_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    trial_particle\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 37, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {}}
{"id": "bb96bb75-e3a5-4926-a78a-a8d3dd0a87d6", "fitness": 0.095245952736914, "name": "RefinedDynamicSwarmOptimizer", "description": "Enhance exploration balance by adding stochastic scaling to the chaotic map and varying mutation strength dynamically.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        scaling_factor = np.random.rand()  # Added stochastic scaling\n        return a * 4 * x * (1 - x) * scaling_factor\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.6 + 0.4 * (eval_count / self.budget) * np.random.rand()  # Vary mutation strength\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 38, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09525 with standard deviation 0.00372.", "error": "", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {"aucs": [0.08999354369582346, 0.09119778773204246, 0.0894292527389069, 0.0966927062952565, 0.0980600725591595, 0.09606100622474001, 0.09833936024737666, 0.09975006547695042, 0.09768977966197001]}}
{"id": "01a869fc-e1a4-47af-9306-52944cfa1f53", "fitness": 0.06483863980489268, "name": "EnhancedSwarmOptimizer", "description": "Enhance swarm optimization with adaptive multi-phase exploration and exploitation strategies to balance convergence and diversity for improved performance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.uniform(size=(self.population_size, dim))\n        self.velocities = np.random.uniform(size=(self.population_size, dim)) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.exploration_phase = True\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_velocity_adjustment(self, eval_count):\n        exploration_weight = 0.9 - (0.6 * eval_count / self.budget) \n        exploitation_weight = 0.4 + (0.6 * eval_count / self.budget)\n        return exploration_weight if self.exploration_phase else exploitation_weight\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.adaptive_velocity_adjustment(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + np.random.rand() * (0.3 if self.exploration_phase else 0.6)\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if eval_count/self.budget > 0.5:\n                self.exploration_phase = False\n\n        return self.global_best", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06484 with standard deviation 0.00609.", "error": "", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {"aucs": [0.06923626183326481, 0.06072135538247281, 0.05613321374420732, 0.073563814361705, 0.06436753263537331, 0.05945889710147434, 0.07459532174049377, 0.06522942410349375, 0.060241937341549034]}}
{"id": "f5c6c438-1cfd-40b6-a2ac-53dcba0c9b76", "fitness": 0.09693680372703722, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhance the dynamically adaptive swarm algorithm by incorporating cooperative co-evolution and local search intensification to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def local_search(self, particle, lower_bound, upper_bound):\n        perturbation = 0.1 * (upper_bound - lower_bound) * np.random.randn(self.dim)\n        new_particle = np.clip(particle + perturbation, lower_bound, upper_bound)\n        return new_particle\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n                # Perform local search for further refinement\n                if eval_count < self.budget:\n                    local_search_vector = self.local_search(trial_vector, lower_bound, upper_bound)\n                    local_search_score = func(local_search_vector)\n                    eval_count += 1\n                    if local_search_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = local_search_score\n                        self.personal_best[i] = local_search_vector.copy()\n                        if local_search_score < self.global_best_score:\n                            self.global_best_score = local_search_score\n                            self.global_best = local_search_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09694 with standard deviation 0.00399.", "error": "", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {"aucs": [0.09186055899804879, 0.09316990309238549, 0.09015100461128589, 0.09883116973133799, 0.10033065088616466, 0.09688950491781034, 0.10055053470572284, 0.10210114272076698, 0.0985467638798121]}}
{"id": "6c9847c7-537b-4ef7-a3ae-4e3211e66aaf", "fitness": 0.09839335080872645, "name": "RefinedDynamicSwarmOptimizer", "description": "Enhance exploration by integrating cosine-modulated inertia weight and chaotic local search for improved convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["0b871dcb-c460-48a7-bc15-d0d19d0f517c"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "b86be89d-14ec-4443-98c1-bb65c4310980", "fitness": -Infinity, "name": "QuantumDynamicSwarmOptimizer", "description": "Introduce Quantum-inspired rotation gates for enhanced exploration and adaptive convergence in dynamic swarm optimization.", "code": "import numpy as np\n\nclass QuantumDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.rotation_angle = np.pi / 4  # Initial rotation angle for quantum-inspired mechanics\n\n    def quantum_rotation(self, vector):\n        rotation_matrix = np.array([[np.cos(self.rotation_angle), -np.sin(self.rotation_angle)],\n                                    [np.sin(self.rotation_angle), np.cos(self.rotation_angle)]])\n        rotated_vector = np.dot(rotation_matrix, vector)\n        return rotated_vector\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = self.personal_best[a] + 0.8 * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                trial_vector = self.quantum_rotation(trial_vector)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 42, "feedback": "An exception occurred: ValueError('shapes (2,2) and (10,) not aligned: 2 (dim 1) != 10 (dim 0)').", "error": "ValueError('shapes (2,2) and (10,) not aligned: 2 (dim 1) != 10 (dim 0)')", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {}}
{"id": "e04a60f8-a315-4768-8e05-56206fef0298", "fitness": 0.09799631952566283, "name": "RefinedDynamicSwarmOptimizer", "description": "Refined exploration by integrating adaptive inertia weight with cosine modulation and chaotic local search for improved convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 43, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09800 with standard deviation 0.00383.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09244124500746664, 0.0927917254992201, 0.09281258385399338, 0.09949386410785954, 0.09988383773830023, 0.09995363886302089, 0.10123516216729378, 0.1016354043144323, 0.10171941417937858]}}
{"id": "583a663c-ca95-492e-a3c5-eef365a8facc", "fitness": 0.09418607527903822, "name": "AdvancedDynamicSwarmOptimizer", "description": "Introduce a dynamic differential mutation strategy and multi-phase chaotic influence to enhance global exploration and convergence stability.", "code": "import numpy as np\n\nclass AdvancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f_min = 0.4\n        self.f_max = 0.9\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def multi_phase_chaotic_map(self, x, it):\n        phase = it / self.budget\n        if phase < 0.33:\n            a = 0.7 + 0.2 * phase\n        elif phase < 0.66:\n            a = 0.8 + 0.1 * phase\n        else:\n            a = 0.9 + 0.1 * phase\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = self.f_min + (self.f_max - self.f_min) * (1 - eval_count / self.budget)\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.multi_phase_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 44, "feedback": "The algorithm AdvancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09419 with standard deviation 0.00429.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08701291304933556, 0.09217195141612744, 0.08854478026165735, 0.09329600809002292, 0.09917799276693973, 0.09506636361023735, 0.09483183951486707, 0.10090665611769167, 0.09666617268446487]}}
{"id": "8e442fbb-3538-4354-ae73-74e428bc38ce", "fitness": 0.09839335080872645, "name": "AdvancedDynamicSwarmOptimizer", "description": "Integrate adaptive multi-phase velocity control with dynamic crossover probability for enhanced global exploration and local exploitation.", "code": "import numpy as np\n\nclass AdvancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                cr = 0.9 - 0.8 * (eval_count / self.budget)\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 45, "feedback": "The algorithm AdvancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "c32ce151-9563-4a07-afab-07124099a1a9", "fitness": 0.07519670018453203, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce a dynamic adjustment to the crossover probability (cr) to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                self.cr = 0.5 + 0.4 * (eval_count / self.budget)  # Dynamic adjustment of crossover probability\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 46, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.00525.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.06990406361089185, 0.06768118691954794, 0.07771820601269985, 0.07430161594794427, 0.07187917964391832, 0.08290340705835819, 0.07535096863018131, 0.07287830832081932, 0.08415336551642727]}}
{"id": "fb7c3412-e7ae-4023-a402-da4e5f085d58", "fitness": 0.09799631952566283, "name": "RefinedDynamicSwarmOptimizer", "description": "Realign learning factors by introducing a dynamic inertia weight and cognitive component to enhance convergence stability.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.sin(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim) + 0.5 * (np.exp(-eval_count / self.budget))\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 47, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09800 with standard deviation 0.00383.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09244124500746664, 0.0927917254992201, 0.09281258385399338, 0.09949386410785954, 0.09988383773830023, 0.09995363886302089, 0.10123516216729378, 0.1016354043144323, 0.10171941417937858]}}
{"id": "d92491f5-9ebb-4b97-9b37-36ac467ccc0d", "fitness": 0.09799631952566283, "name": "RefinedDynamicSwarmOptimizer", "description": "Improve convergence by varying inertia weight formula with a sinusoidal component for better adaptability.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.sin(np.pi * eval_count / self.budget)  # Modified line\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09800 with standard deviation 0.00383.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09244124500746664, 0.0927917254992201, 0.09281258385399338, 0.09949386410785954, 0.09988383773830023, 0.09995363886302089, 0.10123516216729378, 0.1016354043144323, 0.10171941417937858]}}
{"id": "d541bd4b-e66d-4699-b595-9709520ba984", "fitness": 0.09476431159454858, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce adaptive differential weight scaling for enhanced diversity in exploration and convergence.  ", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.5 * (1 - np.cos(np.pi * eval_count / self.budget))  # Adaptive differential weight\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 49, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09476 with standard deviation 0.00360.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.0897761425121717, 0.08992591330566879, 0.08960125244107808, 0.09643951727600253, 0.09663589301351916, 0.09625192369885383, 0.09807642894497348, 0.09828624807754893, 0.09788548508112072]}}
{"id": "6e484fd8-0a1e-4ccd-a5ac-6b69648efb69", "fitness": 0.09495938491557449, "name": "RefinedDynamicSwarmOptimizer", "description": "Augment global exploration using a cosine-decay strategy for differential weight and levy flight intensity.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (1 - np.cos(np.pi * eval_count / self.budget))  # Modified line\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (np.cos(np.pi * eval_count / self.budget)))  # Modified line\n                trial_vector += levy_factor * self.levy_flight(self.dim)  # Modified line\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09496 with standard deviation 0.00365.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08946144073794637, 0.08980109707353268, 0.09055845252396533, 0.09607987212345503, 0.0965071974218834, 0.09734707549155308, 0.09770474166312704, 0.09815705056649915, 0.09901753663820823]}}
{"id": "8b76474c-70a3-4df0-9063-3b7aa1d7436e", "fitness": 0.06078712847488668, "name": "PhaseDynamicSwarmOptimizer", "description": "Introduce a novel phase-based dynamic parameter adjustment with dynamic levy flight to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PhaseDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f_min, self.f_max = 0.4, 0.9\n        self.cr_min, self.cr_max = 0.3, 0.9\n\n    def levy_flight(self, L, beta):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def phase_based_parameter_adjustment(self, eval_count):\n        phase_ratio = eval_count / self.budget\n        f = self.f_min + (self.f_max - self.f_min) * (1 - phase_ratio)\n        cr = self.cr_min + (self.cr_max - self.cr_min) * phase_ratio\n        return f, cr\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f, cr = self.phase_based_parameter_adjustment(eval_count)\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                beta = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Dynamic beta for levy flight\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim, beta)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 51, "feedback": "The algorithm PhaseDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06079 with standard deviation 0.00372.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.054812520081518934, 0.05758029343867632, 0.06220005119813243, 0.058040276108539124, 0.0609964575340366, 0.06597929500464816, 0.0587991674205558, 0.06180156825340177, 0.06687452723447096]}}
{"id": "534d447c-3470-4e32-8f52-95d9b99b9dfb", "fitness": 0.09727059469132583, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce adaptive mutation using a sinusoidal pattern to fine-tune the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Change 1: Adding sinusoidal effect to differential weight\n                self.f = 0.5 + 0.3 * (np.sin(np.pi * eval_count / self.budget)) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 52, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09727 with standard deviation 0.00385.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09228832702681555, 0.09269127093622265, 0.09109318213045825, 0.09931852487171489, 0.09977519653585454, 0.09799422742439357, 0.10105377907539448, 0.10152478821600175, 0.0996960560050768]}}
{"id": "1bb2084d-7554-41eb-94be-5865d81efcd0", "fitness": 0.09839335080872645, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a multi-strategy chaotic adaptive inertia weight and dynamic evolution control mechanism to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_inertia_weight(self, eval_count):\n        a = 0.9 - (0.8 * eval_count / self.budget)  # Linear decrement\n        b = 0.1 * np.cos(np.pi * eval_count / self.budget)  # Cosine modulation\n        c = 0.1 * np.sin(4 * np.pi * eval_count / self.budget)  # Sinusoidal modulation\n        return a + b + c\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.chaotic_inertia_weight(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "b5e8768c-fec3-4924-b241-b3960f8606f1", "fitness": 0.09839335080872645, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate a dynamic inertia weight variation based on sinusoidal modulation to enhance convergence speed and stability.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(2 * np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 54, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "595db8a6-ef04-4c29-b751-fc0aa9e33997", "fitness": 0.08959354903394597, "name": "QuantumDynamicSwarmOptimizer", "description": "Incorporate quantum-inspired rotation gates and adaptive scaling to enhance global search efficiency and local convergence in optimization.", "code": "import numpy as np\n\nclass QuantumDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def quantum_rotation(self, x, global_best, it):\n        theta = np.pi * (0.5 - it / self.budget)\n        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n        rotated_vector = np.dot(rotation_matrix, np.array([x, global_best - x]))\n        return rotated_vector[0]\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.quantum_rotation(mutant_vector[i % self.dim], self.global_best[i % self.dim], eval_count)\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 55, "feedback": "The algorithm QuantumDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.00573.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08141517803813114, 0.09101719700437338, 0.0826114317755362, 0.08709204809366067, 0.09789017298866631, 0.08842280535186875, 0.08847203565350492, 0.09958396124609115, 0.0898371111536812]}}
{"id": "a0f7758a-6cb9-410a-a08d-ddd4bc8691cd", "fitness": 0.09359332891981578, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce a small stochastic noise to the velocity update process to encourage more diverse exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            stochastic_noise = np.random.normal(0, 0.01, size=self.velocities.shape)  # Introduce stochastic noise\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n                + stochastic_noise\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 56, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09359 with standard deviation 0.00498.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08672395308519876, 0.09315509481124495, 0.08613404889731924, 0.09296505629847585, 0.10031624804334172, 0.09245890342230623, 0.09448973272973937, 0.10208683557059361, 0.09401008742012229]}}
{"id": "96dcf2ff-aa38-418a-b38f-62d6ad197194", "fitness": 0.09442438244939017, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate adaptive mutation based on personal and global best diversity alongside improved chaotic maps for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8\n        self.cr = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        chaotic = a * 4 * x * (1 - x)\n        return chaotic * (1 + 0.5 * np.sin(2 * np.pi * it / self.budget))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                diversity = np.mean(np.linalg.norm(self.personal_best - self.global_best, axis=1))\n                self.f = 0.5 + 0.3 * (diversity / (np.linalg.norm(self.global_best))) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09442 with standard deviation 0.00489.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08542462798287365, 0.09025318828752993, 0.09263561716698909, 0.09153741217583777, 0.09701311934404822, 0.09974582809323229, 0.09302994061003667, 0.09867662264353816, 0.10150308574042577]}}
{"id": "2899f43b-3d92-4de5-ab7e-ad9d2c1c5288", "fitness": 0.09707405012696492, "name": "EnhancedMultiSwarmOptimizer", "description": "Integrate multi-swarm strategy and adaptive learning rate to enhance diversity and convergence capabilities.", "code": "import numpy as np\n\nclass EnhancedMultiSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.num_swarms = 3\n        self.particles = np.random.rand(self.num_swarms, self.population_size, dim)\n        self.velocities = np.random.rand(self.num_swarms, self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full((self.num_swarms, self.population_size), float('inf'))\n        self.global_best = [None] * self.num_swarms\n        self.global_best_score = [float('inf')] * self.num_swarms\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for swarm in range(self.num_swarms):\n                for i in range(self.population_size):\n                    score = func(self.particles[swarm][i])\n\n                    if score < self.personal_best_scores[swarm][i]:\n                        self.personal_best_scores[swarm][i] = score\n                        self.personal_best[swarm][i] = self.particles[swarm][i].copy()\n\n                    if score < self.global_best_score[swarm]:\n                        self.global_best_score[swarm] = score\n                        self.global_best[swarm] = self.particles[swarm][i].copy()\n\n                inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n                cognitive_component = np.random.rand(self.population_size, self.dim)\n                social_component = np.random.rand(self.population_size, self.dim)\n                self.velocities[swarm] = (\n                    inertia_weight * self.velocities[swarm]\n                    + cognitive_component * (self.personal_best[swarm] - self.particles[swarm])\n                    + social_component * (self.global_best[swarm] - self.particles[swarm])\n                )\n                self.particles[swarm] += self.velocities[swarm]\n                self.particles[swarm] = np.clip(self.particles[swarm], lower_bound, upper_bound)\n\n                for i in range(self.population_size):\n                    if eval_count >= self.budget:\n                        break\n                    indices = list(range(self.population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                    mutant_vector = self.personal_best[swarm][a] + self.f * (self.personal_best[swarm][b] - self.personal_best[swarm][c])\n                    mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                    mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                    trial_vector = np.where(\n                        np.random.rand(self.dim) < self.cr,\n                        mutant_vector,\n                        self.particles[swarm][i]\n                    )\n\n                    levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                    trial_vector += levy_factor * self.levy_flight(self.dim)\n                    trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                    trial_score = func(trial_vector)\n                    eval_count += 1\n\n                    if trial_score < self.personal_best_scores[swarm][i]:\n                        self.personal_best_scores[swarm][i] = trial_score\n                        self.personal_best[swarm][i] = trial_vector.copy()\n                        if trial_score < self.global_best_score[swarm]:\n                            self.global_best_score[swarm] = trial_score\n                            self.global_best[swarm] = trial_vector.copy()\n\n        best_swarm_index = np.argmin(self.global_best_score)\n        return self.global_best[best_swarm_index]", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedMultiSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09707 with standard deviation 0.00387.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09097940741344601, 0.09291455719271036, 0.09162226146042529, 0.09788358493160754, 0.10003180608677353, 0.09857190801718063, 0.09958672301247906, 0.10179041958002277, 0.10028578344803907]}}
{"id": "38d5a3c4-ed60-4b8a-ad2c-9893f2336434", "fitness": 0.0979563776511436, "name": "RefinedDynamicSwarmOptimizer", "description": "Incorporate a non-linear stochastic inertia weight adjustment to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            inertia_weight *= np.random.rand()  # New stochastic component added\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 59, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09796 with standard deviation 0.00384.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09223707572215545, 0.0927917254992201, 0.09291729806156535, 0.09924904589326977, 0.09988383773830023, 0.10007226298552097, 0.10097907011746332, 0.1016354043144323, 0.1018416785283649]}}
{"id": "3fe60e88-dfbc-4ffe-9881-0a88352a036a", "fitness": 0.09558185539950088, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce stochastic inertia weight variation to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - (0.8 * eval_count / self.budget) + \n                              0.1 * np.cos(np.pi * eval_count / self.budget) + \n                              0.05 * np.random.rand())  # Stochastic Variation\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09558 with standard deviation 0.00470.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09196508364581213, 0.0927917254992201, 0.08675465082307188, 0.09894436653386518, 0.09988383773830023, 0.09303063466909567, 0.10066586384222065, 0.1016354043144323, 0.09456513152948987]}}
{"id": "12ecbdd1-0a36-4f88-ab3d-a0bf9ff67919", "fitness": 0.09652218802570338, "name": "RefinedDynamicSwarmOptimizer", "description": "Enhance exploration by dynamically modulating the differential weight based on sinusoidal functions for improved convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (0.5 + 0.5 * np.sin(2 * np.pi * eval_count / self.budget))  # Dynamic modulation\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 61, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09652 with standard deviation 0.00387.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09271133147461963, 0.09075281671690205, 0.0905901527697831, 0.0998170322349331, 0.0975525920481054, 0.09740006738829565, 0.10157302628720333, 0.09922592482195514, 0.09907674848953296]}}
{"id": "e32dfa64-f51b-41de-8d95-bba74294e991", "fitness": 0.08620085991243208, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a time-varying mutation strategy and a dynamic crossover mechanism to enhance adaptive search through improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Time-varying mutation strategy\n                self.f = 0.5 + 0.3 * np.sin(eval_count / self.budget * np.pi)\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                # Dynamic crossover mechanism\n                cr_dynamic = self.cr * (1 - (eval_count / self.budget) ** 2)\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < cr_dynamic,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08620 with standard deviation 0.00369.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.08452134566557801, 0.08005336397913365, 0.08125791777423619, 0.09048938438961407, 0.08546810181895659, 0.08695590715693946, 0.09194255912829863, 0.08677666983315568, 0.08834248946597645]}}
{"id": "9146dc66-533f-452e-afcd-cac056fa1cff", "fitness": 0.09412659880873284, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce adaptive inertia weight adjustment and enhanced Levy flight perturbation for optimized convergence.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.05 * step  # Adjusted Levy flight perturbation\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.7 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 63, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09413 with standard deviation 0.00508.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09130825996105063, 0.09170064618753682, 0.0845483402882995, 0.09820177919860285, 0.09862980993288106, 0.0905281187832746, 0.09990058790324507, 0.10033753283751712, 0.09198431418618791]}}
{"id": "f564dc24-a6d9-4a5e-921a-ab3f824018bf", "fitness": 0.06873097697987154, "name": "EnhancedDynamicSwarmOptimizer", "description": "Integrate adaptive mutation strength and stochastic ranking to balance exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_mutation_strength(self, eval_count):\n        return 0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget)\n\n    def stochastic_ranking(self, scores):\n        ranks = np.argsort(scores)\n        return ranks\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            scores = np.array([func(self.particles[i]) for i in range(self.population_size)])\n            ranks = self.stochastic_ranking(scores)\n\n            for rank in ranks:\n                score = scores[rank]\n\n                if score < self.personal_best_scores[rank]:\n                    self.personal_best_scores[rank] = score\n                    self.personal_best[rank] = self.particles[rank].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[rank].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            adaptive_strength = self.adaptive_mutation_strength(eval_count)\n            \n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                self.f = adaptive_strength * (0.5 + 0.3 * (eval_count / self.budget) * np.random.rand())\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06873 with standard deviation 0.00494.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.05983734132994001, 0.06809751487853377, 0.06912807741957783, 0.06342199260280845, 0.07241329811729691, 0.07346659991673443, 0.06426876477580357, 0.07344396619112137, 0.07450123758702754]}}
{"id": "e1194418-d1b6-468b-b34b-132a4761243d", "fitness": 0.09839335080872645, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate an inertia weight decay mechanism based on sigmoid function for dynamic control over exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget) + 0.1 * (1 / (1 + np.exp(-0.1 * (eval_count - self.budget / 2))))\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 65, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "58ce44eb-0773-4c33-9568-159a4768fbbc", "fitness": 0.09839335080872645, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce a dynamic crossover probability using a sinusoidal function to enhance diversity and exploration.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f = 0.8  # Initial differential weight\n        # self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                # Dynamic crossover probability\n                self.cr = 0.9 + 0.1 * np.sin(np.pi * eval_count / self.budget)\n                \n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 66, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "acdd7196-df70-42eb-b491-6957906c332c", "fitness": 0.09569250083267501, "name": "RefinedAdaptiveSwarmOptimizer", "description": "Introduce adaptive mutation and selectivity pressure to enhance convergence by dynamically adjusting exploration-exploitation balance and favoring promising regions.", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.f_min, self.f_max = 0.4, 0.9  # Differential weight range\n        self.cr = 0.9  # Crossover probability\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - (0.8 * eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive differential weight\n                self.f = self.f_min + (self.f_max - self.f_min) * (1 - eval_count / self.budget)\n                mutant_vector = self.personal_best[a] + self.f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.cr,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n        return self.global_best", "configspace": "", "generation": 67, "feedback": "The algorithm RefinedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09569 with standard deviation 0.00373.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09011453136984071, 0.0902428394648136, 0.0914234075033934, 0.09685944183268336, 0.09698856730059258, 0.09836246115721647, 0.09851933877562613, 0.09864789762128023, 0.10007402246862862]}}
{"id": "9deea694-3751-448c-959c-7b86641a11a5", "fitness": 0.0983997721298936, "name": "EnhancedDynamicSwarmOptimizer", "description": "Incorporate a dynamic population size and adaptive inertia weight strategy to enhance optimization efficiency and convergence speed.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09840 with standard deviation 0.00388.", "error": "", "parent_ids": ["6c9847c7-537b-4ef7-a3ae-4e3211e66aaf"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09261393166692888, 0.10002586598422614, 0.10083501132664463, 0.09972099868565931, 0.10178674237538177, 0.10262083777227715, 0.10147744935730674]}}
{"id": "3e946113-4a92-4ed2-bc19-f261b35c0bb8", "fitness": 0.0983997721298936, "name": "RefinedHybridDynamicSwarmOptimizer", "description": "Introduce a multi-phase strategy with diversity preservation and a hybrid search phase to enhance convergence performance and solution accuracy.", "code": "import numpy as np\n\nclass RefinedHybridDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually and introduce diversity preservation\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n                unique_particles = np.unique(self.particles, axis=0)\n                if unique_particles.shape[0] < self.population_size:\n                    additional_particles = np.random.rand(self.population_size - unique_particles.shape[0], self.dim)\n                    self.particles = np.concatenate((unique_particles, additional_particles), axis=0)\n\n        return self.global_best", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedHybridDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09840 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09261393166692888, 0.10002586598422614, 0.10083501132664463, 0.09972099868565931, 0.10178674237538177, 0.10262083777227715, 0.10147744935730674]}}
{"id": "aeceb81f-00e7-4c79-91d8-2c9a15dc524c", "fitness": 0.06717494489582983, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a convergence-driven dynamic scaling factor and integrate cosine similarity for enhanced exploration-exploitation balance, optimizing convergence speed and performance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.scaling_factor = 0.1\n        self.cosine_similarity_threshold = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def cosine_similarity(self, a, b):\n        dot_product = np.dot(a, b)\n        norm_a = np.linalg.norm(a)\n        norm_b = np.linalg.norm(b)\n        return dot_product / (norm_a * norm_b)\n\n    def convergence_driven_scaling(self, eval_count):\n        return self.scaling_factor * (1 - (eval_count / self.budget))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = self.convergence_driven_scaling(eval_count)\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n                if self.cosine_similarity(self.velocities[i], self.global_best - self.particles[i]) > self.cosine_similarity_threshold:\n                    self.velocities[i] *= -1\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06717 with standard deviation 0.00824.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.057719790421320805, 0.07469732357481795, 0.06023395812958554, 0.06114244425198878, 0.07954339832433854, 0.06386229119109721, 0.06194909723165343, 0.08070613747265143, 0.0647200634650148]}}
{"id": "05c0cbc5-630e-489e-afb4-a07ab4eda046", "fitness": 0.09836259573337724, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a dynamic mutation scaling factor to enhance exploration during early evaluations and exploitation later on.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                # Updated line for dynamic mutation scaling\n                levy_factor = 0.1 * (1 - (eval_count / self.budget)) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09836 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09289857134750434, 0.09361568968124911, 0.09251652348555772, 0.10002312554981607, 0.10083446024354326, 0.09960912908116704, 0.10178390280787286, 0.10262026663633594, 0.10136169276734885]}}
{"id": "bc276cd8-d1c9-4df9-8911-c5deec2b32d3", "fitness": 0.09839335080872645, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce adaptive learning rates and dynamic crossover strategies to the swarm optimization to enhance convergence and diversity.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                crossover_rate = 0.9 - 0.4 * np.power((eval_count / self.budget), 2)\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < crossover_rate,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 72, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "23bf3213-ff11-4696-8e7c-0b8f99cec2dc", "fitness": 0.09789546721154381, "name": "EnhancedDynamicSwarmOptimizer", "description": "Integrate a dynamic mutation scaling factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim) * (1 + 0.1 * np.tanh(eval_count / self.budget))  # Change made here\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09790 with standard deviation 0.00398.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09293758807379693, 0.09361674333782155, 0.09121935573773887, 0.10006815569520056, 0.1008356774846183, 0.0981150730226491, 0.1018305592241967, 0.10262152817408166, 0.09981452415379066]}}
{"id": "f3fbee01-e861-441a-bc96-186ac7a7708b", "fitness": -Infinity, "name": "CooperativeSwarmDifferentialEvolution", "description": "Integrate a cooperative particle swarm with differential evolution to enhance exploration and exploitation balance for improved convergence performance.", "code": "import numpy as np\n\nclass CooperativeSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_inertia_weight(self, eval_count):\n        return 0.9 - 0.5 * (eval_count / self.budget)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.adaptive_inertia_weight(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Cooperative update to enhance exploration\n            if eval_count < self.budget * 0.75:\n                for i in range(self.population_size):\n                    partner_idx = np.random.randint(0, self.population_size)\n                    trial_partner_vector = self.personal_best[i] + np.random.rand(self.dim) * (self.personal_best[partner_idx] - self.personal_best[i])\n                    trial_partner_vector = np.clip(trial_partner_vector, lower_bound, upper_bound)\n                    partner_score = func(trial_partner_vector)\n                    eval_count += 1\n\n                    if partner_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = partner_score\n                        self.personal_best[i] = trial_partner_vector.copy()\n                        if partner_score < self.global_best_score:\n                            self.global_best_score = partner_score\n                            self.global_best = trial_partner_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 74, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,10) (50,10) ')", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {}}
{"id": "a93f147f-9315-444f-8fc5-76e8f8db9b56", "fitness": 0.09713841757589439, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer with chaotic exploration and improved convergence through modified velocity and crossover strategies.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)  # Adjusted inertia weight\n            cognitive_component = np.random.uniform(0.5, 1.5, size=(self.population_size, self.dim))  # Adjusted range\n            social_component = np.random.uniform(0.5, 1.5, size=(self.population_size, self.dim))  # Adjusted range\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.8,  # Adjusted crossover rate\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09714 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09228091544055084, 0.09267851332068577, 0.0907472374929752, 0.09931921042147296, 0.09976924905981066, 0.0975930806829306, 0.10105690043644566, 0.10152096462578297, 0.09927968670239484]}}
{"id": "e5a02765-3fb8-4c85-bfcc-f71a74c2ef6a", "fitness": 0.06339394669170806, "name": "FuzzyAdaptiveSwarmOptimizer", "description": "Introduce a fuzzy adaptive strategy for inertia weight and velocity scaling, with periodic swarm rejuvenation to prevent premature convergence and enhance exploration.", "code": "import numpy as np\n\nclass FuzzyAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def fuzzy_inertia_weight(self, eval_count):\n        if eval_count < self.budget / 3:\n            return 0.9\n        elif eval_count < 2 * self.budget / 3:\n            return 0.7\n        else:\n            return 0.5\n\n    def periodic_rejuvenation(self, eval_count):\n        if eval_count % (self.budget // 10) == 0:\n            for i in range(self.population_size):\n                self.particles[i] = np.random.rand(self.dim)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            self.periodic_rejuvenation(eval_count)\n\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.fuzzy_inertia_weight(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            scaling_factor = 0.5 + (0.5 * np.random.rand()) * (1 - eval_count / self.budget)\n            self.velocities *= scaling_factor\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 76, "feedback": "The algorithm FuzzyAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06339 with standard deviation 0.00337.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.06060096650685909, 0.05752740047812421, 0.06389056381751679, 0.06425003225235337, 0.06094712565790861, 0.06777166434670368, 0.06511284427821018, 0.06175327014177845, 0.06869165274591815]}}
{"id": "da4659ae-7110-4415-a90b-38e6f7ef55f9", "fitness": 0.05570035695358909, "name": "EnhancedDynamicSwarmOptimizerV2", "description": "Introduce a multi-phase strategy with adaptive exploration and exploitation phases, using chaotic local search and dynamic crowding distance to improve convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_local_search(self, particle, it):\n        r = 4 * particle * (1 - particle) * (0.9 + 0.1 * np.sin(np.pi * it / self.budget))\n        return r\n\n    def dynamic_crowding_distance(self, scores):\n        distances = np.zeros(len(scores))\n        sorted_indices = np.argsort(scores)\n        for i in range(1, len(scores) - 1):\n            distances[sorted_indices[i]] = (\n                scores[sorted_indices[i + 1]] - scores[sorted_indices[i - 1]]\n            )\n        return distances\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate the fitness\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.7 + 0.3 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # Exploration and exploitation phases\n            if eval_count < self.budget / 2:\n                for i in range(self.population_size):\n                    self.particles[i] = self.chaotic_local_search(self.particles[i], eval_count)\n            else:\n                distances = self.dynamic_crowding_distance(self.personal_best_scores)\n                for i in range(self.population_size):\n                    indices = np.argsort(distances)\n                    a, b, c = np.random.choice(indices[:self.population_size // 2], 3, replace=False)\n                    f = 0.5 + 0.3 * np.random.rand()\n                    mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                    mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                    trial_vector = np.where(\n                        np.random.rand(self.dim) < 0.9,\n                        mutant_vector,\n                        self.particles[i]\n                    )\n\n                    levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                    trial_vector += levy_factor * self.levy_flight(self.dim)\n                    trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                    trial_score = func(trial_vector)\n                    eval_count += 1\n\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best[i] = trial_vector.copy()\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually in exploitation phase\n            if eval_count / self.budget > 0.7:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedDynamicSwarmOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05570 with standard deviation 0.00214.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.05245165368255189, 0.05514920896672637, 0.05249158468126991, 0.05552834995471889, 0.05839822161355124, 0.05557404684200917, 0.056250354781417045, 0.05916228664999468, 0.05629750541006262]}}
{"id": "84a3bae2-6027-4e94-9531-e5523ee57a4a", "fitness": 0.06398408718050869, "name": "HierarchicalVariableNeighborhoodOptimizer", "description": "Integrate a hierarchical adaptive strategy with variable neighborhood search and adaptive learning rates to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HierarchicalVariableNeighborhoodOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def adaptive_learning_rate(self, eval_count):\n        return 0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget)\n\n    def variable_neighborhood_search(self, position, radius, lower_bound, upper_bound):\n        perturbation = np.random.uniform(-radius, radius, size=position.shape)\n        trial_position = position + perturbation\n        return np.clip(trial_position, lower_bound, upper_bound)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            adaptive_rate = self.adaptive_learning_rate(eval_count)\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * adaptive_rate * (self.personal_best - self.particles)\n                + social_component * adaptive_rate * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                radius = (1 - (eval_count / self.budget)) * 0.1\n                trial_vector = self.variable_neighborhood_search(self.particles[i], radius, lower_bound, upper_bound)\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 78, "feedback": "The algorithm HierarchicalVariableNeighborhoodOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06398 with standard deviation 0.00264.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.06113737679435316, 0.05926266057761742, 0.06331128676462083, 0.06480744455721454, 0.06279492938041287, 0.06716320199734116, 0.06567510756158856, 0.06362855994141259, 0.06807621705001698]}}
{"id": "46313803-2d53-4496-88a0-6da3120e3939", "fitness": 0.0983997721298936, "name": "HybridDynamicSwarmOptimizer", "description": "Introduce a hybrid approach by integrating differential evolution and adaptive dynamic inertia weights to further enhance the exploration-exploitation balance for improved optimization performance.", "code": "import numpy as np\n\nclass HybridDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 79, "feedback": "The algorithm HybridDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09840 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09261393166692888, 0.10002586598422614, 0.10083501132664463, 0.09972099868565931, 0.10178674237538177, 0.10262083777227715, 0.10147744935730674]}}
{"id": "05f062c5-bc22-42cd-ae72-09fc4dc9c194", "fitness": 0.061249475111818774, "name": "RefinedDynamicSwarmOptimizer", "description": "Integrate a self-adaptive mutation rate and nonlinear time-varying inertia weight to further enhance exploration and exploitation balance in dynamic swarm optimization.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.uniform(0, 1, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, dim))\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def nonlinear_inertia(self, eval_count):\n        return 0.9 - (0.5 * (eval_count / self.budget) ** 2)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.nonlinear_inertia(eval_count)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 80, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06125 with standard deviation 0.00232.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.05763800034357058, 0.060461221444306434, 0.0578224909252959, 0.06106117670425393, 0.06409734555976299, 0.06126422994500691, 0.06186807716420917, 0.06495695219430786, 0.0620757817256552]}}
{"id": "385787ad-3b4a-40c9-822f-8c39e257913c", "fitness": 0.09839335080872645, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a dynamic adjustment of cognitive and social components based on the evaluation budget to enhance diverse exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim) * (1 + 0.5 * eval_count / self.budget)  # Adjusted line\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "d7c1ba57-2c3c-41b6-aef3-a65605930ded", "fitness": 0.09657508842190879, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce a multi-swarm strategy with inter-swarm communication and adaptive mutation rates to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.num_swarms = 3\n        self.swarms = [np.random.rand(self.population_size, dim) for _ in range(self.num_swarms)]\n        self.velocities = [np.random.rand(self.population_size, dim) * 0.1 for _ in range(self.num_swarms)]\n        self.personal_best = [swarm.copy() for swarm in self.swarms]\n        self.personal_best_scores = [np.full(self.population_size, float('inf')) for _ in range(self.num_swarms)]\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                for i in range(self.population_size):\n                    score = func(self.swarms[swarm_idx][i])\n\n                    if score < self.personal_best_scores[swarm_idx][i]:\n                        self.personal_best_scores[swarm_idx][i] = score\n                        self.personal_best[swarm_idx][i] = self.swarms[swarm_idx][i].copy()\n\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = self.swarms[swarm_idx][i].copy()\n\n                inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n                cognitive_component = np.random.rand(self.population_size, self.dim)\n                social_component = np.random.rand(self.population_size, self.dim)\n                self.velocities[swarm_idx] = (\n                    inertia_weight * self.velocities[swarm_idx]\n                    + cognitive_component * (self.personal_best[swarm_idx] - self.swarms[swarm_idx])\n                    + social_component * (self.global_best - self.swarms[swarm_idx])\n                )\n                self.swarms[swarm_idx] += self.velocities[swarm_idx]\n                self.swarms[swarm_idx] = np.clip(self.swarms[swarm_idx], lower_bound, upper_bound)\n\n                for i in range(self.population_size):\n                    if eval_count >= self.budget:\n                        break\n                    indices = list(range(self.population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                    mutant_vector = self.personal_best[swarm_idx][a] + f * (self.personal_best[swarm_idx][b] - self.personal_best[swarm_idx][c])\n                    mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                    mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                    trial_vector = np.where(\n                        np.random.rand(self.dim) < 0.9,\n                        mutant_vector,\n                        self.swarms[swarm_idx][i]\n                    )\n\n                    levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                    trial_vector += levy_factor * self.levy_flight(self.dim)\n                    trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                    trial_score = func(trial_vector)\n                    eval_count += 1\n\n                    if trial_score < self.personal_best_scores[swarm_idx][i]:\n                        self.personal_best_scores[swarm_idx][i] = trial_score\n                        self.personal_best[swarm_idx][i] = trial_vector.copy()\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best = trial_vector.copy()\n\n                # Inter-swarm communication: Share the best found solution among swarms\n                if eval_count % (self.budget // 10) == 0:\n                    inter_swarm_best = np.min([np.min(self.personal_best_scores[s]) for s in range(self.num_swarms)])\n                    if inter_swarm_best < self.global_best_score:\n                        self.global_best_score = inter_swarm_best\n                        best_swarm_idx = np.argmin([np.min(self.personal_best_scores[s]) for s in range(self.num_swarms)])\n                        self.global_best = self.personal_best[best_swarm_idx][np.argmin(self.personal_best_scores[best_swarm_idx])]\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 82, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09658 with standard deviation 0.00393.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09097940741344601, 0.09291455719271036, 0.09027757166006534, 0.09788358493160754, 0.10003180608677353, 0.09702600204949874, 0.09958672301247906, 0.10179041958002277, 0.09868572387057573]}}
{"id": "b7dc028b-bc30-4908-8c13-13ae9834ccd2", "fitness": 0.09688012219196865, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce mutation strategy adjustment and dynamic inertia weight modification to refine optimization effectiveness.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.6 + 0.2 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09688 with standard deviation 0.00393.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.0909528934576549, 0.09318042083573386, 0.09088456872366635, 0.09778176881509049, 0.10034635917958579, 0.09775084036629533, 0.09946281810875957, 0.10211829157488828, 0.09944313866604326]}}
{"id": "b4f10f8b-dc7e-42e7-81d5-bcda69a0625f", "fitness": 0.09816539970362628, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce a sigmoid-based dynamic inertia weight to improve convergence precision and stability.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.5 + 0.4 / (1 + np.exp(-10 * (0.5 - eval_count / self.budget)))  # Changed line\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09817 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.0922911785783288, 0.09352651429972347, 0.09267421351648075, 0.09932748839168304, 0.10073159769695705, 0.09979892367542198, 0.10106455801626946, 0.10251370496360912, 0.10156041819416284]}}
{"id": "d52fc7d8-3015-406e-887f-9548842acb37", "fitness": 0.0659308799571539, "name": "EnhancedQuantumSwarmOptimizer", "description": "Introduce a hybrid strategy combining differential evolution and quantum particle exploration to enhance global and local search capabilities.", "code": "import numpy as np\n\nclass EnhancedQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def quantum_exploration(self, particle, global_best, lower_bound, upper_bound):\n        phi = np.random.rand(self.dim)\n        q_step = phi * (global_best - particle)\n        q_particle = particle + q_step\n        return np.clip(q_particle, lower_bound, upper_bound)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget))\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                trial_vector = self.quantum_exploration(trial_vector, self.global_best, lower_bound, upper_bound)\n                trial_vector += 0.1 * (1 - (eval_count / self.budget)) * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06593 with standard deviation 0.00279.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.0651941534024838, 0.06320427420996022, 0.060822526092137785, 0.06919707135693942, 0.0670412494409931, 0.06447809908049884, 0.07014775170969345, 0.06795045804678335, 0.06534233627489505]}}
{"id": "e5b384c6-1000-425e-bd11-8c23e70bb2e9", "fitness": 0.09598665290727407, "name": "EnhancedDynamicSwarmOptimizer", "description": "Integrate self-adaptive mutation and dynamic crossover strategies with an enhanced convergence mechanism to further boost performance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Self-adaptive mutation strategy\n                f = 0.5 + 0.5 * np.random.rand() * ((self.personal_best_scores[a] - self.personal_best_scores[c]) / (self.personal_best_scores[b] - self.personal_best_scores[c] + 1e-9))\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                # Dynamic crossover strategy\n                cr = 0.9 - 0.8 * (eval_count / self.budget)\n                trial_vector = np.where(np.random.rand(self.dim) < cr, mutant_vector, self.particles[i])\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09599 with standard deviation 0.00408.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.08898592340158584, 0.09286511040505308, 0.09076836250325682, 0.09553527770382586, 0.09997466019242507, 0.0975980005125553, 0.09714167743919866, 0.10173114458561006, 0.0992797194219559]}}
{"id": "e953bb74-91db-4357-a0b9-641c0eaa0487", "fitness": 0.09450770083952802, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhance mutation strategy by modifying the differential weight scaling factor for improved diversity.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.5 * (eval_count / self.budget) * np.random.rand()  # Modified line\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09451 with standard deviation 0.00460.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.08783598934919024, 0.09316791817025882, 0.08749018919859464, 0.09424795823284271, 0.10032235697202574, 0.09399756298134798, 0.09581861568245909, 0.1020909391289665, 0.0955977778400664]}}
{"id": "593a8335-8506-41ae-8c8b-c8f849518e76", "fitness": 0.06183440384946875, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhance convergence by integrating a hybrid mutation strategy with chaotic local search for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_local_search(self, particle, it):\n        x = np.random.rand()\n        return particle + (np.sin(it / self.budget * np.pi) * (0.5 * x - 0.25))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_local_search(mutant_vector, eval_count)\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06183 with standard deviation 0.00419.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.057352817612061235, 0.06415334832568786, 0.05607785124544551, 0.06075277715601202, 0.06805639274361519, 0.05939935286733755, 0.0615539059013297, 0.06898183009911751, 0.060181358694612164]}}
{"id": "225a34e5-4f26-43e5-b60e-75f3c9e946a7", "fitness": 0.06502487037400725, "name": "HybridDifferentialEvolutionPSO", "description": "Implement a hybrid strategy combining Differential Evolution and Particle Swarm Optimization, with adaptive parameter control to enhance convergence and exploration capabilities.", "code": "import numpy as np\n\nclass HybridDifferentialEvolutionPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            # PSO phase\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            # DE phase with adaptive crossover probability and differential weight\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                a, b, c = indices\n                F = 0.5 + 0.5 * (eval_count / self.budget)\n                mutant_vector = self.personal_best[a] + F * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                CR = 0.9 - 0.5 * (eval_count / self.budget)\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < CR,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 89, "feedback": "The algorithm HybridDifferentialEvolutionPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06502 with standard deviation 0.00384.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.06459930389243085, 0.057860817425511524, 0.06419911250298183, 0.0685417874428248, 0.06129301251466546, 0.06811142700360051, 0.06947712272468376, 0.062101993906254704, 0.06903925595311189]}}
{"id": "ea4b77df-ed82-41e8-8387-c0e872c12352", "fitness": -Infinity, "name": "AdvancedDynamicSwarmOptimizer", "description": "Introduce adaptive mutation rates based on individual performance and employ a non-linear decreasing population size to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdvancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.mutation_rate = 0.1\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        return 0.01 * (u / np.abs(v) ** (1 / beta))\n\n    def adaptive_mutation_rate(self, current_score, best_score):\n        return max(0.1, 0.5 * (best_score - current_score) / (best_score + 1e-8))\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                adaptive_mutation = self.adaptive_mutation_rate(score, self.global_best_score)\n                levy_factor = adaptive_mutation * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Non-linear decreasing population size\n            self.population_size = max(10, int(self.initial_population_size * np.exp(-3 * eval_count / self.budget)))\n\n        return self.global_best", "configspace": "", "generation": 90, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (43,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (43,10) (50,10) ')", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {}}
{"id": "34719d63-acbe-4841-910c-b70ab910bdae", "fitness": 0.06490951779010075, "name": "ImprovedSwarmOptimizer", "description": "Integrate a multi-elitist strategy with adaptive learning rates to enhance exploration and exploitation balance in swarm optimization.", "code": "import numpy as np\n\nclass ImprovedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_learning_rate(self, eval_count):\n        return 0.9 - 0.5 * (eval_count / self.budget)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = self.adaptive_learning_rate(eval_count)\n            elite_count = max(1, self.population_size // 5)\n            elites = np.argsort(self.personal_best_scores)[:elite_count]\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            velocities_update = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.velocities[elites] = velocities_update[elites]\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 91, "feedback": "The algorithm ImprovedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06491 with standard deviation 0.00479.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.05980889050267291, 0.06786136495598183, 0.05864524960054418, 0.06338967658149319, 0.07207361353220343, 0.062135852224074584, 0.06423547688541675, 0.07307627633237557, 0.06295925949614434]}}
{"id": "f2beacba-0d2f-4640-a889-e5839ec00b15", "fitness": 0.05987391535969322, "name": "HybridAdaptiveSwarmOptimizer", "description": "Introduce a hybrid approach with self-adaptive learning rates and integrated differential evolution to enhance search efficiency and convergence precision.", "code": "import numpy as np\n\nclass HybridAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.learning_rates = np.random.rand(self.population_size, dim)\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget))\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + self.learning_rates * cognitive_component * (self.personal_best - self.particles)\n                + self.learning_rates * social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n            # Update learning rates adaptively\n            self.learning_rates += np.random.normal(0, 0.01, (self.population_size, self.dim))\n            self.learning_rates = np.clip(self.learning_rates, 0.01, 0.1)\n\n        return self.global_best", "configspace": "", "generation": 92, "feedback": "The algorithm HybridAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05987 with standard deviation 0.00284.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.05586486240099919, 0.06026446351060755, 0.05588279514425287, 0.05916103076358936, 0.06386814808035379, 0.05919416833421154, 0.059936646766137525, 0.06471936501214404, 0.05997375822494311]}}
{"id": "c6f60590-df1d-45e7-8abb-7bb2154885a0", "fitness": 0.09839335080872645, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhance convergence by introducing a dynamic cognitive component based on evaluation progress.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = (0.5 + 0.5 * (eval_count / self.budget)) * np.random.rand(self.population_size, self.dim)  # Modified line\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "d0acf088-e91b-405e-909e-c709e38a854a", "fitness": 0.07173433524258255, "name": "HybridSwarmOptimizer", "description": "Introduce a hybrid crossover mechanism using combined local and global search strategies to enhance convergence precision and robustness.", "code": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.rand()\n        offspring = alpha * parent1 + (1 - alpha) * parent2\n        return offspring\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                crossover_vector = self.crossover(self.particles[i], self.global_best)\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.5,\n                    mutant_vector,\n                    crossover_vector\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 94, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07173 with standard deviation 0.00259.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.0693256537849869, 0.06698294971081942, 0.06929148850248779, 0.07369382529605106, 0.07111643832667991, 0.07366017253304413, 0.07473634780008065, 0.0720993071992111, 0.07470283402988198]}}
{"id": "a974355f-92de-464b-8fb3-ff4fcfb4ddea", "fitness": 0.09839335080872645, "name": "EnhancedDynamicSwarmOptimizer", "description": "Implement a small improvement by adjusting the inertia weight formula for better convergence performance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.5 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)  # Adjusted line\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
{"id": "87e48292-e2d4-4989-ad83-771529643440", "fitness": 0.0983997721298936, "name": "RefinedDynamicSwarmOptimizer", "description": "Introduce self-adaptive mutation strategies and diversity preservation mechanisms to enhance exploration and balance convergence in optimization.", "code": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.diversity_threshold = 0.1\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def compute_diversity(self):\n        centroid = np.mean(self.particles, axis=0)\n        diversity = np.mean(np.linalg.norm(self.particles - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n            # Preserve diversity by reinitializing some particles randomly\n            diversity = self.compute_diversity()\n            if diversity < self.diversity_threshold:\n                num_reinitialize = max(1, int(self.population_size * 0.1))\n                reinitialize_indices = np.random.choice(self.population_size, num_reinitialize, replace=False)\n                self.particles[reinitialize_indices] = np.random.uniform(lower_bound, upper_bound, (num_reinitialize, self.dim))\n\n        return self.global_best", "configspace": "", "generation": 96, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09840 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09261393166692888, 0.10002586598422614, 0.10083501132664463, 0.09972099868565931, 0.10178674237538177, 0.10262083777227715, 0.10147744935730674]}}
{"id": "521676cd-943e-4146-b559-e95cdff99006", "fitness": 0.0983997721298936, "name": "EnhancedDynamicSwarmOptimizerV2", "description": "Introduce a multi-exploration strategy with an adaptive mutation rate to balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.mutation_rate = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < self.mutation_rate,\n                    mutant_vector,\n                    self.particles[i]\n                )\n                \n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n                self.mutation_rate *= 0.95  # Gradually decrease mutation rate for finer exploitation\n\n        return self.global_best", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDynamicSwarmOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09840 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09261393166692888, 0.10002586598422614, 0.10083501132664463, 0.09972099868565931, 0.10178674237538177, 0.10262083777227715, 0.10147744935730674]}}
{"id": "54bb3b88-3182-4d12-b107-ff996f3e6af3", "fitness": 0.09713880183061957, "name": "AdaptiveChaoticDifferentialSwarm", "description": "Enhance convergence by integrating a self-adaptive differential evolution strategy and chaotic maps to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticDifferentialSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n\n            # Update velocities and particles using self-adaptive strategies\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F = 0.5 + 0.2 * np.random.rand()\n                mutant_vector = self.personal_best[a] + F * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Gradually reduce population size for better convergence\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveChaoticDifferentialSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09714 with standard deviation 0.00381.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09155581610143648, 0.09259830804876923, 0.09156265109946493, 0.09847490756640431, 0.09968656013900246, 0.09851848076978564, 0.10018030246297949, 0.10143777510629104, 0.1002344151814425]}}
{"id": "37fa19aa-2dc6-4be5-936e-5bdc1416b34b", "fitness": 0.09839335080872645, "name": "EnhancedDynamicSwarmOptimizer", "description": "Enhance the cognitive component by introducing a non-linear scaling factor for improved personal best attraction and convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.particles = np.random.rand(self.population_size, dim)\n        self.velocities = np.random.rand(self.population_size, dim) * 0.1\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adaptive_chaotic_map(self, x, it):\n        a = 0.9 + 0.1 * (it / self.budget)\n        return a * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(self.particles[i])\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = (0.9 - 0.4 * (eval_count / self.budget)) + 0.1 * np.cos(np.pi * eval_count / self.budget)\n            cognitive_component = np.random.rand(self.population_size, self.dim)\n            social_component = np.random.rand(self.population_size, self.dim)\n            non_linear_scale = 1 + (eval_count / self.budget)  # Introduced non-linear scaling factor\n            self.velocities = (\n                inertia_weight * self.velocities\n                + cognitive_component * non_linear_scale * (self.personal_best - self.particles)\n                + social_component * (self.global_best - self.particles)\n            )\n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, lower_bound, upper_bound)\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = 0.5 + 0.3 * (eval_count / self.budget) * np.random.rand()\n                mutant_vector = self.personal_best[a] + f * (self.personal_best[b] - self.personal_best[c])\n                mutant_vector = self.adaptive_chaotic_map(mutant_vector[i % self.dim], eval_count) * (upper_bound - lower_bound) + lower_bound\n                mutant_vector = np.clip(mutant_vector, lower_bound, upper_bound)\n\n                trial_vector = np.where(\n                    np.random.rand(self.dim) < 0.9,\n                    mutant_vector,\n                    self.particles[i]\n                )\n\n                levy_factor = 0.1 * (1 - (eval_count / self.budget))\n                trial_vector += levy_factor * self.levy_flight(self.dim)\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best[i] = trial_vector.copy()\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best = trial_vector.copy()\n\n            # Reduce population size gradually\n            if (eval_count / self.budget) > 0.5:\n                self.population_size = max(10, int(self.initial_population_size * (1 - (eval_count / self.budget))))\n\n        return self.global_best", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09839 with standard deviation 0.00388.", "error": "", "parent_ids": ["9deea694-3751-448c-959c-7b86641a11a5"], "operator": null, "metadata": {"aucs": [0.09290094529082227, 0.09361616670979556, 0.09259668391989362, 0.10002586598422614, 0.10083501132664463, 0.09970108697992253, 0.10178674237538177, 0.10262083777227715, 0.10145681691957442]}}
