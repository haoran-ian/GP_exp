{"id": "3612d438-6a22-4970-97ef-deb18731e2af", "fitness": -Infinity, "name": "HDE_LS", "description": "Hybrid Differential Evolution with Local Search (HDE-LS) that combines global exploration of Differential Evolution with focused local search for enhanced convergence.", "code": "import numpy as np\n\nclass HDE_LS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx):\n        # Mutation: DE/rand/1 strategy\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Binomial crossover\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _local_search(self, candidate, func, bounds):\n        # Simple gradient-free local search\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        for _ in range(self.dim):\n            step = np.random.uniform(-step_size, step_size)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation and Crossover\n                mutant = self._mutate(pop, i)\n                trial = self._crossover(pop[i], mutant)\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n                # Local search on the best individual\n                if i == 0:\n                    pop[i] = self._local_search(pop[i], func, bounds)\n                    fitness[i] = func(pop[i])\n                    eval_count += 1\n\n                if eval_count >= self.budget:\n                    break\n\n        # Return the best solution found\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 97, in evaluateBBOB\n    budget=budget, dim=dim)\n  File \"<string>\", line 47, in __call__\n  File \"<string>\", line 20, in _mutate\nNameError: name 'bounds' is not defined\n.", "error": "NameError(\"name 'bounds' is not defined\")Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 97, in evaluateBBOB\n    budget=budget, dim=dim)\n  File \"<string>\", line 47, in __call__\n  File \"<string>\", line 20, in _mutate\nNameError: name 'bounds' is not defined\n", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "7dd1b7d7-2fe0-4231-a15b-deb3ca5952a5", "fitness": 0.09566138723859523, "name": "EHDE_ALS", "description": "Enhanced Hybrid Differential Evolution with Adaptive Local Search (EHDE-ALS) that dynamically adjusts local search intensity based on convergence rate to improve performance across diverse problem landscapes.", "code": "import numpy as np\n\nclass EHDE_ALS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 1, "feedback": "The algorithm EHDE_ALS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09566 with standard deviation 0.06943.", "error": "", "parent_ids": ["3612d438-6a22-4970-97ef-deb18731e2af"], "operator": null, "metadata": {"aucs": [0.23900251229274938, 0.16610614381970956, 0.14713547841269337, 0.08608352739993108, 0.07987304646353, 0.053188694068749265, 0.03311128277880304, 0.03410863412949694, 0.022343165781694374]}}
{"id": "bdf10974-358a-449b-b6c7-77e2295cd8da", "fitness": -Infinity, "name": "AMSDE_DEEB", "description": "Adaptive Multi-Strategy Differential Evolution with Dynamic Exploitation-Exploration Balance (AMSDE-DEEB), integrating multiple mutation strategies and dynamically balancing exploration and exploitation based on fitness diversity to enhance performance across various domains.", "code": "import numpy as np\n\nclass AMSDE_DEEB:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n        self.strategies = [self._mutate_rand_1, self._mutate_best_1]\n        self.strategy_weights = np.ones(len(self.strategies)) / len(self.strategies)\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate_rand_1(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _mutate_best_1(self, pop, idx, bounds, best):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b = np.random.choice(indices, 2, replace=False)\n        mutant = best + self.F * (pop[a] - pop[b])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _dynamic_exploitation_exploration_balance(self, fitness):\n        diversity = np.std(fitness)\n        return 1.0 / (1.0 + np.exp(-10 * (diversity - 0.1)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                strategy = np.random.choice(self.strategies, p=self.strategy_weights)\n                mutant = strategy(pop, i, bounds, best)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                if trial_fitness < fitness[best_idx]:\n                    best_idx = i\n                    best = trial\n\n                if self.eval_count < self.budget:\n                    balance = self._dynamic_exploitation_exploration_balance(fitness)\n                    if np.random.rand() < balance:\n                        step_size = 0.01 * (bounds.ub - bounds.lb)\n                        step = np.random.uniform(-step_size, step_size, self.dim)\n                        neighbor = np.clip(pop[i] + step, bounds.lb, bounds.ub)\n                        neighbor_fitness = func(neighbor)\n                        self.eval_count += 1\n                        if neighbor_fitness < fitness[i]:\n                            pop[i] = neighbor\n                            fitness[i] = neighbor_fitness\n                            if neighbor_fitness < fitness[best_idx]:\n                                best_idx = i\n                                best = neighbor\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.strategy_weights = self.strategy_weights * 0.9 + 0.1 * (fitness == np.min(fitness))\n\n        return pop[best_idx]", "configspace": "", "generation": 2, "feedback": "An exception occurred: TypeError('_mutate_rand_1() takes 4 positional arguments but 5 were given').", "error": "TypeError('_mutate_rand_1() takes 4 positional arguments but 5 were given')", "parent_ids": ["7dd1b7d7-2fe0-4231-a15b-deb3ca5952a5"], "operator": null, "metadata": {}}
{"id": "98dc1f33-8652-4f46-979c-c1f64196463b", "fitness": 0.09840535386578644, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) that improves convergence by gradually refining mutation precision based on the evaluation budget utilization.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09841 with standard deviation 0.06968.", "error": "", "parent_ids": ["7dd1b7d7-2fe0-4231-a15b-deb3ca5952a5"], "operator": null, "metadata": {"aucs": [0.24560929051862546, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "33320a14-d26b-40a2-b3c1-9e5c4a31a8bc", "fitness": -Infinity, "name": "EHDE_IPR", "description": "EHDE_IPR2 introduces adaptive crossover probability adjustment based on convergence rate to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Adaptive crossover probability based on convergence\n        crossover = np.random.rand(self.dim) < self.CR * (1 - (np.min(fitness) / (np.max(fitness) + 1e-9)))\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 4, "feedback": "An exception occurred: NameError(\"name 'fitness' is not defined\").", "error": "NameError(\"name 'fitness' is not defined\")", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {}}
{"id": "5e1a1aa6-5f94-499d-b833-cfb59f7e66c6", "fitness": 0.09746256641859669, "name": "EHDE_IPR", "description": "Improved EHDE_IPR by dynamically adjusting crossover probability based on convergence rate to enhance diversity.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                self.CR = 0.9 - 0.5 * convergence_rate  # Adjust crossover probability based on convergence rate\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09746 with standard deviation 0.06771.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.2371242034939176, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "1e9a1705-e509-4e57-b417-fb804dbf2711", "fitness": 0.0877780366375525, "name": "DEM_AC", "description": "Dynamic Exponential Mutation and Adaptive Crossover DE (DEM-AC): An enhanced differential evolution with dynamic mutation scaling using an exponential decay function and adaptive crossover probability for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass DEM_AC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F_start = 0.9\n        self.F_end = 0.1\n        self.CR_start = 0.9\n        self.CR_end = 0.1\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _dynamic_mutation_factor(self):\n        return self.F_start * np.exp(-(self.eval_count / self.budget) * np.log(self.F_start / self.F_end))\n\n    def _adaptive_crossover_probability(self):\n        return self.CR_start - (self.CR_start - self.CR_end) * (self.eval_count / self.budget)\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self._dynamic_mutation_factor()\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        CR = self._adaptive_crossover_probability()\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm DEM_AC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08778 with standard deviation 0.05095.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15063249102795784, 0.16610614381970956, 0.14410973461438903, 0.08608352739993108, 0.07987304646353, 0.07072305808483637, 0.03248719487291307, 0.032416407821404536, 0.027570725633300985]}}
{"id": "d01542da-fae1-4f71-8d03-d517705b5955", "fitness": 0.08793772891543633, "name": "EHDE_IPR", "description": "Enhanced mutation strategy by adapting the differential weight F based on convergence rate.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                self.F = max(0.1, self.F * (1 - ((prev_best_fitness - np.min(fitness)) / prev_best_fitness if prev_best_fitness != 0 else 0)))  # Adapt F\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08794 with standard deviation 0.05165.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14820931359459233, 0.0916377745489948, 0.07987304646353, 0.05559668879377688, 0.032792277865180464, 0.04393705783586621, 0.02276319799369031]}}
{"id": "27d8683c-19e4-434a-90de-f832012512dc", "fitness": 0.08845599010950461, "name": "EHDE_IPR", "description": "EHDE-IPR with Dynamic Crossover that adapts the crossover probability based on the success rate of the trials, aiming for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.9 if np.random.rand() < 0.5 else 0.6  # Dynamically adjust CR based on a random strategy\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08846 with standard deviation 0.05125.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15263739241236296, 0.16610614381970956, 0.14306229654477276, 0.0864160112057103, 0.07943145099318893, 0.07821009007052226, 0.032675714846706394, 0.03512470454608474, 0.02244010654648365]}}
{"id": "a203d4b7-9d89-4e91-b901-ead2cf1e95e1", "fitness": 0.08886064903108501, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement now includes dynamic adaptation of the crossover probability (CR) based on the best fitness improvement rate.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Changing line: Adapt CR based on convergence rate\n        crossover = np.random.rand(self.dim) < (self.CR * (1 + self.eval_count / self.budget))\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 9, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08886 with standard deviation 0.05201.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06360165631576065, 0.03248719487291307, 0.03725582604911204, 0.028687164042569546]}}
{"id": "d9eacecf-3649-49f2-9af6-3e588ff50b5a", "fitness": 0.08946989458172666, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement and Dynamic Population Size Adjustment (EHDE-IPR-DPSA) enhances convergence by adapting population size based on evaluation progress.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Dynamic Population Size Adjustment\n            self.pop_size = int(max(2, 10 * self.dim * (1 - self.eval_count / self.budget)))\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 10, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08947 with standard deviation 0.05075.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.1474719902685555, 0.09590100467087848, 0.0796249110571885, 0.05991400430649718, 0.03248719487291307, 0.05005754142051866, 0.02314220149569257]}}
{"id": "c73b3b1f-c7ff-439f-be16-0b4307131ae4", "fitness": 0.08676579068230775, "name": "EHDE_IPR_2_0", "description": "EHDE-IPR 2.0 introduces a self-adaptive mutation and crossover strategy that dynamically adjusts based on the diversity of the population to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR_2_0:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F_base = 0.5  # Base differential weight\n        self.CR_base = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, diversity):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F = self.F_base * (1 + diversity)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, diversity):\n        CR = self.CR_base * (1 - diversity)\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            current_best_fitness = np.min(fitness)\n            diversity = np.std(fitness) / np.mean(fitness) if np.mean(fitness) != 0 else 0\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, diversity)\n                trial = self._crossover(pop[i], mutant, diversity)\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm EHDE_IPR_2_0 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08677 with standard deviation 0.05345.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15048036925596275, 0.17210089282621455, 0.14637896866355993, 0.08608352739993108, 0.08029804279461839, 0.05654232619267785, 0.033889860024292506, 0.032774963201818275, 0.022343165781694374]}}
{"id": "d08c4188-1181-44a4-97f9-a1f5f40e0de2", "fitness": 0.0896191438576947, "name": "AQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution (AQIDE) leverages quantum behavior and dynamic parameter adaptation to enhance exploration and exploitation in the search space.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F_initial = 0.5\n        self.CR_initial = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _quantum_mutation(self, individual, best, bounds):\n        direction = np.random.uniform(-1, 1, self.dim)\n        step_size = np.random.uniform(0, np.linalg.norm(bounds.ub - bounds.lb))\n        mutant = individual + step_size * direction * np.sign(np.random.rand(self.dim) - 0.5)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _mutate(self, pop, idx, best, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_dynamic = self.F_initial * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + F_dynamic * (best - pop[a]) + F_dynamic * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        CR_dynamic = self.CR_initial * (1 - self.eval_count / self.budget)\n        crossover = np.random.rand(self.dim) < CR_dynamic\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            best_idx = np.argmin(fitness)\n            best = pop[best_idx]\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    mutant = self._mutate(pop, i, best, bounds)\n                else:\n                    mutant = self._quantum_mutation(pop[i], best, bounds)\n\n                trial = self._crossover(pop[i], mutant)\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08962 with standard deviation 0.04999.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15480558462106098, 0.16610614381970956, 0.14665299692168765, 0.08594193586186327, 0.07940004781166177, 0.057659663525225446, 0.038214067140802443, 0.04922092517288912, 0.028570929844352166]}}
{"id": "e18e0925-06a4-4666-9a6c-c4a19d2f4e9f", "fitness": 0.08901509744608752, "name": "EDDE_DPMM", "description": "Enhanced Differential Evolution with Dynamic Population and Multi-phase Mutation (EDDE-DPMM) that adaptively adjusts population size and implements a multi-phase mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EDDE_DPMM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # Initial population size\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _dynamic_population_size(self):\n        # Adapt population size based on the budget utilization\n        return max(4, int(self.initial_pop_size * (1 - self.eval_count / self.budget)))\n\n    def _multi_phase_mutation(self, pop, idx, bounds):\n        # Implement multi-phase mutation strategy\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        \n        # Phase 1: Exploration\n        mutation_factor1 = self.F * (1 - self.eval_count / self.budget)\n        mutant1 = pop[a] + mutation_factor1 * (pop[b] - pop[c])\n        \n        # Phase 2: Exploitation\n        mutation_factor2 = self.F * (self.eval_count / self.budget)\n        mutant2 = pop[a] + mutation_factor2 * (pop[b] - pop[c])\n        \n        # Combine both phases\n        mutant = (mutant1 + mutant2) / 2.0\n        \n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self.pop_size = self._dynamic_population_size()\n            for i in range(self.pop_size):\n                mutant = self._multi_phase_mutation(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 13, "feedback": "The algorithm EDDE_DPMM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08902 with standard deviation 0.05100.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1465360353968217, 0.09094815616553342, 0.0889894960999521, 0.05766176106931242, 0.03809250538626929, 0.03937950093306952, 0.023050188308916697]}}
{"id": "0815f1a8-f0fd-4177-86cf-2f9396cbe3c1", "fitness": 0.09614850880463606, "name": "EHDE_DT", "description": "Enhanced Hybrid Differential Evolution with Dynamic Thresholding (EHDE-DT) that integrates threshold-based local searches to balance exploration and exploitation based on performance improvements.", "code": "import numpy as np\n\nclass EHDE_DT:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, improvement_threshold):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * improvement_threshold))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                improvement = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget and improvement > 0.01:  # Threshold-based search\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, improvement)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 14, "feedback": "The algorithm EHDE_DT got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09615 with standard deviation 0.04563.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15749444756354458, 0.16610614381970956, 0.14920223145077882, 0.08594193586186327, 0.07940004781166177, 0.07194512162181743, 0.052889019811445226, 0.06502796972499358, 0.03732966157591033]}}
{"id": "da798d99-121f-4223-a0f5-b1d613bbf117", "fitness": 0.08721473688178774, "name": "ADE_DPM", "description": "Adaptive Differential Evolution with Dynamic Population Management (ADE-DPM) that enhances convergence by dynamically adjusting population size and mutation strategy based on convergence metrics and evaluation budget utilization.", "code": "import numpy as np\n\nclass ADE_DPM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # Initial Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds, pop_size):\n        return np.random.uniform(bounds.lb, bounds.ub, (pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, population_size_factor):\n        indices = list(range(pop.shape[0]))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.eval_count / self.budget) * population_size_factor\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop_size = self.initial_pop_size\n        pop = self._initialize_population(bounds, pop_size)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            population_size_factor = (self.budget - self.eval_count) / self.budget\n            new_pop = []\n            new_fitness = []\n            for i in range(len(pop)):\n                mutant = self._mutate(pop, i, bounds, population_size_factor)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n                current_best_fitness = np.min(new_fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    new_pop[-1] = self._adaptive_local_search(new_pop[-1], func, bounds, convergence_rate)\n                    new_fitness[-1] = func(new_pop[-1])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Dynamically adjust population size based on convergence\n            pop_size = max(5, int(self.initial_pop_size * population_size_factor))\n            if len(pop) > pop_size:\n                best_indices = np.argsort(fitness)[:pop_size]\n                pop = pop[best_indices]\n                fitness = fitness[best_indices]\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 15, "feedback": "The algorithm ADE_DPM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08721 with standard deviation 0.05171.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1528000607126897, 0.16610614381970956, 0.14540632713852886, 0.08880975853656092, 0.07941700701914212, 0.05548426896681502, 0.03248719487291307, 0.03665053615876468, 0.02777133471096571]}}
{"id": "d9ae57ba-c423-414b-b31a-dea89fc26ef3", "fitness": 0.08572945688273365, "name": "ADE_APDPR", "description": "Advanced Differential Evolution with Adaptive Precision and Dynamic Population Refinement (ADE-APDPR) enhances convergence by dynamically adapting precision and population size based on evaluation progress.", "code": "import numpy as np\n\nclass ADE_APDPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.min_pop_size = 4 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds, pop_size):\n        return np.random.uniform(bounds.lb, bounds.ub, (pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(len(pop)))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (0.5 + 0.5 * (1 - self.eval_count / self.budget))\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _dynamic_population_size(self):\n        return max(self.min_pop_size, int(self.initial_pop_size * (1 - self.eval_count / self.budget)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop_size = self.initial_pop_size\n        pop = self._initialize_population(bounds, pop_size)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            pop_size = self._dynamic_population_size()\n            new_pop = []\n\n            for i in range(pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    new_candidate = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    new_pop.append(new_candidate)\n                    fitness[i] = func(new_candidate)\n                    self.eval_count += 1\n                else:\n                    new_pop.append(pop[i])\n\n                if self.eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_pop[:pop_size])\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 16, "feedback": "The algorithm ADE_APDPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08573 with standard deviation 0.05303.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.150482006856401, 0.16610614381970956, 0.14837185315279255, 0.08750489514171966, 0.07941700701914212, 0.04895971694841528, 0.033282964895609335, 0.03533502173043224, 0.022105502380381004]}}
{"id": "fd159add-f61b-49e4-9255-ed8719e56837", "fitness": 0.086374375314879, "name": "EHDE_IPR", "description": "Improved EHDE-IPR by refining mutation precision with dynamic adjustment based on convergence speed.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Change in the mutation factor computation:\n        mutation_factor = self.F * (1 - 0.5 * self.eval_count / self.budget)  # Dynamic adjustment\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08637 with standard deviation 0.05259.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15368583195365337, 0.16610614381970956, 0.14542316284515, 0.08608352739993108, 0.07987304646353, 0.0548239315942759, 0.03248719487291307, 0.03636400363225922, 0.022522535252488818]}}
{"id": "cdac4fad-0e82-486c-aa01-616320d3c44f", "fitness": 0.0844546869169036, "name": "DADE", "description": "Dynamic Adaptive Differential Evolution (DADE) optimizes by dynamically adjusting mutation and crossover rates based on the diversity of the population for improved convergence.", "code": "import numpy as np\n\nclass DADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        pop_diversity = np.std(pop, axis=0).mean()  # Measure of diversity\n        mutation_factor = self.F * (1 - pop_diversity)  # Adapt mutation based on diversity\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        pop_diversity = np.std(target)  # Individual diversity measure\n        crossover_rate = self.CR * (1 - pop_diversity)  # Adapt crossover based on diversity\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm DADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08445 with standard deviation 0.05374.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.05024561009354578, 0.03248719487291307, 0.026202435322045692, 0.022343165781694374]}}
{"id": "8c5429f6-1917-4f7d-abf3-c75e88f4cd72", "fitness": 0.08731846774299523, "name": "AADE", "description": "Advanced Adaptive Differential Evolution (AADE) enhances convergence by integrating adaptive control of differential weight and crossover probability, alongside adaptive local search based on fitness landscape changes.", "code": "import numpy as np\n\nclass AADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Gradual precision refinement\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate)\n        intensity = int(max(1, self.dim * convergence_rate * (1 + self.F)))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                fitness_change = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, fitness_change)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 19, "feedback": "The algorithm AADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08732 with standard deviation 0.05182.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.03924031392578431, 0.022713876954204792]}}
{"id": "ee639487-9aa1-43b3-b87c-a0e13ba7f316", "fitness": 0.087601256096535, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) with dynamic crossover probability adjustment based on convergence, improving exploitation in later stages.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.9 * (1 - self.eval_count / self.budget)  # Dynamically adjust crossover probability\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "55775c02-d120-40f6-8253-2b417f01ce5a", "fitness": 0.09648208186031658, "name": "ADE_DE", "description": "Adaptive Differential Evolution with Dynamic Ensemble (ADE-DE) combines adaptive mutation precision and dynamic ensemble selection to enhance convergence across diverse optimization landscapes.", "code": "import numpy as np\n\nclass ADE_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.eval_count = 0\n        self.F_base = 0.5  # Base differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F_base * (1 - self.eval_count / self.budget)  # Adaptive mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _local_search(self, candidate, func, bounds):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        for _ in range(int(max(1, self.dim / 10))):  # Dynamic search intensity\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic ensemble selection based on best fitness improvement\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n                \n                if self.eval_count < self.budget:\n                    if convergence_rate > 0.01:  # Perform local search if improvement is significant\n                        pop[i] = self._local_search(pop[i], func, bounds)\n                        fitness[i] = func(pop[i])\n                        self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 21, "feedback": "The algorithm ADE_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09648 with standard deviation 0.04542.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15749444756354458, 0.16610614381970956, 0.14920223145077882, 0.08594193586186327, 0.07940004781166177, 0.07194512162181743, 0.052889019811445226, 0.06803012722611823, 0.03732966157591033]}}
{"id": "53408f54-752a-4b2f-a52e-09d583791c09", "fitness": 0.08886064903108501, "name": "EHDE_IPR", "description": "Improved EHDE-IPR by adding a dynamic crossover probability that adapts based on the population's diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR_base = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, diversity_factor):\n        crossover_probability = self.CR_base * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_probability\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                diversity_factor = np.std(pop) / (np.abs(np.mean(pop)) + 1e-9)  # Diversity measure\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant, diversity_factor)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 22, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08886 with standard deviation 0.05201.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06360165631576065, 0.03248719487291307, 0.03725582604911204, 0.028687164042569546]}}
{"id": "5822c80c-940e-4329-9a36-21377d028226", "fitness": 0.08857522804827221, "name": "EHDE_IPR_APC", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement and Adaptive Parameter Control (EHDE-IPR-APC) that dynamically adjusts the differential weight and crossover probability based on population diversity to improve convergence and exploration.", "code": "import numpy as np\n\nclass EHDE_IPR_APC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.base_F = 0.5  # Base differential weight\n        self.base_CR = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.base_F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, CR):\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _compute_diversity(self, pop):\n        centroid = np.mean(pop, axis=0)\n        diversity = np.mean(np.linalg.norm(pop - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            diversity = self._compute_diversity(pop)\n            F = self.base_F * (1 + diversity / (self.dim * np.max(bounds.ub - bounds.lb)))\n            CR = self.base_CR * (1 - diversity / (self.dim * np.max(bounds.ub - bounds.lb)))\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant, CR)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 23, "feedback": "The algorithm EHDE_IPR_APC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08858 with standard deviation 0.05053.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.08053572737087256, 0.06520275780673268, 0.03248719487291307, 0.04729676571132335, 0.022713876954204792]}}
{"id": "b0977997-0404-4e6c-9288-a49161680ede", "fitness": 0.087601256096535, "name": "EHDE_IPR", "description": "Incorporate an adaptive crossover probability to enhance diversity and potentially improve convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Initial Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Modifying the crossover probability adaptively based on the evaluation budget utilization\n                self.CR = 0.9 * (1 - self.eval_count / self.budget)\n\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 24, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "40883c5a-bc09-453a-8849-032019673ee4", "fitness": 0.09149069505500379, "name": "IHDE_DAPR", "description": "Improved Hybrid Differential Evolution with Dynamic Adaptive Precision Refinement (IHDE-DAPR) that dynamically adjusts mutation and local search strategies based on convergence trends and diversity metrics to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass IHDE_DAPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F_base = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, diversity):\n        indices = np.arange(self.pop_size)\n        indices = indices[indices != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F_base * (1 - self.eval_count / self.budget) * diversity\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate, diversity):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate) * diversity\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                diversity = np.std(pop, axis=0).mean() / (bounds.ub - bounds.lb).mean()\n                mutant = self._mutate(pop, i, bounds, diversity)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate, diversity)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 25, "feedback": "The algorithm IHDE_DAPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09149 with standard deviation 0.05341.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.16195189023486234, 0.08594193586186327, 0.09848414674328654, 0.06716816823109217, 0.03284203200545399, 0.03608296177832615, 0.024466886985237246]}}
{"id": "913c626b-d4fd-45ec-a18b-bd701021e875", "fitness": 0.08603728859166782, "name": "IEHDE_SAM", "description": "Improved Enhanced Hybrid Differential Evolution with Self-Adaptive Mutation (IEHDE-SAM) introduces self-adaptive mutation and integrates dynamic population resizing for enhanced convergence efficiency.", "code": "import numpy as np\n\nclass IEHDE_SAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Initial population size\n        self.F_base = 0.5  # Base differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _self_adaptive_mutation(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_dynamic = self.F_base + 0.1 * np.random.randn()  # Self-adaptive mutation factor\n        mutation_factor = F_dynamic * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _dynamic_population_resizing(self):\n        if self.eval_count < self.budget / 2:\n            self.pop_size = max(5 * self.dim, int(self.pop_size * 0.9))\n        else:\n            self.pop_size = min(10 * self.dim, int(self.pop_size * 1.1))\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self._dynamic_population_resizing()\n            for i in range(self.pop_size):\n                mutant = self._self_adaptive_mutation(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / (prev_best_fitness + 1e-8)\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 26, "feedback": "The algorithm IEHDE_SAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08604 with standard deviation 0.05182.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15193706909075244, 0.16610614381970956, 0.14209826369988487, 0.08594193586186327, 0.07948083184386978, 0.059422781464433694, 0.03347000016060386, 0.026318472111869884, 0.029560099272022966]}}
{"id": "07863fe2-1ac3-4e87-9cb6-4b6933fe0d0f", "fitness": 0.08770935296573858, "name": "EDADE", "description": "Enhanced Dynamic Adaptive Differential Evolution (EDADE) integrates dynamic parameter adaptation and a hybrid local search strategy for improved convergence and precision in black-box optimization.", "code": "import numpy as np\n\nclass EDADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F_init = 0.5\n        self.CR_init = 0.9\n        self.eval_count = 0\n        self.bounds = None\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _dynamic_parameters(self):\n        progress = self.eval_count / self.budget\n        self.F = self.F_init * (1 - progress)\n        self.CR = self.CR_init * (1 - progress * 0.5)\n\n    def _mutate(self, pop, idx):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _hybrid_local_search(self, candidate, func):\n        best = candidate\n        step_size = 0.01 * (self.bounds.ub - self.bounds.lb)\n        intensity = max(1, int(self.dim * 0.1))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, self.bounds.lb, self.bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        pop = self._initialize_population(self.bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            self._dynamic_parameters()\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._hybrid_local_search(pop[i], func)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 27, "feedback": "The algorithm EDADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08771 with standard deviation 0.05223.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1562043323650485, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.05745654993608296, 0.03248719487291307, 0.04026361221510799, 0.024530800955764098]}}
{"id": "251a52e9-49af-4266-aa5a-01e5c86b6d53", "fitness": 0.08597812437494408, "name": "ACDE", "description": "Adaptive Convergence-based Differential Evolution (ACDE) integrates dynamic local search intensity and mutation adaptation to balance exploration and exploitation efficiently.", "code": "import numpy as np\n\nclass ACDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.F * (1 - self.eval_count / self.budget) + 0.1 * np.random.rand()\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (0.5 + np.random.rand())\n        intensity = int(max(1, self.dim * (1 - convergence_rate)))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 28, "feedback": "The algorithm ACDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08598 with standard deviation 0.05366.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1495588292529899, 0.0911940913445849, 0.07940004781166177, 0.05299585360109815, 0.03449352568415465, 0.027839869288982633, 0.021842668736112292]}}
{"id": "32cfcc94-2d25-4504-a09d-acb2ba6897d6", "fitness": 0.087601256096535, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic crossover probability adaptation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        dynamic_CR = self.CR * (1 - self.eval_count / self.budget)  # Dynamic crossover probability\n        crossover = np.random.rand(self.dim) < dynamic_CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 29, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "6eb9498e-023b-4884-ab17-5048664c501d", "fitness": 0.08784032817744877, "name": "ADE_DPM", "description": "Adaptive Differential Evolution with Dynamic Population Management (ADE-DPM) that enhances convergence by adjusting population size and mutation factors based on performance feedback and resource utilization.", "code": "import numpy as np\n\nclass ADE_DPM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.min_pop_size = 4 * dim\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _adjust_population(self, fitness):\n        improvements = np.diff(np.sort(fitness))\n        if len(improvements) > 1 and np.all(improvements[-2:] < 1e-5):\n            self.pop_size = max(self.min_pop_size, self.pop_size - self.dim)\n        elif self.eval_count / self.budget < 0.5:\n            self.pop_size = min(self.initial_pop_size, self.pop_size + self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self._adjust_population(fitness)\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = ((prev_best_fitness - current_best_fitness) / prev_best_fitness) if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 30, "feedback": "The algorithm ADE_DPM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08784 with standard deviation 0.05135.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "8d4868a9-6eb5-46c3-ab41-f52b4042a863", "fitness": 0.0859929785647438, "name": "EHDE_IPR", "description": "EHDE-IPR with Adaptive Differential Weight to dynamically adjust exploration-exploitation based on diversity measures.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.mean(np.std(pop, axis=0))  # Calculate diversity measure\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + diversity)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 31, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08599 with standard deviation 0.05336.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15221726793574997, 0.16610614381970956, 0.14690790144876942, 0.08608352739993108, 0.07987304646353, 0.06171612403835114, 0.03248719487291307, 0.026202435322045692, 0.022343165781694374]}}
{"id": "91b0d4a2-447d-4479-8133-9f6fcfa85b8f", "fitness": 0.087601256096535, "name": "EHDE_DPC", "description": "Enhanced Hybrid Differential Evolution with Dynamic Precision Control (EHDE-DPC) that optimizes convergence by adaptively adjusting mutation and crossover parameters based on the evolutionary progress and resource utilization.", "code": "import numpy as np\n\nclass EHDE_DPC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.initial_F = 0.5  # Initial Differential weight\n        self.initial_CR = 0.9  # Initial Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        dynamic_F = self.initial_F * (1 - self.eval_count / self.budget)  # Dynamic mutation factor\n        mutant = pop[a] + dynamic_F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        dynamic_CR = self.initial_CR * (1 - (self.eval_count / self.budget))  # Dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < dynamic_CR\n        return np.where(crossover_mask, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 32, "feedback": "The algorithm EHDE_DPC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "3f32cc71-0360-4e7e-a9c4-df5fffce1aca", "fitness": 0.08650706104085998, "name": "RDE_AS", "description": "Refined Hybrid Differential Evolution with Adaptive Strategy (RDE-AS), enhancing convergence by dynamically adjusting crossover probability and incorporating enriched local search based on convergence dynamics.", "code": "import numpy as np\n\nclass RDE_AS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, adaptive_cr):\n        crossover = np.random.rand(self.dim) < adaptive_cr\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * (0.5 + convergence_rate)))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                adaptive_cr = self.CR * (1 - self.eval_count / self.budget) + 0.1\n                trial = self._crossover(pop[i], mutant, adaptive_cr)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 33, "feedback": "The algorithm RDE_AS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08651 with standard deviation 0.05251.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14320009789429233, 0.09638946649414104, 0.08111716151484594, 0.055782199255332676, 0.03294028393182724, 0.02771813410745183, 0.024937972514936346]}}
{"id": "80e512c5-0b70-4d86-a03d-ae4630f4cffe", "fitness": 0.0909396464741134, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) that improves convergence by dynamically adjusting crossover probability based on convergence rate.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                self.CR = 0.5 + 0.4 * convergence_rate  # Dynamically adjust CR based on convergence rate\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 34, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09094 with standard deviation 0.05394.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15352644558809936, 0.16610614381970956, 0.1671356957382759, 0.08608352739993108, 0.07987304646353, 0.06008607121429643, 0.03248719487291307, 0.05050926549290358, 0.022649427677361667]}}
{"id": "b16187c5-24d6-4f54-a8f0-bb51af69488f", "fitness": 0.0883235347867453, "name": "EHDE_IPR", "description": "EHDE_IPR_V2 enhances adaptive local search by dynamically adjusting step size based on budget usage to improve convergence further.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - self.eval_count / self.budget)  # Adjusted step size\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 35, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08832 with standard deviation 0.05166.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15284631202358556, 0.16610614381970956, 0.14621270625717453, 0.0916377745489948, 0.08225148878792221, 0.05700662927174016, 0.03249429686994787, 0.043852852122750696, 0.022503609378882294]}}
{"id": "881fb1a9-c45b-4b32-a088-8fc6123a59d5", "fitness": 0.08539053107727476, "name": "EHDE_DP_AI", "description": "Enhanced Hybrid Differential Evolution with Dynamic Precision and Adaptive Intensification (EHDE-DP-AI) that optimizes convergence by dynamically adjusting mutation precision and intensifying local search based on fitness diversity.", "code": "import numpy as np\n\nclass EHDE_DP_AI:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Dynamic mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, intensity):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            fitness_diversity = np.std(fitness) / np.mean(fitness) if np.mean(fitness) != 0 else 0\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                if self.eval_count < self.budget:\n                    intensity = int(max(1, self.dim * (1 + fitness_diversity)))\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, intensity)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 36, "feedback": "The algorithm EHDE_DP_AI got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08539 with standard deviation 0.05382.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15122265092558074, 0.16974400540782664, 0.14306603456516997, 0.0916493751959846, 0.07940004781166177, 0.049688645933211095, 0.03242013403917121, 0.027434998123737175, 0.02388888769312969]}}
{"id": "7cc4dcb0-4f53-490f-a3a8-ef854fef0e2a", "fitness": 0.08726268706542974, "name": "ADE_DPC", "description": "Adaptive Differential Evolution with Dynamic Precision Control (ADE-DPC) enhances convergence by dynamically adjusting mutation and crossover probabilities based on the evolutionary progress and available evaluation budget.", "code": "import numpy as np\n\nclass ADE_DPC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F_base = 0.5  # Base differential weight\n        self.CR_base = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        progress_ratio = self.eval_count / self.budget\n        mutation_factor = self.F_base * (1 - progress_ratio)  # Dynamic mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, progress_ratio):\n        crossover_probability = self.CR_base * (1 - progress_ratio)  # Dynamic crossover precision\n        crossover = np.random.rand(self.dim) < crossover_probability\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            progress_ratio = self.eval_count / self.budget\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant, progress_ratio)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 37, "feedback": "The algorithm ADE_DPC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08726 with standard deviation 0.05167.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.06520275780673268, 0.03248719487291307, 0.03651728894559403, 0.022343165781694374]}}
{"id": "e76c4e74-43eb-4bde-ab3e-df561bb13935", "fitness": 0.08622658649653003, "name": "EADE_DSR", "description": "Enhanced Adaptive Differential Evolution with Dynamic Strategy Refinement (EADE-DSR) that dynamically adapts mutation strategies and intensifies local search based on real-time convergence metrics.", "code": "import numpy as np\n\nclass EADE_DSR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, convergence_metric):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive mutation factor based on convergence\n        mutation_factor = self.F * (1 - convergence_metric)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            current_best_fitness = np.min(fitness)\n            convergence_metric = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n            prev_best_fitness = current_best_fitness\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, convergence_metric)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_metric)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 38, "feedback": "The algorithm EADE_DSR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08623 with standard deviation 0.05326.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15280067191981495, 0.16610614381970956, 0.14894827299470736, 0.08608352739993108, 0.0798785275346181, 0.0526656314008761, 0.033106007145980665, 0.03410863412949694, 0.022341862123635536]}}
{"id": "5ab50796-d02c-4885-b74e-9b427abab8d5", "fitness": 0.087601256096535, "name": "AHDE_DCP", "description": "Adaptive Hybrid Differential Evolution with Dynamic Crossover Precision (AHDE-DCP) enhances convergence by dynamically adjusting both mutation and crossover precision based on the evaluation budget utilization and convergence progress.", "code": "import numpy as np\n\nclass AHDE_DCP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - self.eval_count / self.budget)  # Adaptive mutation precision\n        mutant = pop[a] + adaptive_F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - self.eval_count / self.budget)  # Adaptive crossover precision\n        crossover = np.random.rand(self.dim) < adaptive_CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm AHDE_DCP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "51be62f3-54c6-45a2-b4ae-4695e469c069", "fitness": 0.08741062621786483, "name": "EHDE_IPR_RL", "description": "EHDE-IPR-RL enhances convergence by using reinforcement learning to dynamically adjust the differential weight (F) during the mutation process.", "code": "import numpy as np\n\nclass EHDE_IPR_RL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        self.F = 0.4 + 0.6 * np.random.rand()  # Dynamic adjustment of F using RL\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 40, "feedback": "The algorithm EHDE_IPR_RL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08741 with standard deviation 0.05225.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1476689481876663, 0.0864160112057103, 0.07943145099318893, 0.07110459941339609, 0.032675714846706394, 0.03009867779007458, 0.022821999869128473]}}
{"id": "f27859f6-6a78-4dc1-8827-19390d0cb7c5", "fitness": 0.08713771649213281, "name": "ADDE", "description": "Advanced Dynamic Differential Evolution (ADDE) with Adaptive Mutation and Search Intensity Refinement that dynamically adjusts mutation factors and local search intensity based on fitness diversity and convergence rate for enhanced adaptability and convergence.", "code": "import numpy as np\n\nclass ADDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.base_F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, fitness_diversity):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adjust mutation factor based on fitness diversity\n        mutation_factor = self.base_F * (1 + fitness_diversity)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        # Adjust intensity based on convergence rate\n        intensity = int(max(1, self.dim * (convergence_rate + 0.1)))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            fitness_diversity = np.std(fitness) / np.mean(fitness) if np.mean(fitness) != 0 else 0\n            \n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, fitness_diversity)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 41, "feedback": "The algorithm ADDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08714 with standard deviation 0.05343.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15147892491567938, 0.16610614381970956, 0.15344079976109204, 0.08608352739993108, 0.07987304646353, 0.05904144549483392, 0.03309743159090661, 0.032774963201818275, 0.022343165781694374]}}
{"id": "b8fed6fb-8058-445c-b348-05f772466261", "fitness": 0.0869936732931862, "name": "EHDE_IPR", "description": "Incorporating a dynamic crossover probability adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _dynamic_crossover_probability(self):\n        return 0.9 * (1 - self.eval_count / self.budget) + 0.1\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self._dynamic_crossover_probability()\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 42, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08699 with standard deviation 0.05225.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1508343614809854, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.05740475986764926, 0.03248719487291307, 0.03587764413963945, 0.022343165781694374]}}
{"id": "de83e354-7269-4916-9a87-0221c41450ea", "fitness": 0.08831837669602266, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) improved by dynamically adjusting crossover probability based on convergence rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < (self.CR - (self.eval_count / self.budget) * 0.4)  # Adjusted crossover probability\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 43, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08832 with standard deviation 0.05139.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1508926585823549, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.07440700241212617, 0.03248719487291307, 0.03587764413963945, 0.02275920391043973]}}
{"id": "7d9c6f66-7600-48d6-af24-85295b46badd", "fitness": 0.087601256096535, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement and Adaptive Crossover (EHDE-IPR-AC), integrating adaptive crossover rate based on convergence to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - self.eval_count / self.budget)  # Adaptive crossover rate\n        crossover = np.random.rand(self.dim) < adaptive_CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 44, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "ed7b9461-bff8-4fa0-b12b-458b71b74099", "fitness": 0.0909785575715652, "name": "EADE_SPA", "description": "Enhanced Adaptive Differential Evolution with Success-Based Parameter Adjustment (EADE-SPA) improves convergence by dynamically adjusting mutation and crossover rates based on recent success rates.", "code": "import numpy as np\n\nclass EADE_SPA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F_min, self.F_max = 0.4, 0.9  # Differential weight range\n        self.CR_min, self.CR_max = 0.2, 0.9  # Crossover probability range\n        self.eval_count = 0\n        self.success_rate = 0.2  # Initial success rate\n        self.adaptation_window = 50  # How often to adapt rates\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _adapt_parameters(self):\n        # Adjust mutation factor and crossover probability based on success rate\n        self.F = self.F_min + (self.F_max - self.F_min) * self.success_rate\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * self.success_rate\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        best_fitness = np.min(fitness)\n        success_count = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count % self.adaptation_window == 0:\n                    self._adapt_parameters()\n\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    success_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Update success rate\n            self.success_rate = success_count / self.adaptation_window\n            success_count = 0\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 45, "feedback": "The algorithm EADE_SPA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09098 with standard deviation 0.04831.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1524162016690862, 0.16610614381970956, 0.14732350208949652, 0.08594193586186327, 0.08134757595377662, 0.05986376864773946, 0.039262041039250906, 0.05017869647496698, 0.03636715258819734]}}
{"id": "94c02b74-14fd-41ed-8b8d-71301ab66ebe", "fitness": 0.0869936732931862, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) with dynamic crossover probability adjustment to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        self.CR = 0.9 * (1 - self.eval_count / self.budget) + 0.1  # Dynamically adjust CR\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 46, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08699 with standard deviation 0.05225.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1508343614809854, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.05740475986764926, 0.03248719487291307, 0.03587764413963945, 0.022343165781694374]}}
{"id": "9731e1a9-3369-4577-b83a-d897913eec77", "fitness": 0.087601256096535, "name": "EHDE_IPR", "description": "EHDE-IPR with Adaptive Crossover Probability (EHDE-ACP) that dynamically adjusts the crossover probability based on the evaluation process to enhance solution diversity.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Adaptively adjust the crossover probability\n        self.CR = 0.9 * (1 - self.eval_count / self.budget)\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 47, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "a9e51b7b-f25a-4301-9333-f569a5783287", "fitness": -Infinity, "name": "EHDE_IPR", "description": "EHDE_IPR with Improved Mutation Strategy (EHDE_IPR-IMS) that enhances exploration by dynamically adjusting mutation factor scaling based on fitness variance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_variance = np.var([func(ind) for ind in pop])  # Calculate fitness variance\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + fitness_variance)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 48, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {}}
{"id": "19780acc-1cdb-4395-a7dd-c1a6fdf57c2d", "fitness": 0.09691999043169267, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic crossover probability adjustment to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR_init = 0.9  # Initial crossover probability\n        self.CR_final = 0.6  # Final crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Dynamic crossover probability adjustment\n        dynamic_CR = self.CR_init - (self.CR_init - self.CR_final) * (self.eval_count / self.budget)\n        crossover = np.random.rand(self.dim) < dynamic_CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 49, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09692 with standard deviation 0.06778.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.23734056560620298, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.056656024276969696, 0.03248719487291307, 0.04393705783586621, 0.023417384946551434]}}
{"id": "c1851463-c589-4ec7-82d3-e254ccf9f9e1", "fitness": 0.08912059370229254, "name": "EHDE_IPR", "description": "Enhanced mutation strategy by dynamically adjusting the differential weight (F) based on population diversity for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        pop_diversity = np.mean(np.std(pop, axis=0))  # Calculate population diversity\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + 0.5 * pop_diversity)  # Adjusted mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 50, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08912 with standard deviation 0.05300.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1534996639792593, 0.16662446921038865, 0.1544989727935019, 0.08608352739993108, 0.07987304646353, 0.07082783108479718, 0.03248719487291307, 0.026563640832789615, 0.03162699668352209]}}
{"id": "68cbfe59-d650-48e1-8200-78c945e03b11", "fitness": 0.08784032817744877, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Iterative Precision Refinement (EHDE-IPR) with dynamic adaptive intensity in local search to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate * (1 - self.eval_count / self.budget)))  # Dynamic adaptive intensity\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 51, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08784 with standard deviation 0.05135.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "56228a9b-49e2-43db-8707-e7cfe8a7a843", "fitness": 0.087601256096535, "name": "EHDE_APR", "description": "Enhanced Hybrid Differential Evolution with Adaptive Precision Refinement (EHDE-APR) that dynamically adjusts mutation precision and crossover rate based on the remaining budget to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EHDE_APR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.base_F = 0.5  # Base differential weight\n        self.base_CR = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        budget_scaling = 1 - self.eval_count / self.budget  # Scale based on used budget\n        mutation_factor = self.base_F * budget_scaling\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        budget_scaling = 1 - self.eval_count / self.budget\n        adaptive_CR = self.base_CR * budget_scaling  # Adjust CR based on budget\n        crossover = np.random.rand(self.dim) < adaptive_CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                if self.eval_count >= self.budget:\n                    break\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 52, "feedback": "The algorithm EHDE_APR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08760 with standard deviation 0.05156.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1507144005929263, 0.16610614381970956, 0.14691943657162876, 0.08627399626705856, 0.07987304646353, 0.0658680937499011, 0.03248719487291307, 0.036289309418825244, 0.02387968311232247]}}
{"id": "794766cb-33db-4120-a1c9-a6b0e8c5a0c8", "fitness": 0.08810616141654519, "name": "EADE_MS_ALS", "description": "Enhanced Adaptive Differential Evolution with Multi-Scale Mutation and Adaptive Local Search (EADE-MS-ALS) that improves convergence by utilizing varying mutation scales and an adaptive local search strategy based on convergence trends.", "code": "import numpy as np\n\nclass EADE_MS_ALS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, scale):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = scale * self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate)\n        intensity = max(1, int(self.dim * convergence_rate * 2))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        mutation_scales = [0.5, 1.0, 1.5]  # Different mutation scales\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                scale = mutation_scales[i % len(mutation_scales)]\n                mutant = self._mutate(pop, i, bounds, scale)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 53, "feedback": "The algorithm EADE_MS_ALS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08811 with standard deviation 0.05131.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15108209393761574, 0.16610614381970956, 0.1486811010312017, 0.08608352739993108, 0.07987304646353, 0.06158986919606202, 0.03248719487291307, 0.0422589349724789, 0.024793541055464607]}}
{"id": "9ce853d0-aa8b-4639-8196-ffe8cb32f4b7", "fitness": 0.08784032817744877, "name": "EHDE_IPR", "description": "Enhanced Hybrid Differential Evolution with Adaptive Mutation (EHDE-AM) that dynamically adjusts the differential weight based on convergence rate to improve search efficiency.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                self.F = 0.5 + 0.3 * convergence_rate  # Dynamically adjust differential weight based on convergence rate\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 54, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08784 with standard deviation 0.05135.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "af1e02d0-9140-4378-a9b5-70facea46357", "fitness": 0.08629253368684069, "name": "AHDE_PR", "description": "Adaptive Hybrid Differential Evolution with Precision Refinement (AHDE-PR) that dynamically adjusts mutation and crossover parameters based on population diversity and convergence speed to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHDE_PR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, diversity):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + diversity)  # Adjust mutation factor based on diversity\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, diversity):\n        adjusted_CR = self.CR * (1 + diversity)  # Adjust crossover probability based on diversity\n        crossover = np.random.rand(self.dim) < adjusted_CR\n        return np.where(crossover, mutant, target)\n\n    def _calculate_diversity(self, pop):\n        return np.std(pop, axis=0).mean() / (np.ptp(pop, axis=0).mean() + 1e-10)  # Diversity measure\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            diversity = self._calculate_diversity(pop)\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, diversity)\n                trial = self._crossover(pop[i], mutant, diversity)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 55, "feedback": "The algorithm AHDE_PR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08629 with standard deviation 0.05196.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15126986348311589, 0.16610614381970956, 0.14187073287844487, 0.08608352739993108, 0.07987304646353, 0.06724619399389065, 0.03248719487291307, 0.02821474770665, 0.02348135256338102]}}
{"id": "f9ad74fc-25f8-4a2c-9fc2-9023c24f5ae0", "fitness": 0.09715935187049722, "name": "ADS_DE", "description": "Adaptive Dual-Step Differential Evolution (ADS-DE) that introduces a dynamic adjustment of differential weight and crossover rate based on population diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ADS_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.initial_F = 0.8\n        self.initial_CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, F):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, CR):\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _calculate_diversity(self, pop):\n        return np.mean(np.std(pop, axis=0))\n\n    def _adaptive_control_parameters(self, diversity):\n        F = self.initial_F * (1 + 0.5 * (1 - diversity))\n        CR = self.initial_CR * diversity\n        return F, CR\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            diversity = self._calculate_diversity(pop)\n            F, CR = self._adaptive_control_parameters(diversity)\n\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                mutant = self._mutate(pop, i, bounds, F)\n                trial = self._crossover(pop[i], mutant, CR)\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 56, "feedback": "The algorithm ADS_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09716 with standard deviation 0.04395.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1523315870368529, 0.08975218666085294, 0.08024575941093093, 0.07317388143959047, 0.0669057308255342, 0.05241232977340338, 0.04313445803239768]}}
{"id": "5c2dca30-1583-44b2-bd9f-16f290e30af9", "fitness": 0.08784032817744877, "name": "EHDE_IPR", "description": "EHDE_IPR with Enhanced Adaptive Local Search enhances convergence by integrating a dynamic intensity factor into the local search mechanism.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate * (1 + 0.5 * (self.eval_count / self.budget))))  # Enhanced dynamic intensity\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 57, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08784 with standard deviation 0.05135.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.15052405932358648, 0.16610614381970956, 0.14637896866355993, 0.0916377745489948, 0.07987304646353, 0.056607022968861, 0.03278500301872622, 0.04393705783586621, 0.022713876954204792]}}
{"id": "7ece6cde-5305-44c4-87e2-f7dc0261da48", "fitness": -Infinity, "name": "ADE_PRDPSA", "description": "Adaptive Differential Evolution with Precision Refinement and Dynamic Population Size Adjustment (ADE-PRDPSA) improves convergence by dynamically adjusting population size based on search progress and refining mutation precision.", "code": "import numpy as np\n\nclass ADE_PRDPSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Initial population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _dynamic_population_adjustment(self, fitness):\n        improvement = np.std(fitness)\n        if improvement < 0.01:\n            self.pop_size = max(4, self.pop_size // 2)\n        else:\n            self.pop_size = min(20 * self.dim, self.pop_size * 2)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self._dynamic_population_adjustment(fitness)\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 58, "feedback": "An exception occurred: IndexError('index 139 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 139 is out of bounds for axis 0 with size 100')", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {}}
{"id": "ee0da0a9-dc17-4b94-86bf-52f9ac3df92f", "fitness": 0.09841428637254447, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with adaptive crossover probability based on convergence rate for improved exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 59, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09841 with standard deviation 0.06804.", "error": "", "parent_ids": ["98dc1f33-8652-4f46-979c-c1f64196463b"], "operator": null, "metadata": {"aucs": [0.23734570093481455, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06360165631576065, 0.03248719487291307, 0.03725582604911204, 0.028687164042569546]}}
{"id": "be952970-e356-448c-88c0-71a61a1c109e", "fitness": 0.0880707169394816, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with adaptive local search step size adjustment for improved exploration.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * convergence_rate * (bounds.ub - bounds.lb)  # Adjusted step size based on convergence rate\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 60, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08807 with standard deviation 0.05250.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08594193586186327, 0.07940004781166177, 0.058643738124548594, 0.03242013403917121, 0.03725383634599044, 0.027219334136150297]}}
{"id": "1eed1079-fd07-40b4-ade9-07e4ed1fc485", "fitness": 0.09261095480093867, "name": "EHDE_IPR_Enhanced", "description": "Enhanced EHDE-IPR with self-adaptive mutation and crossover rates for dynamic exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.base_F = 0.5  # Base differential weight\n        self.base_CR = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F = np.random.uniform(0.4, 0.9) * (1 - self.eval_count / self.budget)  # Self-adaptive differential weight\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        CR = np.random.uniform(0.7, 1.0) * (1 + self.eval_count / self.budget)  # Self-adaptive crossover probability\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 61, "feedback": "The algorithm EHDE_IPR_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09261 with standard deviation 0.05130.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1592544145091418, 0.16610614381970956, 0.15322305023270655, 0.08594193586186327, 0.08489087602363277, 0.07319758188454573, 0.03682603868527645, 0.05109691997804122, 0.022961632213530647]}}
{"id": "e3cc4aab-800b-46db-b30f-36367571544b", "fitness": 0.08805369301923302, "name": "EHDE_IPR", "description": "Improved EHDE_IPR with adaptive mutation factor based on population diversity for enhanced exploration.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(pop, axis=0).mean()  # New line: Calculate population diversity\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + diversity)  # Modify mutation factor with diversity\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 62, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08805 with standard deviation 0.05671.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.18671428578779492, 0.14659994638517615, 0.08608352739993108, 0.07987304646353, 0.060446735947876196, 0.03248719487291307, 0.02756324469897853, 0.022343165781694374]}}
{"id": "6979a943-2def-41a0-a5cf-e8ede81d9ffe", "fitness": 0.08880021558357741, "name": "EnhancedEHDE_IPR", "description": "EHDE-IPR with adaptive local search intensity and self-adaptive mutation factor to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - (self.eval_count / self.budget) ** 2)  # Self-adaptive mutation factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate * (1 - self.eval_count / self.budget)))  # Adjust intensity\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08880 with standard deviation 0.05370.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1641181568791893, 0.16610614381970956, 0.1499410097145002, 0.08608352739993108, 0.07987304646353, 0.05225582418609287, 0.032879235936228324, 0.032904840189897255, 0.03504015566311813]}}
{"id": "9c0d113a-593b-4370-b4af-5b7775676886", "fitness": 0.08623116527256858, "name": "EHDE_IPR", "description": "EHDE-IPR with dynamic scaling factor and mutation adaptation based on diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.base_F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.mean(np.std(pop, axis=0))\n        F = self.base_F * (1.0 + diversity)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 64, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08623 with standard deviation 0.05247.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1504188933883409, 0.16610614381970956, 0.14410973461438903, 0.08608352739993108, 0.07987304646353, 0.06845634579056348, 0.03248719487291307, 0.026202435322045692, 0.022343165781694374]}}
{"id": "dd3153ad-4b15-4e6e-a293-8c044abead2f", "fitness": 0.08964752304995775, "name": "EHDE_IPR", "description": "EHDE-IPR with adaptive mutation and crossover strategies based on convergence rate to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, convergence_rate):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F_base * (1 - convergence_rate)  # Adjust mutation factor based on convergence rate\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, convergence_rate):\n        crossover_rate = self.CR_base * (1 + convergence_rate)  # Adjust crossover probability based on convergence rate\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * (1 - convergence_rate)))  # Adjust local search intensity based on convergence rate\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                mutant = self._mutate(pop, i, bounds, convergence_rate)\n                trial = self._crossover(pop[i], mutant, convergence_rate)\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 65, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08965 with standard deviation 0.05851.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1597889922173239, 0.173833087499909, 0.16564654481803787, 0.0911979450084861, 0.07940004781166177, 0.05523459683781451, 0.03242013403917121, 0.027434998123737175, 0.021871361093478203]}}
{"id": "fca2e43a-403f-485e-ac3d-9507e61f23e8", "fitness": 0.0889026978848967, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with improved local search step size based on convergence rate for better exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 + convergence_rate)  # Improved step size\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 66, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08890 with standard deviation 0.05198.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06386265337810848, 0.03248719487291307, 0.03725582604911204, 0.02880460666452689]}}
{"id": "ee802fc5-927a-4064-9128-48d88b753622", "fitness": 0.08638304217401331, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with refined mutation adaptation based on dynamic budget scaling for improved exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - (self.eval_count / self.budget) ** 0.5)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 67, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08638 with standard deviation 0.05240.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14783325756258736, 0.08608352739993108, 0.07987304646353, 0.05651682483584086, 0.03248719487291307, 0.03546211649446529, 0.02271317828193964]}}
{"id": "5835524e-d3f7-485d-9cb5-dada1f639c59", "fitness": 0.08735126939485716, "name": "EHDE_Improved", "description": "Enhanced Differential Evolution with adaptive mutation and crossover rates, incorporating stochastic local search for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F_init = 0.8  # Initial differential weight\n        self.CR_init = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _adaptive_mutation(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F_dynamic = self.F_init * np.random.rand() * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + F_dynamic * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _adaptive_crossover(self, target, mutant):\n        CR_dynamic = self.CR_init * (1 - np.exp(-5 * self.eval_count / self.budget))  # Exponential decay\n        crossover = np.random.rand(self.dim) < CR_dynamic\n        return np.where(crossover, mutant, target)\n\n    def _stochastic_local_search(self, candidate, func, bounds):\n        best = candidate\n        step_size = 0.1 * (bounds.ub - bounds.lb) * np.random.rand()\n        for _ in range(5):  # Fixed number of local attempts\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._adaptive_mutation(pop, i, bounds)\n                trial = self._adaptive_crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count >= self.budget:\n                    break\n\n            for i in range(self.pop_size):\n                if self.eval_count < self.budget:\n                    local_candidate = self._stochastic_local_search(pop[i], func, bounds)\n                    local_fitness = func(local_candidate)\n                    self.eval_count += 1\n                    if local_fitness < fitness[i]:\n                        pop[i] = local_candidate\n                        fitness[i] = local_fitness\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 68, "feedback": "The algorithm EHDE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08735 with standard deviation 0.05094.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.1530808329535246, 0.16610614381970956, 0.14198396810904312, 0.08594193586186327, 0.07940004781166177, 0.06256827965139278, 0.039888951731475664, 0.026489597891635075, 0.03070166672340857]}}
{"id": "83f76acc-341c-499a-a3e1-ad36f8b7a5e1", "fitness": -Infinity, "name": "EHDE_IPR", "description": "Enhanced EHDE_IPR with adaptive step size and dynamic population size adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR * (1 + self.eval_count / self.budget)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate)  # Adaptive step size\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self.pop_size = int(10 * self.dim * (1 + self.eval_count / self.budget))  # Dynamic pop size\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n                \n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 69, "feedback": "An exception occurred: IndexError('index 107 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 107 is out of bounds for axis 0 with size 100')", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {}}
{"id": "7df14ab2-0f42-4418-984a-8162ec301582", "fitness": 0.10102450518368895, "name": "EHDE_IPR", "description": "Improved EHDE-IPR using dynamic strategy adaptation based on population diversity for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 70, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10102 with standard deviation 0.07357.", "error": "", "parent_ids": ["ee0da0a9-dc17-4b94-86bf-52f9ac3df92f"], "operator": null, "metadata": {"aucs": [0.26093107033678153, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06350825621409406, 0.03248719487291307, 0.03725582604911204, 0.028687164042569546]}}
{"id": "e28bc40c-739e-4158-9182-7777d7a29760", "fitness": 0.08550957061229686, "name": "EHDE_IPR", "description": "Enhanced exploration-exploitation by adjusting the mutation factor dynamically based on convergence rate.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adjust mutation_factor dynamically based on convergence rate\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * max(0.1, self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 71, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08551 with standard deviation 0.05370.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15442653772393045, 0.16610614381970956, 0.14637896866355993, 0.08608352739993108, 0.07987304646353, 0.051629236421286584, 0.03251544565420905, 0.026545810547725868, 0.02602741881678916]}}
{"id": "f7ed3a5b-8cb0-48b4-8ef8-62d03b411185", "fitness": 0.08544933034990104, "name": "Enhanced_EHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic population adjustment and adaptive mutation based on learning rates for improved exploration of search space.", "code": "import numpy as np\n\nclass Enhanced_EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.init_pop_size = self.pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - np.exp(-self.eval_count / self.budget))\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _adjust_population_size(self):\n        if self.eval_count / self.budget > 0.5:\n            reduction_factor = 0.5 * (1 - (self.eval_count / self.budget))\n            self.pop_size = int(max(self.init_pop_size * reduction_factor, 4 * self.dim))\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self._adjust_population_size()\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 72, "feedback": "The algorithm Enhanced_EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08545 with standard deviation 0.05324.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16659463939685581, 0.1477881423835895, 0.08608352739993108, 0.07987304646353, 0.052236094356390095, 0.03301041250054959, 0.026754582097247126, 0.026331438715813227]}}
{"id": "fd5372c8-131c-4729-86a5-75336133dc14", "fitness": 0.08572904703963732, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR by incorporating self-adjusting differential weight for better adaptability in different search stages.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adjust F to dynamically reduce as evaluations progress for better adaptability\n        mutation_factor = self.F * np.exp(-3 * self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 73, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08573 with standard deviation 0.05180.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15290452075164307, 0.16610614381970956, 0.1401334375182074, 0.08608352739993108, 0.07987304646353, 0.05459053038639672, 0.03248719487291307, 0.036747209651066814, 0.022635812493338237]}}
{"id": "2a58fa8b-5b8c-4f03-882b-80243e16b2e1", "fitness": 0.08754549424944488, "name": "EnhancedEHDE_IPR", "description": "Enhanced EHDE-IPR with adaptive crossover and mutation scaling based on fitness variance to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, fitness_var):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + fitness_var)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, fitness_var):\n        crossover_rate = self.CR * (1 + fitness_var)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            fitness_var = np.var(fitness) / (1 + np.mean(fitness))\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, fitness_var)\n                trial = self._crossover(pop[i], mutant, fitness_var)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08755 with standard deviation 0.05447.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15266803050358035, 0.1718451373748624, 0.1535347284474501, 0.08608352739993108, 0.07987304646353, 0.05097008623961574, 0.03248719487291307, 0.02893239220570698, 0.03151530473741426]}}
{"id": "cd49042e-058a-4d21-ab96-5c2c5b4f93fd", "fitness": 0.08456390056976051, "name": "AdaptiveEHDE_IPR", "description": "Adaptive EHDE-IPR with dynamic parameter tuning based on success history for enhanced convergence speed and stability.", "code": "import numpy as np\n\nclass AdaptiveEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n        self.success_history = []\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = np.mean(self.success_history[-5:]) if len(self.success_history) >= 5 else self.F\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = np.mean(self.success_history[-5:]) if len(self.success_history) >= 5 else self.CR\n        crossover_rate *= (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                success = trial_fitness < fitness[i]\n                self.success_history.append(1.0 if success else 0.0)\n                \n                if success:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 75, "feedback": "The algorithm AdaptiveEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08456 with standard deviation 0.05387.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14736189153927215, 0.08608352739993108, 0.07987304646353, 0.05024561009354578, 0.03248719487291307, 0.026202435322045692, 0.022343165781694374]}}
{"id": "f56b7721-d945-4440-ad2f-6ea5f45e6116", "fitness": 0.08864816811213931, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with improved mutation factor computation for better convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modification: Adjusted mutation factor calculation for better convergence\n        mutation_factor = self.F * (1 - (self.eval_count / self.budget)**2)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 76, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08865 with standard deviation 0.05382.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1641181568791893, 0.16610614381970956, 0.1499410097145002, 0.08608352739993108, 0.07987304646353, 0.05132222709794654, 0.03248719487291307, 0.03286205109841589, 0.03504015566311813]}}
{"id": "17840030-9262-4c00-a254-5bdff8f2f292", "fitness": 0.08930400679064936, "name": "EnhancedDE_ADC", "description": "Enhanced Differential Evolution with Adaptive Diversity Control leveraging a novel mutation technique and dynamic local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDE_ADC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, global_best):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c]) + mutation_factor * (global_best - pop[a])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        global_best_idx = np.argmin(fitness)\n        global_best = pop[global_best_idx]\n        prev_best_fitness = fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, global_best)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if trial_fitness < fitness[global_best_idx]:\n                    global_best_idx = i\n                    global_best = pop[i]\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        global_best_idx = np.argmin(fitness)\n        return pop[global_best_idx]", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedDE_ADC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08930 with standard deviation 0.04979.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15211098522190714, 0.16610614381970956, 0.1466096358627882, 0.08608352739993108, 0.07987304646353, 0.06271223223050293, 0.0344541582673461, 0.031304408904535674, 0.0444819229455935]}}
{"id": "88de3a8f-832f-4e15-bdb8-41c7d7d9a838", "fitness": 0.0860060837308782, "name": "EHDE_IPR", "description": "Enhanced EHDE_IPR with refined mutation factor calculation to improve solution convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - np.sqrt(self.eval_count / self.budget))  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 78, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08601 with standard deviation 0.05265.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14783325756258736, 0.08608352739993108, 0.07987304646353, 0.053560221585124856, 0.03248719487291307, 0.03527583580590865, 0.022463436232996403]}}
{"id": "8ac2fdcc-4c5c-4d10-b0a6-b43cbe16a260", "fitness": 0.08618665697397984, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with an adaptive mutation factor that dynamically increases as the budget is consumed for improved exploration.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Changed the mutation_factor to increase dynamically as the budget is consumed\n        mutation_factor = self.F * (1 + self.eval_count / self.budget)  # Adaptive mutation factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 79, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08619 with standard deviation 0.05430.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15144166237961398, 0.16610614381970956, 0.15432483921553553, 0.08608352739993108, 0.07987304646353, 0.05326479740764667, 0.03248719487291307, 0.02833340687739927, 0.023765294329539444]}}
{"id": "efc04322-699f-470d-b836-2574837a6da5", "fitness": 0.08885027124201095, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR by introducing a dynamic population size adjustment based on convergence rate to improve adaptability and efficiency.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Dynamically adjust population size based on convergence rate\n            self.pop_size = int(10 * self.dim * (1 - convergence_rate))\n            pop = np.resize(pop, (self.pop_size, self.dim))\n            fitness = np.resize(fitness, self.pop_size)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 80, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08885 with standard deviation 0.05201.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06350825621409406, 0.03248719487291307, 0.03725582604911204, 0.028687164042569546]}}
{"id": "3f0e19e3-3d0c-4938-9551-ecd93410cc8d", "fitness": 0.08585284892777405, "name": "EHDE_IPR", "description": "Introduced a dynamic adaptation of the differential weight based on population diversity to enhance mutation precision.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(pop) / (np.mean(pop) + 1e-9)  # Added population diversity factor\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + diversity_factor)  # Dynamic adaptation based on diversity\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 81, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08585 with standard deviation 0.05300.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1464451817581377, 0.08608352739993108, 0.07987304646353, 0.06276285509680202, 0.03248719487291307, 0.026202435322045692, 0.022343165781694374]}}
{"id": "ca42af79-1ab9-461c-a776-483f1f5c9959", "fitness": 0.08748728455322131, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with time-decreasing differential weight for improved exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (0.9 + 0.1 * np.random.rand())  # Time-decreasing mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 82, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08749 with standard deviation 0.05262.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15544615256869332, 0.16610614381970956, 0.1428182387426874, 0.08748196845422362, 0.07943145099318893, 0.07313939740624775, 0.032675714846706394, 0.027849022841263338, 0.022437471306271495]}}
{"id": "01b8cb99-92b0-4d5b-a377-62a8641a2e2c", "fitness": 0.0888087477309885, "name": "EHDE_IPR", "description": "Enhanced local search step size using the adaptive convergence rate for better fine-tuning near optima.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (1 - convergence_rate) * (bounds.ub - bounds.lb)  # Enhanced step size\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 83, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08881 with standard deviation 0.05204.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.15136296486167944, 0.16610614381970956, 0.15428831745455973, 0.08608352739993108, 0.07987304646353, 0.06325279829275776, 0.03248719487291307, 0.03725582604911204, 0.02856891036470377]}}
{"id": "2362b47a-ab97-404f-b2a4-7dd7a6129f7d", "fitness": -Infinity, "name": "EHDE_IPR", "description": "EHDE_IPR with refined mutation precision dynamically adjusted by relative improvement rate for enhanced adaptability.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - (self.eval_count / self.budget) * (np.min([1.0, np.mean([func(pop[a]), func(pop[b]), func(pop[c])]) / np.min(fitness)])))  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 84, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {}}
{"id": "73394c22-751f-4326-8981-dd9a310f568c", "fitness": 0.09844994231600032, "name": "EHDE_IPR", "description": "Enhanced adaptive local search and refined diversity factor for better convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.abs(np.mean(target)))  # Refined diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim) * 0.5  # Enhanced step size\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 85, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09845 with standard deviation 0.06828.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.23699410011896804, 0.16610614381970956, 0.1563403867897819, 0.08598937037030863, 0.08030635667499819, 0.06270060680901901, 0.03248546745942238, 0.03725674007832991, 0.027870308723465298]}}
{"id": "a8bd781c-7ddc-4257-8f81-2c502b87d432", "fitness": 0.09054609863308677, "name": "EHDE_IPR_Improved", "description": "Introduced a dynamic population size and adaptive mutation strategy based on fitness diversity to enhance convergence and robustness.", "code": "import numpy as np\n\nclass EHDE_IPR_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = max(10, 5 * dim)\n        self.final_pop_size = max(10, int(0.5 * dim))\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds, pop_size):\n        return np.random.uniform(bounds.lb, bounds.ub, (pop_size, self.dim))\n\n    def _adaptive_mutation(self, pop, idx, bounds, fitness):\n        indices = list(range(len(pop)))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n        mutation_factor = self.F * (1 + fitness_diversity)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop_size_range = np.linspace(self.initial_pop_size, self.final_pop_size, num=int(self.budget / self.initial_pop_size))\n        pop = self._initialize_population(bounds, int(pop_size_range[0]))\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = len(pop)\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            current_pop_size = int(pop_size_range[min(self.eval_count // self.initial_pop_size, len(pop_size_range) - 1)])\n            for i in range(current_pop_size):\n                mutant = self._adaptive_mutation(pop, i, bounds, fitness)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            if len(pop) > current_pop_size:\n                pop = pop[:current_pop_size]\n                fitness = fitness[:current_pop_size]\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 86, "feedback": "The algorithm EHDE_IPR_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09055 with standard deviation 0.05357.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.16108190391919164, 0.16610614381970956, 0.15595605744252483, 0.08804114649722206, 0.07940004781166177, 0.06741066067643553, 0.035063928277911716, 0.028874728330321897, 0.03298027092280198]}}
{"id": "42405cbf-dbed-4f2b-b6b4-82345c6d2083", "fitness": 0.08747787944156554, "name": "EHDE_IPR_Enhanced", "description": "Enhanced EHDE-IPR with dynamic population size adjustment and adaptive parameter tuning for improved convergence and robustness.", "code": "import numpy as np\n\nclass EHDE_IPR_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Initial population size\n        self.F_base = 0.5  # Base differential weight\n        self.CR_base = 0.9  # Base crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, F):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, CR):\n        crossover = np.random.rand(self.dim) < CR\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                dynamic_F = self.F_base * (1 - self.eval_count / self.budget)\n                dynamic_CR = self.CR_base * (1 - np.std(fitness) / (np.mean(fitness) + 1e-8))\n                mutant = self._mutate(pop, i, bounds, dynamic_F)\n                trial = self._crossover(pop[i], mutant, dynamic_CR)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count < self.budget:\n                    current_best_fitness = np.min(fitness)\n                    convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                    prev_best_fitness = current_best_fitness\n\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive population size adjustment based on convergence\n            if self.eval_count < self.budget:\n                improvement_rate = (prev_best_fitness - np.min(fitness)) / prev_best_fitness if prev_best_fitness != 0 else 0\n                if improvement_rate < 0.01:\n                    self.pop_size = max(self.dim, int(self.pop_size * 0.9))\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 87, "feedback": "The algorithm EHDE_IPR_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08748 with standard deviation 0.05162.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.14637896866355993, 0.08813970089480916, 0.07941700701914212, 0.06496442105845202, 0.03279157263358057, 0.03666378948310467, 0.022467221566529028]}}
{"id": "a5f9e71b-e625-47c6-b819-2f27646e7bea", "fitness": 0.08696060679218126, "name": "EHDE_IPR_Plus", "description": "EHDE_IPR+ with enhanced adaptive tuning and local search intensification for improved optimization performance.", "code": "import numpy as np\n\nclass EHDE_IPR_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 12 * dim  # Increase population size for better diversity\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - (self.eval_count / self.budget)**2)  # Exponential decay for mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover_rate = min(1, max(0, crossover_rate))  # Ensure crossover rate is within bounds\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _intensified_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.1 * (bounds.ub - bounds.lb) * convergence_rate  # Dynamic step size adjustment\n        intensity = int(max(1, self.dim * (0.5 + convergence_rate)))  # Increased intensity based on convergence\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._intensified_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 88, "feedback": "The algorithm EHDE_IPR_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08696 with standard deviation 0.05310.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.16312473778499925, 0.16610614381970956, 0.140018901019756, 0.08594193586186327, 0.07940004781166177, 0.04926635502851939, 0.03242013403917121, 0.04452453702783865, 0.021842668736112292]}}
{"id": "2564e895-c18a-4570-aba2-033cff827421", "fitness": -Infinity, "name": "EHDE_IPR", "description": "Refined EHDE-IPR with dynamic mutation factor adjustment based on fitness improvement rate for improved convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        current_best_fitness = np.min([func(ind) for ind in pop])  # Added to use in mutation factor adjustment\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * (1 + (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0)  # Refined mutation precision\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 89, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {}}
{"id": "0deb254b-08c1-453d-85e9-947b73e91e3c", "fitness": -Infinity, "name": "EHDE_IPR2", "description": "Enhanced Dynamic Hybrid Differential Evolution (EHDE_IPR2) with adaptive mutation factor and diversity-based population resizing for improved convergence and exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EHDE_IPR2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F_base = 0.5  # Base differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Adaptive mutation factor based on fitness diversity\n        fitness_diversity = np.std(np.array([func(ind) for ind in pop]))\n        mutation_factor = self.F_base * (1 + fitness_diversity / (1 + np.mean(fitness_diversity)))\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            current_pop_size = self.pop_size\n            for i in range(current_pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Dynamically adjust population size based on diversity\n            if self.eval_count < self.budget:\n                diversity = np.std(fitness)\n                new_pop_size = max(4, int(self.pop_size * (1 + diversity / (1 + np.mean(diversity)))))\n                if new_pop_size != current_pop_size:\n                    indices = np.argsort(fitness)[:new_pop_size]\n                    pop = pop[indices]\n                    fitness = fitness[indices]\n                    self.pop_size = new_pop_size\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 90, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {}}
{"id": "ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd", "fitness": 0.10550748442697509, "name": "EHDE_IPR", "description": "Refined EHDE-IPR with adaptive mutation factor based on fitness improvement to enhance convergence.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))  # New adaptive factor\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor  # Adaptive mutation adjustment\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 91, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10551 with standard deviation 0.09040.", "error": "", "parent_ids": ["7df14ab2-0f42-4418-984a-8162ec301582"], "operator": null, "metadata": {"aucs": [0.3218668364794802, 0.16610614381970956, 0.15188003004980477, 0.08608352739993108, 0.07987304646353, 0.055211896577328945, 0.03248719487291307, 0.026202435322045692, 0.029856248858032508]}}
{"id": "b9e1f207-1e3f-4992-8c41-93e54becbda3", "fitness": 0.09283567534914537, "name": "Enhanced_EHDE_IPR", "description": "Enhanced EHDE-IPR with adaptive population size reduction and dynamic convergence-based mutation and crossover strategies for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Initial population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds, convergence_rate):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor * (1 + convergence_rate)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant, convergence_rate):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor) * (1 + convergence_rate)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _adjust_population_size(self):\n        reduction_factor = 0.5 * (self.eval_count / self.budget) ** 2\n        self.pop_size = max(4, int(self.pop_size * (1 - reduction_factor)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            self._adjust_population_size()  # Dynamic population size reduction\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds, convergence_rate=(prev_best_fitness - np.min(fitness)) / max(1e-12, prev_best_fitness))\n                trial = self._crossover(pop[i], mutant, convergence_rate=(prev_best_fitness - np.min(fitness)) / max(1e-12, prev_best_fitness))\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / max(1e-12, prev_best_fitness)\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 92, "feedback": "The algorithm Enhanced_EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09284 with standard deviation 0.04913.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.1583426710173469, 0.16610614381970956, 0.14679285628732086, 0.08659377495043652, 0.08245551559514608, 0.06536731923619521, 0.03259752923247039, 0.029736116304730054, 0.0675291516989528]}}
{"id": "b7c31836-d4fe-45de-89a9-94cbd0d11995", "fitness": 0.08678344605294001, "name": "EnhancedEHDE_IPR", "description": "Introduce a dynamic scaling factor and adaptive neighborhood search for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))\n        dynamic_scaling = 0.5 + 0.5 * (1 - self.eval_count / self.budget)\n        mutation_factor = self.F * dynamic_scaling * fitness_improvement_factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_neighborhood_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        local_search_intensity = int(max(1, self.dim * convergence_rate))\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - convergence_rate)\n        for _ in range(local_search_intensity):\n            new_candidate = np.clip(candidate + np.random.uniform(-step_size, step_size, self.dim), bounds.lb, bounds.ub)\n            if func(new_candidate) < func(best):\n                best = new_candidate\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_neighborhood_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08678 with standard deviation 0.05374.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.1572303080845595, 0.16610614381970956, 0.14631659304786448, 0.08740614458736484, 0.07987304646353, 0.0596326819963795, 0.03594049537331212, 0.026202435322045692, 0.022343165781694374]}}
{"id": "e86e47ce-3bf1-40f9-a62e-eee5cdc603c3", "fitness": -Infinity, "name": "Enhanced_EHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic population size and adaptive search intensity to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n        self.dynamic_pop_adjustment = True\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def _adjust_population(self, bounds, fitness):\n        if self.dynamic_pop_adjustment:\n            sorted_indices = np.argsort(fitness)\n            self.pop_size = max(4, self.pop_size - self.pop_size // 10)\n            selected_indices = sorted_indices[:self.pop_size]\n            return np.array([pop[i] for i in selected_indices]), np.array([fitness[i] for i in selected_indices])\n        return pop, fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            pop, fitness = self._adjust_population(bounds, fitness)\n\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 94, "feedback": "An exception occurred: NameError(\"name 'pop' is not defined\").", "error": "NameError(\"name 'pop' is not defined\")", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {}}
{"id": "250d169d-b3d6-4937-a167-1177bc4f6cc0", "fitness": 0.09465035611899963, "name": "EHDE_IPR", "description": "Improved EHDE_IPR by enhancing mutation factor adaptability and refining local search intensity.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))  # New adaptive factor\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor * 0.95  # Adaptive mutation adjustment\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate * 1.05))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 95, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09465 with standard deviation 0.06873.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.23699410011896804, 0.16610614381970956, 0.1425021674273912, 0.08608352739993108, 0.07987304646353, 0.05111129233575218, 0.03248719487291307, 0.026202435322045692, 0.030493297310755896]}}
{"id": "548f2742-dc8b-4d25-ad6f-0d4c7458ecb9", "fitness": 0.08645251257761094, "name": "EHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic population size reduction based on convergence to accelerate exploitation.", "code": "import numpy as np\n\nclass EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))  # New adaptive factor\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor  # Adaptive mutation adjustment\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))  # Added diversity factor\n        crossover_rate = self.CR * (1 + diversity_factor)  # Adaptively adjust crossover probability\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.pop_size = max(4, int(self.pop_size * (1 - convergence_rate)))  # Dynamic population size reduction\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 96, "feedback": "The algorithm EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08645 with standard deviation 0.05320.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15188003004980477, 0.08608352739993108, 0.07987304646353, 0.055211896577328945, 0.03248719487291307, 0.026202435322045692, 0.029856248858032508]}}
{"id": "bd5bcf4d-4c3a-47b6-8580-9fe5c07026fd", "fitness": 0.089477795689158, "name": "Enhanced_EHDE_IPR", "description": "Enhanced EHDE-IPR introducing diversity maintenance and opposition-based learning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_EHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutation_factor = self.F * (1 - self.eval_count / self.budget)\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        crossover_rate = self.CR\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _opposition_based_learning(self, candidate, bounds):\n        return bounds.lb + bounds.ub - candidate\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.eval_count < self.budget:\n                    opposition_candidate = self._opposition_based_learning(pop[i], bounds)\n                    if func(opposition_candidate) < fitness[i]:\n                        pop[i] = opposition_candidate\n                        fitness[i] = func(opposition_candidate)\n                        self.eval_count += 1\n\n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm Enhanced_EHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08948 with standard deviation 0.05036.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.15443148916213334, 0.16610614381970956, 0.1456283014933465, 0.08964106341585443, 0.08024519547904807, 0.06305983785833347, 0.032478531999253435, 0.03870866993996336, 0.03500092803477983]}}
{"id": "2a9ef265-3fcf-42da-a73b-0e8a46711aa8", "fitness": 0.09099140168592318, "name": "EnhancedEHDE_IPR", "description": "Enhanced EHDE_IPR with adaptive step size and self-adaptive parameters to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.F = 0.5  # Initial Differential weight\n        self.CR = 0.9  # Initial Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        return np.random.uniform(bounds.lb, bounds.ub, (self.pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_step_size(self):\n        return 0.01 + 0.99 * (self.eval_count / self.budget)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = self._adaptive_step_size() * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = self.pop_size\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09099 with standard deviation 0.05330.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.15603640282363507, 0.16610614381970956, 0.16354645098435505, 0.08594193586186327, 0.07940004781166177, 0.06362513102661338, 0.03488488078108587, 0.03072010382077006, 0.03866151824361452]}}
{"id": "a5be1fea-3116-4e8f-87a5-00300f39745d", "fitness": 0.0921361243173763, "name": "EnhancedEHDE_IPR", "description": "Enhanced EHDE-IPR with dynamic population size and adaptive local search intensity for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedEHDE_IPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # Initial population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def _initialize_population(self, bounds):\n        pop_size = self.initial_pop_size // 2 if self.eval_count > self.budget // 2 else self.initial_pop_size\n        return np.random.uniform(bounds.lb, bounds.ub, (pop_size, self.dim))\n\n    def _mutate(self, pop, idx, bounds):\n        indices = list(range(len(pop)))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_improvement_factor = 1 + (np.min([pop[a], pop[b], pop[c]]) - pop[idx]) / (1 + np.abs(pop[idx]))\n        mutation_factor = self.F * (1 - self.eval_count / self.budget) * fitness_improvement_factor\n        mutant = pop[a] + mutation_factor * (pop[b] - pop[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def _crossover(self, target, mutant):\n        diversity_factor = np.std(target) / (1 + np.mean(target))\n        crossover_rate = self.CR * (1 + diversity_factor)\n        crossover = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def _adaptive_local_search(self, candidate, func, bounds, convergence_rate):\n        best = candidate\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        intensity = int(max(1, self.dim * convergence_rate * (0.5 + 0.5 * (self.budget - self.eval_count) / self.budget)))\n        for _ in range(intensity):\n            step = np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(candidate + step, bounds.lb, bounds.ub)\n            if func(neighbor) < func(best):\n                best = neighbor\n        return best\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count = len(pop)\n        prev_best_fitness = np.min(fitness)\n\n        while self.eval_count < self.budget:\n            for i in range(len(pop)):\n                mutant = self._mutate(pop, i, bounds)\n                trial = self._crossover(pop[i], mutant)\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                current_best_fitness = np.min(fitness)\n                convergence_rate = (prev_best_fitness - current_best_fitness) / prev_best_fitness if prev_best_fitness != 0 else 0\n                prev_best_fitness = current_best_fitness\n\n                if self.eval_count < self.budget and np.random.rand() < 0.5:\n                    pop[i] = self._adaptive_local_search(pop[i], func, bounds, convergence_rate)\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n\n                if self.eval_count >= self.budget:\n                    break\n\n            if self.eval_count < self.budget:\n                pop = self._initialize_population(bounds)\n                fitness = np.array([func(ind) for ind in pop])\n                self.eval_count += len(pop)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedEHDE_IPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09214 with standard deviation 0.04971.", "error": "", "parent_ids": ["ffe50f7a-564a-4eb1-8d60-41fd65b4b3bd"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.1718283326057921, 0.1472160604112419, 0.08594193586186327, 0.07940004781166177, 0.07086472559190515, 0.034961224611327224, 0.06632251249883081, 0.02231818962856158]}}
