{"id": "94b191f1-5202-482f-984c-58cd5a285f6a", "fitness": 0.07607076812415618, "name": "HybridPSODE", "description": "A hybrid Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithm that dynamically balances exploration and exploitation to efficiently solve black box optimization problems.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07607 with standard deviation 0.00416.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08078109855763238, 0.07065612812977051, 0.07677507768506564]}}
{"id": "0c7ed730-2a20-46de-8815-1723fbf1b314", "fitness": 0.06393836724490838, "name": "HybridPSODE", "description": "An adjusted hybrid PSO-DE algorithm that modifies DE's mutation strategy for enhanced performance in black box optimization problems.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3 + x1), lb, ub)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06394 with standard deviation 0.00572.", "error": "", "parent_ids": ["94b191f1-5202-482f-984c-58cd5a285f6a"], "operator": null, "metadata": {"aucs": [0.07073724396700387, 0.06432496561273127, 0.05675289215499002]}}
{"id": "42509bef-1404-49cd-bb29-0fe8d56e39f7", "fitness": 0.06148212365423441, "name": "EPSO_ADE", "description": "An enhanced Particle Swarm Optimization with Adaptive Differential Evolution (EPSO-ADE) algorithm that adjusts parameters based on convergence speed to efficiently solve black box optimization problems with improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.f_init = 0.5  # Initial differential weight\n        self.f_final = 0.9  # Final differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n        iter_count = 0\n\n        while eval_count < self.budget:\n            # Calculate inertia weight and differential weight based on progress\n            w = self.w_init - (self.w_init - self.w_final) * (eval_count / self.budget)\n            f = self.f_init + (self.f_final - self.f_init) * (eval_count / self.budget)\n\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            iter_count += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06148 with standard deviation 0.00704.", "error": "", "parent_ids": ["94b191f1-5202-482f-984c-58cd5a285f6a"], "operator": null, "metadata": {"aucs": [0.061707980025132, 0.06998376127988948, 0.05275462965768174]}}
{"id": "a5107008-60fa-4762-9a2d-e51cfcadbfdf", "fitness": 0.045411101616082306, "name": "EnhancedHybridPSODE", "description": "An enhanced Hybrid Particle Swarm and Differential Evolution algorithm integrating adaptive parameter control and chaotic initialization to improve convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_initial, self.c2_initial = 1.5, 1.5\n        self.w_initial, self.w_final = 0.9, 0.4\n        self.f = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        np.random.seed(42)  # Ensure reproducibility\n        pop = lb + (ub - lb) * np.random.rand(self.pop_size, self.dim) * (np.random.rand(self.pop_size, self.dim) > 0.5)\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive PSO parameters\n            w = self.w_final + (self.w_initial - self.w_final) * ((self.budget - eval_count) / self.budget)\n            c1 = self.c1_initial * (eval_count / self.budget)\n            c2 = self.c2_initial * (eval_count / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - pop) +\n                          c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04541 with standard deviation 0.00000.", "error": "", "parent_ids": ["94b191f1-5202-482f-984c-58cd5a285f6a"], "operator": null, "metadata": {"aucs": [0.045411101616082306, 0.045411101616082306, 0.045411101616082306]}}
{"id": "620f0f5f-5d53-449e-be20-7eb6b0eaa87b", "fitness": 0.07625823113889325, "name": "HybridPSODE", "description": "A refined hybrid PSO and DE algorithm with a dynamic inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget  # Line changed\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07626 with standard deviation 0.00106.", "error": "", "parent_ids": ["94b191f1-5202-482f-984c-58cd5a285f6a"], "operator": null, "metadata": {"aucs": [0.0777586474901446, 0.07556246527889787, 0.0754535806476373]}}
{"id": "10010227-bbf7-4175-b88c-9bbc464af54e", "fitness": 0.06880853008140364, "name": "HybridPSODE", "description": "Introduced dynamic crossover probability to improve diversity and adaptation of the search process.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                # Line changed below\n                cross_points = np.random.rand(self.dim) < (self.cr + 0.1 * (self.budget - eval_count) / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06881 with standard deviation 0.01057.", "error": "", "parent_ids": ["620f0f5f-5d53-449e-be20-7eb6b0eaa87b"], "operator": null, "metadata": {"aucs": [0.06210443046484704, 0.08373373613694535, 0.060587423642418536]}}
{"id": "d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3", "fitness": 0.08077307915427934, "name": "HybridPSODE", "description": "Adjusted the crossover probability dynamically based on evaluations to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget  # Line changed\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))  # Line changed\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08077 with standard deviation 0.00401.", "error": "", "parent_ids": ["620f0f5f-5d53-449e-be20-7eb6b0eaa87b"], "operator": null, "metadata": {"aucs": [0.08606412531718077, 0.07634980193833907, 0.07990531020731817]}}
{"id": "c5973feb-9ec1-4734-8f77-387ec825c14d", "fitness": 0.06478306331190582, "name": "ImprovedHybridPSODE", "description": "Introduced adaptive inertia and differential weight strategies to improve convergence efficiency and exploration-exploitation balance dynamically.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.f_min = 0.5  # Minimum differential weight\n        self.f_max = 0.9  # Maximum differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive PSO update\n            w_dynamic = self.w_max - ((self.w_max - self.w_min) * (eval_count / self.budget))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Adaptive DE update\n            f_dynamic = self.f_min + ((self.f_max - self.f_min) * (eval_count / self.budget))\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06478 with standard deviation 0.00634.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.06440938337251612, 0.07272670233292233, 0.05721310423027903]}}
{"id": "fd212e0f-dfcd-41c7-838e-6c0aa77f1c9d", "fitness": 0.07541360121720327, "name": "AdaptiveHybridPSODE", "description": "Introduced adaptive population size and mutation strategy, balancing exploration and exploitation with a dynamically shrinking population and variable mutation step-size.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f_start = 0.9  # Initial differential weight\n        self.f_end = 0.5  # Final differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight and adaptive population size\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with adaptive differential weight\n            f_dynamic = self.f_end + (self.f_start - self.f_end) * (self.budget - eval_count) / self.budget\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Adapt population size\n            pop_size = max(4, int(self.initial_pop_size * (1 - eval_count / self.budget)))\n            pop = pop[:pop_size]\n            velocities = velocities[:pop_size]\n            personal_best_positions = personal_best_positions[:pop_size]\n            personal_best_scores = personal_best_scores[:pop_size]\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07541 with standard deviation 0.00688.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.06605111510770012, 0.08237093090668235, 0.07781875763722734]}}
{"id": "5a7570f1-5324-4655-b981-73945eaac3d4", "fitness": 0.057465430578716704, "name": "ImprovedHybridPSODE", "description": "Introduce adaptive chaos-based mutation and inertia weight to enhance exploration in early stages and exploitation in later stages for improved convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def chaos_mutation(self, position, lb, ub):\n        chaotic_sequence = np.random.rand(self.dim)\n        logistic_map = 4 * chaotic_sequence * (1 - chaotic_sequence)\n        return np.clip(position + logistic_map * (ub - lb) * 0.1, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive inertia weight\n            w_dynamic = self.w_max - ((self.w_max - self.w_min) * (eval_count / self.budget))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with chaos-based mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = self.chaos_mutation(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05747 with standard deviation 0.00455.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.054760813442221834, 0.053755666330229435, 0.06387981196369885]}}
{"id": "13310309-ab11-4728-92a0-83dcb711cd9a", "fitness": 0.06722150742493412, "name": "HybridPSODE", "description": "HybridPSODE with adaptive population size and momentum to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Initial population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_end = 0.4  # Final inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Reduce population size adaptively\n            if eval_count / self.budget > 0.5 and self.pop_size > 5:\n                self.pop_size -= 1\n                pop = pop[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best_positions = personal_best_positions[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = self.w_end + (self.w_init - self.w_end) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06722 with standard deviation 0.00667.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.06296621258065682, 0.06205235604334558, 0.07664595365079996]}}
{"id": "5b33e0b2-0cde-4597-8de8-bd0711c3e2dc", "fitness": 0.06598072174924374, "name": "HybridPSODE", "description": "Introduce adaptive mutation and crossover rates based on the population's diversity to improve convergence speed and avoid premature convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Initial Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Compute diversity\n            diversity = np.mean(np.std(pop, axis=0))\n\n            # Adaptive PSO parameters\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Adaptive DE parameters\n            adaptive_cr = max(0.6, min(1.0, self.cr * (1 + diversity)))\n            adaptive_f = max(0.5, min(1.2, self.f * (1 + diversity)))\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + adaptive_f * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < adaptive_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06598 with standard deviation 0.00698.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.05701730372724234, 0.06687773236871764, 0.07404712915177125]}}
{"id": "1e927da9-a01a-4570-a5c0-ea21dddada90", "fitness": 0.08530728917783781, "name": "HybridPSODE", "description": "Introduced adaptive differential weight to improve diversity and convergence in DE step.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)  # Line changed\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08531 with standard deviation 0.00171.", "error": "", "parent_ids": ["d3150eac-d7d7-4bf0-9f5e-0d27d54d5ee3"], "operator": null, "metadata": {"aucs": [0.08764255396268339, 0.08468919833216859, 0.08359011523866144]}}
{"id": "9f385f18-d47b-49d7-9314-ab8b201c86d5", "fitness": 0.08100926744495267, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive crossover probability to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Line changed\n                cross_points = np.random.rand(self.dim) < (cr_dynamic)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08101 with standard deviation 0.00112.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08115944757416182, 0.08229481347895129, 0.07957354128174488]}}
{"id": "98f8916c-4df1-468d-89fb-43003659b086", "fitness": 0.08034095261812886, "name": "HybridPSODE", "description": "Introduced a dynamic crossover probability in the DE step to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)  # Line changed\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08034 with standard deviation 0.00300.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07610285705428332, 0.08224096262891689, 0.08267903817118638]}}
{"id": "05680488-91e7-45b0-b627-5bca441b0eb8", "fitness": 0.08088377924875496, "name": "EnhancedHybridPSODE", "description": "Enhanced adaptive differential weight and inertia strategy with dynamic population size for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Adjust population size dynamically\n            pop_size_dynamic = self.initial_pop_size - int((self.initial_pop_size / 2) * (eval_count / self.budget))\n            pop = pop[:pop_size_dynamic]\n            velocities = velocities[:pop_size_dynamic]\n            personal_best_positions = personal_best_positions[:pop_size_dynamic]\n            personal_best_scores = personal_best_scores[:pop_size_dynamic]\n\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size_dynamic\n\n            # Update personal bests and global best\n            for i in range(pop_size_dynamic):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size_dynamic, self.dim), np.random.rand(pop_size_dynamic, self.dim)\n            w_dynamic = 0.4 + (0.6 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(pop_size_dynamic):\n                idxs = np.random.choice(np.delete(np.arange(pop_size_dynamic), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.4 * (1 - (eval_count / self.budget))  # Enhanced adaptive differential weight\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08088 with standard deviation 0.00419.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08654788537216851, 0.07654813415531614, 0.07955531821878026]}}
{"id": "1e97b184-0511-4121-9671-c72440d04a61", "fitness": 0.04990756514665562, "name": "EnhancedHybridPSODE", "description": "Enhanced diversity and convergence by adaptive mutation factor and dynamic crossover in DE, and time-varying coefficients in PSO.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_min, self.c1_max = 1.5, 2.0  # Cognitive coefficient range\n        self.c2_min, self.c2_max = 1.5, 2.0  # Social coefficient range\n        self.w_min, self.w_max = 0.4, 0.9  # Inertia weight range\n        self.cr_min, self.cr_max = 0.5, 0.9  # Crossover probability range\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Dynamic coefficients\n            w_dynamic = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            c1_dynamic = self.c1_max - (self.c1_max - self.c1_min) * (eval_count / self.budget)\n            c2_dynamic = self.c2_max - (self.c2_max - self.c2_min) * (eval_count / self.budget)\n\n            # PSO update with dynamic coefficients\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation factor and dynamic crossover\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * np.random.rand()  # Randomized mutation factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr_min + (self.cr_max - self.cr_min) * (eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04991 with standard deviation 0.00369.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.05352239877842213, 0.0513524694485501, 0.04484782721299463]}}
{"id": "da2ef17c-cf35-416c-a85c-57e0b46e5137", "fitness": 0.06673181633690876, "name": "EnhancedHybridPSODE", "description": "Enhanced adaptive hybrid algorithm combining adaptive inertia weight in PSO and time-varying crossover probability in DE to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.cr_start = 0.9  # Start crossover probability\n        self.cr_end = 0.6    # End crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with adaptive inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.9 - ((0.9 - 0.4) * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with time-varying crossover rate\n            cr_dynamic = self.cr_start - (self.cr_start - self.cr_end) * (eval_count / self.budget)\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06673 with standard deviation 0.00866.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.061390615267375326, 0.07894797775348272, 0.05985685598986823]}}
{"id": "e4d874d8-791c-4305-9cc9-955ea281d6bf", "fitness": 0.08299472626814759, "name": "HybridPSODE", "description": "Enhanced dynamic adaptation of differential weight in DE step based on evaluation progress.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.6 + 0.2 * (eval_count / self.budget)  # Line changed\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08299 with standard deviation 0.00309.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08735777872565975, 0.08085547373765822, 0.08077092634112482]}}
{"id": "efa3681b-5940-4d93-a866-f4ea9149b21c", "fitness": 0.07455669349534381, "name": "HybridPSODE", "description": "Enhanced PSO velocity update by introducing a dynamic factor for improved exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop) +\n                          0.1 * np.random.randn(self.pop_size, self.dim))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07456 with standard deviation 0.00771.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07544275630138653, 0.06470081234562586, 0.08352651183901905]}}
{"id": "7fdbc724-426a-413d-aed2-f640e6a89b71", "fitness": 0.07579700612462992, "name": "HybridPSODE", "description": "Refined adaptive DE step with dimension-wise crossover rates and improved exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.6 + 0.4 * (eval_count / self.budget)  # Line changed\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * np.random.rand())  # Line changed\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07580 with standard deviation 0.00182.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07671238042129191, 0.07325931480264436, 0.07741932314995348]}}
{"id": "7f9fbcf6-ecab-4be4-8542-60d0e8ff675c", "fitness": 0.06527742207241916, "name": "HybridPSODE", "description": "Introduced dynamic adjustment of crossover probability and inertia weight for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.initial_w = 0.9  # Initial inertia weight\n        self.final_w = 0.4  # Final inertia weight\n        self.initial_cr = 0.9  # Initial crossover probability\n        self.final_cr = 0.2  # Final crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Dynamic inertia weight and crossover probability\n            w_dynamic = self.final_w + (self.initial_w - self.final_w) * (self.budget - eval_count) / self.budget\n            cr_dynamic = self.final_cr + (self.initial_cr - self.final_cr) * (self.budget - eval_count) / self.budget\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06528 with standard deviation 0.00699.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.0648533014320658, 0.07404587096084836, 0.056933093824343306]}}
{"id": "d68a1f08-6b94-4e01-ac43-109743594373", "fitness": 0.08190444511284985, "name": "ImprovedHybridPSODE", "description": "Introduced adaptive population size and enhanced dynamic crossover strategy to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Initial population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Dynamic population size adjustment\n            pop_size_adjusted = max(5, int(self.pop_size * (1 - eval_count / self.budget)))\n            pop = pop[:pop_size_adjusted]\n            velocities = velocities[:pop_size_adjusted]\n            personal_best_positions = personal_best_positions[:pop_size_adjusted]\n            personal_best_scores = personal_best_scores[:pop_size_adjusted]\n\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size_adjusted\n\n            # Update personal bests and global best\n            for i in range(pop_size_adjusted):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size_adjusted, self.dim), np.random.rand(pop_size_adjusted, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with enhanced dynamic crossover strategy\n            for i in range(pop_size_adjusted):\n                idxs = np.random.choice(np.delete(np.arange(pop_size_adjusted), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                crossover_rate_dynamic = self.cr * (1 - eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < crossover_rate_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08190 with standard deviation 0.00479.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07976731188171482, 0.08853881651596962, 0.07740720694086511]}}
{"id": "e198c59c-a9ff-40d8-9ff3-c13e3a9e7b46", "fitness": 0.0679487735752073, "name": "EnhancedHybridPSODE", "description": "Enhanced diversity and convergence by incorporating adaptive inertia weights and neighborhood-based exploration in PSO and DE steps.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with adaptive inertia weight\n            w_dynamic = self.w_max - ((self.w_max - self.w_min) * eval_count / self.budget)\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with neighborhood-based exploration\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06795 with standard deviation 0.00227.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.06575190877524184, 0.07107880219993634, 0.06701560975044374]}}
{"id": "ae45abcc-66dc-4751-af90-1555ca609c60", "fitness": 0.08322472844556221, "name": "HybridPSODE", "description": "Enhanced exploitation using adaptive cognitive and social coefficients in the PSO component.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            c1_dynamic = 1.0 + (self.c1 - 1.0) * (eval_count / self.budget)  # Line changed\n            c2_dynamic = 1.0 + (self.c2 - 1.0) * ((self.budget - eval_count) / self.budget)  # Line changed\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +  # Line changed\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08322 with standard deviation 0.00313.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08559862280669917, 0.07880057064368895, 0.0852749918862985]}}
{"id": "f6bf07b4-1448-408d-b896-d664a6bde413", "fitness": 0.038709244495640095, "name": "EnhancedHybridPSODE", "description": "Enhanced balancing of exploration and exploitation by dynamically adjusting inertia and differential weights based on convergence rate.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n        previous_best_score = np.inf\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Dynamic adjustment based on convergence rate\n            improvement_rate = (previous_best_score - global_best_score) / max(1.0, previous_best_score)\n            previous_best_score = global_best_score\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (1 - improvement_rate)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * improvement_rate  # Adjust based on improvement rate\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * improvement_rate)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03871 with standard deviation 0.00241.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.039199907911499854, 0.0355481084667606, 0.04137971710865984]}}
{"id": "f42be6b9-dc09-4379-bd7a-d7c93f31dfc7", "fitness": 0.08034095261812886, "name": "HybridPSODE", "description": "Improved the dynamic adjustment of crossover probability to enhance exploration capabilities in DE step.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Line changed: Improved the dynamic crossover probability adjustment\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08034 with standard deviation 0.00300.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07610285705428332, 0.08224096262891689, 0.08267903817118638]}}
{"id": "db93b9b5-58e0-433e-a9b3-64733bb3127d", "fitness": 0.05881153267210545, "name": "HybridPSODE", "description": "Enhanced convergence by introducing velocity clamping and adaptive crossover probability in DE step.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            velocities = np.clip(velocities, -0.1, 0.1)  # Line changed\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget) + 0.1  # Line changed\n                cross_points = np.random.rand(self.dim) < cr_dynamic  # Line changed\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05881 with standard deviation 0.00317.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.05859145436480451, 0.06280185493887336, 0.05504128871263847]}}
{"id": "4f480adf-f251-4367-b5ae-59a93c0cf0da", "fitness": 0.07248262918899051, "name": "EnhancedHybridPSODE", "description": "Enhanced exploration with adaptive inertia and crossover rates to balance diversity and exploitation in PSO and DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with adaptive inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + 0.3 * np.tanh(2.0 * (self.budget - eval_count) / self.budget)  # Adaptive inertia\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with adaptive crossover rate\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * np.sin(eval_count * np.pi / self.budget)  # Periodic differential weight\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = 0.9 - 0.5 * (eval_count / self.budget)  # Decreasing crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07248 with standard deviation 0.00629.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.06444174314714934, 0.07979793247997724, 0.07320821193984495]}}
{"id": "34e0fdef-d693-487a-ae42-9ca0e45a2c25", "fitness": 0.08034095261812886, "name": "HybridPSODE", "description": "Adjusted crossover probability dynamically to improve exploration and exploitation balance in DE step.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)  # Line changed\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08034 with standard deviation 0.00300.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07610285705428332, 0.08224096262891689, 0.08267903817118638]}}
{"id": "2e153c67-a6f6-4503-b52a-904845a00c8d", "fitness": 0.07565045765969285, "name": "HybridPSO_DE_LocalSearch", "description": "Introduced adaptive local search step combined with a velocity update strategy for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE_LocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Local search step when a new global best is found\n            if eval_count < self.budget:\n                for i in range(self.pop_size):\n                    local_trial = pop[i] + np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n\n                    if local_score < scores[i]:\n                        pop[i] = local_trial\n                        scores[i] = local_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSO_DE_LocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07565 with standard deviation 0.00712.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08156428287368844, 0.06562911409883665, 0.07975797600655343]}}
{"id": "b557002b-0b8d-4604-91f1-e675473d6f4a", "fitness": 0.06998099805749199, "name": "EnhancedHybridPSODE", "description": "Enhanced exploration-exploitation balance by introducing adaptive inertia and crossover rates, and incorporating local search for fine-tuning solutions.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Initial Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with adaptive inertia weight\n            w_dynamic = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive crossover rate\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr * (1 - (eval_count / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Local search enhancement\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.1:  # Apply local search with a certain probability\n                    step_size = 0.01 * (ub - lb) * np.random.randn(self.dim)\n                    local_candidate = np.clip(pop[i] + step_size, lb, ub)\n                    local_candidate_score = func(local_candidate)\n                    eval_count += 1\n\n                    if local_candidate_score < scores[i]:\n                        pop[i] = local_candidate\n                        scores[i] = local_candidate_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06998 with standard deviation 0.00960.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07988724477842257, 0.07307341025513703, 0.05698233913891637]}}
{"id": "07e725ef-6fc3-48d0-a649-b8606aba5745", "fitness": 0.08034095261812886, "name": "HybridPSODE", "description": "Enhanced dynamic crossover probability in DE step to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)  # Line changed\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))  # Line changed\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08034 with standard deviation 0.00300.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.07610285705428332, 0.08224096262891689, 0.08267903817118638]}}
{"id": "4cb5bcec-a321-4a66-bd06-17d3b4176f1e", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Enhance diversity and convergence by integrating dynamic population size and adaptive mutation in DE step.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Update population size dynamically\n            new_pop_size = self.initial_pop_size + int((self.budget - eval_count) / self.budget * 10)\n            if new_pop_size != pop_size:\n                additional_pop = np.random.uniform(lb, ub, (new_pop_size - pop_size, self.dim))\n                pop = np.vstack((pop, additional_pop))\n                velocities = np.vstack((velocities, np.random.uniform(-1, 1, (new_pop_size - pop_size, self.dim))))\n                personal_best_positions = np.vstack((personal_best_positions, additional_pop))\n                personal_best_scores = np.append(personal_best_scores, np.full(new_pop_size - pop_size, np.inf))\n                pop_size = new_pop_size\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (self.budget - eval_count) / self.budget\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget) * (1 if np.random.rand() > 0.5 else -1)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {}}
{"id": "61cef578-8c02-4a3e-8d5d-cb296861c01f", "fitness": 0.08563497247283829, "name": "HybridPSODE", "description": "Introduced exponential decay for inertia weight to enhance exploration in early stages.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)  # Line changed\n            velocities = (w_dynamic * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08563 with standard deviation 0.00228.", "error": "", "parent_ids": ["1e927da9-a01a-4570-a5c0-ea21dddada90"], "operator": null, "metadata": {"aucs": [0.08884623883736864, 0.08382080895788435, 0.08423786962326185]}}
{"id": "359600b8-6be0-4445-b98c-35862010c9ef", "fitness": 0.08657987989168307, "name": "HybridPSODE", "description": "Introduce adaptive learning rates for cognitive and social components to balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08658 with standard deviation 0.00194.", "error": "", "parent_ids": ["61cef578-8c02-4a3e-8d5d-cb296861c01f"], "operator": null, "metadata": {"aucs": [0.08416482285126214, 0.08892023962582629, 0.08665457719796077]}}
{"id": "99a3c563-7dba-408e-9fc5-643ca23715ae", "fitness": 0.08657741639414378, "name": "HybridPSODE", "description": "Enhance the dynamic adjustment of inertia weight to further refine the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-6 * eval_count / self.budget)  # Adjusted from -5 to -6\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08658 with standard deviation 0.00142.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.0847174365089799, 0.08816147452290979, 0.08685333815054164]}}
{"id": "74e8ac79-f3c7-48d7-8d5e-1803015ec500", "fitness": 0.08609509216836653, "name": "HybridPSODE", "description": "Introduce a dynamic strategy for crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr_init = 0.9  # Initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr_init * (1 - eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08610 with standard deviation 0.00322.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08906175248310577, 0.08760419538497743, 0.08161932863701638]}}
{"id": "c33d6754-644b-42e6-b827-b251650413b9", "fitness": 0.08609509216836653, "name": "HybridPSODE", "description": "Enhanced PSODE with dynamic crossover probability for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08610 with standard deviation 0.00322.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08906175248310577, 0.08760419538497743, 0.08161932863701638]}}
{"id": "0569a2d6-13e7-4e57-b8e4-6ef145eb8121", "fitness": -Infinity, "name": "ImprovedHybridPSODE", "description": "Implement dynamic adjustments to the population size and employ an adaptive inertia weight and learning rates to improve convergence speed and diversity.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # Dynamic inertia weight\n            w_dynamic = self.w_final + (self.w_init - self.w_final) * (1 - eval_count / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Dynamic population size adjustment\n            remaining_budget = self.budget - eval_count\n            max_new_pop_size = min(pop_size * 2, remaining_budget // self.dim)\n            pop_size = max(pop_size, max_new_pop_size)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {}}
{"id": "8b3a68e5-c265-4b3c-b3e6-59dabfd2b738", "fitness": 0.06954481669019859, "name": "EnhancedHybridPSODE", "description": "Enhance exploration-exploitation balance by introducing dynamic scaling for inertia weight, cognitive, and social components, incorporating a mutation-based local search mechanism.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.f = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            w_dynamic = self.w_max - ((self.w_max - self.w_min) * (eval_count / self.budget))\n            c1_dynamic = self.c1_init * (1 - eval_count / self.budget)\n            c2_dynamic = self.c2_init + (2.5 - self.c2_init) * (eval_count / self.budget)\n\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n                # Local search with mutation\n                if np.random.rand() < 0.1:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    mutated_individual = np.clip(pop[i] + mutation, lb, ub)\n                    mutated_score = func(mutated_individual)\n                    eval_count += 1\n\n                    if mutated_score < scores[i]:\n                        pop[i] = mutated_individual\n                        scores[i] = mutated_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06954 with standard deviation 0.00158.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.0687598053288625, 0.07174682284232659, 0.0681278218994067]}}
{"id": "13f9c559-312f-4518-87f7-2a41c85be70f", "fitness": 0.08657741639414378, "name": "HybridPSODE", "description": "Optimize the balance between exploration and exploitation by adjusting the inertia weight dynamically with a more aggressive decay factor.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-6 * eval_count / self.budget)  # Changed decay factor from -5 to -6\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08658 with standard deviation 0.00142.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.0847174365089799, 0.08816147452290979, 0.08685333815054164]}}
{"id": "505cf12e-176f-404f-9e74-a8f19f13e530", "fitness": 0.0860668410544504, "name": "HybridPSODE", "description": "Introduce adaptive mutation scaling factor in DE update to enhance exploration at different stages.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                # Changed line: Added adaptive mutation scaling for DE update\n                f_dynamic = 0.5 + 0.3 * np.sin(eval_count / self.budget * np.pi) \n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08607 with standard deviation 0.00146.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08454756107341921, 0.08804095963830516, 0.08561200245162681]}}
{"id": "0af76279-26ba-4f60-a438-323805db49a8", "fitness": 0.08653557451877603, "name": "HybridPSODE", "description": "Incorporate dynamic scaling of the differential weight to better adapt exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget)  # Modified line\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08654 with standard deviation 0.00131.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08482967001024433, 0.08801788839879243, 0.08675916514729132]}}
{"id": "21968bda-d26a-484f-80ec-b2408e31b547", "fitness": 0.08617306110390344, "name": "HybridPSODE", "description": "Adjust inertia weight dynamics for more effective balancing of exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.5 + (0.3 - 0.5) * (eval_count / self.budget)  # Change\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08617 with standard deviation 0.00122.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08449239166698785, 0.086654175494279, 0.08737261615044345]}}
{"id": "fc717c4f-d015-4ab7-9d9c-cb2825ffafb1", "fitness": 0.08633800478016607, "name": "HybridPSODE", "description": "Utilize a nonlinear dynamic adjustment for the inertia weight to enhance exploration early and exploitation later.  ", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with nonlinear dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * (1 - np.cos(np.pi * eval_count / (2 * self.budget)))\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08634 with standard deviation 0.00179.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.08381274914417547, 0.08764234821538652, 0.08755891698093621]}}
{"id": "962cf575-1f88-43be-a4d3-752e5030bcec", "fitness": 0.07386482828371828, "name": "EnhancedHybridPSODE", "description": "Enhance HybridPSODE by introducing adaptive differential weight and inertia damping for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_end = 0.4  # Final inertia weight\n        self.f_init = 0.5  # Initial differential weight\n        self.f_end = 0.9  # Final differential weight\n        self.cr_init = 0.9  # Initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # Dynamic inertia weight\n            w_dynamic = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Adaptive differential weight\n            f_dynamic = self.f_init + (self.f_end - self.f_init) * (eval_count / self.budget)\n\n            # DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr_init * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07386 with standard deviation 0.00128.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.07260721365954859, 0.0733579835007393, 0.07562928769086696]}}
{"id": "1c709c6d-37d1-4d44-b369-7a7df2cd9bc2", "fitness": 0.08825369268412286, "name": "HybridPSODE", "description": "Introduce a mutation operation in DE update to improve diversity and exploration capability.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Mutation: add random noise to mutant vector\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08825 with standard deviation 0.00049.", "error": "", "parent_ids": ["359600b8-6be0-4445-b98c-35862010c9ef"], "operator": null, "metadata": {"aucs": [0.0882359377422669, 0.08886212180591757, 0.08766301850418412]}}
{"id": "a173a158-fd1a-4e4a-a375-9132db1bb123", "fitness": 0.05421283391522765, "name": "EnhancedHybridPSODE", "description": "Enhance exploration via adaptive velocity clamping in PSO and incorporate adaptive mutation strength in DE to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.velocity_clamp = 0.1  # Initial velocity clamp factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight and velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n            pop = pop + velocities\n\n            # DE update with adaptive mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = self.f * (1 - eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Mutation: add random noise to mutant vector\n                adaptive_noise = 0.1 * (1 - eval_count / self.budget)\n                mutant = mutant + np.random.normal(0, adaptive_noise, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05421 with standard deviation 0.00601.", "error": "", "parent_ids": ["1c709c6d-37d1-4d44-b369-7a7df2cd9bc2"], "operator": null, "metadata": {"aucs": [0.05054633036796785, 0.04940084538522693, 0.06269132599248817]}}
{"id": "52838cec-4ddd-44fb-9d47-260f406b6e07", "fitness": 0.08802063797412334, "name": "HybridPSODE", "description": "Refine velocity update and enhance exploration by introducing a non-linear dynamic component based on cosine similarity in velocity calculations.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            # Introduce cosine similarity based non-linear component\n            cos_factor = np.cos(np.pi * eval_count / (2 * self.budget))\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop) * cos_factor)\n            pop = pop + velocities\n\n            # DE update with mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Mutation: add random noise to mutant vector\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08802 with standard deviation 0.00078.", "error": "", "parent_ids": ["1c709c6d-37d1-4d44-b369-7a7df2cd9bc2"], "operator": null, "metadata": {"aucs": [0.08811349240144217, 0.08892623002202049, 0.08702219149890733]}}
{"id": "7b104fc2-8118-48d0-b783-d5313e29d44d", "fitness": 0.08176959426265602, "name": "HybridPSO_DE_SA", "description": "Integrate a temperature-based simulated annealing mechanism to balance exploration and exploitation dynamically in PSO-DE hybrid.", "code": "import numpy as np\n\nclass HybridPSO_DE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.initial_temp = 1.0  # Initial temperature for simulated annealing\n        self.final_temp = 0.01  # Final temperature for simulated annealing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Mutation: add random noise to mutant vector\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                # Simulated annealing acceptance criterion\n                temperature = self.initial_temp * (self.final_temp / self.initial_temp) ** (eval_count / self.budget)\n                if trial_score < scores[i] or np.random.rand() < np.exp((scores[i] - trial_score) / temperature):\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSO_DE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08177 with standard deviation 0.00429.", "error": "", "parent_ids": ["1c709c6d-37d1-4d44-b369-7a7df2cd9bc2"], "operator": null, "metadata": {"aucs": [0.08144300663562398, 0.08717505254544922, 0.07669072360689488]}}
{"id": "04086fea-07a5-411d-8c29-abdb649ad096", "fitness": 0.0801495692501442, "name": "EnhancedHybridPSODE", "description": "Enhance exploration through adaptive mutation scaling and crossover probability, improving search space coverage and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f_base = 0.8  # Base differential weight\n        self.cr_base = 0.9  # Base crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation and crossover\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = self.f_base + 0.2 * np.sin(np.pi * eval_count / self.budget)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                # Mutation: add adaptive noise to mutant vector\n                mutant = mutant + np.random.normal(0, 0.1 * (1 - eval_count / self.budget), self.dim)\n                cr_dynamic = self.cr_base - 0.1 * np.cos(np.pi * eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08015 with standard deviation 0.00753.", "error": "", "parent_ids": ["1c709c6d-37d1-4d44-b369-7a7df2cd9bc2"], "operator": null, "metadata": {"aucs": [0.08740421711322155, 0.08326592600501659, 0.06977856463219445]}}
{"id": "612a01e4-3e24-4e1e-ae9d-b2ebf27cc213", "fitness": 0.08833257992660233, "name": "HybridPSODE", "description": "Refine the hybrid PSO-DE algorithm by introducing adaptive mutation scaling and tournament selection to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08833 with standard deviation 0.00182.", "error": "", "parent_ids": ["1c709c6d-37d1-4d44-b369-7a7df2cd9bc2"], "operator": null, "metadata": {"aucs": [0.09071288568106495, 0.08627995423076484, 0.08800489986797722]}}
{"id": "889ba17b-3353-4460-ad5f-ffd9fe319f4e", "fitness": 0.07785533434186583, "name": "EnhancedHybridPSODE", "description": "Enhance the Hybrid PSO-DE algorithm by integrating an adaptive learning rate for the inertia weight and introducing dynamic population size reduction to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # Adaptive inertia weight\n            w_dynamic = self.w_init - (self.w_init - self.w_final) * (eval_count / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Dynamic population size reduction\n            if eval_count / self.budget > 0.5 and pop_size > 5:\n                pop_size = int(pop_size * 0.9)\n                pop = pop[:pop_size]\n                velocities = velocities[:pop_size]\n                personal_best_positions = personal_best_positions[:pop_size]\n                personal_best_scores = personal_best_scores[:pop_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07786 with standard deviation 0.00479.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08288477686347673, 0.07141659584770232, 0.07926463031441844]}}
{"id": "17bb27d7-f3cc-4493-abeb-4de2cbf9bc2d", "fitness": 0.08822155107933312, "name": "HybridPSODE", "description": "Enhance exploration by introducing stochastic gradient perturbation in the DE mutation phase.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                grad_perturbation = np.random.normal(0, 0.01, self.dim)  # Gradient perturbation\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3) + grad_perturbation, lb, ub)  # Apply perturbation\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08822 with standard deviation 0.00195.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09069219846145848, 0.08591740357234812, 0.08805505120419277]}}
{"id": "fd7cbd31-46b6-427c-b7c3-55af51cf46dc", "fitness": 0.0809045034292446, "name": "HybridPSODE", "description": "Introduce oscillatory inertia weights and elite preservation to enhance convergence speed and diversity in the Hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_min = 0.4  # Minimum inertia weight\n        self.w_max = 0.9  # Maximum inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        elite = None\n        elite_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n                # Update elite solution\n                if scores[i] < elite_score:\n                    elite_score = scores[i]\n                    elite = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # Oscillatory inertia weight\n            w_dynamic = self.w_min + (self.w_max - self.w_min) * (0.5 + 0.5 * np.cos(2 * np.pi * eval_count / self.budget))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling and elite preservation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.7 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial with elite consideration\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n                # Preserve elite solution\n                if elite is not None and np.random.rand() < 0.1:\n                    pop[i] = elite\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08090 with standard deviation 0.00605.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.0847880251524995, 0.0723620788996232, 0.0855634062356111]}}
{"id": "548b11c9-f552-4286-8b6a-070465c44d1f", "fitness": 0.08650852159856692, "name": "HybridPSODE", "description": "Enhance the hybrid PSO-DE algorithm by updating the mutation strategy with adaptive differential evolution and refined velocity calculation to boost convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.05, self.dim)  # Changed mutation noise std from 0.1 to 0.05\n                cross_points = np.random.rand(self.dim) < self.cr  # Removed adaptive crossover probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08651 with standard deviation 0.00416.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09039937946377152, 0.08839153633403563, 0.08073464899789362]}}
{"id": "5971ee9d-f9dd-4ff9-8971-ded76d5fc159", "fitness": -Infinity, "name": "HybridPSODE", "description": "Introduce dynamic crossover probability and replace mutation noise with adaptive Gaussian noise to enhance exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr_init = 0.9  # Initial Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            cr_dynamic = self.cr_init * (1 - eval_count / self.budget)  # New dynamic crossover probability\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                adaptive_noise = np.random.normal(0, 0.1 * (1 - scores[i] / global_best_score), self.dim)  # New adaptive noise\n                mutant = mutant + adaptive_noise\n                cross_points = np.random.rand(self.dim) < cr_dynamic  # Use dynamic crossover probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {}}
{"id": "c943061d-528c-4af4-9fb2-a6b7f9d4b7ba", "fitness": 0.08749490487405269, "name": "HybridPSODE", "description": "Enhance the adaptive mutation scaling by refining the scaling factor to further improve exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.5 * (1 - scores[i] / global_best_score)  # Updated scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08749 with standard deviation 0.00088.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08861264139548997, 0.08742218463030338, 0.08644988859636471]}}
{"id": "16f018c4-1d7c-499b-ac0e-c90d2624d6cc", "fitness": 0.08526911567226059, "name": "EnhancedHybridPSODE", "description": "Enhance diversity and convergence by integrating adaptive diversity control and a Lvy flight mechanism into the PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.levy_factor = 0.01  # Lvy flight factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n\n                # Apply Lvy flight for enhanced exploration\n                levy_step = self.levy_factor * np.random.standard_cauchy(self.dim)\n                mutant = np.clip(mutant + levy_step, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08527 with standard deviation 0.00316.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08970891313149254, 0.08347894161899372, 0.0826194922662955]}}
{"id": "da88425f-2890-4b51-9df4-ff2dba2fe2ac", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Enhance the PSO-DE algorithm by dynamically adjusting the crossover probability to adaptively balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))  # Dynamically adjust crossover probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "1f8f4516-71ec-4480-b472-d04e0a1b06d4", "fitness": 0.08821656329633383, "name": "EnhancedHybridPSODE", "description": "Enhance the HybridPSODE algorithm by integrating a self-adaptive parameter tuning mechanism and diversity preservation techniques for robust convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Ensure diversity in the population\n            if eval_count > self.budget / 2:\n                diversity = np.std(pop, axis=0)\n                diversity_threshold = (ub - lb) * 0.1\n                if np.any(diversity < diversity_threshold):\n                    pop += np.random.normal(0, 0.1, pop.shape)\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / max(global_best_score, 1e-8))  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08822 with standard deviation 0.00192.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09071784148787376, 0.08606264153135779, 0.08786920686976996]}}
{"id": "7646e32c-9962-487c-a030-a93924940984", "fitness": 0.08833257992660233, "name": "HybridPSODE", "description": "By introducing learning factor decay, the algorithm balances exploration and exploitation dynamically over iterations.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08833 with standard deviation 0.00182.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09071288568106495, 0.08627995423076484, 0.08800489986797722]}}
{"id": "2b1529df-4010-4895-822f-180e51e4a1bd", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Enhance the HybridPSODE algorithm by introducing a diversity mechanism and adaptive crossover probability to improve exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Introduce diversity mechanism\n            diversity = np.std(pop, axis=0)\n            if np.max(diversity) < 1e-5:\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "0c1fbcdc-f0e6-4ec8-abaa-8a8b81df2a21", "fitness": 0.08228435508685183, "name": "EnhancedHybridPSODE", "description": "Enhance the Hybrid PSO-DE by incorporating a dynamic convergence-based population resizing mechanism and chaos-based mutation for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20\n        self.min_pop_size = 5\n        self.pop_size = self.initial_pop_size\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w = 0.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.resizing_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n        prev_global_best_score = np.inf\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Dynamic convergence-based population resizing\n            if prev_global_best_score - global_best_score < self.resizing_threshold:\n                self.pop_size = max(self.min_pop_size, self.pop_size - 1)\n                pop = pop[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best_positions = personal_best_positions[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n            prev_global_best_score = global_best_score\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with chaos-based mutation\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                \n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                chaos_factor = 0.9 * np.random.rand() + 0.1  # Chaos-based mutation factor\n                mutant = np.clip(x1 + f_dynamic * chaos_factor * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                \n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08228 with standard deviation 0.00147.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08428991998269009, 0.08081123415151448, 0.08175191112635094]}}
{"id": "f0ab2299-98ce-4a24-8d88-b838fbc1470b", "fitness": 0.0792939754955559, "name": "EnhancedHybridPSODE", "description": "Enhance Hybrid PSO-DE by implementing a diversity-preserving mechanism and adjusting inertia weight based on population diversity to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.f = 0.8        # Differential weight\n        self.cr = 0.9       # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Calculate population diversity\n            mean_position = np.mean(pop, axis=0)\n            diversity = np.mean(np.linalg.norm(pop - mean_position, axis=1))\n            \n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight based on diversity\n            w_dynamic = self.w_max - ((self.w_max - self.w_min) * (diversity / (ub - lb).sum()))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07929 with standard deviation 0.00217.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08191514411833833, 0.07659960096427787, 0.07936718140405152]}}
{"id": "ade8a7e3-9151-461a-bb95-d98bbd7518b9", "fitness": 0.07739205380749299, "name": "EnhancedHybridPSODE", "description": "Enhance the Hybrid PSO-DE algorithm by integrating per-iteration adaptive crossover probability and stochastic ranking to optimize exploration-exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w = 0.5\n        self.f = 0.8\n        self.cr_init = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cr_dynamic = self.cr_init * (1 - eval_count / self.budget) + 0.1\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Stochastic ranking for trial\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < scores[i] or np.random.rand() < 0.1:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07739 with standard deviation 0.00772.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08539349018016062, 0.07981710591056068, 0.06696556533175768]}}
{"id": "c42caf26-5e02-46f7-b962-766e5491e037", "fitness": 0.08608746237982763, "name": "DynamicHybridPSODE", "description": "Enhance exploration and exploitation by introducing a dynamic population resizing strategy and competition-based differential evolution.", "code": "import numpy as np\n\nclass DynamicHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 20  # Initial population size\n        self.min_pop_size = 5  # Minimum population size\n        self.max_pop_size = 40  # Maximum population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        shrink_step = (self.initial_pop_size - self.min_pop_size) / (self.budget // 2)\n        \n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with competition-based strategy\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.5 + 0.3 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n            \n            # Dynamic population resizing\n            if eval_count > self.budget // 2 and pop_size > self.min_pop_size:\n                pop_size = max(self.min_pop_size, int(self.initial_pop_size - (eval_count - self.budget // 2) * shrink_step))\n                pop = pop[:pop_size]\n                velocities = velocities[:pop_size]\n                personal_best_positions = personal_best_positions[:pop_size]\n                personal_best_scores = personal_best_scores[:pop_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm DynamicHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08609 with standard deviation 0.00081.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08682824456897731, 0.0864812142487037, 0.0849529283218019]}}
{"id": "d9821892-6a4a-4ad6-8171-d144340bda08", "fitness": 0.08583385126185743, "name": "HybridPSODE", "description": "Introduce adaptive population size and chaos-based mutation to improve exploration efficiency and convergence speed.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w = 0.5\n        self.f = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Chaotic DE update\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mu = 0.8 * np.cos(eval_count)  # Chaos-based mutation scaling\n                mutant = np.clip(x1 + mu * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08583 with standard deviation 0.00163.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08780153545416935, 0.085883162174748, 0.0838168561566549]}}
{"id": "97baddd1-3d9a-4c64-a5d0-520a81cc314b", "fitness": 0.07430697852029389, "name": "EnhancedHybridPSODE", "description": "Enhance the HybridPSODE algorithm by integrating a chaotic local search phase and adaptive inertia weight to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_min = 0.4  # Minimum inertia weight\n        self.w_max = 0.9  # Maximum inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with adaptive inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Chaotic local search phase\n            if np.random.rand() < 0.1:\n                chaotic_idx = np.random.choice(self.pop_size, 1)[0]\n                chaotic_candidate = pop[chaotic_idx] + 0.01 * (ub - lb) * np.random.randn(self.dim)\n                chaotic_candidate = np.clip(chaotic_candidate, lb, ub)\n                chaotic_score = func(chaotic_candidate)\n                eval_count += 1\n\n                if chaotic_score < scores[chaotic_idx]:\n                    pop[chaotic_idx] = chaotic_candidate\n                    scores[chaotic_idx] = chaotic_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07431 with standard deviation 0.00276.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.07143780747188533, 0.07345691079460792, 0.07802621729438841]}}
{"id": "7ea5be48-ff9b-48ee-bbc5-d25ce1ca299f", "fitness": 0.08697484210089294, "name": "HybridPSODE", "description": "Incorporate adaptive inertia weight adjustment and fine-tune mutation scaling to enhance convergence speed and solution quality in HybridPSODE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.6 - 0.4) * np.exp(-5 * eval_count / self.budget)  # Adjusted upper bound\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.35 + 0.45 * (1 - scores[i] / global_best_score)  # Fine-tuned scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08697 with standard deviation 0.00146.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08788507320449601, 0.08492115327411787, 0.08811829982406494]}}
{"id": "b5052ce1-22f8-452a-8342-171124d62eb3", "fitness": 0.08312290830606468, "name": "HybridPSODE", "description": "Introduce nonlinear inertia weight decay and adaptive crossover probability to HybridPSODE for improved convergence behavior.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with nonlinear inertia weight decay\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-10 * (eval_count / self.budget)**2)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling and crossover\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                \n                # Adaptive crossover probability\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08312 with standard deviation 0.00818.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08849301416603184, 0.08931129862200793, 0.0715644121301543]}}
{"id": "a624a585-62ab-4f58-bf87-c366ef7b780d", "fitness": 0.08675799343056316, "name": "HybridPSODE", "description": "Enhance the adaptive mutation scaling of HybridPSODE by incorporating feedback from the personal best positions to improve convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score) + 0.1 * np.mean(personal_best_scores)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08676 with standard deviation 0.00070.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08622344370094681, 0.0863087502464428, 0.08774178634429985]}}
{"id": "4ff60845-686a-4d72-a071-123466e808aa", "fitness": 0.08443278545840967, "name": "ChaoticHybridPSODE", "description": "Enhance HybridPSODE by integrating chaotic maps for parameter tuning and introducing a dynamic population size to improve convergence.", "code": "import numpy as np\n\nclass ChaoticHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Initial population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.chaos_map = self.logistic_map  # Chaotic map function\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n        chaos_param = 0.7  # Initial value for chaos\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components using chaotic map\n            c1_dynamic = self.c1_init * chaos_param\n            c2_dynamic = self.c2_init * (1 - chaos_param)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Dynamically adjust the population size\n            pop_size_dynamic = max(10, int(self.pop_size * (1 - eval_count / self.budget)))\n\n            # DE update with adaptive mutation scaling\n            for i in range(pop_size_dynamic):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Update chaos parameter\n            chaos_param = self.chaos_map(chaos_param)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm ChaoticHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08443 with standard deviation 0.00013.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08425050315041793, 0.0844908471583824, 0.08455700606642869]}}
{"id": "a79a3e45-9aab-4783-a00d-9e9b682d8dbb", "fitness": 0.07870077864916225, "name": "HybridPSODENovel", "description": "Enhance the hybrid PSO-DE algorithm by incorporating Lvy flights for improved exploration and chaos-based dynamic parameter adjustment for better convergence.", "code": "import numpy as np\n\nclass HybridPSODENovel:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        # Chaos-based parameter initialization\n        chaos_sequence = np.random.rand(self.budget // self.pop_size)\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init * chaos_sequence[eval_count // self.pop_size % len(chaos_sequence)]\n            c2_dynamic = self.c2_init * (1 - chaos_sequence[eval_count // self.pop_size % len(chaos_sequence)])\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling and Lvy flights\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                \n                # Lvy flight component\n                step_size = np.random.standard_cauchy(self.dim)\n                mutant = mutant + step_size * (mutant - pop[i])\n                \n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm HybridPSODENovel got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07870 with standard deviation 0.00216.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.07781160934932241, 0.07661856547925705, 0.0816721611189073]}}
{"id": "ad1f4eab-0122-4b04-8c4d-d9a5e6ecb980", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Introduce dynamic crossover probability in the DE update to improve exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "2a05e264-c188-4169-8ba5-9f89aa3ba891", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Introduce a dynamic crossover probability to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))  # Dynamic crossover\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "736b043e-6c74-409b-9890-8f472be7106a", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Introduce dynamic crossover probability in DE update to enhance adaptation during optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cr_dynamic = self.cr * (1 - eval_count / self.budget)  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "8678a91c-aecb-4bc4-86c8-42c3c0d31f15", "fitness": 0.0872098057573351, "name": "HybridPSODE", "description": "Enhance the HybridPSODE algorithm by adjusting the crossover probability dynamically to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - scores[i] / global_best_score))  # Changed line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08721 with standard deviation 0.00095.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08678457590375821, 0.08852795048656859, 0.08631689088167849]}}
{"id": "f7997273-5390-4e44-ac68-4e60128e0af5", "fitness": 0.08709889373841344, "name": "HybridPSODE", "description": "Introduce a dynamic inertia weight range in HybridPSODE to balance exploration and exploitation based on iteration progress.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.3 + (0.7 - 0.3) * np.exp(-5 * eval_count / self.budget)  # Modified inertia weight range\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08710 with standard deviation 0.00264.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08984578803579879, 0.0835301401155859, 0.0879207530638556]}}
{"id": "0235b089-5519-44c3-863e-1318d081d259", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Enhance exploration-exploitation balance in Hybrid PSO-DE by employing dynamic population size reduction and diversity preservation through Gaussian mutation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Initial Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        reduction_factor = 0.9  # Factor to reduce population size over iterations\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with dynamic scaling and Gaussian mutation for diversity\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3) + np.random.normal(0, 0.1, self.dim), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Reduce population size over time to enhance exploitation\n            if eval_count < self.budget and self.pop_size > 2:\n                self.pop_size = int(self.pop_size * reduction_factor)\n                pop = pop[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best_positions = personal_best_positions[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {}}
{"id": "9493cc1b-ab45-4eb2-b7ee-b8b845d0f8e8", "fitness": 0.08172490333382387, "name": "HybridPSODE", "description": "Enhance HybridPSODE by introducing a dynamic crossover probability that adapts based on the evaluation count to improve exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))  # Dynamic crossover probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08172 with standard deviation 0.01078.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08920706709400683, 0.08949195442400826, 0.06647568848345653]}}
{"id": "899bfa11-69d0-41e9-a5a2-b4a7d899f86a", "fitness": 0.0848857218197161, "name": "EnhancedHybridPSODE", "description": "Enhance the hybrid PSO-DE algorithm by incorporating an adaptive elitism strategy and chaotic maps to fine-tune exploration and exploitation dynamics for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w = 0.5\n        self.f = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n        chaos_map = np.random.rand(self.pop_size)\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Introducing chaos map and elitism\n            chaos_map = 4 * chaos_map * (1 - chaos_map)  # Logistic map\n            elite_idx = np.argmin(scores)\n            pop[elite_idx] = global_best_position + chaos_map[elite_idx] * (ub - lb) / 10\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08489 with standard deviation 0.00266.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08248986339782682, 0.08859106948947293, 0.08357623257184854]}}
{"id": "df9ee6b3-0f4f-467e-a1b2-b5ae2f317678", "fitness": 0.07999167418317539, "name": "EnhancedHybridPSODE", "description": "Enhance HybridPSODE by introducing adaptive inertia weight and chaotic sequences to improve exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def chaotic_sequence(self, size):\n        # Generate chaotic sequence using logistic map\n        sequence = np.empty(size)\n        x = 0.7  # Initial condition\n        for i in range(size):\n            x = 4 * x * (1 - x)  # Logistic map\n            sequence[i] = x\n        return sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with adaptive inertia weight using chaotic sequences\n            chaotic_seq = self.chaotic_sequence(self.pop_size)\n            w_dynamic = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) * chaotic_seq\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic[:, None] * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07999 with standard deviation 0.00724.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08689046278970225, 0.06999701143765757, 0.08308754832216636]}}
{"id": "52545503-d4fa-4af0-9c6e-0b2776bb13e3", "fitness": 0.0826308175303994, "name": "HybridPSODE", "description": "Enhance the adaptive mutation scaling and introduce random dimension selection for diversity and improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.5 * (1 - scores[i] / (global_best_score + 1e-10))  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                random_dim = np.random.randint(0, self.dim)  # Random dimension selection\n                mutant[random_dim] += np.random.normal(0, 0.1)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08263 with standard deviation 0.00226.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08067060425235217, 0.08580390140301375, 0.08141794693583226]}}
{"id": "9e6cf852-b24f-468b-b3b9-1ff9dfa344a8", "fitness": 0.08424589169308332, "name": "HybridPSODE", "description": "Integrate a simple local search step in the PSO phase to potentially improve personal bests more frequently.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # Local search step integration\n            for i in range(self.pop_size):\n                local_trial = pop[i] + np.random.normal(0, 0.01, self.dim)\n                local_trial = np.clip(local_trial, lb, ub)\n                local_score = func(local_trial)\n                eval_count += 1\n                if local_score < personal_best_scores[i]:\n                    personal_best_scores[i] = local_score\n                    personal_best_positions[i] = local_trial\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08425 with standard deviation 0.00164.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.0829067676247719, 0.0832817527361609, 0.08654915471831715]}}
{"id": "24bc09fe-eede-48a2-a7e9-984a2e6f2a05", "fitness": 0.08605848649985055, "name": "HybridPSODE", "description": "Introduced self-adaptive crossover probability and normalized initialization of velocities to improve exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.normal(0, 0.5, (self.pop_size, self.dim))  # Normalized initialization of velocities\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (1 - eval_count / self.budget))  # Self-adaptive crossover probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08606 with standard deviation 0.00410.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09151062671453425, 0.08162566298850193, 0.08503916979651549]}}
{"id": "35d33f95-5243-41f9-8ac4-c7c6d97174f2", "fitness": 0.08833257992660233, "name": "HybridPSODE", "description": "Enhance HybridPSODE by incorporating synergy between PSO and DE through dynamic strategy adaptation based on diversity metrics.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.diversity_threshold = 0.1  # Threshold to switch strategies\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        def calculate_diversity(pop):\n            mean = np.mean(pop, axis=0)\n            diversity = np.mean(np.linalg.norm(pop - mean, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # Calculate diversity of the population\n            diversity = calculate_diversity(pop)\n            is_diverse = diversity > self.diversity_threshold\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                if is_diverse:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    x1, x2, x3 = pop[idxs]\n                    f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                    mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                else:\n                    mutant = np.random.uniform(lb, ub, self.dim)\n\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08833 with standard deviation 0.00182.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09071288568106495, 0.08627995423076484, 0.08800489986797722]}}
{"id": "72a84b0d-167b-4020-88e0-fa199e0eedf6", "fitness": 0.08771678208890325, "name": "HybridPSODE", "description": "Enhance the hybrid PSO-DE algorithm by introducing diversity preservation through mutation step size adaptation and dynamic population resizing.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                diversity_factor = np.std(pop, axis=0)  # Added line\n                mutant = mutant + np.random.normal(0, 0.1 * diversity_factor, self.dim)  # Changed line\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            if eval_count % (self.budget // 4) == 0:  # Added condition for dynamic resizing\n                self.pop_size = max(10, int(self.pop_size * 0.9))  # Resizing population\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08772 with standard deviation 0.00211.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09064681996527013, 0.08673083669815873, 0.08577268960328088]}}
{"id": "3e4b8e9f-b120-4c86-818c-69dd31640db5", "fitness": 0.06898692060869031, "name": "HybridPSODE", "description": "Enhance HybridPSODE by incorporating chaotic maps for initialization and mutation, and utilizing a diversity-based strategy for particle movement adaptation to improve convergence and exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w = 0.5\n        self.f = 0.8\n        self.cr = 0.9\n\n    def chaotic_init(self, lb, ub):\n        rand_vals = np.random.rand(self.pop_size, self.dim)\n        chaotic_vals = np.sin(np.pi * rand_vals)\n        return lb + (ub - lb) * chaotic_vals\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            diversity = np.var(pop, axis=0).mean()\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * diversity)\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)\n                chaotic_factor = 0.5 * np.sin(np.pi * np.random.rand(self.dim))\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3) * chaotic_factor, lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06899 with standard deviation 0.00711.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.06780772500031484, 0.07821901402734788, 0.060934022798408205]}}
{"id": "67f4a320-ca70-4192-9767-d968c4a6f8b5", "fitness": 0.08709889373841344, "name": "HybridPSODE", "description": "Utilize adaptive inertia weight scaling for enhanced convergence in HybridPSODE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.3 + (0.7 - 0.3) * np.exp(-5 * eval_count / self.budget)  # Modified inertia weight\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08710 with standard deviation 0.00264.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08984578803579879, 0.0835301401155859, 0.0879207530638556]}}
{"id": "b5dd20ce-3167-4118-93dd-763fcf35e825", "fitness": 0.08557888314081423, "name": "HybridPSODE", "description": "Improve the hybrid PSO-DE algorithm by introducing a time-varying population size and dynamic crossover probability to enhance adaptiveness.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        initial_pop_size = self.pop_size\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Dynamically adjust population size\n            pop_size_dynamic = initial_pop_size - int(10 * (eval_count / self.budget))\n            pop = pop[:pop_size_dynamic]\n            velocities = velocities[:pop_size_dynamic]\n            personal_best_positions = personal_best_positions[:pop_size_dynamic]\n            personal_best_scores = personal_best_scores[:pop_size_dynamic]\n\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size_dynamic\n\n            # Update personal bests and global best\n            for i in range(pop_size_dynamic):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size_dynamic, self.dim), np.random.rand(pop_size_dynamic, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(pop_size_dynamic):\n                idxs = np.random.choice(np.delete(np.arange(pop_size_dynamic), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_prob_dynamic = self.cr * (1 - eval_count / self.budget)  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cross_prob_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08558 with standard deviation 0.00504.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08957948582885789, 0.0886814809423554, 0.0784756826512294]}}
{"id": "5e6bd2f9-e8ef-46f0-8316-330bcb86dd77", "fitness": 0.08763576060140836, "name": "HybridPSODE", "description": "Enhance HybridPSODE by refining dynamic parameter updates and introducing stochastic ranking to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * np.sin(eval_count / self.budget * np.pi)  # Modified\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * np.sin(eval_count / self.budget * np.pi)  # Modified\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / (global_best_score + 1e-9))  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Stochastic ranking for trial\n                if eval_count < self.budget:  # Ensure budget is respected\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < scores[i]:\n                        pop[i] = trial\n                        scores[i] = trial_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08764 with standard deviation 0.00072.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08725487077557914, 0.08865033918655896, 0.08700207184208697]}}
{"id": "84b339ab-df7e-4390-8b87-7688541b8a01", "fitness": 0.08454181380301318, "name": "EnhancedHybridPSODE", "description": "Enhance the Hybrid PSO-DE algorithm by integrating self-adaptive learning rates and incorporating a dynamic neighborhood topology to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight and neighborhood topology\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, 3, replace=False)\n                local_best = min(neighbors, key=lambda x: personal_best_scores[x])\n                velocities[i] = (w_dynamic * velocities[i] +\n                                 c1_dynamic * r1[i] * (personal_best_positions[i] - pop[i]) +\n                                 c2_dynamic * r2[i] * (personal_best_positions[local_best] - pop[i]))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08454 with standard deviation 0.00062.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08419124582171467, 0.08401876319772306, 0.08541543238960181]}}
{"id": "138c626b-a176-470d-b25e-cbbd45498fd8", "fitness": 0.08611964560777192, "name": "HybridPSODE", "description": "Enhance the DE mutation mechanism by introducing self-adaptive scaling based on the best individual's influence on the population.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3 + (global_best_position - x1)), lb, ub)  # Modified line\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08612 with standard deviation 0.00249.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.0896382903217734, 0.08418706540283716, 0.08453358109870523]}}
{"id": "6c8d9471-3b21-475f-9158-8eb1f7adc99a", "fitness": 0.08370138371288134, "name": "EnhancedHybridPSODE", "description": "Enhance the adaptive strategy of HybridPSODE by incorporating a dynamic population size reduction and self-adaptive crossover probability to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30  # Increased initial population size for diversity\n        self.min_pop_size = 10      # Minimum population size\n        self.c1_init = 2.5          # Initial cognitive coefficient\n        self.c2_init = 0.5          # Initial social coefficient\n        self.w = 0.5                # Inertia weight\n        self.f = 0.8                # Differential weight\n        self.cr_init = 0.9          # Initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += pop_size\n\n            # Update personal bests and global best\n            for i in range(pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(pop_size, self.dim), np.random.rand(pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # DE update with adaptive mutation scaling and crossover probability\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cr_dynamic = self.cr_init * (1 - eval_count / self.budget)  # Self-adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Dynamic population size reduction\n            if eval_count % (self.budget // 5) == 0 and pop_size > self.min_pop_size:\n                pop_size = max(self.min_pop_size, int(pop_size * 0.9))\n                pop = pop[:pop_size]\n                velocities = velocities[:pop_size]\n                personal_best_positions = personal_best_positions[:pop_size]\n                personal_best_scores = personal_best_scores[:pop_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08370 with standard deviation 0.00338.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08663419935189809, 0.08550098041581522, 0.07896897137093073]}}
{"id": "a194b7d6-6fcd-4f95-b256-7d0879624add", "fitness": 0.08653164732576235, "name": "HybridPSODE", "description": "Enhance HybridPSODE by introducing a temperature-based mutation scheme for improved convergence speed and robustness.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with temperature-based mutation scaling\n            temp_factor = np.exp(-5 * eval_count / self.budget) \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + temp_factor * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08653 with standard deviation 0.00155.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.08730381507129759, 0.08792152049401658, 0.08436960641197289]}}
{"id": "44310d51-884a-4e8d-9c68-49ad385582a4", "fitness": 0.08546891750482373, "name": "HybridPSODE", "description": "Enhance exploration by introducing Levy flight-based perturbation and refine DE filtering with a self-adaptive control parameter.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / (global_best_score + 1e-10))  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                levy_flight = np.random.normal(0, 0.3 * (ub - lb), self.dim)  # Levy flight perturbation\n                mutant = np.clip(mutant + levy_flight, lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08547 with standard deviation 0.00314.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.0845380333764556, 0.08217895030379418, 0.08968976883422142]}}
{"id": "4e532a61-ff6a-489f-9766-e36afc5b25ca", "fitness": 0.08337163485434047, "name": "EnhancedHybridPSODE", "description": "Enhance the hybrid PSO-DE algorithm by integrating opposition-based learning and dynamic population resizing for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Initial population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * eval_count / self.budget)\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Opposition-based learning\n            opposition_pop = lb + ub - pop\n            opposition_scores = np.apply_along_axis(func, 1, opposition_pop)\n            eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if opposition_scores[i] < scores[i]:\n                    pop[i] = opposition_pop[i]\n                    scores[i] = opposition_scores[i]\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant += np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n            # Dynamic population resizing\n            if eval_count > self.budget / 2:\n                new_pop_size = max(5, int(self.pop_size * (1 - eval_count / self.budget)))\n                pop = pop[:new_pop_size]\n                velocities = velocities[:new_pop_size]\n                personal_best_positions = personal_best_positions[:new_pop_size]\n                personal_best_scores = personal_best_scores[:new_pop_size]\n                self.pop_size = new_pop_size\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08337 with standard deviation 0.00532.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.0881299751860628, 0.07594306272389384, 0.08604186665306479]}}
{"id": "45ccaf7d-5c8d-475b-a820-f24ce38833ed", "fitness": 0.08775036895671558, "name": "HybridPSODE", "description": "Enhance the Hybrid PSO-DE by incorporating an adaptive inertia weight based on convergence progress.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20  # Population size\n        self.c1_init = 2.5  # Initial cognitive coefficient\n        self.c2_init = 0.5  # Initial social coefficient\n        self.w = 0.5  # Inertia weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        eval_count = 0\n\n        while eval_count < self.budget:\n            scores = np.apply_along_axis(func, 1, pop)\n            eval_count += self.pop_size\n\n            # Update personal bests and global best\n            for i in range(self.pop_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = pop[i]\n\n                if scores[i] < global_best_score:\n                    global_best_score = scores[i]\n                    global_best_position = pop[i]\n\n            # Adaptive learning rates for cognitive and social components\n            c1_dynamic = self.c1_init - (self.c1_init - self.c2_init) * (eval_count / self.budget)\n            c2_dynamic = self.c2_init + (self.c1_init - self.c2_init) * (eval_count / self.budget)\n\n            # PSO update with dynamic inertia weight\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            w_dynamic = 0.4 + (0.5 - 0.4) * np.exp(-5 * (1 - global_best_score / np.max(personal_best_scores)))  # Modified inertia weight\n            velocities = (w_dynamic * velocities +\n                          c1_dynamic * r1 * (personal_best_positions - pop) +\n                          c2_dynamic * r2 * (global_best_position - pop))\n            pop = pop + velocities\n\n            # DE update with adaptive mutation scaling\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                f_dynamic = 0.3 + 0.4 * (1 - scores[i] / global_best_score)  # Modified scaling factor\n                mutant = np.clip(x1 + f_dynamic * (x2 - x3), lb, ub)\n                mutant = mutant + np.random.normal(0, 0.1, self.dim)\n                cross_points = np.random.rand(self.dim) < (self.cr * (eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Tournament selection for trial\n                tournament_score = func(trial)\n                eval_count += 1\n\n                if tournament_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = tournament_score\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08775 with standard deviation 0.00176.", "error": "", "parent_ids": ["612a01e4-3e24-4e1e-ae9d-b2ebf27cc213"], "operator": null, "metadata": {"aucs": [0.09018245283568127, 0.08607528578767831, 0.08699336824678716]}}
