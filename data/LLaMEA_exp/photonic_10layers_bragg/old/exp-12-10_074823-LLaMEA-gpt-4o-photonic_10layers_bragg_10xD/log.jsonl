{"id": "38d4e4bd-b0e2-49dd-b104-5b350c128c3e", "fitness": 0.05697366238292623, "name": "PSODE", "description": "A hybrid Particle Swarm Optimization (PSO) integrated with Differential Evolution (DE) for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 0, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05697 with standard deviation 0.00187.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05958459683663753, 0.056041927351448195]}}
{"id": "42532eb0-5e96-492b-b72f-4b773c5749aa", "fitness": 0.05604085218602506, "name": "AdaptivePSODE", "description": "Enhanced PSODE with Adaptive Velocity and Differential Weight Scaling for Improved Convergence Stability and Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F_max = 0.9  # maximum differential weight\n        self.F_min = 0.3  # minimum differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            adaptive_F = self.adaptive_differential_weight()\n            self.de(mut_func=func, lb=lb, ub=ub, F=adaptive_F)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            inertia_weight = np.random.uniform(0.5, 0.9) # Adaptive inertia weight to balance exploration and exploitation\n            self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub, F):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n    \n    def adaptive_differential_weight(self):\n        # Calculate an adaptive differential weight based on the current best solution progress\n        progress_ratio = self.evaluations / self.budget\n        return self.F_min + (self.F_max - self.F_min) * (1 - progress_ratio)", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05604 with standard deviation 0.00362.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05532494223990514, 0.05200810497227182, 0.06078950934589822]}}
{"id": "c1832b48-81c2-4500-8591-7f5289a1bdea", "fitness": 0.054448165094804324, "name": "EnhancedPSODE", "description": "An enhanced PSODE algorithm incorporating adaptive parameters and a local search strategy to improve convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n            self.local_search(func, lb, ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * self.evaluations / self.budget)\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def local_search(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Simple local search strategy\n            perturbed = self.population[i] + np.random.normal(0, 0.1, self.dim)\n            perturbed = np.clip(perturbed, lb, ub)\n            \n            fitness = func(perturbed)\n            self.evaluations += 1\n            \n            if fitness < self.personal_best_value[i]:\n                self.population[i] = perturbed\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = perturbed.copy()\n                \n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = perturbed.copy()", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "650e7e60-b3a7-4a21-8ad9-eb87ff7c24de", "fitness": 0.05569771740387219, "name": "PSODE", "description": "Enhanced velocity update rule for improved convergence in PSODE.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i])) * 0.9\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 3, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05570 with standard deviation 0.00289.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05237137628029542, 0.0594273129706282]}}
{"id": "d79c2b93-80dc-410b-993a-38908c323e9d", "fitness": 0.054448165094804324, "name": "PSODE", "description": "Introduced adaptive inertia weight to PSODE for improved exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            self.w = 0.9 - (0.5 * self.evaluations / self.budget)  # Adaptive inertia weight\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 4, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "6257251b-11a2-409c-ae07-f547cd520b18", "fitness": 0.054448165094804324, "name": "EnhancedPSODE", "description": "Introduction of an adaptive inertia weight and chaotic maps in PSODE for improved balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.F = 0.5  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n        self.global_best_position = np.copy(self.population[np.argmin(self.personal_best_value)])\n        self.global_best_value = min(self.personal_best_value)\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i using chaotic maps\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = self.chaotic_selection(candidates)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def chaotic_selection(self, candidates):\n        np.random.shuffle(candidates)\n        return candidates[:3]", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "b77d5571-8b57-4aba-a661-a8568eb8903c", "fitness": 0.05667966848113948, "name": "PSODE", "description": "Slightly increase cognitive and social coefficients in PSODE for improved convergence speed.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.6  # increased cognitive coefficient\n        self.c2 = 1.6  # increased social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 6, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05668 with standard deviation 0.00146.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05870261513127728, 0.056041927351448195]}}
{"id": "22dd4474-13e5-4256-939f-8fa66858f3ab", "fitness": 0.054448165094804324, "name": "PSODE", "description": "Enhanced exploration by adjusting inertia weight dynamically in PSODE.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n            \n            self.w = 0.9 - 0.4 * (self.evaluations / self.budget)  # Dynamically adjust inertia weight\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 7, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "1c7b2974-6a7c-483c-a529-2f23a0d5d82e", "fitness": 0.055319763629520104, "name": "PSODE", "description": "Improved PSODE by adjusting the inertia weight dynamically for better convergence.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.w = 0.7 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight adjustment\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 8, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05532 with standard deviation 0.00237.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05652869278657935, 0.05200810497227182, 0.05742249312970915]}}
{"id": "d655d64f-4995-4a23-b1c3-1f7fc070296f", "fitness": 0.054448165094804324, "name": "PSODE", "description": "Enhance the balance between exploration and exploitation by tuning the inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.9   # adjusted initial inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update inertia weight dynamically\n            self.w = 0.9 - 0.7 * (self.evaluations / self.budget)\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 9, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "48184fd2-5667-4029-9db8-cd530365b44b", "fitness": 0.054839947592083806, "name": "PSODE", "description": "Introducing adaptive inertia weight to enhance dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.9   # initial inertia weight\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 10, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05484 with standard deviation 0.00121.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05318345246411027, 0.056041927351448195]}}
{"id": "cebb5ca6-93f0-4188-acf5-b36db45ce9dc", "fitness": 0.05477907030244511, "name": "PSODE", "description": "Introduce adaptive inertia weight to enhance PSO's exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.9   # Adaptive inertia weight starts high\n        self.F = 0.5   # differential weight\n        self.CR = 0.9  # crossover probability\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n        \n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n    \n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Evaluate the current solution\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            \n            # Update personal best\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n                \n            # Update global best\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n            \n            # Update velocity and position\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            \n            # Clamp the position within bounds\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + (0.9 - 0.4) * (1 - (self.evaluations / self.budget))\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Select three random individuals different from i\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Create a mutant vector\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            # Perform crossover\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Evaluate the trial solution\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            # Selection\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n                \n                # Update global best\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 11, "feedback": "The algorithm PSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05478 with standard deviation 0.00208.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.05703464297437055]}}
{"id": "15e1105b-ea95-44e8-8693-65b6353c69fb", "fitness": 0.05808426225980279, "name": "EnhancedPSODE", "description": "An enhanced PSODE variant using adaptive parameters and chaotic maps to dynamically balance exploration and exploitation in the optimization process.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))  # chaotic map to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05808 with standard deviation 0.00442.", "error": "", "parent_ids": ["38d4e4bd-b0e2-49dd-b104-5b350c128c3e"], "operator": null, "metadata": {"aucs": [0.06306937180115324, 0.05232006408506662, 0.058863350893188504]}}
{"id": "c9bdc47b-ac43-439e-9f84-b5c905cea42b", "fitness": 0.05837855759370991, "name": "EnhancedPSODE", "description": "Introducing a dynamic population size mechanism to adaptively adjust exploration and exploitation stages.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))  # chaotic map to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05838 with standard deviation 0.00432.", "error": "", "parent_ids": ["15e1105b-ea95-44e8-8693-65b6353c69fb"], "operator": null, "metadata": {"aucs": [0.06306937180115324, 0.05265282047204778, 0.05941348050792872]}}
{"id": "824e9a4e-7bb0-4a21-b615-f3b760db1708", "fitness": 0.05908544438247787, "name": "EnhancedPSODE", "description": "EnhancedPSODE with improved chaotic inertia weight adjustment to boost convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05909 with standard deviation 0.00355.", "error": "", "parent_ids": ["c9bdc47b-ac43-439e-9f84-b5c905cea42b"], "operator": null, "metadata": {"aucs": [0.06306937180115324, 0.05443994689755993, 0.05974701444872044]}}
{"id": "0c71e575-e1bb-4ece-ac9e-0642b22f5768", "fitness": 0.05784831154446335, "name": "EnhancedPSODE", "description": "EnhancedPSODE with dynamic F factor and additional local search to improve convergence and diversification.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n            self.local_search(func, lb, ub)  # New line for local search\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F + 0.1 * (1 - t)  # Dynamic F factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def local_search(self, func, lb, ub):  # New method for additional local search\n        # Simple local search to exploit best position\n        if self.evaluations >= self.budget:\n            return\n        perturbation = np.random.uniform(-0.1, 0.1, size=self.dim)\n        new_position = self.global_best_position + perturbation\n        new_position = np.clip(new_position, lb, ub)\n        new_fitness = func(new_position)\n        self.evaluations += 1\n        if new_fitness < self.global_best_value:\n            self.global_best_value = new_fitness\n            self.global_best_position = new_position.copy()", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05785 with standard deviation 0.00249.", "error": "", "parent_ids": ["824e9a4e-7bb0-4a21-b615-f3b760db1708"], "operator": null, "metadata": {"aucs": [0.061366325145081335, 0.056125342853911464, 0.05605326663439725]}}
{"id": "5eded61e-ecbd-4ba7-856a-ee23403f2a25", "fitness": 0.05977831273375663, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive mutation scale factor for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05978 with standard deviation 0.00588.", "error": "", "parent_ids": ["824e9a4e-7bb0-4a21-b615-f3b760db1708"], "operator": null, "metadata": {"aucs": [0.06739885981528237, 0.05307272749279901, 0.058863350893188504]}}
{"id": "74611468-129d-4954-b1fb-99b88cf628a3", "fitness": 0.05591646648759929, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive levy-flight-based exploration and chaotic local search for improved convergence and robustness.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n            self.levy_flight_search(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def levy_flight_search(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            step = levy.rvs(size=self.dim)\n            new_position = self.population[i] + step * (self.population[i] - self.global_best_position)\n            new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.evaluations += 1\n\n            if new_fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = new_fitness\n                self.personal_best_position[i] = new_position.copy()\n\n                if new_fitness < self.global_best_value:\n                    self.global_best_value = new_fitness\n                    self.global_best_position = new_position.copy()", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05592 with standard deviation 0.00314.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.059699367139077864, 0.05200810497227182, 0.056041927351448195]}}
{"id": "6406dcfc-7b35-4902-a5a3-5716821b9c14", "fitness": 0.05575078326956854, "name": "EnhancedPSODE", "description": "Enhanced PSODE with improved exploration by introducing Cauchy mutation during DE phase.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            # Introducing Cauchy mutation\n            mutant += np.random.standard_cauchy(self.dim)\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05575 with standard deviation 0.00294.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.05920231748498561, 0.05200810497227182, 0.056041927351448195]}}
{"id": "9a69ba7e-3d0d-485e-a30d-6dd013f9fbb5", "fitness": 0.059747006190789466, "name": "EnhancedPSODE", "description": "Improved adaptive cooling schedule for mutation factor to enhance convergence rate.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t**2)  # Modified adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05975 with standard deviation 0.00592.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.06739885981528237, 0.052978807863897526, 0.058863350893188504]}}
{"id": "0b923c05-b955-4390-a074-c56a759e4148", "fitness": 0.05543842197762169, "name": "EnhancedPSODE", "description": "Refined EnhancedPSODE with an additional local search step for improved exploitation.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n            self.local_search(func, lb, ub)  # Added local search step\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def local_search(self, func, lb, ub):  # New local search function\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = self.global_best_position + perturbation\n            candidate = np.clip(candidate, lb, ub)\n            fitness = func(candidate)\n            self.evaluations += 1\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = candidate.copy()", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05544 with standard deviation 0.00236.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.057855387611919995, 0.05224542951060629, 0.05621444881033877]}}
{"id": "5fd9c57a-8fed-40a3-9608-10077753c13e", "fitness": 0.054448165094804324, "name": "EnhancedPSODEPlusPlus", "description": "EnhancedPSODE++ with dynamic neighborhood learning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedPSODEPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            # Dynamic neighborhood learning factor\n            neighborhood_best = self.get_neighborhood_best(i)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (neighborhood_best - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def get_neighborhood_best(self, index):\n        neighbors = list(range(self.population_size))\n        neighbors.remove(index)\n        neighbors = np.random.choice(neighbors, min(3, len(neighbors)), replace=False)\n        best_neighbor = self.population[neighbors[0]]\n        best_value = self.personal_best_value[neighbors[0]]\n        for neighbor in neighbors[1:]:\n            if self.personal_best_value[neighbor] < best_value:\n                best_value = self.personal_best_value[neighbor]\n                best_neighbor = self.population[neighbor]\n        return best_neighbor\n\n    def de(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedPSODEPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00175.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.05200810497227182, 0.056041927351448195]}}
{"id": "ea13507f-e43a-40c1-93cf-5bb291cc5364", "fitness": 0.05977831273375663, "name": "AdvancedEnPSODE", "description": "AdvancedEnPSODE with dual-phase learning for enhanced exploration using hybrid local-global search dynamics.", "code": "import numpy as np\n\nclass AdvancedEnPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            phase = 'exploration' if self.evaluations < self.budget // 2 else 'exploitation'\n            self.update_particles(func, lb, ub, phase)\n            self.de(mut_func=func, lb=lb, ub=ub, phase=phase)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub, phase):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            if phase == 'exploration':\n                self.velocity[i] = (self.w * self.velocity[i] +\n                                    self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.c2 * r2 * (self.global_best_position - self.population[i]))\n            else:  # exploitation phase\n                self.velocity[i] = (self.w * self.velocity[i] +\n                                    self.c1 * r1 * (self.global_best_position - self.population[i]))\n\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub, phase):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedEnPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05978 with standard deviation 0.00588.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.06739885981528237, 0.05307272749279901, 0.058863350893188504]}}
{"id": "61c11950-97fd-4f11-a200-3902778d01c5", "fitness": 0.05662533997150032, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive parameters and dynamic population size utilizing Levy Flights for exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.levy_flight_update(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def levy_flight_update(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            step = self.levy_flight(self.dim)\n            trial = self.population[i] + step * (self.population[i] - self.global_best_position)\n            trial = np.clip(trial, lb, ub)\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        return u / np.abs(v)**(1 / beta)", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05663 with standard deviation 0.00403.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.06182598759078095, 0.05200810497227182, 0.056041927351448195]}}
{"id": "104c643b-1e66-4879-9af3-1a73401a5f94", "fitness": 0.058883225994821875, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive differential evolution parameters and chaotic maps for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.5\n        self.c2_min, self.c2_max = 1.0, 2.5\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR_min, self.CR_max = 0.5, 1.0  # Adaptive crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * chaos_factor\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05888 with standard deviation 0.00283.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.0627100955075851, 0.055971433777030066, 0.05796814869985045]}}
{"id": "5ee98698-6554-4fc3-b423-82541e0be57d", "fitness": 0.05695621913969684, "name": "EnhancedPSODE", "description": "EnhancedPSODE with integrated Lvy Flight strategy for superior exploration capabilities and robust convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(func, lb, ub)\n            self.levy_flight(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def levy_flight(self, func, lb, ub):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            u = np.random.normal(0, sigma, size=self.dim)\n            v = np.random.normal(0, 1, size=self.dim)\n            step = u / abs(v) ** (1 / beta)\n\n            levy_step = 0.01 * step * (self.population[i] - self.global_best_position)\n            new_position = self.population[i] + levy_step\n            new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.evaluations += 1\n\n            if new_fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = new_fitness\n                self.personal_best_position[i] = new_position\n\n                if new_fitness < self.global_best_value:\n                    self.global_best_value = new_fitness\n                    self.global_best_position = new_position", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05696 with standard deviation 0.00286.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.059596353840912664, 0.05298064165617522, 0.058291661922002636]}}
{"id": "79493df4-7f6c-48fd-abd8-f012bc75dd52", "fitness": 0.05791799115309911, "name": "EnhancedPSODE", "description": "EnhancedPSODE with a new chaotic map for updating inertia weight to improve exploration.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(np.pi * t)  # Modified chaotic map for w using sine function\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05792 with standard deviation 0.00162.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.05925768330782488, 0.05563293925828394, 0.058863350893188504]}}
{"id": "d915429a-7fe3-4148-bbac-02dd19e622b5", "fitness": 0.054580117303904774, "name": "EnhancedPSODE", "description": "EnhancedPSODE with Gaussian mutation for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub) + np.random.normal(0, 0.01, self.dim)  # Gaussian mutation\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05458 with standard deviation 0.00182.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.05569031958799431, 0.05200810497227182, 0.056041927351448195]}}
{"id": "b0a910e8-94c8-45c7-9eff-636c8ad0bcf5", "fitness": 0.05906432964553724, "name": "EnhancedPSODE", "description": "EnhancedPSODE with refined chaotic map and adaptive population size for superior convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2 + 0.05  # refined chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05906 with standard deviation 0.00536.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.0665942443181744, 0.05455681726698913, 0.056041927351448195]}}
{"id": "775639f1-e889-4633-92de-322395b4412c", "fitness": 0.05659256880844802, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive parameters refined by introducing an elite preservation strategy and diversity boosting mechanism for better convergence and global search capabilities.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.elite_fraction = 0.1  # Fraction of elite solutions to preserve\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(func, lb, ub)\n            self.preserve_elites(func)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t)) ** 2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def preserve_elites(self, func):\n        elite_count = max(1, int(self.elite_fraction * self.population_size))\n        elite_indices = np.argsort(self.personal_best_value)[:elite_count]\n        elite_positions = self.personal_best_position[elite_indices]\n        \n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            \n            if i not in elite_indices:\n                diversity_factor = np.random.uniform(0.5, 1.5, size=self.dim)\n                self.population[i] = diversity_factor * self.population[i] + (1 - diversity_factor) * elite_positions[np.random.randint(elite_count)]\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05659 with standard deviation 0.00349.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.060478755273816076, 0.05200810497227182, 0.05729084617925617]}}
{"id": "143bd18d-d6c7-4cad-a34b-72458de5a260", "fitness": 0.06357981451748233, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive mutation scale, dynamic particle update, and chaos-based perturbation to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)  # add chaos-based perturbation\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06358 with standard deviation 0.00380.", "error": "", "parent_ids": ["5eded61e-ecbd-4ba7-856a-ee23403f2a25"], "operator": null, "metadata": {"aucs": [0.062085798075643295, 0.05985523260761427, 0.06879841286918942]}}
{"id": "e8701dc5-f877-4c39-98f7-9fc6e0d7fd56", "fitness": 0.06030146584020768, "name": "EnhancedPSODE", "description": "EnhancedPSODE with dynamic inertia weight, adaptive crossover, and elite selection to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR_min, self.CR_max = 0.5, 1.0  # Adaptive crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t)) ** 2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * t  # Adaptive crossover rate\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        elite_index = np.argmin(self.personal_best_value)\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n            if i != elite_index:\n                self.population[i] = 0.9 * self.population[i] + 0.1 * self.population[elite_index]  # Elite selection\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06030 with standard deviation 0.00346.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.06034963924733239, 0.06451283092184246, 0.056041927351448195]}}
{"id": "c131eedb-b149-4d57-91c6-851ea02341e5", "fitness": 0.0585110969480808, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSO-DE with Stochastic Adaptive Learning Rate and Chaos-Enhanced Exploration to improve robustness and convergence.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        stochastic_lr = np.random.uniform(0.5, 1.5, self.population_size)\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (stochastic_lr[i] * self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 32, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05851 with standard deviation 0.00352.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.0634896018447002, 0.056001761648094006, 0.056041927351448195]}}
{"id": "50c57dff-0717-42aa-a764-4dc4709309d1", "fitness": 0.05705896805491739, "name": "ImprovedEnhancedPSODE", "description": "Improved EnhancedPSODE by incorporating an elite preservation mechanism and adaptive learning factors for better convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 0.5, 2.5\n        self.c2_min, self.c2_max = 0.5, 2.5\n        self.w_min, self.w_max = 0.3, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.elite_preservation()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * np.sin(np.pi * t / 2)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * np.cos(np.pi * t / 2)\n        self.w = self.w_max - (self.w_max - self.w_min) * (t**2)\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def elite_preservation(self):\n        elite_index = np.argmin(self.personal_best_value)\n        self.population[0] = self.personal_best_position[elite_index]\n        self.velocity[0] = np.zeros(self.dim)\n\n    def update_particles(self, func, lb, ub):\n        for i in range(1, self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(1, self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 33, "feedback": "The algorithm ImprovedEnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05706 with standard deviation 0.00362.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.06177432118811188, 0.0529823410405027, 0.056420241936137594]}}
{"id": "f1fbd056-0236-45a9-9090-3f8b86cd5e1a", "fitness": 0.05774456323372886, "name": "EnhancedPSODE", "description": "EnhancedPSO with adaptive mutation scale and chaos-based perturbation, improved by dynamic adjustment of the crossover rate.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR_min, self.CR_max = 0.7, 0.9  # Dynamic crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * t  # Dynamic crossover rate\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)  # add chaos-based perturbation\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05774 with standard deviation 0.00106.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.056300314177845645, 0.05882985894269932, 0.05810351658064161]}}
{"id": "9e75e643-4f77-4e93-b39f-1e7808dba5df", "fitness": 0.054566898698344336, "name": "QiAPSDDE", "description": "Quantum-inspired Adaptive Particle Swarm with Dynamic Differential Evolution (QiAPSDDE) enhances exploration-exploitation balance using quantum potential fields and time-varying adaptive strategies.", "code": "import numpy as np\n\nclass QiAPSDDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            \n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            quantum_factor = np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                quantum_factor * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 35, "feedback": "The algorithm QiAPSDDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05457 with standard deviation 0.00182.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.055650663771313, 0.05200810497227182, 0.056041927351448195]}}
{"id": "b3781667-cf46-4829-92a6-7b574de85d64", "fitness": 0.06337656052717278, "name": "EnhancedPSODE", "description": "EnhancedPSODE with dynamic inertia weight using sinusoidal fluctuation to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor * (0.5 + 0.5 * np.sin(2 * np.pi * t))  # Dynamic inertia weight\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)  # add chaos-based perturbation\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06338 with standard deviation 0.00396.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.06134115179444832, 0.05987632122916664, 0.06891220855790336]}}
{"id": "62bc5188-8772-456d-bd0a-dec01941f9ba", "fitness": 0.060217486132338016, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive inertia weight, chaotic perturbation, and dynamic crossover in DE for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR_min, self.CR_max = 0.3, 0.9  # Dynamic crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2  # enhanced chaotic map with power to adjust w\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)  # Adaptive mutation scale factor\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * chaos_factor  # Dynamic crossover rate\n        self.population_size = max(5, int(20 * (1 - t)))  # Dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)  # add chaos-based perturbation\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06022 with standard deviation 0.00333.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.06419691687347784, 0.060413614172088015, 0.056041927351448195]}}
{"id": "381e0a77-6e94-49ee-9f09-7985db5fb76d", "fitness": 0.044908106407921124, "name": "EnhancedPSODE", "description": "EnhancedPSODE with new inertia weight adaptation based on Lvy flight and chaos-driven mutation for improved convergence speed and exploration.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        levy_flight = np.random.normal(0, 1) * np.power(t, -1.5)\n        self.w = self.w_min + (self.w_max - self.w_min) * (chaos_factor * levy_flight)\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04491 with standard deviation 0.00178.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.04575887009733748, 0.042435931620372624, 0.046529517506053275]}}
{"id": "8ec7f4ff-45ac-4783-bd5a-0fba15adb343", "fitness": 0.0613031154834884, "name": "EnhancedPSODE", "description": "EnhancedPSODE with multi-swarm strategy, chaotic inertia weight update, and mutation diversity to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.5  # Adjusted\n        self.c2_min, self.c2_max = 1.0, 2.5  # Adjusted\n        self.w_min, self.w_max = 0.2, 0.8  # Adjusted\n        self.F_min, self.F_max = 0.1, 0.8  # Adjusted\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n        self.num_swarms = 3  # New\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n            self.multi_swarm_exchange()  # New\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t)**3)  # Adjusted\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.normal(0, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def multi_swarm_exchange(self):  # New\n        for _ in range(self.num_swarms):\n            if self.evaluations >= self.budget:\n                break\n            idx = np.random.choice(self.population_size)\n            partner_idx = np.random.choice(self.population_size)\n            if self.personal_best_value[partner_idx] < self.personal_best_value[idx]:\n                self.personal_best_position[idx] = self.population[partner_idx].copy()\n                self.personal_best_value[idx] = self.personal_best_value[partner_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06130 with standard deviation 0.00320.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.05679187712862799, 0.06381493663744309, 0.06330253268439412]}}
{"id": "0318d8d0-fb8c-4b73-a843-6b5d1bc98a0f", "fitness": 0.06145899641472086, "name": "EnhancedPSODE", "description": "EnhancedPSODE with adaptive inertia weight and mutation factor scaling, integrating Lvy flight perturbations for improved exploration.", "code": "import numpy as np\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9  # Adaptive mutation scale factor\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.de(mut_func=func, lb=lb, ub=ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget  # normalized time\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * np.cos(t * np.pi)  # Slightly modified adaptive mutation scale factor\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        levy_exponent = 1.5\n        levy_perturb = np.random.normal(0, 1, (self.population_size, self.dim)) * (np.abs(np.random.normal(0, 1, (self.population_size, self.dim))) ** (-1 / levy_exponent))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                levy_perturb[i] * 0.05)  # Integrating Lvy flight perturbation\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def de(self, mut_func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = mut_func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06146 with standard deviation 0.00479.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.05841621281662701, 0.057741578427155216, 0.06821919800038034]}}
{"id": "0fe16c78-7c3e-4a94-8e03-4c1e2cb7cf7a", "fitness": 0.06632609538751477, "name": "EnhancedPSODE_v2", "description": "EnhancedPSODE_v2 introducing a Lvy flight-inspired mutation and elite-based crossover to enhance exploration and exploitation, while refining chaotic perturbations for improved convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.elite_mutation(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.laplace(0, 0.1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def elite_mutation(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = elite + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedPSODE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06633 with standard deviation 0.00483.", "error": "", "parent_ids": ["143bd18d-d6c7-4cad-a34b-72458de5a260"], "operator": null, "metadata": {"aucs": [0.060665312609165634, 0.0724711959936084, 0.06584177755977028]}}
{"id": "72238210-9e44-43d7-86e2-ab655ed15e19", "fitness": 0.05584634464778304, "name": "EnhancedPSODE_v3", "description": "EnhancedPSODE_v3 improves convergence by introducing a dynamic inertia weight adjustment for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedPSODE_v3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.elite_mutation(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_max - (self.w_max - self.w_min) * t  # Changed line: Dynamic inertia weight adjustment\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.laplace(0, 0.1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def elite_mutation(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = elite + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedPSODE_v3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05585 with standard deviation 0.00235.", "error": "", "parent_ids": ["0fe16c78-7c3e-4a94-8e03-4c1e2cb7cf7a"], "operator": null, "metadata": {"aucs": [0.05646609328052721, 0.052702874508349984, 0.058370066154471933]}}
{"id": "ef1059ed-fc9c-467b-ba84-00a28b9831d9", "fitness": 0.05901334193893867, "name": "EnhancedPSODE_v3", "description": "EnhancedPSODE_v3 integrates a self-adaptive learning mechanism, dynamic inertia weight, and stochastic ranking to balance exploration and exploitation, further refining convergence efficacy.", "code": "import numpy as np\n\nclass EnhancedPSODE_v3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.5\n        self.c2_min, self.c2_max = 1.0, 2.5\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        self.fitness_history = np.zeros(self.population_size)\n\n        while self.evaluations < self.budget:\n            self.dynamic_inertia_weight()\n            self.update_particles(func, lb, ub)\n            self.stochastic_ranking(func, lb, ub)\n            self.self_adaptive_learning()\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def dynamic_inertia_weight(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        self.w = self.w_max - ((self.w_max - self.w_min) * (t**2))\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n            self.fitness_history[i] = fitness\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def stochastic_ranking(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            mutant = elite + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = trial_fitness\n                self.population[i] = trial\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def self_adaptive_learning(self):\n        sorted_indices = np.argsort(self.fitness_history)\n        elite_count = max(1, self.population_size // 5)\n        elite_indices = sorted_indices[:elite_count]\n        for i in range(self.population_size):\n            if i not in elite_indices:\n                self.velocity[i] *= 0.5  # Dampen velocity for non-elite solutions", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedPSODE_v3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05901 with standard deviation 0.00218.", "error": "", "parent_ids": ["0fe16c78-7c3e-4a94-8e03-4c1e2cb7cf7a"], "operator": null, "metadata": {"aucs": [0.05841458438591329, 0.05669642072107062, 0.06192902070983208]}}
{"id": "ffeb333c-ff19-4792-bd25-3d97321ac592", "fitness": 0.07052000220459287, "name": "EnhancedPSODE_v3", "description": "Optimized EnhancedPSODE_v3 adding dynamic Lvy flight parameter adjustment and adaptive elite crossover for improved exploration and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedPSODE_v3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.adaptive_elite_mutation(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.laplace(0, 0.1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def adaptive_elite_mutation(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            # Dynamic Lvy flight parameter adjustment\n            levy_factor = np.random.uniform(0.1, 1.0) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedPSODE_v3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07052 with standard deviation 0.00328.", "error": "", "parent_ids": ["0fe16c78-7c3e-4a94-8e03-4c1e2cb7cf7a"], "operator": null, "metadata": {"aucs": [0.06915646433423095, 0.0750411345653954, 0.06736240771415225]}}
{"id": "08581196-c3d6-4382-b93b-25ac227479ba", "fitness": 0.06450573180533721, "name": "EnhancedPSODE_v4", "description": "Introduce a dynamic environment-driven perturbation approach and stochastic opposition-based learning for improved exploration-exploitation balance and convergence in diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_min, self.c1_max = 1.0, 2.0\n        self.c2_min, self.c2_max = 1.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.F_min, self.F_max = 0.1, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.stochastic_opposition_based_learning(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (1 - np.cos(np.pi * t))**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(20 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        chaos_perturb = np.random.laplace(0, 0.1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                chaos_perturb[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def stochastic_opposition_based_learning(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            # Generate a random opposition candidate\n            opposition = lb + ub - self.population[i]\n            opposition = np.clip(opposition, lb, ub)\n            candidate = np.where(np.random.rand(self.dim) < 0.5, self.population[i], opposition)\n\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n\n            if candidate_fitness < self.personal_best_value[i]:\n                self.population[i] = candidate\n                self.personal_best_value[i] = candidate_fitness\n                self.personal_best_position[i] = candidate.copy()\n\n                if candidate_fitness < self.global_best_value:\n                    self.global_best_value = candidate_fitness\n                    self.global_best_position = candidate.copy()", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06451 with standard deviation 0.01033.", "error": "", "parent_ids": ["ffeb333c-ff19-4792-bd25-3d97321ac592"], "operator": null, "metadata": {"aucs": [0.05529446296069296, 0.07893806215936816, 0.059284670295950526]}}
{"id": "d357883d-826a-441d-82a0-302548011526", "fitness": 0.07075429028543967, "name": "EnhancedPSODE_v4", "description": "Refined EnhancedPSODE_v3 by integrating stochastic tunneling and social learning strategy to enhance exploration and convergence under limited budget conditions.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.00102.", "error": "", "parent_ids": ["ffeb333c-ff19-4792-bd25-3d97321ac592"], "operator": null, "metadata": {"aucs": [0.06936543575557097, 0.0717817183070798, 0.07111571679366824]}}
{"id": "5ba5a945-edf6-4a0c-990f-d54cf6f4e5b1", "fitness": 0.07075429028543967, "name": "EnhancedPSODE_v4", "description": "Introduced adaptive mutation scaling for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.00102.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06936543575557097, 0.0717817183070798, 0.07111571679366824]}}
{"id": "f452ae4a-dc19-4d43-8efc-e34941f985b9", "fitness": 0.06738227440495208, "name": "EnhancedPSODE_v4", "description": "Enhanced exploration by modifying the social learning strategy to dynamically adjust the Lvy factor based on current best individual's performance.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5 * (self.global_best_value / (self.personal_best_value[elite_index] + 1e-9)))  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06738 with standard deviation 0.00171.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06978896317389693, 0.06596865370776728, 0.06638920633319201]}}
{"id": "780ce696-24a3-4a96-8114-aea57c23963a", "fitness": 0.06723686122367845, "name": "EnhancedPSODE_v4", "description": "Integrated an elite perturbation strategy to enhance the exploitation phase for better fine-tuning.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        elite_perturb = np.random.normal(0, 0.01, self.dim)  # Added elite perturbation strategy\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05 + elite_perturb)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06724 with standard deviation 0.00591.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.07479725376967206, 0.06653889337153429, 0.06037443652982899]}}
{"id": "d3128788-8b9c-4521-a37b-10e9ab1fe22c", "fitness": 0.06740880251230441, "name": "EnhancedPSODE_v4", "description": "Refined EnhancedPSODE_v4 by introducing a dynamic crossover rate in the social learning strategy to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            self.CR = 0.5 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamic crossover rate\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06741 with standard deviation 0.00450.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06134345108624828, 0.06877493800709844, 0.07210801844356651]}}
{"id": "4dca5834-f313-40ac-863e-a9709d3885b2", "fitness": 0.0670627814116808, "name": "EnhancedPSODE_v4", "description": "Introduced non-linear velocity scaling in particle update to enhance convergence precision.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.velocity[i] *= (1 - self.evaluations / self.budget)  # Non-linear velocity scaling\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06706 with standard deviation 0.00540.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06775405174971494, 0.060130341795072706, 0.07330395069025475]}}
{"id": "7b5e4394-bc88-48d9-9a2e-f928c740e04c", "fitness": 0.058472246941696504, "name": "EnhancedPSODE_v4", "description": "Refined inertia weight adaptation using cosine-based decay for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * (0.5 * (1 + np.cos(np.pi * t)))  # Refined weight adaptation\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05847 with standard deviation 0.00181.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.058635955221113534, 0.05617482579618327, 0.06060595980779271]}}
{"id": "b139902b-3137-46eb-91d3-128e4774478d", "fitness": 0.07032486374400142, "name": "EnhancedPSODE_v4", "description": "Improved EnhancedPSODE_v4 by refining the chaos factor formula to enhance adaptive parameter tuning for better convergence within budget constraints.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(np.pi * t)**2  # Updated chaos factor calculation for more dynamic changes\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07032 with standard deviation 0.00098.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06896402951928327, 0.07125929005242082, 0.07075127166030015]}}
{"id": "f0b3ae55-09fb-463b-ba76-246dffc66498", "fitness": 0.06361047136482208, "name": "EnhancedPSODE_v5", "description": "Enhanced EnhancedPSODE_v4 by integrating dynamic particle regrouping and adaptive mutation rate for better handling of multimodal landscapes.", "code": "import numpy as np\n\nclass EnhancedPSODE_v5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.c1_min, self.c1_max = 1.5, 2.0\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.w_min, self.w_max = 0.3, 0.8\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        dynamic_perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                dynamic_perturbation[i] * np.random.uniform(0.01, 0.1))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            adaptive_levy_factor = np.random.uniform(0.1, 0.5) * (1 - np.power(self.evaluations / self.budget, 2))\n            mutant = elite + adaptive_levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedPSODE_v5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06361 with standard deviation 0.00184.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.0621338902696964, 0.062487877077855525, 0.06620964674691432]}}
{"id": "cc68e5a9-e417-4627-bcba-e5ebf9618337", "fitness": 0.058658997259655475, "name": "EnhancedPSODE_v5", "description": "Introduced a dynamic subpopulation strategy and chaotic Lvy flight for enhanced exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedPSODE_v5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 25\n        self.population_size = self.initial_population_size\n        self.c1_min, self.c1_max = 1.5, 2.0\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.w_min, self.w_max = 0.3, 0.8\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n        self.subpopulations = 3  # Number of dynamic subpopulations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.initial_population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.initial_population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        self.w = self.w_min + (self.w_max - self.w_min) * (0.5 * (np.sin(np.pi * t) + 1))\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(self.initial_population_size * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        subpop_size = self.population_size // self.subpopulations\n        for subpop_index in range(self.subpopulations):\n            start = subpop_index * subpop_size\n            end = start + subpop_size if subpop_index != self.subpopulations - 1 else self.population_size\n            for i in range(start, end):\n                if self.evaluations >= self.budget:\n                    break\n\n                elite_index = np.argmin(self.personal_best_value[start:end]) + start\n                elite = self.personal_best_position[elite_index]\n\n                candidates = list(range(start, end))\n                candidates.remove(i)\n                if len(candidates) >= 3:\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n                else:\n                    a, b, c = 0, 1, 2  # Fallback case for small populations\n\n                chaos_factor = np.abs(np.sin(0.5 * np.pi * (1 - self.evaluations / self.budget)))\n                levy_factor = np.random.uniform(0.1, 0.5) * chaos_factor\n                mutant = elite + levy_factor * (self.population[a] - self.population[b])\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_fitness\n                    self.personal_best_position[i] = trial.copy()\n\n                    if trial_fitness < self.global_best_value:\n                        self.global_best_value = trial_fitness\n                        self.global_best_position = trial.copy()", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedPSODE_v5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05866 with standard deviation 0.00444.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06491455523139023, 0.055020509196128, 0.056041927351448195]}}
{"id": "edebe17c-049d-4815-acc2-975485c367af", "fitness": 0.07075422943424918, "name": "EnhancedPSODE_v4", "description": "Introduced a dynamic scaling factor for the perturbation to enhance exploration early and exploitation later in the optimization process.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation_scale = 0.1 * (1 - self.evaluations / self.budget)  # Dynamic scaling factor for perturbation\n        perturbation = np.random.normal(0, perturbation_scale, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.00102.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06936625788981787, 0.07178103800360802, 0.07111539240932163]}}
{"id": "2702478a-f605-49fd-b036-cf92964a871e", "fitness": 0.060561955899506636, "name": "EnhancedPSODE_v4", "description": "Introduced a Gaussian mutation strategy during the social learning phase to enhance diversity and exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            # Gaussian mutation for better diversity\n            trial += np.random.normal(0, 0.01, self.dim)\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06056 with standard deviation 0.00067.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06050343221362586, 0.05977347836083913, 0.06140895712405492]}}
{"id": "7bcf7965-1a7b-4528-b00a-5b1a576006ea", "fitness": 0.05585271061935215, "name": "EnhancedPSODE_v5", "description": "Introduce an adaptive grouping-based learning and dynamic mutation strategy to improve convergence and diversification in black-box optimization scenarios.", "code": "import numpy as np\n\nclass EnhancedPSODE_v5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.c1_min, self.c1_max = 1.5, 2.0\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.w_min, self.w_max = 0.3, 0.8\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.group_based_learning(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        self.w = self.w_min + (self.w_max - self.w_min) * (1 - t)\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * np.exp(-t)))  # Exponential decay for dynamic population size\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def group_based_learning(self, func, lb, ub):\n        elite_size = max(1, self.population_size // 5)\n        elite_indices = np.argsort(self.personal_best_value)[:elite_size]\n        elite_group = self.personal_best_position[elite_indices]\n        \n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            group_factor = np.random.uniform(0.1, 0.3)\n            group_leader = elite_group[np.random.randint(elite_size)]\n            dynamic_mutation = np.random.normal(scale=group_factor, size=self.dim)\n            candidate = self.population[i] + dynamic_mutation * (group_leader - self.population[i])\n            candidate = np.clip(candidate, lb, ub)\n\n            candidate_fitness = func(candidate)\n            self.evaluations += 1\n\n            if candidate_fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = candidate_fitness\n                self.personal_best_position[i] = candidate.copy()\n\n                if candidate_fitness < self.global_best_value:\n                    self.global_best_value = candidate_fitness\n                    self.global_best_position = candidate.copy()", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedPSODE_v5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05585 with standard deviation 0.00053.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.05638333502307358, 0.055132869483534686, 0.056041927351448195]}}
{"id": "b2233941-dcf4-43e6-a2bc-4b1d5552d2c0", "fitness": 0.07075429707781782, "name": "EnhancedPSODE_v4", "description": "Enhanced PSO with refined stochastic tunneling for improved exploration and convergence by slightly adjusting the perturbation scaling factor.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.8  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.08, (self.population_size, self.dim))  # Adjusted perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.00102.", "error": "", "parent_ids": ["d357883d-826a-441d-82a0-302548011526"], "operator": null, "metadata": {"aucs": [0.06936591387122393, 0.07178140184895143, 0.07111557551327807]}}
{"id": "a248d046-ed7e-4e84-b531-467afa24fbea", "fitness": 0.06821749391237227, "name": "EnhancedPSODE_v5", "description": "Enhanced PSODE with adaptive chaotic inertia weight and dynamic adjustment of exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedPSODE_v5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better diversity\n        self.c1_min, self.c1_max = 1.2, 2.5  # Wider range for cognitive parameter\n        self.c2_min, self.c2_max = 1.2, 2.8  # Wider range for social parameter\n        self.w_min, self.w_max = 0.2, 0.9  # Broader inertia weight range\n        self.F_min, self.F_max = 0.1, 0.7  # Adjusted differential weight range\n        self.CR = 0.9  # Increased crossover rate for more exploration\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * np.cos(t * np.pi / 2)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * np.sin(t * np.pi / 2)\n        chaotic_factor = np.sin(0.5 * np.pi * t) ** 2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaotic_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(10, int(30 * (1 - t)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.3) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedPSODE_v5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06822 with standard deviation 0.00437.", "error": "", "parent_ids": ["b2233941-dcf4-43e6-a2bc-4b1d5552d2c0"], "operator": null, "metadata": {"aucs": [0.06362368590748146, 0.07409001174378682, 0.06693878408584852]}}
{"id": "72e9aebe-02ec-475f-8d77-df68c226f5f0", "fitness": 0.06877964635137719, "name": "EnhancedPSODE_v4", "description": "Slightly increased the crossover rate to enhance the exploration capability of the algorithm.", "code": "import numpy as np\n\nclass EnhancedPSODE_v4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slightly increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.0  # Adjusted cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 2.5  # Adjusted social parameter range\n        self.w_min, self.w_max = 0.3, 0.8  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.2, 0.8\n        self.CR = 0.85  # Slightly increased crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.social_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(0.5 * np.pi * t)**2  # Changed chaos factor calculation\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(25 * (1 - t)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.08, (self.population_size, self.dim))  # Adjusted perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.05)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def social_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedPSODE_v4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06878 with standard deviation 0.00791.", "error": "", "parent_ids": ["b2233941-dcf4-43e6-a2bc-4b1d5552d2c0"], "operator": null, "metadata": {"aucs": [0.07601333050137382, 0.057780640451832954, 0.07254496810092481]}}
{"id": "e3a16c4f-98d7-4ed9-83e8-6059d1f8ddc3", "fitness": 0.07187658536212664, "name": "HybridAdaptivePSODE", "description": "Hybrid Adaptive PSODE with dynamic learning and chaos injection for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.5  # Wider cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 3.0  # Wider social parameter range\n        self.w_min, self.w_max = 0.2, 1.0  # Wider inertia weight range for chaos injection\n        self.F_min, self.F_max = 0.3, 0.9  # Increased differential weight range\n        self.CR = 0.9  # Higher crossover rate for better diversity\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(2 * np.pi * t)**2  # New chaos factor for dynamic adjustment\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.1, (self.population_size, self.dim))  # Increased perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.6) * (1 - self.evaluations / self.budget)  # Enhanced Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 62, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07188 with standard deviation 0.00589.", "error": "", "parent_ids": ["b2233941-dcf4-43e6-a2bc-4b1d5552d2c0"], "operator": null, "metadata": {"aucs": [0.07678495412486352, 0.07524643521446361, 0.06359836674705277]}}
{"id": "20175b51-3057-43ac-9da2-e29546c04317", "fitness": 0.07187750675964825, "name": "HybridAdaptivePSODE", "description": "Improved exploration by adjusting perturbation scaling factor slightly.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.5  # Wider cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 3.0  # Wider social parameter range\n        self.w_min, self.w_max = 0.2, 1.0  # Wider inertia weight range for chaos injection\n        self.F_min, self.F_max = 0.3, 0.9  # Increased differential weight range\n        self.CR = 0.9  # Higher crossover rate for better diversity\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(2 * np.pi * t)**2  # New chaos factor for dynamic adjustment\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))  # Slightly reduced perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.6) * (1 - self.evaluations / self.budget)  # Enhanced Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 63, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07188 with standard deviation 0.00589.", "error": "", "parent_ids": ["e3a16c4f-98d7-4ed9-83e8-6059d1f8ddc3"], "operator": null, "metadata": {"aucs": [0.07678541573764419, 0.07524511511771503, 0.06360198942358553]}}
{"id": "0474423b-168e-4bf8-a5cf-a23922dd99d9", "fitness": 0.07074857603023528, "name": "EnhancedHybridAdaptivePSODE", "description": "Introduce a time-varying Lvy factor and adaptive perturbation for enhanced global exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.2, 1.0\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(2 * np.pi * t)**2\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation_scale = (0.05 + 0.1 * (1 - self.evaluations / self.budget))\n        perturbation = np.random.normal(0, perturbation_scale, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.6) * (1 - (self.evaluations / self.budget)**1.5)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07075 with standard deviation 0.00866.", "error": "", "parent_ids": ["20175b51-3057-43ac-9da2-e29546c04317"], "operator": null, "metadata": {"aucs": [0.07664789474826283, 0.07709645285977107, 0.05850138048267195]}}
{"id": "31f17a6d-0991-413b-b88a-93d95aab0e50", "fitness": 0.05959503453, "name": "EnhancedHybridAdaptivePSODE", "description": "Further enhance exploration-exploitation balance by integrating chaotic maps and adaptive mutation strategies.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.5  # Wider cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 3.0  # Wider social parameter range\n        self.w_min, self.w_max = 0.2, 1.0  # Wider inertia weight range for chaos injection\n        self.F_min, self.F_max = 0.3, 0.9  # Increased differential weight range\n        self.CR = 0.9  # Higher crossover rate for better diversity\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n        self.chaos_sequence = self.generate_chaos_sequence()\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def generate_chaos_sequence(self, size=1000):\n        # Generate a logistic map sequence\n        r = 3.999\n        x = np.random.rand()\n        chaos_sequence = []\n        for _ in range(size):\n            x = r * x * (1 - x)\n            chaos_sequence.append(x)\n        return chaos_sequence\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = self.chaos_sequence[self.evaluations % len(self.chaos_sequence)]\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.025, (self.population_size, self.dim))  # Reduced perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.6) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05960 with standard deviation 0.00585.", "error": "", "parent_ids": ["20175b51-3057-43ac-9da2-e29546c04317"], "operator": null, "metadata": {"aucs": [0.06086600824111388, 0.06604032287635764, 0.05187877247252848]}}
{"id": "dd381fbe-e4e7-4696-acc9-5c1d1dfb54b4", "fitness": 0.06622846746554305, "name": "EnhancedHybridAdaptivePSODE", "description": "Enhanced exploration and exploitation balance through adaptive chaos modulation and refined Lvy flight perturbations.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.2, 1.0\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = 0.5 * (np.sin(2 * np.pi * t) + 1)  # Refined chaos factor for smoother parameter transitions\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = (np.random.uniform(0.15, 0.6) * \n                           np.random.normal(1, 0.3) *  # Modified Lvy factor for enhanced exploration\n                           (1 - self.evaluations / self.budget))\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06623 with standard deviation 0.00146.", "error": "", "parent_ids": ["20175b51-3057-43ac-9da2-e29546c04317"], "operator": null, "metadata": {"aucs": [0.06425322370677444, 0.06773320834389407, 0.06669897034596062]}}
{"id": "5e799abf-6f9a-428b-8f31-4e1fc508ffad", "fitness": -Infinity, "name": "HybridAdaptivePSODE", "description": "Utilize a dynamic perturbation scaling factor based on the cosine function for improved exploration.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for better exploration\n        self.c1_min, self.c1_max = 1.5, 2.5  # Wider cognitive parameter range\n        self.c2_min, self.c2_max = 1.5, 3.0  # Wider social parameter range\n        self.w_min, self.w_max = 0.2, 1.0  # Wider inertia weight range for chaos injection\n        self.F_min, self.F_max = 0.3, 0.9  # Increased differential weight range\n        self.CR = 0.9  # Higher crossover rate for better diversity\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(2 * np.pi * t)**2  # New chaos factor for dynamic adjustment\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/2)))  # Adjusted population size update\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.05 * np.cos(np.pi * self.evaluations / self.budget), (self.population_size, self.dim))  # Updated perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.6) * (1 - self.evaluations / self.budget)  # Enhanced Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 67, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_ids": ["20175b51-3057-43ac-9da2-e29546c04317"], "operator": null, "metadata": {}}
{"id": "b99e7a1e-14ac-43a9-a8d4-95ae81c3f947", "fitness": 0.07373334574683403, "name": "HybridAdaptivePSODE", "description": "Enhanced exploration and exploitation through dynamic chaos and multi-faceted perturbation strategies.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9  # Adjusted wider inertia weight range for enhanced chaos\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.85  # Slightly reduced crossover rate for fine-tuning\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2  # Refined chaos factor for better dynamic adjustment\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/3)))  # Refined population size adjustment\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.1, (self.population_size, self.dim))  # Adjusted perturbation scaling factor\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  # Increased perturbation impact\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.65) * (1 - self.evaluations / self.budget)  # Refined Lvy factor for exploration\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 68, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07373 with standard deviation 0.00829.", "error": "", "parent_ids": ["20175b51-3057-43ac-9da2-e29546c04317"], "operator": null, "metadata": {"aucs": [0.08527876070000995, 0.06622816708616308, 0.06969310945432905]}}
{"id": "0f3a87fc-7fc5-48b5-b1d4-f6c7b947a103", "fitness": 0.07477171402362233, "name": "HybridAdaptivePSODE", "description": "Refined chaotic and exploration strategies through adaptive factors and stochastic perturbation enhancements.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9  # Adjusted crossover rate for improved balance\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(2 * np.pi * t)**2) * 1.8  # Enhanced chaos for dynamic exploration\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.2, (self.population_size, self.dim))  # Enhanced perturbation scaling\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.25)  # Refined perturbation impact\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.7) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 69, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07477 with standard deviation 0.00766.", "error": "", "parent_ids": ["b99e7a1e-14ac-43a9-a8d4-95ae81c3f947"], "operator": null, "metadata": {"aucs": [0.08548479957149302, 0.06804496616134448, 0.0707853763380295]}}
{"id": "8eabc027-75bc-4fb0-86af-31b20356ea95", "fitness": 0.07453839600356149, "name": "HybridAdaptivePSODE", "description": "Enhanced HybridAdaptivePSODE with a dynamic regrouping strategy to enhance diversity and convergence by reallocating particles every iteration.", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9  # Adjusted crossover rate for improved balance\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n            if self.evaluations < self.budget:\n                self.regroup_population(lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(2 * np.pi * t)**2) * 1.8  # Enhanced chaos for dynamic exploration\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.2, (self.population_size, self.dim))  # Enhanced perturbation scaling\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.25)  # Refined perturbation impact\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.7) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def regroup_population(self, lb, ub):\n        distance_to_gbest = np.linalg.norm(self.population - self.global_best_position, axis=1)\n        regroup_threshold = np.median(distance_to_gbest)\n        for i in range(self.population_size):\n            if distance_to_gbest[i] > regroup_threshold:\n                self.population[i] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                self.velocity[i] = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=self.dim)", "configspace": "", "generation": 70, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07454 with standard deviation 0.00772.", "error": "", "parent_ids": ["0f3a87fc-7fc5-48b5-b1d4-f6c7b947a103"], "operator": null, "metadata": {"aucs": [0.08534661655394293, 0.06782021124053517, 0.07044836021620637]}}
{"id": "46e2b1c4-bfb0-4ebe-b085-1ca6016c3bc9", "fitness": 0.0695286024988055, "name": "EnhancedAdaptivePSODE", "description": "Enhanced adaptive chaotic and exploration strategies using dynamic perturbation and improved convergence strategies.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.2, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - np.sqrt(t))\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * np.sqrt(t)\n        chaos_factor = (np.sin(2 * np.pi * t)**2) * 2.0  # Enhanced chaos for dynamic exploration\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t**2)\n        self.population_size = max(5, int(30 * (1 - t/3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.3, (self.population_size, self.dim))  # Enhanced perturbation scaling\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.3)  # Refined perturbation impact\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.6) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06953 with standard deviation 0.00718.", "error": "", "parent_ids": ["0f3a87fc-7fc5-48b5-b1d4-f6c7b947a103"], "operator": null, "metadata": {"aucs": [0.07596754888763324, 0.07311015268564913, 0.05950810592313416]}}
{"id": "c6a39fb0-1d48-4aaf-8115-b9acec5d5dfd", "fitness": 0.07375054090241218, "name": "HybridAdaptivePSODE", "description": "Enhanced dynamic strategies and chaotic exploration for improved convergence. ", "code": "import numpy as np\n\nclass HybridAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.7  # Adjusted max cognitive factor\n        self.c2_min, self.c2_max = 1.5, 3.1  # Adjusted max social factor\n        self.w_min, self.w_max = 0.1, 0.95  # Adjusted inertia weight range\n        self.F_min, self.F_max = 0.3, 0.95  # Adjusted scaling factor\n        self.CR = 0.85  # Adjusted crossover rate for improved balance\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_learning_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(2.5 * np.pi * t)**2) * 1.9  # Enhanced chaos for dynamic exploration\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t/3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))  # Enhanced perturbation scaling\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.3)  # Refined perturbation impact\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_learning_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.75) * (1 - self.evaluations / self.budget)  # Adjusted Lvy factor\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 72, "feedback": "The algorithm HybridAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07375 with standard deviation 0.01046.", "error": "", "parent_ids": ["0f3a87fc-7fc5-48b5-b1d4-f6c7b947a103"], "operator": null, "metadata": {"aucs": [0.08820786965398886, 0.0637842701738901, 0.06925948287935757]}}
{"id": "3b4a771f-7f8d-4d0c-872b-497b7b72fa88", "fitness": 0.07722037899969432, "name": "QuantumAdaptivePSODE", "description": "Enhanced chaotic perturbation and adaptive exploration using quantum-inspired strategies for diverse solution spaces.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))  # Modified perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  # Adjusted perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 73, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["0f3a87fc-7fc5-48b5-b1d4-f6c7b947a103"], "operator": null, "metadata": {"aucs": [0.08531276577418312, 0.07541736096062468, 0.07093101026427517]}}
{"id": "c5124c29-87aa-4d05-ab3e-10d4db8f4640", "fitness": 0.07143578974142062, "name": "QuantumAdaptivePSODE", "description": "Introduction of adaptive Levy flights and inertia moment correction to enhance the global search capability and fine-tune convergence in QuantumAdaptivePSODE.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            levy_factor = np.random.standard_cauchy(self.dim) * 0.01  # Adaptive Levy flight\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.18 + levy_factor)  # Adjusted with Levy\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.15, 0.75) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 74, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07144 with standard deviation 0.00583.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.06935296597760088, 0.07939133441691826, 0.06556306882974272]}}
{"id": "6fdc9a03-a3a7-4316-93a8-2815e1f0a720", "fitness": 0.07683366293622225, "name": "QuantumAdaptivePSODE", "description": "Enhanced chaos factor dynamics and hybrid mutation strategies for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = np.sin(np.pi * t)**2  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim)) \n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  \n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.7) * (1 - self.evaluations / self.budget)  # Adjusted levy factor range\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 75, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07683 with standard deviation 0.00739.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08652671912724808, 0.06859439822201552, 0.07537987145940317]}}
{"id": "66229efc-fd55-45d8-92ce-2b54f5fe8790", "fitness": 0.07178956079852523, "name": "QuantumAdaptivePSODE", "description": "Enhanced chaotic perturbation and adaptive exploration with stochastic ranking and elite retention for improved convergence.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  \n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n        self.stochastic_ranking()\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def stochastic_ranking(self):\n        rank_order = np.argsort(self.personal_best_value)\n        self.population = self.population[rank_order]\n        self.personal_best_position = self.personal_best_position[rank_order]\n        self.personal_best_value = self.personal_best_value[rank_order]", "configspace": "", "generation": 76, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07179 with standard deviation 0.00455.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.06773581465792944, 0.07814943039284106, 0.06948343734480522]}}
{"id": "512c763a-5c62-40f5-ab3a-ffdc77fcb080", "fitness": 0.06045579844347152, "name": "EnhancedQuantumDualStrategy", "description": "Integrate adaptive diversity control and dual-phase quantum strategies for robust convergence across dynamic solution landscapes.", "code": "import numpy as np\n\nclass EnhancedQuantumDualStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.8\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dual_phase_quantum(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        self.w = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * t)**2\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dual_phase_quantum(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            if np.random.rand() < 0.5:\n                levy_factor = np.random.uniform(0.1, 0.5) * (1 - self.evaluations / self.budget)\n                mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            else:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                mutant = self.population[i] + perturbation\n\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedQuantumDualStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06046 with standard deviation 0.00320.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.06178964200958281, 0.06353582596938356, 0.056041927351448195]}}
{"id": "ede89daf-e18a-4d95-823b-492b72121caa", "fitness": 0.0772177799549183, "name": "QuantumAdaptivePSODE", "description": "Improved chaotic perturbation and adaptive exploration with enhanced stochastic exploration to boost performance for diverse solution spaces.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))  # Modified perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.25)  # Adjusted perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 78, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08531422784346365, 0.0754144063208807, 0.07092470570041054]}}
{"id": "9b253b92-89a9-4214-9a3c-3c52061758a7", "fitness": 0.07722037899969432, "name": "QuantumAdaptivePSODE", "description": "Integrating adaptive inertia weight and elite-guided mutation to boost exploitation and exploration balance.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  \n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim)) \n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  \n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 79, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08531276577418312, 0.07541736096062468, 0.07093101026427517]}}
{"id": "291b24b5-370c-4030-ac00-a169704350b3", "fitness": 0.06484300914869771, "name": "QuantumAdaptivePSODE", "description": "Introducing adaptive crossover and dynamic mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.velocity[i] *= 1 + 0.1 * np.random.randn(self.dim)  # Dynamic mutation factor\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            self.CR = 0.8 + 0.2 * np.random.rand()  # Adaptive crossover rate\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 80, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06484 with standard deviation 0.00761.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.060503601465764945, 0.07554647445629215, 0.05847895152403604]}}
{"id": "fbb7aa8a-ac8f-4815-ac41-2db5b2ac19d0", "fitness": 0.05974106567430607, "name": "QuantumAdaptivePSODEPlus", "description": "QuantumAdaptivePSODE+ with enhanced adaptive learning and differential elitism for improved exploration and convergence.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        adaptive_chaos = (np.cos(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * adaptive_chaos\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.15, (self.population_size, self.dim))  # Further tuned perturbation\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.1)  # Reduced perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 81, "feedback": "The algorithm QuantumAdaptivePSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05974 with standard deviation 0.00168.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.05788666093856476, 0.0619625292428273, 0.05937400684152616]}}
{"id": "afa76742-51dc-4e6d-bab8-5e1c3fe5ed07", "fitness": 0.07017234607765614, "name": "QuantumAdaptivePSODE", "description": "Improved adaptive exploration with hybrid quantum-inspired and differential evolution strategies for diverse solution spaces.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.95  # Tweaked parameters\n        self.CR = 0.95  # Adjusted crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.1, 0.7)  # Modified levy factor range\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 82, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07017 with standard deviation 0.01028.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08470873640311238, 0.06287456327477647, 0.06293373855507955]}}
{"id": "67a4c6bd-e3f3-4462-ab68-3c52a27d5abf", "fitness": 0.06816736537751988, "name": "QuantumAdaptivePSODE", "description": "Introducing adaptive chaotic maps for parameter tuning and enhanced exploration-exploitation balance in QuantumAdaptivePSODE.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n        # Adjust population size using a logistic map for improved exploration\n        x = 4.0 * t * (1 - t)\n        self.population_size = max(5, int(30 * x))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))  # Modified perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  # Adjusted perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 83, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06817 with standard deviation 0.00825.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.07565619142220925, 0.0721699034467218, 0.056676001263628595]}}
{"id": "63bb56dd-001e-49ea-b006-0b8e202e811e", "fitness": 0.0734056428818286, "name": "QuantumAdaptivePSODE", "description": "Introduced dynamic mutation scaling based on evaluations to enhance exploration diversity.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))  # Modified perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  # Adjusted perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 1.0 - (self.evaluations / self.budget)) * (1 - self.evaluations / self.budget)  # Dynamic mutation scaling\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 84, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07341 with standard deviation 0.00834.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08518330293472998, 0.06799659250016166, 0.06703703321059418]}}
{"id": "73b365e0-4753-40fa-b775-b2bcf2b1fa00", "fitness": 0.07688675516670289, "name": "DynamicAdaptiveQuantumPSO", "description": "Dynamic Adaptive Quantum-Inspired PSO with Chaotic Perturbations and Multi-Phase Exploration for Robust Solution Optimization.", "code": "import numpy as np\n\nclass DynamicAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n            self.multi_phase_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def multi_phase_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            perturbation_factor = np.random.uniform(0.9, 1.1)\n            new_position = self.global_best_position + perturbation_factor * (self.personal_best_position[i] - self.global_best_position)\n            new_position = np.clip(new_position, lb, ub)\n\n            new_fitness = func(new_position)\n            self.evaluations += 1\n\n            if new_fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = new_fitness\n                self.personal_best_position[i] = new_position.copy()\n\n                if new_fitness < self.global_best_value:\n                    self.global_best_value = new_fitness\n                    self.global_best_position = new_position.copy()", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07689 with standard deviation 0.00616.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08523140742196345, 0.07488994701354901, 0.0705389110645962]}}
{"id": "d7ced32c-6730-4cb7-91bc-84ea0c68851f", "fitness": 0.07722037899969432, "name": "EnhancedQuantumAdaptivePSODE", "description": "Enhanced Quantum-Inspired Hybrid Optimization Algorithm using Dynamic Diversity Preservation for Improved Global Exploration and Convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adjust_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n            self.dynamic_diversity_preservation(lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adjust_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.25, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def dynamic_diversity_preservation(self, lb, ub):\n        if self.evaluations >= self.budget * 0.8:  # Activate near the end of budget\n            distances = np.linalg.norm(self.population - self.global_best_position, axis=1)\n            mean_distance = np.mean(distances)\n            diversity_threshold = mean_distance * 0.5\n\n            for i in range(self.population_size):\n                if distances[i] < diversity_threshold:\n                    self.population[i] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                    self.velocity[i] = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=self.dim)", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08531276577418312, 0.07541736096062468, 0.07093101026427517]}}
{"id": "c664c87e-7968-4a6f-8327-d61b961b99c8", "fitness": 0.07497249413885036, "name": "QuantumAdaptivePSODE", "description": "Refined chaotic perturbation with hybrid crossover for enhanced global search and stability.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.95  # Increased crossover rate\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        perturbation = np.random.normal(0, 0.2, (self.population_size, self.dim))  # Reduced perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.5)  # Increased perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 87, "feedback": "The algorithm QuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07497 with standard deviation 0.00840.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08684119692292025, 0.06861946157753518, 0.06945682391609564]}}
{"id": "11d8aa15-4142-447d-83e9-fdcade492fd5", "fitness": 0.07722246924028331, "name": "EnhancedQuantumAdaptivePSODE", "description": "Enhanced Quantum-inspired PSO with Adaptive Dynamic Scaling and Chaotic Mutation for Improved Convergence in Diverse Solution Spaces.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0  # Enhanced dynamic exploration factor\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))  # Dynamic scaling\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))  # Adjusted perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)  # Adjusted perturbation influence\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["3b4a771f-7f8d-4d0c-872b-497b7b72fa88"], "operator": null, "metadata": {"aucs": [0.08531162640896572, 0.07541973155771653, 0.07093604975416767]}}
{"id": "72d936b6-1596-444c-a125-51b8e1765116", "fitness": 0.07722246924028331, "name": "AdvancedQuantumAdaptivePSO", "description": "Advanced Quantum Adaptive PSO with Stochastic Rewiring and Adaptive Mutation for Enhanced Convergence and Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass AdvancedQuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.stochastic_rewiring(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def stochastic_rewiring(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 89, "feedback": "The algorithm AdvancedQuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["11d8aa15-4142-447d-83e9-fdcade492fd5"], "operator": null, "metadata": {"aucs": [0.08531162640896572, 0.07541973155771653, 0.07093604975416767]}}
{"id": "014ca872-4fa0-4caa-ad35-c212f20bebe9", "fitness": 0.05914372499664422, "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive PSO with Nonlinear Time-Varying Strategies and Chaotic Differential Mutation for Accelerated Convergence and Solution Diversity.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.w_min, self.w_max = 0.4, 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.chaotic_mutation(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t**2)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t**2\n        self.w = self.w_max * (1 - t) + self.w_min * t\n        self.population_size = max(5, int(50 * (1 - t / 2)))\n\n    def update_particles(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def chaotic_mutation(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            # Chaotic Differential Mutation\n            beta = 0.5 + 0.3 * np.cos(3 * np.pi * self.evaluations / self.budget)\n            mutant = elite + beta * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 90, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05914 with standard deviation 0.00187.", "error": "", "parent_ids": ["11d8aa15-4142-447d-83e9-fdcade492fd5"], "operator": null, "metadata": {"aucs": [0.05660842407734379, 0.06106047334302911, 0.05976227756955976]}}
{"id": "d1c3a29f-4265-4b94-b2b6-3f2d806d4c6c", "fitness": 0.07721832343253994, "name": "EnhancedQuantumAdaptivePSODE", "description": "Improved exploration by enhancing perturbation influence in the velocity update.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        self.population_size = max(5, int(30 * (1 - t / 3)))\n\n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.3 * scaling_factor, (self.population_size, self.dim))  # Adjusted perturbation range\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.2)\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.2, 0.8) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07722 with standard deviation 0.00601.", "error": "", "parent_ids": ["11d8aa15-4142-447d-83e9-fdcade492fd5"], "operator": null, "metadata": {"aucs": [0.08531398205128948, 0.07541502066690742, 0.07092596757942293]}}
{"id": "f392f9e9-5928-45c9-a95e-9ab1fd453aff", "fitness": 0.07776868269275106, "name": "EnhancedQuantumAdaptivePSODE", "description": "Enhanced Quantum-inspired PSO with Improved Levy Mutation and Adaptive Velocity Clamping for Better Convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15) \n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07777 with standard deviation 0.00597.", "error": "", "parent_ids": ["11d8aa15-4142-447d-83e9-fdcade492fd5"], "operator": null, "metadata": {"aucs": [0.08613713150920788, 0.07263784108042681, 0.07453107548861848]}}
{"id": "0b70dba4-1d6f-428e-939a-c966270acc23", "fitness": 0.07771946311482998, "name": "HybridAdaptiveQuantumPSO", "description": "Hybrid Particle Swarm Optimization with Adaptive Quantum Mutation and Chaos-Driven Selection to Enhance Global Convergence and Stability.", "code": "import numpy as np\n\nclass HybridAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n            self.chaos_selection(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15) \n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n    \n    def chaos_selection(self, func, lb, ub):\n        chaos_factor = np.random.rand() * (1 - self.evaluations / self.budget)\n        if chaos_factor < 0.05:\n            for i in range(self.population_size):\n                chaos_candidate = lb + (ub - lb) * np.random.rand(self.dim)\n                chaos_fitness = func(chaos_candidate)\n                if chaos_fitness < self.personal_best_value[i]:\n                    self.personal_best_value[i] = chaos_fitness\n                    self.personal_best_position[i] = chaos_candidate.copy()\n                    \n                if chaos_fitness < self.global_best_value:\n                    self.global_best_value = chaos_fitness\n                    self.global_best_position = chaos_candidate.copy()", "configspace": "", "generation": 93, "feedback": "The algorithm HybridAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07772 with standard deviation 0.00547.", "error": "", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {"aucs": [0.0853679148161538, 0.07293055470530108, 0.07485991982303508]}}
{"id": "167c05b0-f6a4-49e1-b2b3-2622ef070555", "fitness": 0.07757646230381447, "name": "EnhancedQuantumAdaptivePSODE", "description": "Enhanced Quantum-inspired PSO with Hybrid Mutation Strategy and Dynamic Population Resizing for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.dynamic_population_resizing()\n            self.update_particles(func, lb, ub)\n            self.hybrid_mutation_strategy(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n\n    def dynamic_population_resizing(self):\n        if self.evaluations > self.budget // 2 and self.population_size > 10:\n            self.population_size = max(10, self.population_size - 1)\n            self.population = self.population[:self.population_size]\n            self.velocity = self.velocity[:self.population_size]\n            self.personal_best_position = self.personal_best_position[:self.population_size]\n            self.personal_best_value = self.personal_best_value[:self.population_size]\n\n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15) \n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def hybrid_mutation_strategy(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07758 with standard deviation 0.00569.", "error": "", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {"aucs": [0.08550874294941468, 0.07240985245614229, 0.07481079150588643]}}
{"id": "2dc8ce1a-7a8f-4f38-b24a-2450b5b77cd1", "fitness": 0.06949964317137296, "name": "EnhancedQuantumAdaptivePSODE", "description": "Introducing a dynamic crossover rate in the quantum exploration phase to enhance diversity and exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15) \n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * (self.evaluations / self.budget))  # Changed line\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06950 with standard deviation 0.00650.", "error": "", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {"aucs": [0.0767085139140079, 0.060962186174293276, 0.07082822942581768]}}
{"id": "9b103485-7374-4e23-a128-755d8842095d", "fitness": 0.07590707488394617, "name": "HybridQuantumAdaptivePSO", "description": "Hybrid Quantum-Inspired Adaptive PSO with Dynamic Neighborhoods for Enhanced Diversity and Convergence.", "code": "import numpy as np\n\nclass HybridQuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.neighborhood_size = 5\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            neighborhood_best = self.find_neighborhood_best(i)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (neighborhood_best - self.population[i]) +\n                                perturbation[i] * 0.15) \n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def find_neighborhood_best(self, index):\n        start = max(0, index - self.neighborhood_size // 2)\n        end = min(self.population_size, index + self.neighborhood_size // 2 + 1)\n        neighborhood_indices = list(range(start, end))\n        neighborhood_indices.remove(index)\n        neighborhood_best_index = min(neighborhood_indices, key=lambda i: self.personal_best_value[i])\n        return self.personal_best_position[neighborhood_best_index]\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 96, "feedback": "The algorithm HybridQuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07591 with standard deviation 0.00463.", "error": "", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {"aucs": [0.08244717355712194, 0.07233121004526577, 0.07294284104945081]}}
{"id": "60129aa4-163a-4568-b703-cf9c52d587a9", "fitness": -Infinity, "name": "EnhancedQuantumAdaptivePSODEPlus", "description": "Enhanced Quantum-inspired PSO with Dynamic Swarm Restructuring and Adaptive Differential Perturbation for Superior Convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n            self.dynamic_swarm_restructuring()\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.cos(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n\n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.5 * np.cos(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.2 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15)\n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()\n\n    def dynamic_swarm_restructuring(self):\n        dist_matrix = np.linalg.norm(self.population[:, np.newaxis, :] - self.population[np.newaxis, :, :], axis=2)\n        dist_threshold = np.mean(dist_matrix) * 0.5\n        for i in range(self.population_size):\n            neighbors = np.where(dist_matrix[i] < dist_threshold)[0]\n            if len(neighbors) > 1:\n                local_best_idx = neighbors[np.argmin(self.personal_best_value[neighbors])]\n                local_best_position = self.personal_best_position[local_best_idx]\n                r = np.random.rand(self.dim)\n                self.population[i] = self.population[i] + r * (local_best_position - self.population[i])\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)", "configspace": "", "generation": 97, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {}}
{"id": "fb80639a-2055-4ffa-96e2-8e6e604635ab", "fitness": 0.07777444878962607, "name": "EnhancedQuantumAdaptivePSODE", "description": "Enhanced Quantum-inspired PSO with adjusted perturbation scaling and chaotic velocity for improved exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.quantum_exploration(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.7 * np.sin(np.pi * self.evaluations / self.budget))  # Changed from 0.5\n        perturbation = np.random.normal(0, 0.1 * scaling_factor, (self.population_size, self.dim))  # Changed from 0.2\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15)\n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_exploration(self, func, lb, ub):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite_index = np.argmin(self.personal_best_value)\n            elite = self.personal_best_position[elite_index]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            levy_factor = np.random.uniform(0.3, 0.9) * (1 - self.evaluations / self.budget)\n            mutant = elite + levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07777 with standard deviation 0.00596.", "error": "", "parent_ids": ["f392f9e9-5928-45c9-a95e-9ab1fd453aff"], "operator": null, "metadata": {"aucs": [0.08613703150562202, 0.07264124028616303, 0.07454507457709314]}}
{"id": "70e9e61f-862a-4a05-abd0-a593d9c057d3", "fitness": 0.06541004902177043, "name": "RefinedQuantumAdaptivePSODE", "description": "Refined Quantum-inspired PSO with dynamic elite selection and adaptive mutation for enhanced global search capability.", "code": "import numpy as np\n\nclass RefinedQuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 3.0\n        self.w_min, self.w_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_value = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adaptive_parameters()\n            self.update_particles(func, lb, ub)\n            self.dynamic_elite_selection_and_mutation(func, lb, ub)\n\n        return self.global_best_position\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        self.velocity = np.random.uniform(low=-abs(ub - lb), high=abs(ub - lb), size=(self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.array([float('inf')] * self.population_size)\n\n    def adaptive_parameters(self):\n        t = self.evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - t)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * t\n        chaos_factor = (np.sin(np.pi * t)**2) * 2.0\n        self.w = self.w_min + (self.w_max - self.w_min) * chaos_factor\n        self.F = self.F_min + (self.F_max - self.F_min) * (1 - t)\n        \n    def update_particles(self, func, lb, ub):\n        scaling_factor = 1.0 + (0.7 * np.sin(np.pi * self.evaluations / self.budget))\n        perturbation = np.random.normal(0, 0.1 * scaling_factor, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            fitness = func(self.population[i])\n            self.evaluations += 1\n\n            if fitness < self.personal_best_value[i]:\n                self.personal_best_value[i] = fitness\n                self.personal_best_position[i] = self.population[i].copy()\n\n            if fitness < self.global_best_value:\n                self.global_best_value = fitness\n                self.global_best_position = self.population[i].copy()\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.population[i]) +\n                                perturbation[i] * 0.15)\n            self.velocity[i] = np.clip(self.velocity[i], -abs(ub-lb), abs(ub-lb))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def dynamic_elite_selection_and_mutation(self, func, lb, ub):\n        elite_indices = np.argpartition(self.personal_best_value, 3)[:3]\n        elites = self.personal_best_position[elite_indices]\n\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n\n            elite = elites[np.random.randint(0, len(elites))]\n\n            candidates = list(range(self.population_size))\n            candidates.remove(i)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n\n            adaptive_levy_factor = np.random.uniform(0.3, 1.0) * (1 - self.evaluations / self.budget)\n            mutant = elite + adaptive_levy_factor * (self.population[a] - self.population[b])\n            mutant = np.clip(mutant, lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n\n            trial_fitness = func(trial)\n            self.evaluations += 1\n\n            if trial_fitness < self.personal_best_value[i]:\n                self.population[i] = trial\n                self.personal_best_value[i] = trial_fitness\n                self.personal_best_position[i] = trial.copy()\n\n                if trial_fitness < self.global_best_value:\n                    self.global_best_value = trial_fitness\n                    self.global_best_position = trial.copy()", "configspace": "", "generation": 99, "feedback": "The algorithm RefinedQuantumAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06541 with standard deviation 0.00113.", "error": "", "parent_ids": ["fb80639a-2055-4ffa-96e2-8e6e604635ab"], "operator": null, "metadata": {"aucs": [0.06411093678317958, 0.0668700639359966, 0.0652491463461351]}}
