{"id": "af107257-7dc5-4915-9b54-68be703ee32d", "fitness": 0.05409101967372776, "name": "HybridPSODE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization and differential evolution for robust search and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Number of particles/agents\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7  # Inertia weight\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05409 with standard deviation 0.00222.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.051219214631943566, 0.054645767167428416, 0.05097180615099861, 0.05325313777016083, 0.05682588742139161, 0.052987962714491244, 0.05450866855805225, 0.058174857160442794, 0.0542318754886405]}}
{"id": "f8cfef98-a15d-45f4-b5f2-639b8bc02a5e", "fitness": 0.052825779028088174, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm combining adaptive particle swarm optimization and differential evolution with dynamic parameter adjustment for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_initial = 2.0  \n        self.c2_initial = 2.0  \n        self.w_initial = 0.9   \n        self.w_final = 0.4     \n        self.F = 0.8  \n        self.CR = 0.9  \n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def dynamic_parameters(self, evaluations):\n        c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n        c2 = self.c2_initial - (self.c2_initial - 1.5) * (evaluations / self.budget)\n        w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n        return c1, c2, w\n\n    def pso_step(self, func, evaluations):\n        c1, c2, w = self.dynamic_parameters(evaluations)\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05283 with standard deviation 0.00269.", "error": "", "parent_ids": ["af107257-7dc5-4915-9b54-68be703ee32d"], "operator": null, "metadata": {"aucs": [0.0489278107096881, 0.054164711037676616, 0.050083206306747785, 0.05086602170559973, 0.056323274251826705, 0.05206352528064995, 0.052060439322552665, 0.057658414344236686, 0.053284608293815316]}}
{"id": "fb07f92e-4f19-46a6-8e13-f145274beb9d", "fitness": 0.05409101967372776, "name": "HybridPSODE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization and differential evolution with optimized differential weight for robust search and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Number of particles/agents\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7  # Inertia weight\n        self.F = 0.9  # Differential weight (changed from 0.8 to 0.9)\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05409 with standard deviation 0.00222.", "error": "", "parent_ids": ["af107257-7dc5-4915-9b54-68be703ee32d"], "operator": null, "metadata": {"aucs": [0.051219214631943566, 0.054645767167428416, 0.05097180615099861, 0.05325313777016083, 0.05682588742139161, 0.052987962714491244, 0.05450866855805225, 0.058174857160442794, 0.0542318754886405]}}
{"id": "d47fc828-8d1f-4886-a95d-c2bb3a51d091", "fitness": 0.053902663046660075, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic algorithm with improved inertia weight dynamics for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Number of particles/agents\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9  # Improved Inertia weight for better balance between exploration and exploitation\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05390 with standard deviation 0.00221.", "error": "", "parent_ids": ["af107257-7dc5-4915-9b54-68be703ee32d"], "operator": null, "metadata": {"aucs": [0.05204613244039347, 0.054164711037676616, 0.050083206306747785, 0.05411210238779518, 0.056323274251826705, 0.05206352528064995, 0.05538799307679898, 0.057658414344236686, 0.053284608293815316]}}
{"id": "b39f7e2a-4f3e-4ff9-9090-208ed335c9c1", "fitness": 0.053902663046660075, "name": "HybridPSODE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization and differential evolution with adaptive inertia weight for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Number of particles/agents\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9  # Inertia weight (adjusted for improvement)\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05390 with standard deviation 0.00221.", "error": "", "parent_ids": ["af107257-7dc5-4915-9b54-68be703ee32d"], "operator": null, "metadata": {"aucs": [0.05204613244039347, 0.054164711037676616, 0.050083206306747785, 0.05411210238779518, 0.056323274251826705, 0.05206352528064995, 0.05538799307679898, 0.057658414344236686, 0.053284608293815316]}}
{"id": "7994d92a-438c-4326-9bbb-6db56221be0d", "fitness": 0.05462114747211089, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic integrating particle swarm optimization and differential evolution with adaptive parameters to enhance convergence in black-box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.99  # Decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05462 with standard deviation 0.00178.", "error": "", "parent_ids": ["af107257-7dc5-4915-9b54-68be703ee32d"], "operator": null, "metadata": {"aucs": [0.05263390030608728, 0.054164711037676616, 0.05157426226531969, 0.05472581044872438, 0.056323274251826705, 0.053615763609959566, 0.0560183252046379, 0.057658414344236686, 0.054875865780529165]}}
{"id": "7270d86d-f677-4bf6-9fee-e33eb20f0b12", "fitness": 0.05445174613097992, "name": "EnhancedHybridPSODE", "description": "Introduce dynamic parameter tuning and population diversity preservation with adaptive mutation strategies to enhance convergence and robustness in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.99\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.eps = 1e-8  # Small epsilon for stability\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n        self.dynamic_parameter_tuning(scores)\n\n    def dynamic_parameter_tuning(self, scores):\n        diversity = np.mean(np.std(self.population, axis=0))\n        self.c1 = np.clip(self.c1 + np.random.uniform(-0.1, 0.1) * diversity, 1.0, 2.0)\n        self.c2 = np.clip(self.c2 + np.random.uniform(-0.1, 0.1) * diversity, 1.0, 2.0)\n\n    def adaptive_de_step(self, bounds, scores):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        sorted_indices = np.argsort(scores)\n        for i in sorted_indices:\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = self.F + np.random.uniform(-0.2, 0.2)\n            mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < self.personal_best_scores[i]:\n                new_population[i] = trial\n                self.personal_best_scores[i] = func(trial)\n                self.personal_best_positions[i] = trial\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.adaptive_de_step(bounds, self.personal_best_scores)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05445 with standard deviation 0.00234.", "error": "", "parent_ids": ["7994d92a-438c-4326-9bbb-6db56221be0d"], "operator": null, "metadata": {"aucs": [0.05363133728097358, 0.054164711037676616, 0.050083206306747785, 0.0557677803064478, 0.056323274251826705, 0.05206352528064995, 0.057088858076444815, 0.057658414344236686, 0.053284608293815316]}}
{"id": "c147cfdc-f1eb-436e-9d91-e416656e124f", "fitness": 0.05462114747211089, "name": "EnhancedRefinedHybridPSODE", "description": "EnhancedRefinedHybridPSODE: An enhanced hybrid strategy integrating particle swarm optimization, differential evolution, and an adaptive mutation mechanism for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedRefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.99  # Decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.adaptive_mutation_rate = 0.1  # Initial mutation rate for enhanced exploration\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n            else:\n                # Implement adaptive mutation if no improvement\n                mutation_rate = self.adaptive_mutation_rate * np.random.rand(self.dim)\n                mutated = np.clip(self.population[i] + mutation_rate * (ub - lb), lb, ub)\n                new_population[i] = mutated if func(mutated) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedRefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05462 with standard deviation 0.00178.", "error": "", "parent_ids": ["7994d92a-438c-4326-9bbb-6db56221be0d"], "operator": null, "metadata": {"aucs": [0.05263390030608728, 0.054164711037676616, 0.05157426226531969, 0.05472581044872438, 0.056323274251826705, 0.053615763609959566, 0.0560183252046379, 0.057658414344236686, 0.054875865780529165]}}
{"id": "473189dc-3b1b-42cc-8cba-c27085f4ea77", "fitness": -Infinity, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic integrating particle swarm optimization and differential evolution with adaptive parameters and a dynamic population size to enhance convergence in black-box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.99  # Decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["7994d92a-438c-4326-9bbb-6db56221be0d"], "operator": null, "metadata": {}}
{"id": "f6cbea62-f5e1-4bb3-90af-c657d5fcc4b3", "fitness": 0.05432732871741235, "name": "EnhancedHybridPSODE", "description": "Enhanced Hybrid PSO-DE with Dynamic Strategy Switching and Adaptive Parameter Control for Robust Black-Box Optimization", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.99  # Decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.strategy_switch = 0.5  # Proportion of budget to dynamically switch\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, func, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            new_population[i] = trial if func(trial) < func(self.population[i]) else self.population[i]\n        self.population = new_population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n        use_pso = True  # Start with PSO\n\n        while evaluations < self.budget:\n            if evaluations < self.budget * self.strategy_switch:\n                if use_pso:\n                    self.pso_step(func)\n                else:\n                    self.de_step(func, bounds)\n                use_pso = not use_pso  # Switch strategies\n            else:\n                # Use PSO predominantly in the second phase for fine-tuning\n                self.pso_step(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05433 with standard deviation 0.00283.", "error": "", "parent_ids": ["7994d92a-438c-4326-9bbb-6db56221be0d"], "operator": null, "metadata": {"aucs": [0.05170738930018859, 0.055727708518035435, 0.050083206306747785, 0.05375937042604717, 0.057956727687382026, 0.05206352528064995, 0.055026335638771684, 0.05933708700507323, 0.053284608293815316]}}
{"id": "4a859258-fedb-4e73-8487-c495cc3e046a", "fitness": 0.05595090888197164, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic combining adaptive particle swarm optimization, differential evolution, and variable population size strategy to optimize convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.98  # Modified decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        # Reduce population size as budget decreases to focus on exploitation\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05595 with standard deviation 0.00146.", "error": "", "parent_ids": ["7994d92a-438c-4326-9bbb-6db56221be0d"], "operator": null, "metadata": {"aucs": [0.053713340578383284, 0.05428188896193431, 0.0542103310341302, 0.05585311981639729, 0.05644565994790396, 0.05637649207059525, 0.05717632246708737, 0.05778413907135904, 0.05771688598995406]}}
{"id": "2329903a-ecfb-4517-9bb6-546fc187ecf7", "fitness": 0.05280729611564042, "name": "EnhancedHybridPSODE", "description": "A refined hybrid algorithm integrating adaptive PSO and DE with a new inertia weight update and mutation strategy to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 2.0  # Updated cognitive component\n        self.w = 0.9\n        self.w_decay = 0.95  # Modified decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.current_population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05281 with standard deviation 0.00308.", "error": "", "parent_ids": ["4a859258-fedb-4e73-8487-c495cc3e046a"], "operator": null, "metadata": {"aucs": [0.04764630178860163, 0.054164711037676616, 0.05130904297617778, 0.04953440161262246, 0.056323274251826705, 0.053339689962828674, 0.05069695812074704, 0.057658414344236686, 0.054592870946046146]}}
{"id": "17f83de9-0afa-4716-91a5-78ee1d0f73b8", "fitness": 0.0569562897045803, "name": "ImprovedHybridPSODE", "description": "An improved metaheuristic combining adaptive PSO, DE, and chaotic initialization for enhanced exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.95  # Slightly increased decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        \"\"\"Initializes population using a chaotic map for improved exploration.\"\"\"\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7  # Arbitrary starting point for chaotic map\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)  # Logistic map\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        # Reduce population size as budget decreases to focus on exploitation\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05696 with standard deviation 0.00242.", "error": "", "parent_ids": ["4a859258-fedb-4e73-8487-c495cc3e046a"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05404362761450798, 0.057650226684348826, 0.05555793597494796, 0.05618795405970001, 0.05995791323376887, 0.05686695912693773, 0.05751370135737954, 0.06138854780002523]}}
{"id": "d8028462-ff0b-4564-9b4b-5e5b7f6012a9", "fitness": 0.05549332596696382, "name": "AdvancedHybridPSODE", "description": "A novel hybrid metaheuristic leveraging adaptive PSO, DE, chaos theory, and Levy flights for enhanced global and local search in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.93\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            levy = self.levy_flight()\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + levy\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05549 with standard deviation 0.00145.", "error": "", "parent_ids": ["17f83de9-0afa-4716-91a5-78ee1d0f73b8"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.0540325870103594, 0.05343974148960651, 0.05555793597494796, 0.0561763464869065, 0.05555793597494796, 0.05686695912693773, 0.057501727022424065, 0.05686695912693773]}}
{"id": "aa54d216-bece-475c-adbe-7366b77c9f74", "fitness": 0.0569562897045803, "name": "ImprovedHybridPSODE", "description": "Introducing mutation scaling adaptation to finetune exploration and exploitation balance in DE step.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive inertia weight, starting high\n        self.w_decay = 0.95  # Slightly increased decay rate for inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        \"\"\"Initializes population using a chaotic map for improved exploration.\"\"\"\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7  # Arbitrary starting point for chaotic map\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)  # Logistic map\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay  # Decaying inertia weight for balance between exploration and exploitation\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # New mutation scaling adaptation\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        # Reduce population size as budget decreases to focus on exploitation\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05696 with standard deviation 0.00242.", "error": "", "parent_ids": ["17f83de9-0afa-4716-91a5-78ee1d0f73b8"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05404362761450798, 0.057650226684348826, 0.05555793597494796, 0.05618795405970001, 0.05995791323376887, 0.05686695912693773, 0.05751370135737954, 0.06138854780002523]}}
{"id": "6094d5e6-74f2-458e-9f79-ba42fe7a4e35", "fitness": 0.046582107389128775, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic algorithm that introduces an adaptive population size management and Lvy flight mechanism to improve exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1/L)\n        return step\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n        self.w *= self.w_decay\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def levy_flight_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.current_population_size):\n            levy_step = self.levy_flight(1.5)\n            self.population[i] += levy_step\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 3 == 0:\n                self.pso_step(func)\n            elif evaluations % 3 == 1:\n                self.de_step(bounds, func)\n            else:\n                self.levy_flight_step(bounds)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04658 with standard deviation 0.00167.", "error": "", "parent_ids": ["17f83de9-0afa-4716-91a5-78ee1d0f73b8"], "operator": null, "metadata": {"aucs": [0.04388232616413401, 0.04440773074985738, 0.045761213736234096, 0.046022059492454304, 0.046570105480055135, 0.047984237745304914, 0.047344395798392, 0.04790692788206041, 0.04935996945366672]}}
{"id": "f4aa4d04-a015-4185-856b-2c5f72b6843d", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE integrates Lvy flight and elite preservation with adaptive PSO and DE for superior exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, lb, ub):\n        num_steps = self.initial_population_size // 5\n        lf_population = np.zeros((num_steps, self.dim))\n        for i in range(num_steps):\n            step_size = np.random.standard_normal(self.dim) * 0.01\n            step = np.tan(np.pi * (np.random.rand() - 0.5)) * step_size\n            lf_population[i] = np.clip(self.global_best_position + step, lb, ub)\n        return lf_population\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.population = np.vstack((self.population, self.levy_flight(lb, ub)))\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\")", "parent_ids": ["17f83de9-0afa-4716-91a5-78ee1d0f73b8"], "operator": null, "metadata": {}}
{"id": "3bc50599-b592-41fd-b07b-05e49a19775c", "fitness": 0.05730145593701937, "name": "EnhancedHybridPSODE", "description": "Introduce neighborhood attraction and chaos-enhanced mutation to improve convergence and exploration in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00254.", "error": "", "parent_ids": ["17f83de9-0afa-4716-91a5-78ee1d0f73b8"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.054448666085929576, 0.05566971894701278, 0.060463780231907016, 0.05661175643258243, 0.056981684589243575, 0.061912240747747704, 0.05794957287410174]}}
{"id": "f3bb7219-ab04-4223-a26b-9f6b562f9804", "fitness": 0.05717524875518355, "name": "EnhancedHybridPSODE", "description": "Enhance convergence and exploration by dynamically adjusting chaotic mutation and incorporating levy flight for perturbation in hybrid PSO-DE.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        mutation_factor = x * (1 - x) * 4\n        return lb + (ub - lb) * mutation_factor\n\n    def levy_flight_perturbation(self, individual):\n        return individual + 0.01 * levy.rvs(size=self.dim)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            trial = self.levy_flight_perturbation(trial)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00259.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05408510231755104, 0.05566971894701278, 0.060463780231907016, 0.056231106324998836, 0.056981684589243575, 0.061912240747747704, 0.05755792211354149]}}
{"id": "fbd4afc6-7ca8-479b-832b-3685e4e1a0b5", "fitness": 0.05582736137227161, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive inertia weight and Levy flight-based mutation to enhance exploration and exploitation in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def levy_flight(self, L=1.5):\n        u = np.random.normal(0, 1, size=self.dim) * (np.sqrt(np.pi) / 2) ** (1 / L)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / L))\n        return step\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        w_adaptive = self.w * (1 - (self.global_best_score / np.max(self.personal_best_scores + 1e-10)))\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = w_adaptive * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial += self.levy_flight() * (ub - lb) * 0.01\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05583 with standard deviation 0.00150.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.05589987669967034, 0.05555793597494796, 0.05649121016388148, 0.05555793597494796, 0.05826226693152681, 0.0569305844993192, 0.05686695912693773]}}
{"id": "9209a278-0295-4de0-b9f9-2bee70e88258", "fitness": 0.05718265158559102, "name": "EnhancedHybridPSODE", "description": "Introduce slight variation in chaos-enhanced mutation by modifying its calculation to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 3.9)  # Slight variation here\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00258.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05410648619331415, 0.05566971894701278, 0.060463780231907016, 0.05625342707671832, 0.056981684589243575, 0.061912240747747704, 0.0575808429597261]}}
{"id": "dcd466d3-d46c-447b-b303-8d59feb5aaf5", "fitness": 0.055520418766166674, "name": "EnhancedHybridPSODERefined", "description": "Integrate adaptive inertia weight and Lvy flight mechanism to further enhance exploration and exploitation in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adapt_inertia_weight(self, evaluations):\n        return self.w_min + (self.w_max - self.w_min) * (1 - evaluations / self.budget)\n\n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        w = self.adapt_inertia_weight(evaluations)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + 0.01 * self.levy_flight()\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05552 with standard deviation 0.00144.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.053982147972740924, 0.053568464714693675, 0.05343974148960651, 0.056123648738775955, 0.055692320139999474, 0.05555793597494796, 0.057447580428703904, 0.057004970309093905, 0.05686695912693773]}}
{"id": "7ad0c5df-e71e-4088-975f-43481e00adbb", "fitness": 0.05587830030274658, "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic inertia weight update strategy based on diversity to improve exploration and exploitation balance in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        # Changed line: Dynamic inertia weight update based on population diversity\n        self.w = 0.9 - (0.5 * np.std(self.population))\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05588 with standard deviation 0.00166.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.05513776920391256, 0.05555793597494796, 0.05555793597494796, 0.05733788761886027, 0.05686695912693773, 0.05686695912693773, 0.058699772718961984]}}
{"id": "f1305ea7-253d-49f4-a188-20dc6bb02007", "fitness": 0.055910660369275514, "name": "EnhancedHybridPSODE", "description": "Update inertia weight decay strategy for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.99  # Updated line: changed from 0.95 to 0.99\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05591 with standard deviation 0.00168.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.055236244691003744, 0.05343974148960651, 0.05343974148960651, 0.057434893589105696, 0.05555793597494796, 0.05555793597494796, 0.058795531860385775, 0.05686695912693773, 0.05686695912693773]}}
{"id": "e1e2545c-4760-420e-bec1-d68f2e2562af", "fitness": 0.05534992553870442, "name": "EnhancedHybridPSODE", "description": "Introduce a nonlinear weight decay to improve the balance between exploration and exploitation in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay**0.5  # Nonlinear weight decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05535 with standard deviation 0.00141.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.053501355102915316, 0.05355655586396735, 0.05555793597494796, 0.055622176649030575, 0.055679752149760287, 0.05686695912693773, 0.05693287939993896, 0.05699197409123513]}}
{"id": "f57f0ff3-a52e-4512-86cc-048431b54165", "fitness": 0.05717524875518355, "name": "EnhancedHybridPSODE", "description": "Fine-tune the scaling factor for chaos-enhanced mutation to improve diversity and exploration in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 3.5)  # Adjusted chaos scaling factor\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00259.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05408510231755104, 0.05566971894701278, 0.060463780231907016, 0.056231106324998836, 0.056981684589243575, 0.061912240747747704, 0.05755792211354149]}}
{"id": "4534657d-d210-4c20-a0c3-0466f4e7e03b", "fitness": 0.05488861959644652, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive chaotic factor in the chaotic initialization to diversify initial solutions in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        chaotic_factor = np.random.uniform(3.7, 4.0)  # Modified line\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = chaotic_factor * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05489 with standard deviation 0.00352.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.049078225601126735, 0.056672021459059585, 0.05337331284994551, 0.05103222555396614, 0.058954728505860365, 0.05548690540738921, 0.05223704957377673, 0.06037018435640418, 0.05679292306049022]}}
{"id": "63d5bf14-e14f-40a8-8433-2c38fbc28146", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridPSODE", "description": "Incorporate adaptive learning rates and dynamic population clustering to enhance exploration and exploitation in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_learning_rate(self, scores):\n        return np.mean(scores) / np.std(scores) if np.std(scores) != 0 else 1.0\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        learning_rate = self.adaptive_learning_rate(scores)\n\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + learning_rate * (cognitive_component + social_component + 0.1 * neighborhood_attraction)\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def dynamic_clustering(self, scores):\n        threshold = np.median(scores)\n        cluster = [i for i, s in enumerate(scores) if s < threshold]\n        return cluster if cluster else list(range(self.current_population_size))\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        cluster = self.dynamic_clustering(self.personal_best_scores)\n\n        for i in cluster:\n            idxs = [idx for idx in cluster if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {}}
{"id": "7cb7a59b-8622-40a9-9694-62acb1bd2901", "fitness": 0.05717524875518355, "name": "EnhancedHybridPSODE", "description": "Introduce a small decay in the chaos-enhanced mutation rate to balance exploration and exploitation gradually.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4 * self.w_decay)  # Added decay to chaos mutation\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00259.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05408510231755104, 0.05566971894701278, 0.060463780231907016, 0.056231106324998836, 0.056981684589243575, 0.061912240747747704, 0.05755792211354149]}}
{"id": "2a8c0ba7-8596-4d50-9e80-1e5124ffb4aa", "fitness": 0.05730145593701937, "name": "EnhancedHybridPSODE", "description": "Enhance the exploration of EnhancedHybridPSODE further by dynamically adjusting the chaos parameter in the chaotic initialization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7  # Change the initial value of x to introduce more variability\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00254.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.054448666085929576, 0.05566971894701278, 0.060463780231907016, 0.05661175643258243, 0.056981684589243575, 0.061912240747747704, 0.05794957287410174]}}
{"id": "d0033e2b-2557-4ca0-93af-095bb3aa7faf", "fitness": 0.05549323551505241, "name": "AdvancedHybridPSODE", "description": "Introduce adaptive velocity scaling and self-tuning parameters to enhance convergence and robustness in hybrid PSO-DE.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_scale = 0.1  # Initial velocity scale\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim)) * self.velocity_scale\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n            self.update_velocity_scale(evaluations)\n\n    def update_velocity_scale(self, evaluations):\n        self.velocity_scale = 0.1 + 0.9 * (evaluations / self.budget)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05549 with standard deviation 0.00144.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05349419728139626, 0.0539779467251813, 0.05555793597494796, 0.05561471494194037, 0.05611928578323344, 0.05686695912693773, 0.056925223461178676, 0.05744311485104947]}}
{"id": "4e1477e6-cad9-4e9f-8084-f0861b03d557", "fitness": 0.0553836017701344, "name": "EnhancedHybridPSODE_v2", "description": "Introduce adaptive learning rates and dynamic inertia weight adjustment to enhance convergence and robustness in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.learning_rate_adjustment = 0.05\n        self.inertia_weight_min = 0.4\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w = max(self.inertia_weight_min, self.w * self.w_decay)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n        if np.random.rand() < self.learning_rate_adjustment:\n            self.c1 += np.random.uniform(-0.1, 0.1)\n            self.c2 += np.random.uniform(-0.1, 0.1)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSODE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05538 with standard deviation 0.00142.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.053715506661309864, 0.05343974148960651, 0.05555793597494796, 0.0558455252093889, 0.05555793597494796, 0.05686695912693773, 0.05716211087752643, 0.05686695912693773]}}
{"id": "31931b28-cdc7-4ee8-8db8-3213de49184c", "fitness": 0.05585583598068406, "name": "RefinedHybridPSODE", "description": "Incorporate adaptive inertia weight and elitist learning into the hybrid PSO-DE to enhance convergence stability and exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        inertia_weight = self.adaptive_inertia_weight(evaluations)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            elitist_learning = np.mean(self.population[np.argsort(scores)[:3]], axis=0) - self.population[i]  # Top 3 elitist positions\n            self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_component + social_component + 0.1 * elitist_learning\n            self.population[i] += self.velocities[i]\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05586 with standard deviation 0.00160.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05356427082896753, 0.05495533258616636, 0.05555793597494796, 0.055687782904420446, 0.05713951206170709, 0.05686695912693773, 0.05700020617439283, 0.05849078267901009]}}
{"id": "4d617e14-0486-4c70-a6ab-7461bdd307f5", "fitness": 0.05207222992110026, "name": "EnhancedHybridPSODE", "description": "Introduce opposition-based learning and adaptive parameter adjustment to enhance exploration and convergence in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.opposition_rate = 0.5\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def opposition_based_learning(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        opposite_population = lb + ub - self.population\n        for i in range(self.current_population_size):\n            if np.random.rand() < self.opposition_rate:\n                self.population[i] = opposite_population[i]\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.opposition_based_learning(bounds)\n            \n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05207 with standard deviation 0.00326.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.047662678562219285, 0.054311482423074486, 0.049014738175324646, 0.049550096482219086, 0.0564684643457376, 0.05096334808732694, 0.050712180085970004, 0.057802359687956884, 0.05216472144007345]}}
{"id": "08fb594b-33ad-45c6-976d-a29baaac7fd8", "fitness": 0.05717524875518355, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive inertia weight and F, CR parameters with chaotic map-based dynamic parameter adjustment in EnhancedHybridPSODE for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.x_chaos = 0.7\n\n    def chaotic_map(self):\n        self.x_chaos = 4 * self.x_chaos * (1 - self.x_chaos)\n        return self.x_chaos\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = self.chaotic_map()\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = (self.w * self.velocities[i] + cognitive_component +\n                                  social_component + 0.1 * neighborhood_attraction)\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = self.chaotic_map()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F * self.chaotic_map()\n            mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR * self.chaotic_map()\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00259.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05408510231755104, 0.05566971894701278, 0.060463780231907016, 0.056231106324998836, 0.056981684589243575, 0.061912240747747704, 0.05755792211354149]}}
{"id": "650c57ea-f431-4640-a929-fd592b21852e", "fitness": 0.055288212197164066, "name": "EnhancedHybridPSODE", "description": "Implement adaptive learning rates and crowding mechanism to enhance diversity and convergence speed in the optimization process.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.max_c1 = 2.5  # Adaptive learning rate\n        self.max_c2 = 2.5  # Adaptive learning rate\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_learning_rate(self, evaluations):\n        self.c1 = self.max_c1 * (1 - evaluations / self.budget)\n        self.c2 = self.max_c2 * (evaluations / self.budget)\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        self.adaptive_learning_rate(np.sum(scores < self.personal_best_scores))  # Adaptive learning rate\n\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n\n        # Crowding mechanism\n        for i in range(self.current_population_size):\n            dists = np.linalg.norm(new_population - new_population[i], axis=1)\n            closest_idx = np.argpartition(dists, 2)[1]\n            if func(new_population[closest_idx]) > func(new_population[i]):\n                new_population[closest_idx] = new_population[i]\n\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05529 with standard deviation 0.00141.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.05343974148960651, 0.05555793597494796, 0.05555793597494796, 0.05555793597494796, 0.05686695912693773, 0.05686695912693773, 0.05686695912693773]}}
{"id": "aec7139c-01db-4680-a077-2c4389dc8227", "fitness": 0.05698079214796584, "name": "RefinedEnhancedHybridPSODE", "description": "Introduce adaptive inertia weight and learning strategies to enhance exploration and exploitation balance in hybrid PSO-DE.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n\n    def pso_step(self, func):\n        w = self.adaptive_inertia_weight()\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self):\n        if self.evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (self.evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n\n        while self.evaluations < self.budget:\n            if self.evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            self.evaluations += self.current_population_size\n            self.adapt_population_size()\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm RefinedEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05698 with standard deviation 0.00281.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.05832095490235545, 0.05555793597494796, 0.05555793597494796, 0.06066225892235311, 0.05686695912693773, 0.05686695912693773, 0.06211464232399966]}}
{"id": "61f7c526-bbd5-42ba-94f9-1c818b081e80", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Introduce dynamic inertia weight adaptation for improved convergence balance in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w = 0.5 + 0.4 * (1 - (evaluations / self.budget))  # Updated line for dynamic inertia weight\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {}}
{"id": "5669a123-ebca-41b0-b752-8daf2dec0ed9", "fitness": 0.05620566400534267, "name": "EnhancedHybridPSODEV2", "description": "Employ a multi-phase strategy with adaptive inertia weights and a chaotic map for diversity, enhancing convergence speed and exploration in PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_inertia(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.adaptive_inertia(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridPSODEV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05621 with standard deviation 0.00194.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.05608820644445711, 0.05555793597494796, 0.05555793597494796, 0.05832439994054728, 0.05686695912693773, 0.05686695912693773, 0.05970909648009526]}}
{"id": "c4205e1a-0c46-4f53-8e2b-d9ff50897583", "fitness": 0.05717524875518355, "name": "EnhancedHybridPSODE", "description": "Slightly increase the influence of chaotic mutation to enhance exploration in the DE step.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + 0.05 * self.chaos_enhanced_mutation(lb, ub)  # Slightly increase the influence of chaotic mutation\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00259.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.0535469241632347, 0.05812875936141482, 0.05408510231755104, 0.05566971894701278, 0.060463780231907016, 0.056231106324998836, 0.056981684589243575, 0.061912240747747704, 0.05755792211354149]}}
{"id": "5a18d23c-79c3-4194-b4c2-6908278500b0", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Integrate adaptive inertia weight and Lvy flight-based mutation to enhance exploration and exploitation in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.w_decay = 0.99\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n        \n        self.w = self.w_min + (self.w_max - self.w_min) * ((self.budget - func.evaluations) / self.budget) ** self.w_decay\n\n    def levy_flight(self, lb, ub, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return lb + (ub - lb) * step\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.levy_flight(lb, ub, trial.shape)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "An exception occurred: AttributeError(\"'ioh.iohcpp.problem.RealSingleObjectiveWrappedProbl' object has no attribute 'evaluations'\").", "error": "AttributeError(\"'ioh.iohcpp.problem.RealSingleObjectiveWrappedProbl' object has no attribute 'evaluations'\")", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {}}
{"id": "da058a16-971f-49bd-84d7-14f0a64f364e", "fitness": 0.05589335877694617, "name": "AdvancedHybridPSODE", "description": "Integrate adaptive chaotic maps and self-adaptive parameters to enhance exploration and exploitation in hybrid PSO-DE for improved convergence.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.w_decay = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def pso_step(self, func):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            chaos_term = 0.1 * np.random.rand(self.dim) * (np.mean(self.population, axis=0) - self.population[i])\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction + chaos_term\n            self.population[i] += self.velocities[i]\n        \n        self.w *= self.w_decay\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05589 with standard deviation 0.00153.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.054724068267215764, 0.05390387217715231, 0.05343974148960651, 0.05689831491229358, 0.05604212349885074, 0.05555793597494796, 0.05824323196419101, 0.057363981581319945, 0.05686695912693773]}}
{"id": "4c453be1-dfbe-42da-927e-fe20bc52210e", "fitness": 0.05620770811126267, "name": "ImprovedHybridPSODE", "description": "Incorporate adaptive inertia weight adjustment and differential evolution scaling to enhance exploration and convergence in a chaotic hybrid PSO-DE.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def adaptive_inertia(self, evaluations):\n        return 0.9 - 0.5 * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        w = self.adaptive_inertia(evaluations)\n        \n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            neighborhood_attraction = np.mean(self.population, axis=0) - self.population[i]\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component + 0.1 * neighborhood_attraction\n            self.population[i] += self.velocities[i]\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = 0.5 + 0.3 * np.random.rand()\n            mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05621 with standard deviation 0.00194.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05344565214111607, 0.05608820644445711, 0.05555793597494796, 0.05556409858337519, 0.05832439994054728, 0.05686695912693773, 0.056873282820280924, 0.05970909648009526]}}
{"id": "6bdf13af-e4aa-4a77-8236-5e54fb83b748", "fitness": 0.05732618355117974, "name": "EnhancedHybridPSODE", "description": "Integrate adaptive inertia weights and levy flight-enhanced exploration into hybrid PSO-DE for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05733 with standard deviation 0.00324.", "error": "", "parent_ids": ["3bc50599-b592-41fd-b07b-05e49a19775c"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.059315665226347014, 0.05343974148960651, 0.05555793597494796, 0.06170401659555269, 0.05555793597494796, 0.05686695912693773, 0.06318669695573353, 0.05686695912693773]}}
{"id": "47a9de1c-7b9b-4221-8f64-861ff0678272", "fitness": 0.05732618355117974, "name": "EnhancedHybridPSODE", "description": "Introduce stochastic component with noise for robustness to the EnhancedHybridPSODE approach.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population + np.random.normal(0, 0.01, self.population.shape)  # Added stochastic noise\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05733 with standard deviation 0.00324.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.059315665226347014, 0.05343974148960651, 0.05555793597494796, 0.06170401659555269, 0.05555793597494796, 0.05686695912693773, 0.06318669695573353, 0.05686695912693773]}}
{"id": "c21b5f6b-b962-4431-9259-c6cf03644baf", "fitness": 0.056339130849814484, "name": "EnhancedAdaptiveHybridPSODE", "description": "Introduce an adaptive learning rate mechanism and a dynamic exploration-exploitation balance to enhance convergence speed and solution accuracy in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def adapt_learning_rate(self, evaluations):\n        return 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n    \n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        learning_rate = self.adapt_learning_rate(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + learning_rate * (cognitive_component + social_component)\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05634 with standard deviation 0.00163.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.0551251534382281, 0.05478697622049, 0.05343974148960651, 0.05731685820331678, 0.05696805430990681, 0.05555793597494796, 0.058672952765318365, 0.05831754611957807, 0.05686695912693773]}}
{"id": "ad7f689f-57dc-4c7d-b32f-8db27f0f623f", "fitness": -Infinity, "name": "RefinedEnhancedHybridPSODE", "description": "Introduce adaptive mutation scaling in DE and dynamic neighborhood exploration in PSO to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.dynamic_neighborhood_size = max(1, self.initial_population_size // 5)\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            local_neighborhood = np.random.choice(self.current_population_size, self.dynamic_neighborhood_size, replace=False)\n            local_best = np.argmin([self.personal_best_scores[j] for j in local_neighborhood])\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[local_best] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n\n    def adapt_mutation_scale(self, evaluations):\n        return self.F * (1 - evaluations / self.budget)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = self.adapt_mutation_scale(evaluations)\n            mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {}}
{"id": "51b4c625-3bdf-4d7a-a6e9-419302d1b927", "fitness": 0.05644322948630699, "name": "EnhancedHybridPSODE", "description": "Enhanced convergence through chaotic mutation scaling and weighted Levy flight mixing in PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = (w + 0.5) * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + 0.5 * self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05644 with standard deviation 0.00170.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.0555528381494621, 0.05343974148960651, 0.05466077863391905, 0.05776462469968846, 0.05555793597494796, 0.0568340750788342, 0.05913364347664807, 0.05686695912693773, 0.05817846874671884]}}
{"id": "2507c0fe-5da3-45f8-8c46-a96a2792d51d", "fitness": 0.05732618355117974, "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic feedback mechanism for parameter adaptation in EnhancedHybridPSODE to optimize convergence speed and precision.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.dynamic_F = self.F\n        self.dynamic_CR = self.CR\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def adjust_DE_params(self, improvement_rate):\n        self.dynamic_F = np.clip(self.F + 0.1 * improvement_rate, 0.1, 0.9)\n        self.dynamic_CR = np.clip(self.CR + 0.1 * improvement_rate, 0.1, 1.0)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        scores_before = np.apply_along_axis(func, 1, self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.dynamic_F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < scores_before[i]:\n                new_population[i] = trial\n        scores_after = np.apply_along_axis(func, 1, new_population)\n        improvement_rate = (np.mean(scores_before) - np.mean(scores_after)) / (np.mean(scores_before) + 1e-8)\n        self.adjust_DE_params(improvement_rate)\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05733 with standard deviation 0.00324.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.059315665226347014, 0.05343974148960651, 0.05555793597494796, 0.06170401659555269, 0.05555793597494796, 0.05686695912693773, 0.06318669695573353, 0.05686695912693773]}}
{"id": "a98878d4-ec0d-4db4-b5f2-79c3ca30b26c", "fitness": 0.0572739278754357, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive chaotic maps and quantum-behaved particle swarm optimization to enhance exploration and exploitation balance in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = trial + self.chaos_enhanced_mutation(lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def quantum_behaved_pso(self, func, evaluations):\n        beta = 1.0 + (0.1 * (1 - (evaluations / self.budget)))\n        for i in range(self.current_population_size):\n            mbest = np.mean(self.personal_best_positions, axis=0)\n            phi = np.random.rand()\n            u = phi * (self.personal_best_positions[i] - mbest) + (1 - phi) * (self.global_best_position - mbest)\n            L = np.random.normal(0, 1, self.dim)\n            new_position = self.population[i] + beta * np.sign(u) * np.abs(L)\n            new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n            if func(new_position) < func(self.population[i]):\n                self.population[i] = new_position\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 3 == 0:\n                self.pso_step(func, evaluations)\n            elif evaluations % 3 == 1:\n                self.de_step(bounds, func)\n            else:\n                self.quantum_behaved_pso(func, evaluations)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05727 with standard deviation 0.00317.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05916500051514828, 0.05343974148960651, 0.05555793597494796, 0.061546424784767906, 0.05555793597494796, 0.05686695912693773, 0.06302465239602073, 0.05686695912693773]}}
{"id": "c881ec5f-dc14-4697-85c8-6dfe00b5007b", "fitness": 0.05747184899726803, "name": "EnhancedHybridPSODE", "description": "Integrate non-linear inertia weights and chaotic map-enhanced DE mutations into hybrid PSO-DE for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05747 with standard deviation 0.00315.", "error": "", "parent_ids": ["6bdf13af-e4aa-4a77-8236-5e54fb83b748"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.059315665226347014, 0.05386063188551338, 0.05555793597494796, 0.06170401659555269, 0.055997127188927465, 0.05686695912693773, 0.06318669695573353, 0.05731786653184601]}}
{"id": "5cedfb69-a608-4623-93c9-d4d792c43e97", "fitness": 0.055349772278092395, "name": "EnhancedHybridPSODE", "description": "Add adaptive chaotic factor to enhance exploration and exploitative balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        chaotic_factor = 0.7 + 0.3 * (np.sin((evaluations / self.budget) * np.pi / 2))  # Adaptive chaotic factor\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + chaotic_factor * self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05535 with standard deviation 0.00142.", "error": "", "parent_ids": ["c881ec5f-dc14-4697-85c8-6dfe00b5007b"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.053617657136495356, 0.05555793597494796, 0.05555793597494796, 0.05574353889128181, 0.05686695912693773, 0.05686695912693773, 0.05705748129207]}}
{"id": "1c577918-f867-4fe4-9451-53b7890435bf", "fitness": 0.05732618355117974, "name": "RefinedHybridPSODE", "description": "Utilize dynamic adaptation of exploration-exploitation balance and a self-adaptive control parameter strategy to enhance the convergence and robustness of hybrid PSO-DE.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_parameter_adjustment(self, evaluations):\n        self.c1 = 1.5 + 1.5 * (evaluations / self.budget)\n        self.c2 = 1.5 - 1.5 * (evaluations / self.budget)\n        self.F = 0.5 + 0.5 * (1 - evaluations / self.budget)\n        self.CR = 0.9 - 0.4 * (evaluations / self.budget)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_parameter_adjustment(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05733 with standard deviation 0.00324.", "error": "", "parent_ids": ["c881ec5f-dc14-4697-85c8-6dfe00b5007b"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.059315665226347014, 0.05343974148960651, 0.05555793597494796, 0.06170401659555269, 0.05555793597494796, 0.05686695912693773, 0.06318669695573353, 0.05686695912693773]}}
{"id": "bc76bdb6-f4fe-48dd-a184-48a9cf1943c6", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic CR (crossover rate) that decreases linearly over time for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_CR = self.CR - ((evaluations / self.budget) * self.CR)  # Adjust the crossover rate dynamically.\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < dynamic_CR  # Use dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["c881ec5f-dc14-4697-85c8-6dfe00b5007b"], "operator": null, "metadata": {}}
{"id": "c3de6b35-5caf-4c9c-81ba-d24381cb7b06", "fitness": 0.05787829324221234, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive velocity scaling in PSO for dynamic control of exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05788 with standard deviation 0.00298.", "error": "", "parent_ids": ["c881ec5f-dc14-4697-85c8-6dfe00b5007b"], "operator": null, "metadata": {"aucs": [0.05503455835466764, 0.059315665226347014, 0.05343974148960651, 0.057222638528065195, 0.06170401659555269, 0.05555793597494796, 0.05857642692805276, 0.06318669695573353, 0.05686695912693773]}}
{"id": "c9913841-ac57-43c5-8f8b-7b7019ae6afa", "fitness": 0.05800870490437544, "name": "EnhancedHybridPSODE", "description": "Incorporate dynamic swarm topology adjustment and chaotic levy flight for enhanced exploration in PSO-DE hybrid.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05801 with standard deviation 0.00295.", "error": "", "parent_ids": ["c3de6b35-5caf-4c9c-81ba-d24381cb7b06"], "operator": null, "metadata": {"aucs": [0.05540924846575135, 0.059315665226347014, 0.05343974148960651, 0.05761608042710564, 0.06170401659555269, 0.05555793597494796, 0.058981999877396496, 0.06318669695573353, 0.05686695912693773]}}
{"id": "b7a98c43-924b-4a17-80b1-a76071b3ea98", "fitness": 0.056369005376738376, "name": "EnhancedHybridPSODE", "description": "Improved global best update strategy for enhanced convergence in PSO-DE hybrid.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index] + np.random.normal(0, 0.1, self.dim) # Change made here\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05637 with standard deviation 0.00168.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05404323423945723, 0.05376089988848387, 0.05563498614031337, 0.05618770423043562, 0.05589317517942871, 0.05785193860522175, 0.057513550524467716, 0.05721121809754348, 0.05922434148529365]}}
{"id": "78cffc00-31de-4685-b525-8d8c5002fe9b", "fitness": 0.056676199378108666, "name": "RefinedHybridPSODE", "description": "Introducing adaptive multi-phase exploration-exploitation strategy using periodic chaotic boosting and differential mutation refinement to enhance convergence in hybrid PSO-DE.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget) ** 0.5  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            if evaluations % 10 == 0:\n                self.population[i] += self.velocities[i] + self.levy_flight(self.dim) * 0.1  # Periodic boost\n            else:\n                self.population[i] += self.velocities[i]\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05668 with standard deviation 0.00175.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.055487062697234246, 0.055396859812732346, 0.05343974148960651, 0.05769512090436624, 0.05760632322600445, 0.05555793597494796, 0.05906171288897499, 0.05897407828217349, 0.05686695912693773]}}
{"id": "36832224-7feb-47b4-ae11-1a649f4ec8a2", "fitness": 0.05723443632742225, "name": "RefinedHybridPSODE", "description": "Enhance the PSO-DE hybrid optimization by introducing adaptive learning rates and stochastic sampling, improving local and global search balance.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def adaptive_learning_rate(self, evaluations):\n        return 0.5 + 0.5 * (evaluations / self.budget)\n\n    def stochastic_sampling(self, evaluations):\n        return np.random.uniform(0.9, 1.1, self.dim) * (1 - (evaluations / self.budget))\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        learning_rate = self.adaptive_learning_rate(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += learning_rate * (self.velocities[i] + self.levy_flight(self.dim))\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        stochastic_factor = self.stochastic_sampling(0)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub) * stochastic_factor\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05723 with standard deviation 0.00225.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05359825619426839, 0.05752147525511275, 0.054816006411980145, 0.055723225417683486, 0.059825100610300885, 0.0569942853865989, 0.057036580666981807, 0.06125321151102814, 0.058341785492845744]}}
{"id": "4604a8d0-9b02-488e-9210-9ce555213c9f", "fitness": 0.05800870490437544, "name": "EnhancedHybridPSODEPlus", "description": "Integrate adaptive elite retention and stochastic perturbation mechanisms for robust optimization in dynamic PSO-DE hybrid.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.elite_fraction = 0.1  # Fraction of population considered elite\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n        self.elite_individuals = []\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n        self.update_elite_individuals(scores)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            if i in self.elite_individuals:\n                continue\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def update_elite_individuals(self, scores):\n        elite_count = int(self.elite_fraction * self.current_population_size)\n        self.elite_individuals = np.argsort(scores)[:elite_count]\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05801 with standard deviation 0.00295.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05540924846575135, 0.059315665226347014, 0.05343974148960651, 0.05761608042710564, 0.06170401659555269, 0.05555793597494796, 0.058981999877396496, 0.06318669695573353, 0.05686695912693773]}}
{"id": "b7f90e29-0ede-47b8-89fb-fe6610b56127", "fitness": 0.05773184923981048, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive Levy flight scaling to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size, scaling_factor=1.0):  # Modified line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step * scaling_factor\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            levy_scaling_factor = 1 - (evaluations / self.budget)  # New scaling factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim, levy_scaling_factor)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05773 with standard deviation 0.00299.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05418527061227285, 0.059315665226347014, 0.05386663941931802, 0.0563356614753856, 0.06170401659555269, 0.056003286910869754, 0.057665287079492256, 0.06318669695573353, 0.05732411888332256]}}
{"id": "88958c1b-07be-41bb-999c-ae2c6687fbbf", "fitness": 0.05731634937571254, "name": "AdaptiveFuzzyHybridPSODE", "description": "Introduce a multi-phase adaptation strategy using fuzzy logic to dynamically balance exploration-exploitation in PSO-DE hybrid with adaptive inertia weights and phase-based population management.", "code": "import numpy as np\n\nclass AdaptiveFuzzyHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def fuzzy_dynamic_topology(self, evaluations):\n        fuzzy_factor = evaluations / self.budget\n        if fuzzy_factor < 0.33:\n            self.c1, self.c2 = 1.7, 1.3  # More exploration\n        elif fuzzy_factor < 0.66:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.3, 1.7  # More exploitation\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.fuzzy_dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        phase = evaluations / self.budget\n        if phase > 0.5:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - phase))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveFuzzyHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05732 with standard deviation 0.00215.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.0570884107645907, 0.05343974148960651, 0.05564206183223197, 0.059375056692642314, 0.05555793597494796, 0.057856843888541065, 0.06079239491211974, 0.05686695912693773, 0.05922773969979489]}}
{"id": "a27f054c-b5ac-44d8-bb56-1662b690fe8d", "fitness": 0.057928596512542355, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive levy flight scaling based on evaluations to enhance the exploration-exploitation balance in the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size, evaluations):  # Modified line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        scaling_factor = 1 + np.sin((evaluations / self.budget) * np.pi)  # New scaling factor based on evaluations\n        return step * scaling_factor\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5\n        else:\n            self.c1, self.c2 = 1.2, 1.8\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim, evaluations)  # Modified line\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05793 with standard deviation 0.00297.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05517786135047975, 0.059315665226347014, 0.05343974148960651, 0.05737454267049957, 0.06170401659555269, 0.05555793597494796, 0.058733949222776416, 0.06318669695573353, 0.05686695912693773]}}
{"id": "dad83841-193a-431e-8f3d-2e1105706a6d", "fitness": 0.05785162303070779, "name": "EnhancedHybridPSODE", "description": "Introduce an adaptive factor in the DE step to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = self.F * (0.5 + (0.5 * np.random.rand()))  # Adaptive scaling factor\n            mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05785 with standard deviation 0.00299.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05495763863512526, 0.059315665226347014, 0.05343974148960651, 0.057142209535699484, 0.06170401659555269, 0.05555793597494796, 0.05849374373641991, 0.06318669695573353, 0.05686695912693773]}}
{"id": "6e8034cf-fe66-4881-af73-81c0337ab8f3", "fitness": 0.05785162303070779, "name": "EnhancedHybridPSO_DENeuromodulated", "description": "Introduce adaptive neuron-inspired mutation and synergy-driven dynamics to improve exploration-exploitation balance in PSO-DE hybrid.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DENeuromodulated:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def neuron_inspired_mutation(self, lb, ub, t):\n        modulation_factor = np.sin(t) + np.random.rand()\n        return lb + (ub - lb) * modulation_factor\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def synergy_driven_mutation(self, lb, ub, evaluations):\n        alpha = np.random.rand() * np.sin(evaluations / self.budget * np.pi)\n        return lb + (ub - lb) * alpha\n\n    def de_step(self, bounds, func, evaluations):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.synergy_driven_mutation(lb, ub, evaluations), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func, evaluations)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridPSO_DENeuromodulated got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05785 with standard deviation 0.00299.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05495763863512526, 0.059315665226347014, 0.05343974148960651, 0.057142209535699484, 0.06170401659555269, 0.05555793597494796, 0.05849374373641991, 0.06318669695573353, 0.05686695912693773]}}
{"id": "bdc61269-b8dc-4f20-ad14-7c7fd0e4e9e6", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Introduced adaptive CR in the DE step based on evaluations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        cr_dynamic = self.CR * (0.5 + (0.5 * np.sin(np.pi * evaluations / self.budget)))\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < cr_dynamic\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {}}
{"id": "05283d47-10a5-44b7-8f41-04709ec15f48", "fitness": 0.05814847245571511, "name": "EnhancedHybridPSODE", "description": "Enhanced exploration by tweaking velocity scaling factor multiplier to improve global search effectiveness.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05815 with standard deviation 0.00293.", "error": "", "parent_ids": ["c9913841-ac57-43c5-8f8b-7b7019ae6afa"], "operator": null, "metadata": {"aucs": [0.05580488530420524, 0.059315665226347014, 0.05343974148960651, 0.05803841925707487, 0.06170401659555269, 0.05555793597494796, 0.05942193217103042, 0.06318669695573353, 0.05686695912693773]}}
{"id": "89393811-47de-4fbf-a30c-2bb842b240c0", "fitness": 0.056523601936973304, "name": "EnhancedHybridPSODE", "description": "Slightly refined the inertia weight calculation to allow a more gradual transition in particle velocity, potentially enhancing convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.cos((evaluations / self.budget) * np.pi / 2))  # Changed \"sin\" to \"cos\" for gradual transition\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05652 with standard deviation 0.00218.", "error": "", "parent_ids": ["05283d47-10a5-44b7-8f41-04709ec15f48"], "operator": null, "metadata": {"aucs": [0.053593864393924995, 0.05343974148960651, 0.056851729969397025, 0.05571882745442169, 0.05555793597494796, 0.05912223046437204, 0.057032186871765034, 0.05686695912693773, 0.06052894168738676]}}
{"id": "f9786eb2-78e2-4da3-abc2-103bc6b7e3f6", "fitness": 0.05814847245571511, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive differential evolution mutation factor to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 2:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        else:\n            self.c1, self.c2 = 1.2, 1.8  # More focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)  # Adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_F = self.F + 0.2 * (1 - np.random.rand())  # Change: adaptive mutation factor\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05815 with standard deviation 0.00293.", "error": "", "parent_ids": ["05283d47-10a5-44b7-8f41-04709ec15f48"], "operator": null, "metadata": {"aucs": [0.05580488530420524, 0.059315665226347014, 0.05343974148960651, 0.05803841925707487, 0.06170401659555269, 0.05555793597494796, 0.05942193217103042, 0.06318669695573353, 0.05686695912693773]}}
{"id": "0e56209b-d2a2-4d13-9035-9974192c55b7", "fitness": 0.05617336549665001, "name": "EnhancedAdaptivePSODE", "description": "Introduce adaptive learning strategies and diverse mutation operators to enhance global exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 40\n        self.min_population_size = 10\n        self.c1 = 0.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        return self.w_max - (self.w_max - self.w_min) * (np.sin((evaluations / self.budget) * np.pi / 2))\n\n    def dynamic_topology(self, evaluations):\n        if evaluations < self.budget / 3:\n            self.c1, self.c2 = 1.5, 1.5  # Balanced exploration and exploitation\n        elif evaluations < 2 * self.budget / 3:\n            self.c1, self.c2 = 0.5, 2.0  # More focus on global search\n        else:\n            self.c1, self.c2 = 0.3, 2.2  # Even more focus on global search\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.dynamic_topology(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 2.0 * (evaluations / self.budget)  # Increased adaptive velocity scaling\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + np.random.randn(self.dim) * self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub) + 0.1 * self.levy_flight(self.dim), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 3:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05617 with standard deviation 0.00191.", "error": "", "parent_ids": ["05283d47-10a5-44b7-8f41-04709ec15f48"], "operator": null, "metadata": {"aucs": [0.05599481031868636, 0.05343974148960651, 0.05343974148960651, 0.05822702596829865, 0.05555793597494796, 0.05555793597494796, 0.05960917999988069, 0.05686695912693773, 0.05686695912693773]}}
{"id": "afed1cd8-fc72-4c2e-938d-17b2b3651904", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Introduce adaptive learning factors and chaotic inertia damping to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["05283d47-10a5-44b7-8f41-04709ec15f48"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "72ff4958-92a6-4d40-83ae-3dc075a27445", "fitness": -Infinity, "name": "RefinedAdaptivePSODE", "description": "Introduce multi-phase adaptive exploration-exploitation and dynamic chaos-enhanced mutation for superior convergence and robustness.", "code": "import numpy as np\n\nclass RefinedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 0.5\n        self.c1_max = 2.5\n        self.c2_min = 0.5\n        self.c2_max = 2.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        phase = progress // (1 / 3)\n        if phase == 0:\n            self.c1, self.c2 = self.c1_max, self.c2_min\n        elif phase == 1:\n            self.c1, self.c2 = (self.c1_min + self.c1_max) / 2, (self.c2_min + self.c2_max) / 2\n        else:\n            self.c1, self.c2 = self.c1_min, self.c2_max\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub, evaluations):\n        x = np.random.rand()\n        dynamic_factor = 1 - (evaluations / self.budget)\n        return lb + (ub - lb) * (x * (1 - x) * 4 * dynamic_factor)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub, evaluations), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {}}
{"id": "b0a3a4fc-5f24-4318-9307-efdb2b9842ef", "fitness": 0.05621957514756805, "name": "EnhancedAdaptivePSODE", "description": "Integrate a hybrid mutation strategy and an adaptive velocity scaling factor to enhance exploitation and convergence precision.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def gaussian_mutation(self, size):\n        return np.random.normal(0, 0.1, size=size)\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        velocity_scaling_factor = 1 + 2.0 * (evaluations / self.budget)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim) + self.gaussian_mutation(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05622 with standard deviation 0.00194.", "error": "", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.053461386295752256, 0.05610493736369715, 0.05555793597494796, 0.05558050256340141, 0.05834398558842713, 0.05686695912693773, 0.056890115005360675, 0.05973061291998161]}}
{"id": "866bda59-78cb-4329-a245-7fd2540399ef", "fitness": 0.05874421075917158, "name": "SelfAdaptiveChaoticPSODE", "description": "Incorporate self-adaptive strategies with adaptive population dynamics and chaos-driven adjustments to enhance solution quality and convergence speed in diverse optimization landscapes.", "code": "import numpy as np\n\nclass SelfAdaptiveChaoticPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n        self.F = self.F_min + (self.F_max - self.F_min) * progress\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - progress)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm SelfAdaptiveChaoticPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "09774294-837d-4e77-b6d5-b7e34a7a1ffa", "fitness": -Infinity, "name": "QuantumAdaptivePSODE", "description": "Integrate quantum-inspired variables for position updates and adaptive mutation for enhanced search capability and convergence speed.", "code": "import numpy as np\n\nclass QuantumAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            quantum_component = np.random.uniform(-0.5, 0.5, self.dim) * self.levy_flight(self.dim)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component + quantum_component)\n            self.population[i] += self.velocities[i]\n\n    def adaptive_mutation(self, bounds, evaluations):\n        lb, ub = bounds.lb, bounds.ub\n        mutation_rate = 0.05 + 0.45 * (1 - (evaluations / self.budget))\n        x = np.random.rand()\n        if x < mutation_rate:\n            return lb + (ub - lb) * (np.random.rand(self.dim) * (1 - np.random.rand(self.dim)) * 4)\n        else:\n            return np.zeros(self.dim)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.adaptive_mutation(bounds, evaluations), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {}}
{"id": "2237fa2a-a7b8-4323-bddb-2110ab5bf5bd", "fitness": 0.05645960717120302, "name": "EnhancedAdaptivePSODEv2", "description": "Introduce adaptive crowding distance and dynamic convergence acceleration to enhance diversity and accelerate convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def crowding_distance(self):\n        distances = np.zeros(self.current_population_size)\n        for i in range(self.current_population_size):\n            distances[i] = np.sum(np.linalg.norm(self.population - self.population[i], axis=1))\n        return distances\n\n    def dynamic_convergence_acceleration(self, distances):\n        max_distance = np.max(distances)\n        return 1.0 + 0.1 * (max_distance - distances) / max_distance\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        distances = self.crowding_distance()\n        convergence_factors = self.dynamic_convergence_acceleration(distances)\n\n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * convergence_factors[i]\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptivePSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05646 with standard deviation 0.00167.", "error": "", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.055142236288871826, 0.05511682817359709, 0.05555793597494796, 0.05733721478528153, 0.0573110808838293, 0.05686695912693773, 0.05869552378325915, 0.05866894403449607]}}
{"id": "5b30749f-c554-40f5-979c-0bd3add9d545", "fitness": 0.05944546629762686, "name": "EnhancedAdaptivePSODE", "description": "Improve the velocity update by incorporating a decaying factor to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05945 with standard deviation 0.00420.", "error": "", "parent_ids": ["afed1cd8-fc72-4c2e-938d-17b2b3651904"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05641157232696814, 0.062440662720549045, 0.05555793597494796, 0.05866365827227882, 0.0649911085317938, 0.05686695912693773, 0.060058619698037496, 0.06657893853752228]}}
{"id": "38ac0e1f-9a43-4b7c-b170-aa50e2eb61d8", "fitness": 0.05700597941822916, "name": "EnhancedAdaptivePSODE", "description": "Introduce a dynamic inertia weight update based on a chaotic sequence for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            w = 0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05701 with standard deviation 0.00217.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05468747816628128, 0.0571421890735726, 0.05343974148960651, 0.05686053461753149, 0.05943601769165385, 0.05555793597494796, 0.058204707867619, 0.060858250755912, 0.05686695912693773]}}
{"id": "f56c366b-a128-4f08-92ad-bd99692db609", "fitness": 0.059088002260518704, "name": "EnhancedAdaptivePSODE", "description": "Incorporate a more aggressive decay strategy to enhance velocity reduction for faster convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.98 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05909 with standard deviation 0.00423.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05443300483986546, 0.05438969829051321, 0.062440662720549045, 0.05659450223295537, 0.056548821474528665, 0.0649911085317938, 0.05793125303079549, 0.057884030686145005, 0.06657893853752228]}}
{"id": "20207a51-e559-4af8-b97b-c5ea149da2f1", "fitness": 0.059173972726236465, "name": "ImprovedAdaptivePSODE", "description": "Integrate chaotic initialization with self-adaptive learning rates and a dynamic inertia weight to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        progress = evaluations / self.budget\n        chaotic_factor = 4 * progress * (1 - progress)  # Enhanced chaotic factor\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress**2)  # Non-linear adaptation\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress**2\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm ImprovedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05917 with standard deviation 0.00418.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05468145304332295, 0.05438969829051321, 0.062440662720549045, 0.05685370407955048, 0.056548821474528665, 0.0649911085317938, 0.05819733717220277, 0.057884030686145005, 0.06657893853752228]}}
{"id": "4de1242e-7245-4673-8f2f-6b20af9aef38", "fitness": 0.059088002260518704, "name": "EnhancedAdaptivePSODE", "description": "Enhance the velocity update by adjusting the decaying factor to reinforce convergence stability in dynamic environments.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.98 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05909 with standard deviation 0.00423.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05443300483986546, 0.05438969829051321, 0.062440662720549045, 0.05659450223295537, 0.056548821474528665, 0.0649911085317938, 0.05793125303079549, 0.057884030686145005, 0.06657893853752228]}}
{"id": "125d1d2f-67d3-48cb-a1c1-d3c16adab552", "fitness": 0.056497501610959185, "name": "EnhancedAdaptivePSODE_v2", "description": "Introduce a dynamic particle-swarm inertia mechanism coupled with differential evolution for balanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        progress = evaluations / self.budget\n        chaotic_factor = 4 * progress * (1 - progress)\n        return self.w_max * chaotic_factor + self.w_min * (1 - chaotic_factor)\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.98 ** (evaluations / self.budget)  \n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptivePSODE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05650 with standard deviation 0.00224.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05343974148960651, 0.056919723080013696, 0.05555793597494796, 0.05555793597494796, 0.05920562940968477, 0.05686695912693773, 0.05686695912693773, 0.060622888825949794]}}
{"id": "f0904163-ed17-485b-a46d-3716a18e9e7c", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Refine the velocity update by slightly adjusting the decaying factor to enhance convergence dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.995 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "672aacc0-1256-4ea4-aa26-15146dcccbcc", "fitness": 0.05660588968397346, "name": "EnhancedAdaptivePSODE", "description": "Introduce a multi-strategy mutation mechanism that dynamically combines chaotic sequences, Lvy flights, and Gaussian perturbations for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def gaussian_perturbation(self, size):\n        return np.random.normal(0, 0.1, size=size)\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim) + self.gaussian_perturbation(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05661 with standard deviation 0.00233.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05718382200621108, 0.05343974148960651, 0.053494450883137534, 0.05947463614407733, 0.05555793597494796, 0.055615107624519045, 0.060894642910242824, 0.05686695912693773, 0.056925710996081125]}}
{"id": "daac1b34-d200-43fe-8f45-87a11b1a1800", "fitness": 0.057897292655757084, "name": "EnhancedAdaptivePSODE", "description": "Refine the velocity update by incorporating both a decaying factor and a progressive velocity cap based on evaluations to enhance convergence stability.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)  # Change applied here\n            velocity_cap = 1.0 + 0.5 * (evaluations / self.budget)  # Added line\n            self.velocities[i] = np.clip((w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor, -velocity_cap, velocity_cap)  # Change applied here\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05790 with standard deviation 0.00268.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05461299109289597, 0.05894542123909419, 0.05427231886318207, 0.05678227872615471, 0.06133442285424506, 0.05642672599142129, 0.058124015239438, 0.0628185269071121, 0.057758932988270395]}}
{"id": "826c0e50-9162-4667-8623-c6cf2dfbecec", "fitness": 0.04619948367163492, "name": "IntelligentExplorationExploitation", "description": "Introduce an intelligent exploration-exploitation balance by dynamically adjusting the velocity and mutation strategies based on population diversity to improve convergence.", "code": "import numpy as np\n\nclass IntelligentExplorationExploitation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def calculate_population_diversity(self):\n        mean_position = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - mean_position, axis=1))\n        return diversity\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        diversity = self.calculate_population_diversity()\n\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n\n            velocity_scaling_factor = 1 + 1.5 * (1 - diversity / self.dim)\n            decaying_factor = 0.98 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        diversity = self.calculate_population_diversity()\n\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n\n            mutation_strength = (1 - diversity / self.dim)\n            mutant = np.clip(a + self.F * mutation_strength * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm IntelligentExplorationExploitation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04620 with standard deviation 0.00153.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.04501486107074015, 0.04392526653924245, 0.04400516513039321, 0.04720582356596448, 0.0460668317592241, 0.04615015796794297, 0.048561049827912206, 0.04739033932001169, 0.04747585786328301]}}
{"id": "37a5769d-4069-4a85-9bcc-8854dc0209c6", "fitness": 0.05925941262725934, "name": "EnhancedAdaptivePSODE", "description": "Introduce a dynamic Levy step size and improved diversity control mechanism to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size, evaluations):\n        beta = 1.5\n        dynamic_step_scale = 0.1 + 0.9 * (1 - evaluations / self.budget)\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = dynamic_step_scale * (u / np.abs(v) ** (1 / beta))\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim, evaluations)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05926 with standard deviation 0.00425.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05587638684766505, 0.062440662720549045, 0.05555793597494796, 0.05810241705412933, 0.0649911085317938, 0.05686695912693773, 0.059480563362182326, 0.06657893853752228]}}
{"id": "e03ab58e-5bb5-46eb-b34b-38d5519182e9", "fitness": 0.059088002260518704, "name": "EnhancedAdaptivePSODE", "description": "Fine-tune the PSO velocity update by adjusting the decaying factor formula for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.98 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05909 with standard deviation 0.00423.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05443300483986546, 0.05438969829051321, 0.062440662720549045, 0.05659450223295537, 0.056548821474528665, 0.0649911085317938, 0.05793125303079549, 0.057884030686145005, 0.06657893853752228]}}
{"id": "9e58a2b4-0e8f-44a0-af75-6c7267474117", "fitness": 0.056356208092644855, "name": "MultiChaoticAdaptivePSODE", "description": "Introduce multi-chaotic maps for initialization and adaptive mutation strategies to diversify exploration and enhance convergence.", "code": "import numpy as np\n\nclass MultiChaoticAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n    \n    def multi_chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x) if i % 2 == 0 else np.sin(np.pi * x)  # Use two different chaotic maps\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n    \n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.multi_chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n    \n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n    \n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n    \n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n    \n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n    \n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n    \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4) if np.random.rand() < 0.5 else lb + (ub - lb) * np.sin(np.pi * x)\n    \n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n    \n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm MultiChaoticAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05636 with standard deviation 0.00234.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05218543930130903, 0.05472395349224013, 0.05648493030728108, 0.05425152658104382, 0.05690002263163563, 0.058743602443541265, 0.055527289098571075, 0.05824618013212335, 0.06014292884605832]}}
{"id": "75bd46d4-dd58-47aa-9c4b-395372782866", "fitness": 0.05944546629762686, "name": "EnhancedAdaptivePSODE", "description": "Introduce a dynamic strategy adjustment inspired by Pareto optimality to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pareto_dominance_adjustment(self, evaluations):\n        dominance_factor = (1 - evaluations / self.budget) ** 2\n        self.F = self.F * dominance_factor\n        self.CR = self.CR * (1 - dominance_factor)\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n\n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.pareto_dominance_adjustment(evaluations)\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05945 with standard deviation 0.00420.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05641157232696814, 0.062440662720549045, 0.05555793597494796, 0.05866365827227882, 0.0649911085317938, 0.05686695912693773, 0.060058619698037496, 0.06657893853752228]}}
{"id": "21e70a78-a4b2-4918-9295-0f5497a39045", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Enhance convergence by adding a nonlinear component to the decaying factor in velocity adjustment.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** ((evaluations / self.budget) ** 2)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "890d9c06-1495-471c-9532-bbe9afbbd46f", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Further refined the decaying factor for velocity update by altering its base to enhance convergence. ", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.995 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "a1cf203a-ad6f-46bd-9eba-480e2f5a2aa0", "fitness": 0.05875227673686407, "name": "EnhancedAdaptivePSODE", "description": "Refine the decaying factor to incorporate a cosine component for enhanced particle velocity control.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget) * np.cos(np.pi * evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05875 with standard deviation 0.00447.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.053463045572846535, 0.05438969829051321, 0.062440662720549045, 0.055582255680199366, 0.056548821474528665, 0.0649911085317938, 0.05689192913767871, 0.057884030686145005, 0.06657893853752228]}}
{"id": "051c32f9-6a95-49d2-b11a-310891f97132", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Refine the inertia weight calculation by introducing a sine component for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor * np.sin(np.pi * evaluations / self.budget)  # Modified line\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
{"id": "ea6eb504-a891-4be3-8708-6eda9035c857", "fitness": -Infinity, "name": "EnhancedAdaptivePSODEv2", "description": "Introduce a stochastic decay factor and dynamic population adaptation to enhance convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = np.exp(-0.01 * np.random.rand() * (evaluations / self.budget))\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            decaying_population_size = int(self.min_population_size + np.random.rand() * (self.initial_population_size - self.min_population_size))\n            self.current_population_size = max(\n                self.min_population_size,\n                decaying_population_size\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {}}
{"id": "fac87349-afb4-4fdb-8582-34a2285c3257", "fitness": 0.05930044732077676, "name": "EnhancedAdaptivePSODE", "description": "Enhance chaotic factor contribution in inertia weight to improve search space exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))**2  # Increased contribution\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05930 with standard deviation 0.00410.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05467650071582686, 0.05475831355935068, 0.062440662720549045, 0.056850443445284116, 0.056933617481340626, 0.0649911085317938, 0.05819524863066816, 0.05827919226465528, 0.06657893853752228]}}
{"id": "4f28ccc5-7ff0-43f0-bdf2-97a7788081d9", "fitness": 0.059088002260518704, "name": "EnhancedAdaptivePSODE", "description": "Refine the velocity decaying factor to improve convergence by increasing its rate of decay.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.98 ** (evaluations / self.budget)  # Change applied here\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05909 with standard deviation 0.00423.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05443300483986546, 0.05438969829051321, 0.062440662720549045, 0.05659450223295537, 0.056548821474528665, 0.0649911085317938, 0.05793125303079549, 0.057884030686145005, 0.06657893853752228]}}
{"id": "c348d119-5960-4baa-8ef7-681f5f80d762", "fitness": 0.05919460673817172, "name": "EnhancedAdaptivePSODE", "description": "Introduced a minor modification to the velocity scaling factor to refine convergence in the PSO step.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.2 * (evaluations / self.budget)  # Change applied here\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05919 with standard deviation 0.00419.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05401573396584969, 0.05511451048181615, 0.062440662720549045, 0.05615884523656478, 0.05730595468189026, 0.0649911085317938, 0.05748381447903084, 0.05866189200852867, 0.06657893853752228]}}
{"id": "ff139f5f-eb26-4fcb-8659-de8151c25217", "fitness": 0.05639648243459136, "name": "EnhancedAdaptivePSODE", "description": "Further refine the velocity update by adding a small random perturbation to improve escape from local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor + np.random.normal(0, 0.1, self.dim)  # Change applied here\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim)\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05640 with standard deviation 0.00145.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.054370625124739336, 0.05457987556065036, 0.05456961434338381, 0.05652904832705263, 0.0567480597974942, 0.056738370022613505, 0.0578638150358759, 0.058089105058792834, 0.0580798286407197]}}
{"id": "896f29f6-4d97-4e68-be4a-3ca2de2973d4", "fitness": 0.05874421075917158, "name": "EnhancedAdaptivePSODE", "description": "Enhance convergence by dynamically adjusting the Levy flight step size based on evaluation progress.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.c1_min = 1.2\n        self.c1_max = 2.0\n        self.c2_min = 1.2\n        self.c2_max = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def chaotic_initialization(self, lb, ub):\n        pop = np.zeros((self.initial_population_size, self.dim))\n        x = 0.7\n        for i in range(self.initial_population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)\n                pop[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return pop\n\n    def levy_flight(self, size, progress):  # Added progress parameter\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step_size = 1 - progress  # Adjust levy flight step size based on progress\n        step = (u / np.abs(v) ** (1 / beta)) * step_size\n        return step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.current_population_size = self.initial_population_size\n        self.population = self.chaotic_initialization(lb, ub)\n        self.velocities = np.random.uniform(-1, 1, (self.current_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.current_population_size, float('inf'))\n\n    def update_personal_best(self, func):\n        scores = np.apply_along_axis(func, 1, self.population)\n        for i, score in enumerate(scores):\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n        return scores\n\n    def update_global_best(self, scores):\n        min_index = np.argmin(scores)\n        if scores[min_index] < self.global_best_score:\n            self.global_best_score = scores[min_index]\n            self.global_best_position = self.population[min_index]\n\n    def calculate_inertia_weight(self, evaluations):\n        chaotic_factor = 4 * (evaluations / self.budget) * (1 - (evaluations / self.budget))\n        return self.w_max - (self.w_max - self.w_min) * chaotic_factor\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        self.c1 = self.c1_min + (self.c1_max - self.c1_min) * (1 - progress)\n        self.c2 = self.c2_min + (self.c2_max - self.c2_min) * progress\n\n    def pso_step(self, func, evaluations):\n        scores = self.update_personal_best(func)\n        self.update_global_best(scores)\n        \n        w = self.calculate_inertia_weight(evaluations)\n        self.adaptive_learning_factors(evaluations)\n        progress = evaluations / self.budget  # Calculate progress once\n        for i in range(self.current_population_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n            velocity_scaling_factor = 1 + 1.5 * (evaluations / self.budget)\n            decaying_factor = 0.99 ** (evaluations / self.budget)\n            self.velocities[i] = (w * self.velocities[i] + cognitive_component + social_component) * velocity_scaling_factor * decaying_factor\n            self.population[i] += self.velocities[i] + self.levy_flight(self.dim, progress)  # Pass progress here\n        \n    def chaos_enhanced_mutation(self, lb, ub):\n        x = np.random.rand()\n        return lb + (ub - lb) * (x * (1 - x) * 4)\n\n    def de_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.current_population_size):\n            idxs = [idx for idx in range(self.current_population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.population[i])\n            trial = np.clip(trial + self.chaos_enhanced_mutation(lb, ub), lb, ub)\n            if func(trial) < func(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def adapt_population_size(self, evaluations):\n        if evaluations > self.budget // 2:\n            self.current_population_size = max(\n                self.min_population_size,\n                int(self.initial_population_size * (1 - (evaluations / self.budget)))\n            )\n            self.population = self.population[:self.current_population_size]\n            self.velocities = self.velocities[:self.current_population_size]\n            self.personal_best_positions = self.personal_best_positions[:self.current_population_size]\n            self.personal_best_scores = self.personal_best_scores[:self.current_population_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % 2 == 0:\n                self.pso_step(func, evaluations)\n            else:\n                self.de_step(bounds, func)\n            \n            evaluations += self.current_population_size\n            self.adapt_population_size(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05874 with standard deviation 0.00448.", "error": "", "parent_ids": ["5b30749f-c554-40f5-979c-0bd3add9d545"], "operator": null, "metadata": {"aucs": [0.05343974148960651, 0.05438969829051321, 0.062440662720549045, 0.05555793597494796, 0.056548821474528665, 0.0649911085317938, 0.05686695912693773, 0.057884030686145005, 0.06657893853752228]}}
