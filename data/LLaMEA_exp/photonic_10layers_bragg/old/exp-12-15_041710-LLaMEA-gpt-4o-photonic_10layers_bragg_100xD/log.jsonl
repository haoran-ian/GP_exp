{"id": "02807a35-688d-4e7e-9571-143ecf7b5843", "fitness": 0.039778596553740796, "name": "HybridBatAlgorithm", "description": "A hybrid bat-inspired optimization algorithm using Lévy flight for exploration and local search for exploitation.", "code": "import numpy as np\n\nclass HybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = 1.0\n        self.pulse_rate = 0.5\n        self.alpha = 0.9\n        self.gamma = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.rand()\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate:\n                    candidate = best_solution + 0.01 * np.random.randn(self.dim) * self.loudness\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness *= self.alpha\n                    self.pulse_rate *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return best_solution", "configspace": "", "generation": 0, "feedback": "The algorithm HybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03978 with standard deviation 0.00240.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0403332723091141, 0.03659981428194259, 0.04240270307016569]}}
{"id": "bad61e4f-228c-4e6e-ac9e-625c13ae40c7", "fitness": 0.04036594800561669, "name": "EnhancedHybridBatAlgorithm", "description": "A hybrid bat-inspired algorithm enhanced with dynamic loudness and pulse rate adjustment for adaptive exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.rand()\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + 0.01 * np.random.randn(self.dim) * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return best_solution", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04037 with standard deviation 0.00327.", "error": "", "parent_ids": ["02807a35-688d-4e7e-9571-143ecf7b5843"], "operator": null, "metadata": {"aucs": [0.04240518276297178, 0.03575390743696405, 0.042938753816914255]}}
{"id": "88bb0044-fdb6-4be8-a0f1-2fa2abf98a06", "fitness": 0.04479022341524511, "name": "EnhancedHybridBatAlgorithmV2", "description": "A hybrid bat-inspired algorithm with adaptive frequency adjustment and memory-enhanced bats for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithmV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.memory = np.zeros((self.population_size, self.dim))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.randn()\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + 0.01 * np.random.randn(self.dim) * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                    \n                if eval_count >= self.budget:\n                    break\n            \n            # Memory-enhanced exploration\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        candidate_memory = self.memory[i] + 0.01 * np.random.randn(self.dim)\n                        candidate_memory = np.clip(candidate_memory, lb, ub)\n                        candidate_memory_fitness = func(candidate_memory)\n                        eval_count += 1\n                        \n                        if candidate_memory_fitness < fitness[i]:\n                            population[i] = candidate_memory\n                            fitness[i] = candidate_memory_fitness\n                        \n                        if candidate_memory_fitness < best_fitness:\n                            best_solution = candidate_memory\n                            best_fitness = candidate_memory_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridBatAlgorithmV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04479 with standard deviation 0.00850.", "error": "", "parent_ids": ["bad61e4f-228c-4e6e-ac9e-625c13ae40c7"], "operator": null, "metadata": {"aucs": [0.04249408603746874, 0.03571822660528923, 0.05615835760297738]}}
{"id": "ba709f5c-01c9-470f-a27f-e10657b024ec", "fitness": 0.04171186424053941, "name": "EnhancedHybridBatAlgorithmV3", "description": "A hybrid bat-inspired algorithm with dynamic loudness and adaptive local search strategies leveraging Levy flights for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithmV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.memory = np.zeros((self.population_size, self.dim))\n        \n    def levy_flight(self, L):\n        # Generate Levy flight step using Mantegna's algorithm\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return 0.01 * step * L\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.rand()\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight(self.loudness[i])\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                    \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        candidate_memory = self.memory[i] + self.levy_flight(1.0)\n                        candidate_memory = np.clip(candidate_memory, lb, ub)\n                        candidate_memory_fitness = func(candidate_memory)\n                        eval_count += 1\n                        \n                        if candidate_memory_fitness < fitness[i]:\n                            population[i] = candidate_memory\n                            fitness[i] = candidate_memory_fitness\n                        \n                        if candidate_memory_fitness < best_fitness:\n                            best_solution = candidate_memory\n                            best_fitness = candidate_memory_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridBatAlgorithmV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04171 with standard deviation 0.00283.", "error": "", "parent_ids": ["88bb0044-fdb6-4be8-a0f1-2fa2abf98a06"], "operator": null, "metadata": {"aucs": [0.04382914812729988, 0.03770649270595383, 0.04359995188836452]}}
{"id": "5149ec9a-2b41-4f33-816b-3ae9fa0c246a", "fitness": 0.051460522246528084, "name": "EnhancedHybridBatAlgorithmV3", "description": "A hybrid bat-inspired algorithm with dynamic adaptive learning rates and opposition-based learning for enhanced convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithmV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.randn()\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * np.random.randn(self.dim) * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridBatAlgorithmV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05146 with standard deviation 0.00948.", "error": "", "parent_ids": ["88bb0044-fdb6-4be8-a0f1-2fa2abf98a06"], "operator": null, "metadata": {"aucs": [0.04891322701044942, 0.04132979251866742, 0.06413854721046741]}}
{"id": "08a3e783-1fcf-4a27-ba3d-b580d4bc1a84", "fitness": 0.04650941109361384, "name": "EnhancedHybridBatAlgorithmV3", "description": "An enhanced hybrid bat-inspired algorithm with dynamic adaptive learning rates, refined velocity update, and opposition-based learning for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithmV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.random() # Changed np.random.randn() to np.random.random()\n                velocities[i] += (population[i] - best_solution) * frequency + np.random.random(self.dim) * 0.01 # Added random noise to velocity update\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * np.random.randn(self.dim) * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridBatAlgorithmV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04651 with standard deviation 0.00424.", "error": "", "parent_ids": ["5149ec9a-2b41-4f33-816b-3ae9fa0c246a"], "operator": null, "metadata": {"aucs": [0.051849387499417365, 0.04148399456383334, 0.046194851217590815]}}
{"id": "6196bc7b-e642-4df5-889d-813bc3909d2e", "fitness": 0.05881805932835319, "name": "AdvancedHybridBatAlgorithm", "description": "An advanced hybrid bat algorithm incorporating Lévy flight for enhanced global exploration and adaptive frequency control for improved convergence.", "code": "import numpy as np\n\nclass AdvancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 6, "feedback": "The algorithm AdvancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05882 with standard deviation 0.01526.", "error": "", "parent_ids": ["5149ec9a-2b41-4f33-816b-3ae9fa0c246a"], "operator": null, "metadata": {"aucs": [0.08023466150239611, 0.04581257270089922, 0.050406943781764246]}}
{"id": "49d8fee3-4a0d-46e3-b12f-f1ed6c8865cc", "fitness": 0.04496855371362115, "name": "RefinedHybridBatAlgorithm", "description": "A refined hybrid bat algorithm with enhanced adaptive learning rate and dynamic loudness scaling for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass RefinedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.adaptive_learning_rate = 0.2\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) /\n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.adaptive_learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic loudness scaling\n            self.loudness = np.clip(self.loudness * (1 - np.exp(-eval_count / self.budget)), 0.1, 1.0)\n        \n        return best_solution", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04497 with standard deviation 0.00333.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.048725996548202755, 0.0406213637155699, 0.045558300877090785]}}
{"id": "c908354c-3214-47d8-9aec-b78ee300222e", "fitness": 0.050044823339451185, "name": "AdvancedHybridBatAlgorithm", "description": "A refined hybrid bat algorithm with stochastic opposition learning and adaptive learning rate for enhanced convergence. ", "code": "import numpy as np\n\nclass AdvancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                    self.learning_rate = max(0.01, self.learning_rate * 0.95)\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm AdvancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05004 with standard deviation 0.01315.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.06822943001484771, 0.03759673873769642, 0.044308301265809424]}}
{"id": "e634386e-2b0c-453b-a657-aa0702466e32", "fitness": 0.054890083392632495, "name": "RefinedHybridBatAlgorithm", "description": "A refined hybrid bat algorithm with adaptive random walks and fitness diversity preservation to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass RefinedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.diversity_factor = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def adaptive_random_walk(self, best_solution, candidate):\n        random_walk = np.random.uniform(-1, 1, self.dim)\n        return best_solution + self.diversity_factor * random_walk * (candidate - best_solution)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive Random Walk and Diversity Check\n            if eval_count < self.budget:\n                diversity_threshold = np.std(fitness) * self.diversity_factor\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1 or np.abs(fitness[i] - best_fitness) > diversity_threshold:\n                        candidate = self.adaptive_random_walk(best_solution, population[i])\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_fitness = func(candidate)\n                        eval_count += 1\n                        \n                        if candidate_fitness < fitness[i]:\n                            population[i] = candidate\n                            fitness[i] = candidate_fitness\n                        \n                        if candidate_fitness < best_fitness:\n                            best_solution = candidate\n                            best_fitness = candidate_fitness\n                        \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm RefinedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05489 with standard deviation 0.00674.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.06346061248210311, 0.046983908225189275, 0.05422572947060511]}}
{"id": "521ad7e5-a9bc-4bf6-80e4-669a9178645e", "fitness": 0.05875651380251112, "name": "EnhancedHybridBatAlgorithm", "description": "Enhanced hybrid bat algorithm with a dynamic population size and adaptive loudness scaling for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.final_population_size = 5\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.initial_population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.initial_population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.initial_population_size)\n        self.memory = np.zeros((self.initial_population_size, self.dim))\n        self.learning_rate = 0.1\n        self.population_size = self.initial_population_size\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def reduce_population_size(self, current_eval, total_eval):\n        return int(self.final_population_size + (self.initial_population_size - self.final_population_size) * \n                   (1 - current_eval / total_eval))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.population_size = self.reduce_population_size(eval_count, self.budget)\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n        return best_solution", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05876 with standard deviation 0.01482.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.079509242154015, 0.04583548835283724, 0.05092481090068113]}}
{"id": "ac758923-1a90-485a-bbe1-28f4cb6dd036", "fitness": 0.05716691833024279, "name": "AdvancedHybridBatAlgorithm", "description": "Introduce adaptive loudness based on fitness improvement to enhance convergence.", "code": "import numpy as np\n\nclass AdvancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] = min(self.loudness[i] * self.alpha + (best_fitness - candidate_fitness) / (best_fitness + 1e-9), 1.0)  # Adaptive loudness\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm AdvancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05717 with standard deviation 0.01540.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.07877563039614799, 0.04402922335643111, 0.048695901238149264]}}
{"id": "195b84ac-ed21-4ca8-ab3b-3e470edaaed8", "fitness": 0.056632187431491864, "name": "EnhancedAdvancedHybridBatAlgorithm", "description": "Enhanced AdvancedHybridBatAlgorithm with dynamic population size and adaptive opposition-based learning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdvancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.population_growth_factor = 1.1\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def dynamic_population_size(self, iteration):\n        return int(self.population_size * (1 + (iteration / self.budget) * (self.population_growth_factor - 1)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        iteration = 0\n        while eval_count < self.budget:\n            current_population_size = self.dynamic_population_size(iteration)\n            for i in range(current_population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive opposition-based learning\n            if eval_count < self.budget:\n                opposition_probability = max(0.1, 1.0 - eval_count / self.budget)\n                for i in range(current_population_size):\n                    if np.random.rand() < opposition_probability:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            iteration += 1\n        \n        return best_solution", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdvancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05663 with standard deviation 0.01353.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.07572344396849884, 0.04601153171413863, 0.048161586611838114]}}
{"id": "aab354f0-a5b1-4047-92f8-493ad473f5cc", "fitness": 0.05134344815103442, "name": "EnhancedHybridBatAlgorithm", "description": "An enhanced hybrid bat algorithm utilizing differential evolution for improved exploration and convergence, augmented with opposition-based learning and adaptive parameter tuning.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.f_cr = 0.9  # Crossover probability for DE\n        self.f_weight = 0.8  # Weight factor for DE\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def differential_evolution(self, population, lb, ub, fitness, eval_count, func):\n        for i in range(self.population_size):\n            if eval_count >= self.budget: break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f_weight * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.f_cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = func(trial)\n            eval_count += 1\n            if trial_fitness < fitness[i]:\n                population[i] = trial\n                fitness[i] = trial_fitness\n        return population, fitness, eval_count\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Differential Evolution Phase\n            if eval_count < self.budget:\n                population, fitness, eval_count = self.differential_evolution(population, lb, ub, fitness, eval_count, func)\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05134 with standard deviation 0.00187.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.05121012411534165, 0.04911843505690161, 0.053701785280860004]}}
{"id": "845a0e54-092a-41c2-bb33-433553433017", "fitness": 0.05587662984549546, "name": "AdvancedHybridBatAlgorithm", "description": "Enhanced bat algorithm with adaptive memory update and dynamic loudness for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdvancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha * 0.9  # Change: Dynamically adjust loudness\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                            self.memory[i] = opposite_candidate  # Change: Update memory with better solutions\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 14, "feedback": "The algorithm AdvancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05588 with standard deviation 0.01529.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.07723645634035381, 0.04230025661846237, 0.048093176577670205]}}
{"id": "0a38c136-62c3-481e-9706-e2e6537bf642", "fitness": 0.058464339314516, "name": "EnhancedHybridBatAlgorithm", "description": "Enhanced Hybrid Bat Algorithm with Self-Adaptive Mechanisms and Dynamic Population Adjustment to improve convergence and adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.dynamic_adjustment_factor = 0.1\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory[i] = candidate\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * eval_count / self.budget))\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Self-Adaptive Population Adjustment\n            if eval_count < self.budget and eval_count > self.budget * self.dynamic_adjustment_factor:\n                new_population_size = int(self.population_size * (1 - self.dynamic_adjustment_factor))\n                if new_population_size < 5:\n                    new_population_size = 5\n                if new_population_size < len(population):\n                    sorted_indices = np.argsort(fitness)\n                    population = population[sorted_indices[:new_population_size]]\n                    fitness = fitness[sorted_indices[:new_population_size]]\n                    self.population_size = new_population_size\n                    self.loudness = self.loudness[sorted_indices[:new_population_size]]\n                    self.pulse_rate = self.pulse_rate[sorted_indices[:new_population_size]]\n                    self.memory = self.memory[sorted_indices[:new_population_size]]\n            \n            # Opposition-based learning\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n\n        return best_solution", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05846 with standard deviation 0.01483.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.07923583282762425, 0.04558442666704243, 0.050572758448881316]}}
{"id": "ac5aafd8-f051-40aa-a4bd-eb95a1eba379", "fitness": 0.06267261928370664, "name": "EnhancedBatAlgorithm", "description": "An enhanced bat algorithm with dynamic loudness and pulse rate adjustment based on fitness improvement frequency and adaptive memory mechanism for better convergence.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06267 with standard deviation 0.01434.", "error": "", "parent_ids": ["6196bc7b-e642-4df5-889d-813bc3909d2e"], "operator": null, "metadata": {"aucs": [0.08085870594758005, 0.04581257270089922, 0.06134657920264064]}}
{"id": "91397c2f-9c9b-4f8d-8e1c-9533ec63b489", "fitness": 0.05320378010165072, "name": "ChaoticEnhancedBatAlgorithm", "description": "An improved bat algorithm using chaotic maps for dynamic parameter tuning and self-adaptive mutation strategies to enhance exploration capabilities and convergence speed.", "code": "import numpy as np\n\nclass ChaoticEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.chaos_parameter = 0.7\n        \n    def chaotic_sequence(self, x):\n        return np.sin(np.pi * x)\n\n    def self_adaptive_mutation(self, candidate, best_solution):\n        mutation_strength = np.random.uniform(0, 1, self.dim)\n        return candidate + mutation_strength * (best_solution - candidate)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = self.chaotic_sequence(self.beta[i])\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = self.self_adaptive_mutation(best_solution, candidate) + self.learning_rate * np.random.randn(self.dim) * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n        \n        return best_solution", "configspace": "", "generation": 17, "feedback": "The algorithm ChaoticEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05320 with standard deviation 0.00709.", "error": "", "parent_ids": ["ac5aafd8-f051-40aa-a4bd-eb95a1eba379"], "operator": null, "metadata": {"aucs": [0.062390808585014446, 0.04513396497913147, 0.05208656674080625]}}
{"id": "d49a79f4-5793-4ce0-b6e1-d0e7fe4ab8e2", "fitness": 0.057576770295871826, "name": "EnhancedBatAlgorithm", "description": "An enhanced bat algorithm with dynamic loudness and pulse rate adjustment, incorporating an adaptive learning rate based on improvement frequency for better convergence.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + (0.05 + 0.95 * self.improvement_count[i] / self.budget) * self.levy_flight() * self.loudness[i]  # Changed line\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05758 with standard deviation 0.01482.", "error": "", "parent_ids": ["ac5aafd8-f051-40aa-a4bd-eb95a1eba379"], "operator": null, "metadata": {"aucs": [0.07774857523651602, 0.042558614811744166, 0.0524231208393553]}}
{"id": "7fb9ba8b-7566-41d7-81bd-4dd0887eb78a", "fitness": 0.06268911205841336, "name": "EnhancedBatAlgorithm", "description": "Improve exploration by adjusting the learning rate dynamically based on the fitness variance in the population.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)  # New line 1\n            self.learning_rate = 0.1 + 0.1 * fitness_variance  # New line 2\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06269 with standard deviation 0.01436.", "error": "", "parent_ids": ["ac5aafd8-f051-40aa-a4bd-eb95a1eba379"], "operator": null, "metadata": {"aucs": [0.08090244361414423, 0.0458139167335192, 0.06135097582757665]}}
{"id": "c9c21229-8f0f-44d1-abc9-d1f49da7755a", "fitness": 0.06268911205841336, "name": "AdaptiveEnhancedBatAlgorithm", "description": "Introduce adaptive parameter tuning using fitness trend analysis to dynamically adjust exploration and exploitation balance in the Enhanced Bat Algorithm.", "code": "import numpy as np\n\nclass AdaptiveEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.prev_best_fitness = np.inf  # Added for fitness trend analysis\n        self.no_improvement_steps = 0\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            # Adaptive parameter tuning based on fitness trend\n            if best_fitness == self.prev_best_fitness:\n                self.no_improvement_steps += 1\n            else:\n                self.no_improvement_steps = 0\n                self.prev_best_fitness = best_fitness\n            \n            if self.no_improvement_steps > 5:  # If no improvement in 5 iterations\n                self.learning_rate *= 1.1  # Increase exploration\n                self.loudness = np.clip(self.loudness + 0.05, 0.5, 1.0)\n                self.no_improvement_steps = 0  # Reset step counter\n        \n        return best_solution", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06269 with standard deviation 0.01436.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.08090244361414423, 0.0458139167335192, 0.06135097582757665]}}
{"id": "7b96fa62-2fdb-4beb-8c74-31c8b198df91", "fitness": 0.04528641359181318, "name": "EnhancedBatAlgorithm", "description": "Incorporate dynamic loudness and pulse rate adaptation using sigmoid functions to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > 1 / (1 + np.exp(-fitness[i])):  # Change 1\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < 1 / (1 + np.exp(-self.improvement_count[i])):  # Change 2\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04529 with standard deviation 0.00377.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.04964765912448654, 0.040452941371588946, 0.04575864027936405]}}
{"id": "42a33b58-0425-49d7-b4a4-fc39e751a02d", "fitness": 0.06078226078372717, "name": "EnhancedBatAlgorithm", "description": "Adjust the initial loudness values to a higher range to promote exploration in early iterations.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.7, 1.2, self.population_size)  # Changed initial loudness range\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06078 with standard deviation 0.01462.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.08138568800590873, 0.04902330446476122, 0.051937789880511565]}}
{"id": "b728fbe7-7b63-4b95-8aa2-69924489fffa", "fitness": 0.06058158703892654, "name": "ImprovedBatAlgorithm", "description": "Improve exploration by dynamically adapting a memory-based feedback mechanism that adjusts loudness and pulse rate based on individual bat improvement.", "code": "import numpy as np\n\nclass ImprovedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * (self.improvement_count[i] / max(1, fitness_variance))))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 23, "feedback": "The algorithm ImprovedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06058 with standard deviation 0.01343.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.07816510324866877, 0.045574634721639695, 0.05800502314647116]}}
{"id": "9966912b-f51e-49b3-8320-58055c4fd001", "fitness": 0.06268911205841336, "name": "EnhancedBatAlgorithm", "description": "Enhance exploration by modifying the pulse rate update formula with fitness variance to better adapt to the problem landscape.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    # Modified pulse rate update with fitness variance\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget + fitness_variance))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n        \n        return best_solution", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06269 with standard deviation 0.01436.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.08090244361414423, 0.0458139167335192, 0.06135097582757665]}}
{"id": "db29457b-40a8-4400-bb1a-ae7117e23a54", "fitness": 0.06675548198029906, "name": "EnhancedBatAlgorithm", "description": "Enhance convergence by introducing adaptive elitism and dynamically adjusting pulse rate and loudness based on historical improvements.", "code": "import numpy as np\n\nclass EnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.elitism_rate = 0.2  # New line 1\n        self.global_best_history = []  # New line 2\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)  # New line 3\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha * (1 + 0.1 * self.improvement_count[i]))  # Modified line 1\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))  # Modified line 2\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            self.global_best_history.append(best_fitness)  # New line 4\n            if len(self.global_best_history) > 2 and self.global_best_history[-1] == self.global_best_history[-3]:  # New line 5\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)  # New line 6\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)  # New line 7\n            \n            elite_count = int(self.elitism_rate * self.population_size)  # New line 8\n            elite_indices = np.argsort(fitness)[:elite_count]  # New line 9\n            population[elite_indices] = best_solution  # New line 10\n\n        return best_solution", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06676 with standard deviation 0.01311.", "error": "", "parent_ids": ["7fb9ba8b-7566-41d7-81bd-4dd0887eb78a"], "operator": null, "metadata": {"aucs": [0.08381265487391454, 0.051949138630048575, 0.06450465243693404]}}
{"id": "a7887167-f9f2-4974-8a14-c3dee287ca57", "fitness": 0.07182865068860844, "name": "RefinedEnhancedBatAlgorithm", "description": "Incorporate adaptive memory and neighborhood search inspired by PSO to improve exploration and exploitation balancing.", "code": "import numpy as np\n\nclass RefinedEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.elitism_rate = 0.2\n        self.global_best_history = []\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                    \n                    # Update personal best\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha * (1 + 0.1 * self.improvement_count[i]))\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            self.global_best_history.append(best_fitness)\n            if len(self.global_best_history) > 2 and self.global_best_history[-1] == self.global_best_history[-3]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n            \n            elite_count = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_count]\n            population[elite_indices] = best_solution\n\n        return best_solution", "configspace": "", "generation": 26, "feedback": "The algorithm RefinedEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07183 with standard deviation 0.00256.", "error": "", "parent_ids": ["db29457b-40a8-4400-bb1a-ae7117e23a54"], "operator": null, "metadata": {"aucs": [0.07217232735454382, 0.07478412367281784, 0.06852950103846367]}}
{"id": "c0956ef3-e54e-4637-8c8f-7f5c29f9d9fd", "fitness": 0.07207913050507546, "name": "RefinedEnhancedBatAlgorithm", "description": "Increase frequency range for better exploration.", "code": "import numpy as np\n\nclass RefinedEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 3  # Changed from 2 to 3 to increase exploration\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.elitism_rate = 0.2\n        self.global_best_history = []\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                    \n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha * (1 + 0.1 * self.improvement_count[i]))\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            self.global_best_history.append(best_fitness)\n            if len(self.global_best_history) > 2 and self.global_best_history[-1] == self.global_best_history[-3]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n            \n            elite_count = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_count]\n            population[elite_indices] = best_solution\n\n        return best_solution", "configspace": "", "generation": 27, "feedback": "The algorithm RefinedEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07208 with standard deviation 0.00156.", "error": "", "parent_ids": ["a7887167-f9f2-4974-8a14-c3dee287ca57"], "operator": null, "metadata": {"aucs": [0.07038129184391662, 0.07414614485215809, 0.07170995481915166]}}
{"id": "1d0cc5ba-cd4f-4936-80e6-50e8a4fe9e86", "fitness": 0.07207913050507546, "name": "RefinedEnhancedBatAlgorithm", "description": "Introduced adaptive elitism rate based on fitness variance for better convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 3  # Changed from 2 to 3 to increase exploration\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.learning_rate = 0.1\n        self.improvement_count = np.zeros(self.population_size)\n        self.elitism_rate = 0.2\n        self.global_best_history = []\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            fitness_variance = np.var(fitness)\n            self.learning_rate = 0.1 + 0.1 * fitness_variance\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.learning_rate * self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    fitness_improvement = fitness[i] - candidate_fitness\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate if fitness_improvement > 0 else self.memory[i]\n                    \n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha * (1 + 0.1 * self.improvement_count[i]))\n                    self.pulse_rate[i] *= (1 - np.exp(-self.gamma * self.improvement_count[i] / self.budget))\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            self.global_best_history.append(best_fitness)\n            if len(self.global_best_history) > 2 and self.global_best_history[-1] == self.global_best_history[-3]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n            \n            elite_count = int((self.elitism_rate + 0.1 * fitness_variance) * self.population_size)  # Modified line\n            elite_indices = np.argsort(fitness)[:elite_count]\n            population[elite_indices] = best_solution\n\n        return best_solution", "configspace": "", "generation": 28, "feedback": "The algorithm RefinedEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07208 with standard deviation 0.00156.", "error": "", "parent_ids": ["c0956ef3-e54e-4637-8c8f-7f5c29f9d9fd"], "operator": null, "metadata": {"aucs": [0.07038129184391662, 0.07414614485215809, 0.07170995481915166]}}
{"id": "cb26b57a-6f4e-4ab7-b4fa-06b807b358e9", "fitness": 0.08177871211181853, "name": "AdaptiveBatAlgorithm", "description": "Introduce adaptive loudness and pulse rate based on stagnation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    self.pulse_rate[i] = 1 - (1 - self.pulse_rate[i]) * self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            self.global_best_history.append(best_fitness)\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08178 with standard deviation 0.00356.", "error": "", "parent_ids": ["c0956ef3-e54e-4637-8c8f-7f5c29f9d9fd"], "operator": null, "metadata": {"aucs": [0.08491079722775885, 0.0767962998613444, 0.08362903924635234]}}
{"id": "63604d19-b94c-475e-b0ca-72d6c940a624", "fitness": 0.08392248540667198, "name": "DynamicPopulationBatAlgorithm", "description": "Integrate dynamic population size adjustment based on exploration-exploitation balance to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass DynamicPopulationBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    self.pulse_rate[i] = 1 - (1 - self.pulse_rate[i]) * self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n                    \n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 30, "feedback": "The algorithm DynamicPopulationBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08392 with standard deviation 0.00190.", "error": "", "parent_ids": ["cb26b57a-6f4e-4ab7-b4fa-06b807b358e9"], "operator": null, "metadata": {"aucs": [0.08607761631812838, 0.08423025625844172, 0.08145958364344585]}}
{"id": "61068657-6bc5-4d92-8323-9514e2b90b91", "fitness": 0.08439606212325561, "name": "DynamicPopulationBatAlgorithm", "description": "Incorporate adaptive pulse rate decay based on fitness improvement to enhance convergence efficiency.", "code": "import numpy as np\n\nclass DynamicPopulationBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.98\n        self.gamma = 0.95\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim)) \n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:  # Change 1\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n                    \n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 31, "feedback": "The algorithm DynamicPopulationBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08440 with standard deviation 0.00048.", "error": "", "parent_ids": ["63604d19-b94c-475e-b0ca-72d6c940a624"], "operator": null, "metadata": {"aucs": [0.0846107333627496, 0.08484934299395763, 0.08372811001305958]}}
{"id": "070f4426-c7fa-4caf-8f8a-ece0dc4046c7", "fitness": 0.08666799046481881, "name": "AdaptiveBatAlgorithm", "description": "Enhance exploitation by integrating self-adaptive loudness and pulse rate adjustment based on historical search experience to improve convergence to the global optimum.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.gamma = 0.8 + 0.2 * improvement_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08667 with standard deviation 0.00206.", "error": "", "parent_ids": ["61068657-6bc5-4d92-8323-9514e2b90b91"], "operator": null, "metadata": {"aucs": [0.08391137113437408, 0.08886113385105354, 0.08723146640902879]}}
{"id": "7568107b-8de6-4684-a50f-9f1cdffbce7a", "fitness": -Infinity, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Introduce adaptive dimensionality reduction and dynamic frequency adjustment to improve exploration and exploitation balance, enhancing convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.dim_reduction_rate = 0.9\n        self.reduced_dim = self.dim\n        self.dim_reduction_threshold = 0.1\n    \n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.reduced_dim)\n        v = np.random.normal(0, 1, self.reduced_dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.dim_reduction_threshold:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n                self.reduced_dim = max(int(self.reduced_dim * self.dim_reduction_rate), 1)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.gamma = 0.8 + 0.2 * improvement_rate\n        dynamic_frequency_adjustment = (self.frequency_max - self.frequency_min) * improvement_rate\n        self.frequency_max = min(5, self.frequency_max + dynamic_frequency_adjustment)\n        self.frequency_min = max(0, self.frequency_min - dynamic_frequency_adjustment)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.reduced_dim))\n        velocities = np.zeros((self.population_size, self.reduced_dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb[:self.reduced_dim], ub[:self.reduced_dim])\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n        \n        return best_solution", "configspace": "", "generation": 33, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["070f4426-c7fa-4caf-8f8a-ece0dc4046c7"], "operator": null, "metadata": {}}
{"id": "41b413f7-9298-4775-a483-14a48193b07b", "fitness": -Infinity, "name": "AdaptiveBatAlgorithm", "description": "Introduce dynamic mutation strategies and enhance convergence by balancing exploration and exploitation using adaptive memory and neighborhood search.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.dynamic_mutation_rate = 0.1  # New parameter for mutation\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def neighborhood_search(self, candidate):\n        mutation_vector = np.random.normal(0, self.dynamic_mutation_rate, self.dim)\n        return candidate + mutation_vector\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.gamma = 0.8 + 0.2 * improvement_rate\n        self.dynamic_mutation_rate = 0.1 + 0.1 * (1 - improvement_rate)  # Adjust mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate = self.neighborhood_search(candidate)  # Apply neighborhood search\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 34, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_ids": ["070f4426-c7fa-4caf-8f8a-ece0dc4046c7"], "operator": null, "metadata": {}}
{"id": "0d1ee274-4118-461c-893d-6c6e21826350", "fitness": 0.08498340524866987, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Integrate adaptive learning rates based on historical improvement to enhance convergence and dynamically balance exploration and exploitation in the Adaptive Bat Algorithm.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.9\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) /\n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.8 + 0.2 * improvement_rate\n        self.gamma = 0.7 + 0.3 * improvement_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] *= self.alpha\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.population_size + 1)\n            self.adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n        \n        return best_solution", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08498 with standard deviation 0.00188.", "error": "", "parent_ids": ["070f4426-c7fa-4caf-8f8a-ece0dc4046c7"], "operator": null, "metadata": {"aucs": [0.0870567251080262, 0.08538004161550239, 0.08251344902248103]}}
{"id": "6b9fba04-d547-48ce-b5a2-65ea7de0208e", "fitness": 0.08515388070516731, "name": "AdaptiveBatAlgorithm", "description": "Enhance exploration by incorporating dynamic adjustment of frequency range and adding adaptive inertia for velocity control to improve global search capabilities.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.dynamic_freq_range = (0.5, 5)  # Changed frequency range for exploration\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.inertia_weight = 0.9  # Introduced inertia weight for velocity update\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.gamma = 0.8 + 0.2 * improvement_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.dynamic_freq_range[0] + (self.dynamic_freq_range[1] - self.dynamic_freq_range[0]) * self.beta[i]  # Updated frequency calculation\n                velocities[i] = self.inertia_weight * velocities[i] + (population[i] - best_solution) * frequency  # Applied inertia weight\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08515 with standard deviation 0.00117.", "error": "", "parent_ids": ["070f4426-c7fa-4caf-8f8a-ece0dc4046c7"], "operator": null, "metadata": {"aucs": [0.08447464761840717, 0.08418839824733271, 0.08679859624976205]}}
{"id": "09bab2ce-3d81-4e04-8d76-063011698566", "fitness": 0.08914874399151136, "name": "AdaptiveBatAlgorithm", "description": "Introduced dynamic adjustment of loudness and pulse rate based on recent fitness improvement to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.loudness = np.clip(self.loudness * (1.0 + improvement_rate), 0.5, 1.0)  # Adjusted loudness\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - improvement_rate), 0.2, 0.8)  # Adjusted pulse rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08915 with standard deviation 0.00161.", "error": "", "parent_ids": ["070f4426-c7fa-4caf-8f8a-ece0dc4046c7"], "operator": null, "metadata": {"aucs": [0.0910366490958705, 0.08709622184190136, 0.08931336103676224]}}
{"id": "71fee9a0-e6c7-4a66-93c3-8f7ec87dd0aa", "fitness": 0.0805244719561931, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Enhanced Adaptive Bat Algorithm with a self-adaptive velocity scaling mechanism based on improvement trends to improve exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.velocity_scaling = np.ones(self.population_size)\n        self.global_best_history = []\n        self.stagnation_threshold = 3\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.loudness = np.clip(self.loudness * (1.0 + improvement_rate), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - improvement_rate), 0.2, 0.8)\n        self.velocity_scaling *= (1.0 + improvement_rate / 2.0)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += self.velocity_scaling[i] * (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(np.maximum(0, self.personal_best_fitness - fitness) / (self.personal_best_fitness + 1e-9))\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08052 with standard deviation 0.00092.", "error": "", "parent_ids": ["09bab2ce-3d81-4e04-8d76-063011698566"], "operator": null, "metadata": {"aucs": [0.08125509460026537, 0.08108869771997751, 0.0792296235483364]}}
{"id": "dccd8c3e-b8a1-422c-86a4-41a66ac57a92", "fitness": 0.08914874399151136, "name": "AdaptiveBatAlgorithm", "description": "Enhanced adaptive mechanisms by refining dynamic parameter adjustments and introducing condition-based global restart to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n    \n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n    \n    def self_adaptive_parameters(self, improvement_rate):\n        self.alpha = 0.9 + 0.1 * improvement_rate\n        self.loudness = np.clip(self.loudness * (1.0 + improvement_rate), 0.5, 1.0)  # Adjusted loudness\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - improvement_rate), 0.2, 0.8)  # Adjusted pulse rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n                \n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                \n                candidate_fitness = func(candidate)\n                eval_count += 1\n                \n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n                \n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n                    \n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n                \n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n                        \n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n                        \n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n                            \n                        if eval_count >= self.budget:\n                            break\n            \n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] > self.global_best_history[-self.stagnation_threshold]:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                self.improvement_count.fill(0)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08915 with standard deviation 0.00161.", "error": "", "parent_ids": ["09bab2ce-3d81-4e04-8d76-063011698566"], "operator": null, "metadata": {"aucs": [0.0910366490958705, 0.08709622184190136, 0.08931336103676224]}}
{"id": "18543cf7-02d8-4a72-bca1-f46c2e30ef5f", "fitness": 0.09065045996297476, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Introducing a multi-phase adaptation strategy with dynamic learning acceleration and adaptive memory retention to boost convergence efficiency and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09065 with standard deviation 0.00132.", "error": "", "parent_ids": ["09bab2ce-3d81-4e04-8d76-063011698566"], "operator": null, "metadata": {"aucs": [0.08892263207973905, 0.09212008906370839, 0.09090865874547682]}}
{"id": "c1bed94a-aa64-46f6-b197-6cc06b4180c0", "fitness": 0.07834867629394023, "name": "ChaoticEnhancedAdaptiveBatAlgorithm", "description": "Integrating chaotic maps for parameter tuning and neighborhood attraction to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass ChaoticEnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = np.random.rand()\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_parameters(self):\n        self.chaos_factor = 4 * self.chaos_factor * (1 - self.chaos_factor)  # Logistic map\n        self.alpha = 0.9 + 0.1 * self.chaos_factor\n        self.loudness = np.clip(self.loudness * (1.0 + self.chaos_factor), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - self.chaos_factor), 0.2, 0.8)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.chaotic_parameters()\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 41, "feedback": "The algorithm ChaoticEnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07835 with standard deviation 0.00475.", "error": "", "parent_ids": ["18543cf7-02d8-4a72-bca1-f46c2e30ef5f"], "operator": null, "metadata": {"aucs": [0.07164082137361205, 0.08196870760185948, 0.08143649990634916]}}
{"id": "e72a0aa0-7dd3-4a6f-9fd2-c9a42b94e732", "fitness": 0.09065029439512606, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Refining the algorithm by enhancing the adaptation phase to better balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.55  # Slight increase in adaptation phase for better balance\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09065 with standard deviation 0.00078.", "error": "", "parent_ids": ["18543cf7-02d8-4a72-bca1-f46c2e30ef5f"], "operator": null, "metadata": {"aucs": [0.09096080792965167, 0.09141002426131473, 0.0895800509944118]}}
{"id": "6aa76534-da99-4d8b-b3e3-9df109016a2b", "fitness": 0.09065822983263272, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Enhance the adaptive bat algorithm by integrating a dynamic population variance strategy and chaotic search perturbations to improve convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09066 with standard deviation 0.00131.", "error": "", "parent_ids": ["18543cf7-02d8-4a72-bca1-f46c2e30ef5f"], "operator": null, "metadata": {"aucs": [0.08893442321510348, 0.09211743276449269, 0.090922833518302]}}
{"id": "3af685ac-a47e-435a-adb6-bd6ff3b97973", "fitness": 0.08875790895731872, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Refine the enhanced adaptive bat algorithm by introducing adaptive chaotic perturbations and improving the opposition-based learning with dynamic boundary adjustments for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        # Adjusted to consider dynamic boundary relaxation\n        mid_point = (lb + ub) / 2\n        return mid_point + (mid_point - candidate) * np.random.uniform(0.5, 1.5)\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        # Adaptive chaotic factor based on iteration\n        dynamic_chaos_factor = self.chaos_factor * (1 - min(len(self.global_best_history) / (self.stagnation_threshold + 1), 1))\n        chaotic_factor = np.random.uniform(-dynamic_chaos_factor, dynamic_chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply adaptive chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08876 with standard deviation 0.00065.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08946221526619558, 0.08788994601349531, 0.08892156559226527]}}
{"id": "d352b0f9-85d5-4083-80db-467b66ac97da", "fitness": 0.09059775900210128, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Introduce a more aggressive adaptation phase adjustment to potentially enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.7  # Changed from 0.5 to 0.7\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09060 with standard deviation 0.00062.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.09104354310048457, 0.09102895708113523, 0.08972077682468405]}}
{"id": "99b09a70-8b47-40ce-91ba-c8d7b9fe5407", "fitness": 0.09064872592968738, "name": "EnhancedMultiObjectiveBatAlgorithm", "description": "Improve the Enhanced Adaptive Bat Algorithm by introducing a multi-objective optimization approach that balances exploration and exploitation, leveraging both dynamic multi-swarm strategies and adaptive local search with an entropy-based global learning mechanism to enhance overall performance and solution quality.", "code": "import numpy as np\n\nclass EnhancedMultiObjectiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n        self.entropy_weight = 0.5\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def entropy_based_global_search(self, population, lb, ub):\n        entropy_values = -np.sum(population * np.log(np.clip(population, 1e-10, None)), axis=1)\n        max_entropy_idx = np.argmax(entropy_values)\n        return self.chaotic_perturbation(population[max_entropy_idx], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                population[-1] = self.entropy_based_global_search(population, lb, ub)\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedMultiObjectiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09065 with standard deviation 0.00132.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08891645200411347, 0.09211191651787842, 0.09091780926707027]}}
{"id": "6e06379a-614f-429a-9008-9124fefbea1a", "fitness": 0.09065822983263272, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Slightly increase the chaotic perturbation factor to improve solution diversity and exploration capability.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.15  # Slightly increased chaotic perturbation factor\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09066 with standard deviation 0.00131.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08893442321510348, 0.09211743276449269, 0.090922833518302]}}
{"id": "8ee977d1-43c5-4c1d-8103-91096c7c4e14", "fitness": 0.09065822983263272, "name": "MultiPhaseEnhancedAdaptiveBatAlgorithm", "description": "Introduce a multi-phase adaptive strategy in the Enhanced Adaptive Bat Algorithm to enhance exploration and exploitation balance through environment-driven parameter tuning and strategic population rejuvenation.", "code": "import numpy as np\n\nclass MultiPhaseEnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def rejuvenate_population(self, lb, ub):\n        diversity_metric = np.std(self.personal_best, axis=0).mean()\n        if diversity_metric < 0.01:\n            self.personal_best = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            self.personal_best_fitness = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n            self.rejuvenate_population(lb, ub)\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 48, "feedback": "The algorithm MultiPhaseEnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09066 with standard deviation 0.00131.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08893442321510348, 0.09211743276449269, 0.090922833518302]}}
{"id": "1f17462c-e79d-4fe4-89c8-e951695646e5", "fitness": 0.08851868697463332, "name": "ImprovedAdaptiveBatAlgorithm", "description": "Improve the EnhancedAdaptiveBatAlgorithm by incorporating a novel multi-scale Levy flight strategy and adaptive chaotic perturbation to enhance exploration and exploitation balance and increase solution robustness.", "code": "import numpy as np\n\nclass ImprovedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5, scale=0.01):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return scale * step\n\n    def chaotic_perturbation(self, solution, lb, ub, scale=0.1):\n        chaotic_factor = np.random.uniform(-scale, scale, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight(scale=self.loudness[i]) * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, scale=self.chaos_factor)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 49, "feedback": "The algorithm ImprovedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08852 with standard deviation 0.00125.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08910797402038395, 0.08678356498722783, 0.08966452191628815]}}
{"id": "5a00f407-3f95-4d3c-a5c9-43189844d808", "fitness": 0.09065822983263272, "name": "RefinedEnhancedAdaptiveBatAlgorithm", "description": "Integrate a multi-phase search strategy combining opposition-based learning, adaptive chaotic perturbations, and adaptive exploration-exploitation balance to improve solution convergence and diversity.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  \n        self.opposite_learning_prob = 0.1  # Probability of applying opposition-based learning\n        self.chaotic_perturbation_prob = 0.2  # Probability for chaotic perturbations\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < self.opposite_learning_prob:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaotic_perturbation_prob:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedEnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09066 with standard deviation 0.00131.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08893442321510348, 0.09211743276449269, 0.090922833518302]}}
{"id": "b85bda51-628b-4b14-a716-949a6167fa3d", "fitness": 0.09065407555528256, "name": "EnhancedAdaptiveBatAlgorithm", "description": "Introduce adaptive chaos factor variation and diversity restart mechanism to improve convergence and diversity in the Enhanced Adaptive Bat Algorithm.", "code": "import numpy as np\n\nclass EnhancedAdaptiveBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n        self.chaotic_variation_rate = 0.2  # New variable for chaos factor adaptation\n        self.diversity_threshold = 0.05  # New variable for diversity restart\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        self.chaos_factor *= (1 + np.random.uniform(-self.chaotic_variation_rate, self.chaotic_variation_rate))  # Adaptive chaos factor\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                # Apply chaotic search perturbations to enhance diversity\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n            # Diversity restart mechanism\n            if np.std(fitness) < self.diversity_threshold:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.zeros((self.population_size, self.dim))\n                fitness = np.array([func(ind) for ind in population])\n                eval_count += self.population_size\n\n        return best_solution", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09065 with standard deviation 0.00130.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08894799042042778, 0.09210426645467173, 0.09090996979074817]}}
{"id": "f274d75e-e9d0-43e7-97eb-4b444fa1a944", "fitness": 0.09072202208882381, "name": "HybridAdaptiveQuantumBatAlgorithm", "description": "Introduce a hybrid exploration-exploitation mechanism by combining adaptive inertia weight and quantum-behavior random walks to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass HybridAdaptiveQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Chaotic perturbation factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.9 + 0.1 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.2:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 52, "feedback": "The algorithm HybridAdaptiveQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09072 with standard deviation 0.00205.", "error": "", "parent_ids": ["6aa76534-da99-4d8b-b3e3-9df109016a2b"], "operator": null, "metadata": {"aucs": [0.08811813143045288, 0.09312928811589138, 0.09091864672012717]}}
{"id": "0710594c-1181-4e0e-b7fb-9f3d8ab4a03f", "fitness": 0.09094501270311366, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhance convergence and solution quality by integrating adaptive chaos-based inertia weight and quantum-inspired exploration techniques.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Enhanced chaotic perturbation factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment  # Adjust alpha range\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09095 with standard deviation 0.00176.", "error": "", "parent_ids": ["f274d75e-e9d0-43e7-97eb-4b444fa1a944"], "operator": null, "metadata": {"aucs": [0.08882896718457112, 0.09312708542862924, 0.0908789854961406]}}
{"id": "d35fc452-2d68-4302-9cd7-c9256f043139", "fitness": 0.08942336608879724, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhance convergence and solution quality by fine-tuning the inertia decay rate for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Enhanced chaotic perturbation factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.95  # Adjusted from 0.99 to 0.95 for better balance\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment  # Adjust alpha range\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08942 with standard deviation 0.00108.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.0889851827887348, 0.08837505942890511, 0.09090985604875179]}}
{"id": "4d996288-0a02-4be8-a5d8-2335ba247b4b", "fitness": 0.0769781321809651, "name": "RefinedQuantumBatAlgorithm", "description": "Integrate dynamic leader selection and multi-strategy perturbation to enhance exploration and exploitation balance in quantum bat algorithm.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def dynamic_leader_selection(self, population, fitness):\n        sorted_indices = np.argsort(fitness)\n        return population[sorted_indices[:3]], fitness[sorted_indices[:3]]\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        leaders, leaders_fitness = self.dynamic_leader_selection(population, fitness)\n        best_solution = leaders[np.argmin(leaders_fitness)]\n        best_fitness = np.min(leaders_fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = leaders[np.random.choice(len(leaders))] + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            leaders, leaders_fitness = self.dynamic_leader_selection(population, fitness)\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 55, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07698 with standard deviation 0.00108.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.0774346987126211, 0.07800591151013558, 0.07549378632013859]}}
{"id": "dc1652f0-c819-41d1-9a6b-90f30df1911d", "fitness": 0.09007233493095552, "name": "EnhancedAdaptativeQuantumBatAlgorithm", "description": "Improve convergence and adaptability by incorporating dynamic population resizing, enhanced chaotic perturbation, and adaptive levy flights with scaling factors.", "code": "import numpy as np\n\nclass EnhancedAdaptativeQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5, scale=1.0):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma * scale, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight(scale=self.loudness[i]) * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptativeQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09007 with standard deviation 0.00094.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08994175553536532, 0.09128475865943597, 0.0889904905980653]}}
{"id": "0361ba4d-28a3-43fb-a8f5-7eccfcbac3a3", "fitness": -Infinity, "name": "EnhancedDifferentialQuantumBatAlgorithm", "description": "Integrate adaptive differential mutation and enhanced quantum-inspired exploration to improve convergence and solution diversity.", "code": "import numpy as np\n\nclass EnhancedDifferentialQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1  # Enhanced chaotic perturbation factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.differential_weight = 0.8\n        self.crossover_probability = 0.9\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment  # Adjust alpha range\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def differential_mutation(self, population):\n        mutated_population = np.copy(population)\n        for i in range(self.population_size):\n            indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutated_vector = population[a] + self.differential_weight * (population[b] - population[c])\n            crossover = np.random.rand(self.dim) < self.crossover_probability\n            mutated_population[i] = np.where(crossover, mutated_vector, population[i])\n        return mutated_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = self.differential_mutation(candidate.reshape(1, -1)).flatten()\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 57, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 1').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 1')", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {}}
{"id": "c727c172-a29f-4773-8883-3398c75343a7", "fitness": 0.0857818338491837, "name": "RefinedQuantumBatAlgorithm", "description": "Improve convergence speed and solution precision of the EnhancedQuantumBatAlgorithm by integrating an adaptive learning rate with differential evolution-inspired mutation strategies.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.learning_rate = 0.5  # Adaptive learning rate\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def differential_mutation(self, population, best_solution, lb, ub):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        mutant = a + self.learning_rate * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return np.clip(mutant + np.random.uniform(-self.learning_rate, self.learning_rate, self.dim), lb, ub)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n        self.learning_rate = 0.2 + 0.6 * phase_adjustment  # Adaptive learning rate adjustment\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                if np.random.rand() < 0.3:  # Differential mutation strategy\n                    candidate = self.differential_mutation(population, best_solution, lb, ub)\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.2:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.3:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 58, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08578 with standard deviation 0.00411.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08026622598001587, 0.08693824031560782, 0.0901410352519274]}}
{"id": "4ef14187-1f74-495d-82a6-075e78db0366", "fitness": 0.08526257854364223, "name": "EnhancedQuantumBatAlgorithmWithDE", "description": "Improve convergence and solution quality by introducing dynamic population resizing and hybridizing with a differential evolution-inspired mutation strategy.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithmWithDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.exploration_exploitation_tradeoff = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        self.F = 0.8  # Scaling factor for DE mutation\n        self.CR = 0.9  # Crossover rate for DE\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def differential_mutation(self, population, i, lb, ub):\n        idxs = [idx for idx in range(self.population_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = np.clip(population[a] + self.F * (population[b] - population[c]), lb, ub)\n        return mutant\n\n    def differential_crossover(self, target, mutant):\n        trial = np.copy(target)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                trial[j] = mutant[j]\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_solution = candidate\n                        best_fitness = candidate_fitness\n\n            for i in range(self.population_size):\n                mutant = self.differential_mutation(population, i, lb, ub)\n                trial = self.differential_crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            self.inertia_weight *= self.inertia_decay\n            \n        return best_solution", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedQuantumBatAlgorithmWithDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08526 with standard deviation 0.00100.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08622828830074813, 0.08389181005829138, 0.0856676372718872]}}
{"id": "b9b43248-b7f9-4c13-b8c9-313ba61c7b75", "fitness": 0.09094008222664492, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhance convergence by incorporating a dynamic balance of exploration-exploitation using adaptive quantum-inspired strategies and chaos-based perturbations.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.5, 1.5, self.dim)  # Adjusted for more variability\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Slightly increased probability for chaos\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:  # Further increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09094 with standard deviation 0.00174.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08882765938698722, 0.09309972628959717, 0.09089286100335037]}}
{"id": "125d31d9-6ec0-44fb-a51d-7d9f2bb3a111", "fitness": 0.09091295324315751, "name": "EnhancedQuantumBatAlgorithm", "description": "Improve convergence through dynamic memory management and hybrid mutation strategies, enhancing exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99\n        # Memory size management\n        self.memory_size = 10\n        self.memory_fitness = np.full(self.memory_size, np.inf)\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 2, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def hybrid_mutation(self, candidate, best_solution, lb, ub):\n        if np.random.rand() < 0.5:\n            return self.chaotic_perturbation(candidate, lb, ub)\n        else:\n            return self.quantum_random_walk(best_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.3:\n                        population[j] = self.hybrid_mutation(population[j], best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09091 with standard deviation 0.00178.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08875740914639063, 0.09312165239751868, 0.09085979818556322]}}
{"id": "c3a71b41-a608-4a08-bc73-5e3da8524fb5", "fitness": 0.09098313274298146, "name": "RefinedQuantumBatAlgorithm", "description": "Improve convergence and solution quality by incorporating adaptive inertia weight and chaotic random walks, with enhanced self-adaptation and population diversity mechanisms.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased probability for chaotic perturbation\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 62, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09098 with standard deviation 0.00172.", "error": "", "parent_ids": ["0710594c-1181-4e0e-b7fb-9f3d8ab4a03f"], "operator": null, "metadata": {"aucs": [0.08892920873819232, 0.09312732848740168, 0.09089286100335037]}}
{"id": "d594f127-b8f2-4e45-b66f-97d95b09bbc2", "fitness": 0.08871402795754635, "name": "RefinedQuantumBatAlgorithm", "description": "Enhance quantum bat algorithm by introducing adaptive levy flights, dynamic chaos factors, and optimally utilizing memory to bolster exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step * np.random.uniform(0.5, 1.5)  # Adaptive step size\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    if np.random.rand() < 0.3:  # Higher probability to use memory\n                        population[i] = self.memory[i] \n                    else:\n                        population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.25:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 63, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08871 with standard deviation 0.00179.", "error": "", "parent_ids": ["c3a71b41-a608-4a08-bc73-5e3da8524fb5"], "operator": null, "metadata": {"aucs": [0.09097131845782713, 0.08658885048888876, 0.08858191492592316]}}
{"id": "7d2c48fc-3f69-4524-a2dc-55be8ba49e1f", "fitness": 0.0707575414281209, "name": "RefinedQuantumBatAlgorithm", "description": "Enhance solution quality by integrating additional chaotic perturbation with adaptive probability to improve exploration.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased probability for chaotic perturbation\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n            \n            # Apply additional chaotic perturbation with adaptive probability\n            if np.random.rand() < 0.05: \n                best_solution = self.chaotic_perturbation(best_solution, lb, ub)\n\n        return best_solution", "configspace": "", "generation": 64, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07076 with standard deviation 0.01481.", "error": "", "parent_ids": ["c3a71b41-a608-4a08-bc73-5e3da8524fb5"], "operator": null, "metadata": {"aucs": [0.09096819846308757, 0.06543079189612921, 0.05587363392514588]}}
{"id": "948db690-cf4f-4427-a464-77ef806ed7c7", "fitness": 0.09098313274298146, "name": "RefinedQuantumBatAlgorithm", "description": "Enhance solution exploration by increasing the weight of the chaotic perturbation factor.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.15  # Increased chaos factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.25:  # Increased probability for chaotic perturbation\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 65, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09098 with standard deviation 0.00172.", "error": "", "parent_ids": ["c3a71b41-a608-4a08-bc73-5e3da8524fb5"], "operator": null, "metadata": {"aucs": [0.08892920873819232, 0.09312732848740168, 0.09089286100335037]}}
{"id": "80777f51-cabf-4d07-bbef-b6a277844936", "fitness": 0.08955995993026966, "name": "EnhancedQuantumBatAlgorithm", "description": "Integrate multi-phase evolution with quantum-inspired mechanisms and adaptive chaos to enhance exploration-exploitation balance and solution robustness.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.85\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 5\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.6\n        self.chaos_factor = 0.15\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.97\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate)\n        self.alpha = 0.8 + 0.2 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.12:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Increased probability for chaotic perturbation\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.4:  # Increased probability for quantum random walk\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.00151.", "error": "", "parent_ids": ["c3a71b41-a608-4a08-bc73-5e3da8524fb5"], "operator": null, "metadata": {"aucs": [0.08869573480246218, 0.09167870961688396, 0.08830543537146285]}}
{"id": "81d8dffd-bf4f-4a61-bacc-b54d429c9c53", "fitness": 0.09121350658336502, "name": "RefinedQuantumBatAlgorithm", "description": "Enhance exploitation by modifying chaotic perturbation probability and self-adaptive parameter phase adjustment.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_factor, self.chaos_factor, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_random_walk(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)  # Modified\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.3:  # Modified\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_random_walk(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 67, "feedback": "The algorithm RefinedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["c3a71b41-a608-4a08-bc73-5e3da8524fb5"], "operator": null, "metadata": {"aucs": [0.0912003483445436, 0.0930123536578108, 0.08942781774774067]}}
{"id": "7bb4fa23-dcdc-4126-8a74-968396685d29", "fitness": 0.09121350674529238, "name": "EnhancedQuantumBatAlgorithm", "description": "Introducing adaptive chaos control and quantum harmonic oscillation for robust exploration and exploitation balance in optimization.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["81d8dffd-bf4f-4a61-bacc-b54d429c9c53"], "operator": null, "metadata": {"aucs": [0.09120034883032568, 0.0930123536578108, 0.08942781774774067]}}
{"id": "03dfd199-983a-45c1-af87-744635c2bb8d", "fitness": -Infinity, "name": "AdvancedAdaptiveSwarm", "description": "Introducing dynamic adaptive strategies and perturbed swarm intelligence for enhanced convergence and solution diversity in optimization.", "code": "import numpy as np\n\nclass AdvancedAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.frequency_bounds = (0, 3)\n        self.alpha_bounds = (0.5, 0.9)\n        self.gamma_bounds = (0.7, 0.95)\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.memory = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best = np.copy(self.memory)\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 5\n        self.exploration_exploitation_tradeoff = 0.4\n        self.chaos_intensity = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.95\n        self.global_best_history = []\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_injection(self, solution, lb, ub):\n        chaotic_change = np.random.uniform(-self.chaos_intensity, self.chaos_intensity, self.dim)\n        return np.clip(solution + chaotic_change * (ub - lb), lb, ub)\n\n    def quantum_tunneling(self, best_solution, lb, ub):\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * (ub - lb), lb, ub)\n\n    def dynamic_parameter_adjustment(self, improvement_rate):\n        phase_adjustment = np.tanh(self.exploration_exploitation_tradeoff * improvement_rate)\n        self.alpha = np.clip(self.alpha_bounds[0] + (self.alpha_bounds[1] - self.alpha_bounds[0]) * phase_adjustment, *self.alpha_bounds)\n        self.gamma = np.clip(self.gamma_bounds[0] + (self.gamma_bounds[1] - self.gamma_bounds[0]) * phase_adjustment, *self.gamma_bounds)\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_bounds[0] + (self.frequency_bounds[1] - self.frequency_bounds[0]) * np.random.rand()\n                self.velocity[i] = self.inertia_weight * self.velocity[i] + (population[i] - best_solution) * frequency\n                candidate = population[i] + self.velocity[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.dynamic_parameter_adjustment(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        population[j] = self.chaotic_injection(population[j], lb, ub)\n                    if np.random.rand() < 0.3:\n                        population[j] = self.quantum_tunneling(best_solution, lb, ub)\n\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 69, "feedback": "An exception occurred: AttributeError(\"'AdvancedAdaptiveSwarm' object has no attribute 'alpha'\").", "error": "AttributeError(\"'AdvancedAdaptiveSwarm' object has no attribute 'alpha'\")", "parent_ids": ["7bb4fa23-dcdc-4126-8a74-968396685d29"], "operator": null, "metadata": {}}
{"id": "a99e12ec-cae9-48c9-9983-43cce0a18a2c", "fitness": 0.09113050820208517, "name": "EnhancedQuantumBatAlgorithm", "description": "Improved exploration-exploitation balance by introducing adaptive memory and selective chaos interventions.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n        self.memory_factor = 0.5  # New memory factor for exploration\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        if np.random.rand() < self.memory_factor:  # Conditional chaos application\n                            population[j] = self.chaotic_perturbation(self.memory[j], lb, ub, self.chaos_factor)\n                        else:\n                            population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09113 with standard deviation 0.00147.", "error": "", "parent_ids": ["7bb4fa23-dcdc-4126-8a74-968396685d29"], "operator": null, "metadata": {"aucs": [0.09097292272346624, 0.09299906521090062, 0.08941953667188862]}}
{"id": "b96437ad-070b-494a-8317-580d6289bff5", "fitness": 0.08861965147464672, "name": "ImprovedQuantumBatAlgorithm", "description": "Introducing adaptive chaos control and quantum harmonic oscillation with dynamic inertia and frequency adjustment for enhanced convergence in optimization.  ", "code": "import numpy as np\n\nclass ImprovedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def dynamic_inertia_and_frequency_adjustment(self, improvement_rate):\n        self.inertia_weight = 0.5 + 0.5 * np.tanh(improvement_rate)\n        self.frequency_max = 2 + improvement_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.dynamic_inertia_and_frequency_adjustment(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 71, "feedback": "The algorithm ImprovedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08862 with standard deviation 0.00011.", "error": "", "parent_ids": ["7bb4fa23-dcdc-4126-8a74-968396685d29"], "operator": null, "metadata": {"aucs": [0.08850834227238702, 0.08877752678623996, 0.08857308536531316]}}
{"id": "3b4c854e-6fbf-4302-a51c-3039d3ca955c", "fitness": 0.0912135067874665, "name": "EnhancedQuantumBatAlgorithm", "description": "Refining the quantum harmonic oscillation process to enhance convergence by adjusting step sizes based on chaotic mapping.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)  # Changed line\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["7bb4fa23-dcdc-4126-8a74-968396685d29"], "operator": null, "metadata": {"aucs": [0.09120034895684803, 0.0930123536578108, 0.08942781774774067]}}
{"id": "622dbc3a-0a40-4674-9dac-a8fbe8610025", "fitness": 0.09105689564786368, "name": "AdaptiveQuantumBatAlgorithm", "description": "Introduce adaptive swarm dynamics and fitness diversity awareness to enhance exploration and exploitation balance in quantum harmonic oscillations.", "code": "import numpy as np\n\nclass AdaptiveQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n        self.fitness_diversity_threshold = 0.05\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub, diversity_factor):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb) * diversity_factor, lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate, fitness_diversity):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n        if fitness_diversity < self.fitness_diversity_threshold:\n            self.loudness *= 1.1\n            self.pulse_rate *= 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-10)\n            self.self_adaptive_parameters(improvement_rate, fitness_diversity)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                diversity_factor = 1 + fitness_diversity * 0.1\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub, diversity_factor)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09106 with standard deviation 0.00166.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120034895709361, 0.0930123536578108, 0.08895798432868662]}}
{"id": "e44016d7-a3eb-4bf0-802c-379cd906252c", "fitness": 0.09121350677362439, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhanced convergence by modifying the quantum harmonic oscillation step size for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 2, self.dim) * np.sin(omega * np.pi)  # Changed line\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.0912003489153217, 0.0930123536578108, 0.08942781774774067]}}
{"id": "4d9197bb-1112-4d1e-b321-0588bb431721", "fitness": -Infinity, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhancing convergence and diversity by incorporating dynamic population clustering and adaptive quantum perturbation with chaotic influence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n        self.n_clusters = 3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        dynamic_factor = q * (1 + np.random.rand())  # Dynamic modification\n        return np.clip(best_solution + step_size * dynamic_factor * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def cluster_population(self, population):\n        kmeans = KMeans(n_clusters=self.n_clusters)\n        labels = kmeans.fit_predict(population)\n        centers = kmeans.cluster_centers_\n        return labels, centers\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            labels, centers = self.cluster_population(population)\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                cluster_centroid = centers[labels[i]]\n                candidate = candidate * 0.5 + cluster_centroid * 0.5  # Cluster-centric perturbation\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 75, "feedback": "An exception occurred: AttributeError(\"'EnhancedQuantumBatAlgorithm' object has no attribute 'self_adaptive_parameters'\").", "error": "AttributeError(\"'EnhancedQuantumBatAlgorithm' object has no attribute 'self_adaptive_parameters'\")", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {}}
{"id": "57ffcceb-48bc-4209-a00c-225cd60483df", "fitness": 0.0839871723372682, "name": "AdaptiveQuantumBatAlgorithm", "description": "Incorporate adaptive memory and chaotic exploration to improve convergence and robustness to diverse landscapes.", "code": "import numpy as np\n\nclass AdaptiveQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08399 with standard deviation 0.00362.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.07990386479613032, 0.08336029682812185, 0.08869735538755241]}}
{"id": "e38d7017-fe1c-4273-a290-20d6c2fe38b2", "fitness": 0.09121350675257041, "name": "EnhancedQuantumBatAlgorithm", "description": "Modifying the step size calculation in the quantum harmonic oscillation to optimize performance.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.5, 1.0, self.dim) * np.sin(omega * np.pi)  # Changed line\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120034885215977, 0.0930123536578108, 0.08942781774774067]}}
{"id": "8c039b6a-187d-423e-bf45-024d008f32aa", "fitness": 0.08881057285051878, "name": "EnhancedQuantumBatAlgorithm", "description": "Introduced a dynamic inertia weight strategy to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            # Adjusting inertia weight dynamically based on improvement rate\n            self.inertia_weight = 0.4 + 0.5 * (1 - improvement_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08881 with standard deviation 0.00067.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.08956174019428564, 0.08893461558446258, 0.08793536277280811]}}
{"id": "29233012-97a0-452b-bed9-c03ab58bed4d", "fitness": -Infinity, "name": "EnhancedQuantumBatAlgorithmV2", "description": "Enhance the exploration and exploitation balance by dynamically adjusting chaotic mapping and incorporating adaptive parameter tuning based on population diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithmV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n        else:\n            diversity = np.mean(np.std(self.memory, axis=0))\n            if diversity < 1e-3:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 79, "feedback": "An exception occurred: TypeError(\"'float' object cannot be interpreted as an integer\").", "error": "TypeError(\"'float' object cannot be interpreted as an integer\")", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {}}
{"id": "b23d5a22-1fcf-487d-a363-21bd1047fa1d", "fitness": -Infinity, "name": "RefinedQuantumBatAlgorithm", "description": "Introducing adaptive chaos intensity and dynamic population resizing based on fitness variance to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best_history = []\n        self.chaos_intensity = 0.1\n        self.chaos_intensity_adaptation_rate = 0.05\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub):\n        chaotic_factor = np.random.uniform(-self.chaos_intensity, self.chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self, fitness):\n        fitness_variance = np.var(fitness)\n        if fitness_variance < 1e-3:\n            self.population_size = max(int(self.population_size * 0.9), 5)\n        else:\n            self.population_size = min(int(self.population_size * 1.1), 50)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_solution = candidate\n                        best_fitness = candidate_fitness\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n            self.inertia_weight *= self.inertia_decay\n            self.chaos_intensity = max(0.1, self.chaos_intensity - self.chaos_intensity_adaptation_rate)\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size(fitness)\n\n            if len(self.global_best_history) > 3 and self.global_best_history[-1] == self.global_best_history[-3]:\n                for j in range(self.population_size):\n                    if np.random.rand() < 0.3:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n\n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        \n        return best_solution", "configspace": "", "generation": 80, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {}}
{"id": "599f542f-02c2-4ec7-854d-1b539f449868", "fitness": 0.09121210182353941, "name": "AdaptiveChaoticQuantumBatAlgorithm", "description": "Introducing adaptive chaotic maps and dynamic parameters tuning to enhance convergence and robustness.", "code": "import numpy as np\n\nclass AdaptiveChaoticQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adaptive_chaotic_map(self, current_iteration, max_iterations):\n        return 0.5 * (1 - np.cos(np.pi * current_iteration / max_iterations))\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            chaotic_map_value = self.adaptive_chaotic_map(eval_count, self.budget)\n            self.chaos_factor = chaotic_map_value\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveChaoticQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09300756050336578, 0.08942781774774067]}}
{"id": "da63f688-ed04-41ac-a64b-3c6171ba29b9", "fitness": 0.09121190931726579, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhance the quantum harmonic oscillation by dynamically adjusting the omega parameter to accelerate convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim) * (np.mean(self.improvement_count) / self.stagnation_threshold)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)  # Changed line\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120034970069091, 0.09300756050336578, 0.08942781774774067]}}
{"id": "89313f24-e3d2-41a6-b80a-64306ea97d1b", "fitness": 0.09121190875932624, "name": "EnhancedQuantumBatAlgorithm", "description": "Introduce a small modification in step size computation within quantum harmonic oscillation to enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.cos(omega * np.pi)  # Changed line\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120034802687227, 0.09300756050336578, 0.08942781774774067]}}
{"id": "207eec59-90c8-4293-91af-c0df309f1835", "fitness": 0.09090597534998875, "name": "EnhancedQuantumBatAlgorithm", "description": "Enhanced convergence by refining the inertia decay rate for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99  # Changed line\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09091 with standard deviation 0.00182.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09297023065738019, 0.08854676817307428]}}
{"id": "b11fec3a-1e1a-4308-a007-72f81f936293", "fitness": 0.0900810925617243, "name": "DynamicChaosQuantumBatAlgorithm", "description": "Integrating dynamic chaos-based pulse modulation and adaptive levy flights for improved convergence in high-dimensional search spaces.", "code": "import numpy as np\n\nclass DynamicChaosQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 2\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) /\n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicChaosQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09008 with standard deviation 0.00067.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09006384934602663, 0.08926622574605425, 0.09091320259309199]}}
{"id": "efc2b42f-899a-4788-9b92-d22b7150e521", "fitness": 0.09121210182353941, "name": "EnhancedQuantumBatAlgorithmImproved", "description": "Improved EnhancedQuantumBatAlgorithm by integrating adaptive chaotic maps to fine-tune exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithmImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n        self.adaptive_chaos = 0.5\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_map = np.random.rand(self.dim) * self.adaptive_chaos\n        perturbed_solution = solution + chaotic_map * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def quantum_harmonic_oscillation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0, 1, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n        self.adaptive_chaos = 0.3 + 0.4 * phase_adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.quantum_harmonic_oscillation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumBatAlgorithmImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09300756050336578, 0.08942781774774067]}}
{"id": "1ef0ad2a-52b2-4fa8-b464-81ff194fd1cd", "fitness": 0.09121736430916279, "name": "EnhancedQuantumBatAlgorithm", "description": "Integrating adaptive quantum perturbations and dynamic feedback mechanisms to enhance solution diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09122 with standard deviation 0.00146.", "error": "", "parent_ids": ["3b4c854e-6fbf-4302-a51c-3039d3ca955c"], "operator": null, "metadata": {"aucs": [0.09121192152193691, 0.0930123536578108, 0.08942781774774067]}}
{"id": "05b27df9-f1ba-4efa-80ce-b4c2d40e2eca", "fitness": 0.0851213487615291, "name": "AdaptiveClusteringQuantumBatAlgorithm", "description": "Introducing adaptive mutation and clustering to dynamically balance exploration and exploitation, enhancing convergence speed and solution robustness.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveClusteringQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.98\n        self.cluster_factor = 0.1\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adaptive_mutation(self, population, best_solution, lb, ub):\n        mutation_rate = np.random.uniform(0.1, 0.3, self.population_size)\n        for i in range(self.population_size):\n            if np.random.rand() < mutation_rate[i]:\n                mutation_strength = np.random.uniform(0, 0.1)\n                population[i] += mutation_strength * (best_solution - population[i])\n                population[i] = np.clip(population[i], lb, ub)\n        return population\n\n    def cluster_analysis(self, population):\n        if len(population) > 1:\n            kmeans = KMeans(n_clusters=min(len(population) // 2, 10))\n            kmeans.fit(population)\n            clusters = kmeans.cluster_centers_\n            return clusters\n        return population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            population = self.adaptive_mutation(population, best_solution, lb, ub)\n            clusters = self.cluster_analysis(population)\n            population = np.concatenate((population, clusters), axis=0)\n\n            self.global_best_history.append(best_fitness)\n            self.inertia_weight *= self.inertia_decay\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.cluster_factor:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveClusteringQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08512 with standard deviation 0.00271.", "error": "", "parent_ids": ["1ef0ad2a-52b2-4fa8-b464-81ff194fd1cd"], "operator": null, "metadata": {"aucs": [0.08141241049989512, 0.0878358370950425, 0.08611579868964969]}}
{"id": "a9c09c44-a902-4e97-ae9b-3d313a0cc2dc", "fitness": 0.09126284306054162, "name": "EnhancedQuantumBatAlgorithm", "description": "Introducing a slight adjustment in the inertia weight decay rate to potentially stabilize convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985  # Adjusted decay rate\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09126 with standard deviation 0.00152.", "error": "", "parent_ids": ["1ef0ad2a-52b2-4fa8-b464-81ff194fd1cd"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09315978421437243, 0.08942781774774067]}}
{"id": "23028a69-c497-4bbc-b855-ff17fcb6ff78", "fitness": 0.09090597534998875, "name": "AdaptiveQuantumBatAlgorithm", "description": "Introducing adaptive swarm intelligence to enhance exploration and dynamic adaptation mechanisms.", "code": "import numpy as np\n\nclass AdaptiveQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.990  # Further adjusted decay rate for stability\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09091 with standard deviation 0.00182.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09297023065738019, 0.08854676817307428]}}
{"id": "2665a1fd-e5c3-4099-8c2d-9f1cdc84ad1d", "fitness": 0.0912251485973515, "name": "EnhancedQuantumBatAlgorithm", "description": "Slightly modified the chaotic perturbation range and adjusted adaptation phase to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.6  # Adjusted adaptation phase\n        self.chaos_factor = 0.12  # Adjusted chaos factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09123 with standard deviation 0.00142.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.0911538140017869, 0.09300053973400035, 0.08952109205626724]}}
{"id": "b5825d5e-ecd5-41c8-86eb-ccac64e1be77", "fitness": 0.09021881756600729, "name": "EnhancedQuantumBatAlgorithm", "description": "Improved exploration by slightly increasing the frequency range to allow wider coverage of the search space.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3.1  # Slightly increased for wider exploration\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09022 with standard deviation 0.00138.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.09012389332968995, 0.0919577544750323, 0.08857480489329961]}}
{"id": "1d5e78e7-5496-4007-9e22-5bcaca70db0e", "fitness": 0.07753061739923343, "name": "AdaptiveQuantumBatAlgorithm", "description": "Adaptive Quantum Bat Algorithm introduces dynamic parameter tuning based on swarm diversity and memory-based quantum perturbations for enhanced convergence stability.", "code": "import numpy as np\n\nclass AdaptiveQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.global_best_history = []\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.99  # Further adjusted decay rate\n        self.chaos_threshold = 0.3\n        self.diversity_threshold = 0.01\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def memory_based_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        memory_effect = np.mean(self.memory, axis=0)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb) + memory_effect, lb, ub)\n\n    def calculate_diversity(self, population):\n        return np.mean([np.linalg.norm(ind - np.mean(population, axis=0)) for ind in population])\n\n    def adjust_parameters_based_on_diversity(self, diversity):\n        if diversity < self.diversity_threshold:\n            self.inertia_weight = min(1.0, self.inertia_weight * 1.05)\n            self.alpha = max(0.85, self.alpha * 0.95)\n        else:\n            self.inertia_weight = max(0.7, self.inertia_weight * 0.95)\n            self.alpha = min(1.0, self.alpha * 1.05)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.adjust_parameters_based_on_diversity(diversity)\n            \n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n\n            if len(self.global_best_history) > 3 and self.global_best_history[-1] == self.global_best_history[-3]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, 0.1)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.memory_based_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07753 with standard deviation 0.00996.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.06619208967925783, 0.07595495755175496, 0.0904448049666875]}}
{"id": "f7ffade0-cd3a-40bc-9e70-46dfc4833c5c", "fitness": 0.08874499303304621, "name": "EnhancedQuantumBatAlgorithm", "description": "Implement dynamic learning strategies and chaotic movements to enhance exploration and convergence in a quantum bat algorithm with adaptive population adjustments.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.7  # Reduced to encourage exploration\n        self.inertia_decay = 0.98\n        self.chaos_threshold = 0.3\n        self.dynamic_learning_rate = 0.01\n    \n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n        self.dynamic_learning_rate = 1.0 / (1.0 + improvement_rate)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += self.dynamic_learning_rate * (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08874 with standard deviation 0.00218.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.0908216002940897, 0.08574030170640046, 0.08967307709864847]}}
{"id": "19ecaf27-a4ff-4e72-92df-492ffc262043", "fitness": 0.09126284306054162, "name": "EnhancedQuantumBatAlgorithm", "description": "Slight adjustment to chaos factor for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.15  # Adjusted chaos factor\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985  # Adjusted decay rate\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09126 with standard deviation 0.00152.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09315978421437243, 0.08942781774774067]}}
{"id": "f96ada38-7fc0-44c2-8447-24cad4bd26ca", "fitness": 0.09126284306054162, "name": "EnhancedQuantumBatAlgorithm", "description": "Fine-tuning the population size adjustment by altering the exploration_exploitation_tradeoff value for potentially better convergence stability.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.45 # Adjusted value\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09126 with standard deviation 0.00152.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.09120092721951178, 0.09315978421437243, 0.08942781774774067]}}
{"id": "ad55330d-0039-4323-8e2d-b010dba72b0c", "fitness": 0.0855310840958059, "name": "EnhancedQuantumBatAlgorithm", "description": "Slightly adjust global best update condition to improve convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985  # Adjusted decay rate\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)  # Adaptive range\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness and np.random.rand() < 0.5:  # Changed condition\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, self.chaos_factor)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08553 with standard deviation 0.00069.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.08570217476012187, 0.08627636106563874, 0.08461471646165708]}}
{"id": "b2013784-627e-4c24-857c-41a0200ab4de", "fitness": 0.07792691925344541, "name": "EnhancedQuantumBatAlgorithm", "description": "Incorporating dynamic chaos intensity and selective Levy flights to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n        self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, self.population_size)\n        self.memory = np.zeros((self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.improvement_count = np.zeros(self.population_size)\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985\n        self.chaos_threshold = 0.3\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        self.loudness = np.clip(self.loudness * (1.0 + phase_adjustment), 0.5, 1.0)\n        self.pulse_rate = np.clip(self.pulse_rate * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = np.min(fitness)\n        eval_count = self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                self.beta[i] = np.random.uniform(0, 1)\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[i]\n                velocities[i] *= self.inertia_weight\n                velocities[i] += (population[i] - best_solution) * frequency\n                candidate = population[i] + velocities[i]\n                candidate = np.clip(candidate, lb, ub)\n\n                if np.random.rand() > self.pulse_rate[i]:\n                    if np.random.rand() > 0.7:  # Selective Levy flight\n                        candidate = best_solution + self.levy_flight() * self.loudness[i]\n\n                candidate_fitness = func(candidate)\n                eval_count += 1\n\n                if candidate_fitness < fitness[i]:\n                    self.improvement_count[i] += 1\n                    self.memory[i] = candidate\n                    if candidate_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = candidate\n                        self.personal_best_fitness[i] = candidate_fitness\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.loudness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.loudness[i] = min(1.0, self.loudness[i] * self.alpha)\n                    if candidate_fitness < best_fitness:\n                        self.pulse_rate[i] *= self.gamma\n\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count < self.budget:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        opposite_candidate = self.opposition_based_learning(population[i], lb, ub)\n                        opposite_candidate_fitness = func(opposite_candidate)\n                        eval_count += 1\n\n                        if opposite_candidate_fitness < fitness[i]:\n                            population[i] = opposite_candidate\n                            fitness[i] = opposite_candidate_fitness\n\n                        if opposite_candidate_fitness < best_fitness:\n                            best_solution = opposite_candidate\n                            best_fitness = opposite_candidate_fitness\n\n                        if eval_count >= self.budget:\n                            break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for j in range(self.population_size):\n                    dynamic_chaos = self.chaos_factor * (1 + np.sin(eval_count / self.budget * np.pi))  # Dynamic chaos intensity\n                    if np.random.rand() < self.chaos_threshold:\n                        population[j] = self.chaotic_perturbation(population[j], lb, ub, dynamic_chaos)\n                    if np.random.rand() < 0.35:\n                        population[j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                self.loudness = np.random.uniform(0.5, 1.0, self.population_size)\n                self.pulse_rate = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedQuantumBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07793 with standard deviation 0.00280.", "error": "", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {"aucs": [0.08151165688631856, 0.07467254789176925, 0.07759655298224843]}}
{"id": "c26200ad-85f7-42ae-8148-d6531e81ea05", "fitness": -Infinity, "name": "MultiSwarmQuantumBatAlgorithm", "description": "Introducing multi-swarm optimization with periodic regrouping to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass MultiSwarmQuantumBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.frequency_min = 0\n        self.frequency_max = 3\n        self.loudness = np.random.uniform(0.5, 1.0, (self.num_swarms, self.population_size))\n        self.pulse_rate = np.random.uniform(0.2, 0.8, (self.num_swarms, self.population_size))\n        self.alpha = 0.95\n        self.gamma = 0.9\n        self.beta = np.random.uniform(0, 1, (self.num_swarms, self.population_size))\n        self.memory = np.zeros((self.num_swarms, self.population_size, self.dim))\n        self.personal_best = np.random.uniform(0, 1, (self.num_swarms, self.population_size, self.dim))\n        self.personal_best_fitness = np.full((self.num_swarms, self.population_size), np.inf)\n        self.improvement_count = np.zeros((self.num_swarms, self.population_size))\n        self.stagnation_threshold = 3\n        self.global_best_history = []\n        self.exploration_exploitation_tradeoff = 0.5\n        self.adaptation_phase = 0.5\n        self.chaos_factor = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_decay = 0.985\n        self.chaos_threshold = 0.3\n        self.regroup_interval = 10  # Swarm regrouping interval\n\n    def opposition_based_learning(self, candidate, lb, ub):\n        return lb + ub - candidate\n\n    def levy_flight(self, lam=1.5):\n        sigma = (np.math.gamma(1 + lam) * np.sin(np.pi * lam / 2) / \n                 (np.math.gamma((1 + lam) / 2) * lam * 2**((lam - 1) / 2)))**(1 / lam)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / lam)\n        return step\n\n    def chaotic_perturbation(self, solution, lb, ub, chaos_intensity):\n        chaotic_factor = np.random.uniform(-chaos_intensity, chaos_intensity, self.dim)\n        perturbed_solution = solution + chaotic_factor * (ub - lb)\n        return np.clip(perturbed_solution, lb, ub)\n\n    def enhanced_quantum_perturbation(self, best_solution, lb, ub):\n        omega = np.linspace(0.1, 1.0, self.dim)\n        q = np.random.normal(0, 1, self.dim)\n        step_size = np.random.uniform(0.1, 0.5, self.dim) * np.sin(omega * np.pi)\n        return np.clip(best_solution + step_size * q * omega * (ub - lb), lb, ub)\n\n    def adjust_population_size(self):\n        if len(self.global_best_history) > self.stagnation_threshold:\n            improvement = (self.global_best_history[-self.stagnation_threshold] - self.global_best_history[-1]) / self.global_best_history[-self.stagnation_threshold]\n            if improvement < self.exploration_exploitation_tradeoff:\n                self.population_size = max(int(self.initial_population_size / 2), 5)\n            else:\n                self.population_size = min(self.initial_population_size * 1.5, 50)\n\n    def self_adaptive_parameters(self, improvement_rate):\n        phase_adjustment = np.tanh(self.adaptation_phase * improvement_rate * 1.1)\n        self.alpha = 0.85 + 0.15 * phase_adjustment\n        for swarm in range(self.num_swarms):\n            self.loudness[swarm] = np.clip(self.loudness[swarm] * (1.0 + phase_adjustment), 0.5, 1.0)\n            self.pulse_rate[swarm] = np.clip(self.pulse_rate[swarm] * (1.0 - phase_adjustment), 0.2, 0.8)\n\n    def regroup_swarms(self, lb, ub):\n        new_population = np.random.uniform(lb, ub, (self.num_swarms, self.population_size, self.dim))\n        for swarm in range(self.num_swarms):\n            self.memory[swarm] = new_population[swarm]\n            self.loudness[swarm] = np.random.uniform(0.5, 1.0, self.population_size)\n            self.pulse_rate[swarm] = np.random.uniform(0.2, 0.8, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.num_swarms, self.population_size, self.dim))\n        velocities = np.zeros((self.num_swarms, self.population_size, self.dim))\n        fitness = np.array([[func(ind) for ind in swarm] for swarm in population])\n        best_solution_idx = np.unravel_index(np.argmin(fitness), fitness.shape)\n        best_solution = population[best_solution_idx]\n        best_fitness = fitness.min()\n        eval_count = self.num_swarms * self.population_size\n        self.global_best_history.append(best_fitness)\n\n        while eval_count < self.budget:\n            for swarm in range(self.num_swarms):\n                for i in range(self.population_size):\n                    self.beta[swarm, i] = np.random.uniform(0, 1)\n                    frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * self.beta[swarm, i]\n                    velocities[swarm, i] *= self.inertia_weight\n                    velocities[swarm, i] += (population[swarm, i] - best_solution) * frequency\n                    candidate = population[swarm, i] + velocities[swarm, i]\n                    candidate = np.clip(candidate, lb, ub)\n\n                    if np.random.rand() > self.pulse_rate[swarm, i]:\n                        candidate = best_solution + self.levy_flight() * self.loudness[swarm, i]\n\n                    candidate_fitness = func(candidate)\n                    eval_count += 1\n\n                    if candidate_fitness < fitness[swarm, i]:\n                        self.improvement_count[swarm, i] += 1\n                        self.memory[swarm, i] = candidate\n                        if candidate_fitness < self.personal_best_fitness[swarm, i]:\n                            self.personal_best[swarm, i] = candidate\n                            self.personal_best_fitness[swarm, i] = candidate_fitness\n\n                    if candidate_fitness < fitness[swarm, i] and np.random.rand() < self.loudness[swarm, i]:\n                        population[swarm, i] = candidate\n                        fitness[swarm, i] = candidate_fitness\n                        self.loudness[swarm, i] = min(1.0, self.loudness[swarm, i] * self.alpha)\n                        if candidate_fitness < best_fitness:\n                            self.pulse_rate[swarm, i] *= self.gamma\n\n                    if candidate_fitness < best_fitness:\n                        best_solution = candidate\n                        best_fitness = candidate_fitness\n\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count < self.budget:\n                    for i in range(self.population_size):\n                        if np.random.rand() < 0.1:\n                            opposite_candidate = self.opposition_based_learning(population[swarm, i], lb, ub)\n                            opposite_candidate_fitness = func(opposite_candidate)\n                            eval_count += 1\n\n                            if opposite_candidate_fitness < fitness[swarm, i]:\n                                population[swarm, i] = opposite_candidate\n                                fitness[swarm, i] = opposite_candidate_fitness\n\n                            if opposite_candidate_fitness < best_fitness:\n                                best_solution = opposite_candidate\n                                best_fitness = opposite_candidate_fitness\n\n                            if eval_count >= self.budget:\n                                break\n\n            improvement_rate = np.mean(self.improvement_count) / (self.stagnation_threshold + 1)\n            self.self_adaptive_parameters(improvement_rate)\n            self.inertia_weight *= self.inertia_decay\n            self.global_best_history.append(best_fitness)\n            self.adjust_population_size()\n\n            if eval_count % self.regroup_interval == 0:\n                self.regroup_swarms(lb, ub)\n\n            if len(self.global_best_history) > self.stagnation_threshold and self.global_best_history[-1] == self.global_best_history[-self.stagnation_threshold]:\n                for swarm in range(self.num_swarms):\n                    for j in range(self.population_size):\n                        if np.random.rand() < self.chaos_threshold:\n                            population[swarm, j] = self.chaotic_perturbation(population[swarm, j], lb, ub, self.chaos_factor)\n                        if np.random.rand() < 0.35:\n                            population[swarm, j] = self.enhanced_quantum_perturbation(best_solution, lb, ub)\n                \n                    self.loudness[swarm] = np.random.uniform(0.5, 1.0, self.population_size)\n                    self.pulse_rate[swarm] = np.random.uniform(0.2, 0.8, self.population_size)\n\n        return best_solution", "configspace": "", "generation": 99, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (10,10) into shape (20,10)').", "error": "ValueError('could not broadcast input array from shape (10,10) into shape (20,10)')", "parent_ids": ["a9c09c44-a902-4e97-ae9b-3d313a0cc2dc"], "operator": null, "metadata": {}}
