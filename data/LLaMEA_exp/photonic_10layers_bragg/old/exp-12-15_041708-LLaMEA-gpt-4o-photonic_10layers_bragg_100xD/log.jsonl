{"id": "da27412a-b04b-48d1-a928-42f1d65e4d7a", "fitness": 0.05940784590029846, "name": "HybridPSODE", "description": "A hybrid Particle Swarm and Differential Evolution metaheuristic algorithm that dynamically adjusts search strategies to tackle diverse and high-dimensional black box optimization problems efficiently.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n        \n        while eval_count < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = 1.5, 1.5\n\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = np.clip(swarm[a] + 0.8 * (swarm[b] - swarm[c]), lb, ub)\n                crossover = np.random.rand(self.dim) < 0.9\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05941 with standard deviation 0.01259.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.04721378814972843, 0.05426680635906378, 0.07674294319210317]}}
{"id": "10dc4af5-259d-420c-b1f3-dc60ee036821", "fitness": 0.06278264325139671, "name": "EnhancedHybridPSODE", "description": "An enhanced Hybrid Particle Swarm and Differential Evolution algorithm using adaptive inertia weight and elitist learning to improve convergence speed and solution accuracy for optimizing complex black box functions.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n        \n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F = 0.8  # Differential evolution scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06278 with standard deviation 0.01212.", "error": "", "parent_ids": ["da27412a-b04b-48d1-a928-42f1d65e4d7a"], "operator": null, "metadata": {"aucs": [0.05411050183776833, 0.0543122092075885, 0.07992521870883329]}}
{"id": "e07f9829-2869-4531-8873-d807b4a80705", "fitness": 0.053096743470461706, "name": "AdaptiveMemeticPSO", "description": "A novel Adaptive Memetic Particle Swarm Optimization integrating adaptive acceleration coefficients and local search to enhance exploration and exploitation in black box optimization tasks.", "code": "import numpy as np\n\nclass AdaptiveMemeticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive PSO parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1_min, c1_max = 1.5, 2.5\n        c2_min, c2_max = 1.5, 2.5\n        local_search_prob = 0.1\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight and acceleration coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1 = c1_min + ((c1_max - c1_min) * (eval_count / self.budget))\n            c2 = c2_max - ((c2_max - c2_min) * (eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - swarm) +\n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Evaluate new swarm positions\n            for i in range(population_size):\n                f_swarm = func(swarm[i])\n                eval_count += 1\n\n                if f_swarm < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = f_swarm\n                    if f_swarm < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = f_swarm\n\n                # Local search for exploitation\n                if np.random.rand() < local_search_prob:\n                    local_best = self.local_search(func, swarm[i], lb, ub)\n                    f_local_best = func(local_best)\n                    eval_count += 1\n                    if f_local_best < personal_best_scores[i]:\n                        personal_best_positions[i] = local_best\n                        personal_best_scores[i] = f_local_best\n                        if f_local_best < global_best_score:\n                            global_best_position = local_best\n                            global_best_score = f_local_best\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}\n\n    def local_search(self, func, position, lb, ub):\n        # Simple random walk as local search\n        step_size = 0.1\n        candidate = position + step_size * np.random.uniform(-1, 1, self.dim)\n        candidate = np.clip(candidate, lb, ub)\n        return candidate", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveMemeticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05310 with standard deviation 0.00377.", "error": "", "parent_ids": ["10dc4af5-259d-420c-b1f3-dc60ee036821"], "operator": null, "metadata": {"aucs": [0.048470858099448066, 0.05770031652968388, 0.05311905578225318]}}
{"id": "ad5bcdfe-a48c-4a67-91f9-57bfaf2d65ac", "fitness": 0.05132432347921253, "name": "SelfAdaptiveHybridPSODE", "description": "A novel Self-adaptive Hybrid Particle Swarm and Differential Evolution algorithm integrating dynamic swarm topology and stochastic differential mutation to enhance exploration and exploitation of black box functions.", "code": "import numpy as np\n\nclass SelfAdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.5  # Differential evolution base scaling factor\n        CR_base = 0.7  # Base crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Dynamic topology: Randomly rewire connections\n            if eval_count % (population_size // 2) == 0:\n                np.random.shuffle(personal_best_positions)\n                local_best_positions = personal_best_positions[:population_size // 2]\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                F = F_base + np.random.rand() * (1 - F_base)  # Stochastic F\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                CR = CR_base + np.random.rand() * (1 - CR_base)  # Stochastic CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 3, "feedback": "The algorithm SelfAdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05132 with standard deviation 0.00235.", "error": "", "parent_ids": ["10dc4af5-259d-420c-b1f3-dc60ee036821"], "operator": null, "metadata": {"aucs": [0.048315659055039095, 0.05159879337648077, 0.05405851800611772]}}
{"id": "ec0b80c8-da2c-40aa-b608-6201efca79fa", "fitness": 0.06359179838191675, "name": "AdvancedHybridPSODE", "description": "A novel Hybrid Particle Swarm and Differential Evolution algorithm integrates a self-adaptive mechanism for tuning mutation strategies and incorporates a neighborhood-based elitism to enhance exploration and exploitation balance for optimizing complex black box functions.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Self-adaptive mutation strategy\n                F = F_base + 0.2 * np.random.rand()\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 4, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06359 with standard deviation 0.00691.", "error": "", "parent_ids": ["10dc4af5-259d-420c-b1f3-dc60ee036821"], "operator": null, "metadata": {"aucs": [0.06467197570344951, 0.054641121291256534, 0.07146229815104421]}}
{"id": "946d6ac6-cae2-48fe-9225-da150dfc16e6", "fitness": 0.06181748490354, "name": "EnhancedAdvancedHybridPSODE", "description": "Enhanced AdvancedHybridPSODE integrates a dynamic multi-swarm strategy and adaptive learning factor for improved convergence and robustness in optimizing black box functions.", "code": "import numpy as np\n\nclass EnhancedAdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        num_swarms = 2  # Number of sub-swarms for dynamic multi-swarm strategy\n        swarm_size = population_size // num_swarms\n        swarms = [np.random.uniform(lb, ub, (swarm_size, self.dim)) for _ in range(num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (swarm_size, self.dim)) for _ in range(num_swarms)]\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        global_best_indices = [np.argmin(scores) for scores in personal_best_scores]\n        global_best_positions = [np.copy(personal_best_positions[i][global_best_indices[i]]) for i in range(num_swarms)]\n        global_best_scores = [personal_best_scores[i][global_best_indices[i]] for i in range(num_swarms)]\n        \n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            for s in range(num_swarms):\n                # Adaptive inertia weight\n                w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n                \n                # Particle Swarm Optimization update\n                r1, r2 = np.random.rand(2)\n                velocities[s] = (w * velocities[s] + \n                                 c1 * r1 * (personal_best_positions[s] - swarms[s]) + \n                                 c2 * r2 * (global_best_positions[s] - swarms[s]))\n                swarms[s] += velocities[s]\n                swarms[s] = np.clip(swarms[s], lb, ub)\n\n                # Differential Evolution mutation and crossover with adaptive strategy\n                for i in range(swarm_size):\n                    candidates = list(range(swarm_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                    # Self-adaptive mutation strategy with learning factor\n                    F = F_base + 0.2 * np.random.rand()\n                    learning_factor = 0.5 + 0.5 * np.random.rand()\n                    mutant = np.clip(swarms[s][a] + F * (swarms[s][b] - swarms[s][c]) * learning_factor, lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarms[s][i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[s][i]:\n                        personal_best_positions[s][i] = trial\n                        personal_best_scores[s][i] = f_trial\n                        if f_trial < global_best_scores[s]:\n                            global_best_positions[s] = trial\n                            global_best_scores[s] = f_trial\n                            # Neighborhood-based elitism\n                            neighbors = np.argsort(personal_best_scores[s])[:3]\n                            for neighbor in neighbors:\n                                if personal_best_scores[s][neighbor] > f_trial:\n                                    personal_best_positions[s][neighbor] = trial\n                                    personal_best_scores[s][neighbor] = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        overall_best_index = np.argmin(global_best_scores)\n        return {'best_position': global_best_positions[overall_best_index], 'best_score': global_best_scores[overall_best_index]}", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06182 with standard deviation 0.00287.", "error": "", "parent_ids": ["ec0b80c8-da2c-40aa-b608-6201efca79fa"], "operator": null, "metadata": {"aucs": [0.06581028200798078, 0.060471555705753466, 0.05917061699688575]}}
{"id": "6bb62cb8-0117-4159-856e-60e705b35a65", "fitness": 0.06838258504520871, "name": "AdvancedHybridPSODE", "description": "Introduce a decay factor in the mutation strategy to gradually reduce exploration over iterations and enhance convergence in the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Self-adaptive mutation strategy\n                F = F_base + 0.2 * np.random.rand() * ((self.budget - eval_count) / self.budget)  # Decaying factor added\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 6, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06838 with standard deviation 0.00427.", "error": "", "parent_ids": ["ec0b80c8-da2c-40aa-b608-6201efca79fa"], "operator": null, "metadata": {"aucs": [0.062477568948416606, 0.07022719509532582, 0.07244299109188368]}}
{"id": "acf91c44-016c-462a-859c-d058f1f40e52", "fitness": 0.06304068375963075, "name": "EnhancedHybridPSODE", "description": "Incorporate a dynamic local search phase to refine the personal best solutions iteratively, increasing convergence speed and precision in the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n        local_search_rate = 0.1 * self.dim  # Controls local search intensity\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Self-adaptive mutation strategy\n                F = F_base + 0.2 * np.random.rand() * ((self.budget - eval_count) / self.budget)  # Decaying factor added\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                # Dynamic local search to refine personal bests\n                if np.random.rand() < local_search_rate / self.dim:\n                    local_search_candidate = personal_best_positions[i] + 0.1 * np.random.normal(size=self.dim)\n                    local_search_candidate = np.clip(local_search_candidate, lb, ub)\n                    f_local = func(local_search_candidate)\n                    eval_count += 1\n                    if f_local < personal_best_scores[i]:\n                        personal_best_positions[i] = local_search_candidate\n                        personal_best_scores[i] = f_local\n                        if f_local < global_best_score:\n                            global_best_position = local_search_candidate\n                            global_best_score = f_local\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06304 with standard deviation 0.00677.", "error": "", "parent_ids": ["6bb62cb8-0117-4159-856e-60e705b35a65"], "operator": null, "metadata": {"aucs": [0.05805117139692073, 0.058458796104759125, 0.0726120837772124]}}
{"id": "0dc01c97-a7fd-4ba1-8a10-b41528f40b60", "fitness": 0.06817326226900829, "name": "RefinedHybridPSODE", "description": "Introduce a dynamic swarm size reduction to focus exploration in early stages and intensify exploitation in later stages of the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        initial_population_size = 50\n        min_population_size = 10\n        swarm = np.random.uniform(lb, ub, (initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (initial_population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = initial_population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Dynamic population size reduction\n            population_size = int(initial_population_size - ((initial_population_size - min_population_size) * (eval_count / self.budget)))\n            swarm = swarm[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Self-adaptive mutation strategy\n                F = F_base + 0.2 * np.random.rand() * ((self.budget - eval_count) / self.budget)  # Decaying factor added\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 8, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06817 with standard deviation 0.00759.", "error": "", "parent_ids": ["6bb62cb8-0117-4159-856e-60e705b35a65"], "operator": null, "metadata": {"aucs": [0.06017962207420524, 0.06595811582981981, 0.07838204890299982]}}
{"id": "218ffa21-6ce6-4f6e-b5bc-f536ac9e7ace", "fitness": 0.06929974381591086, "name": "AdvancedHybridPSODE", "description": "Enhance the hybrid PSO-DE algorithm by introducing a variable step size for DE mutation based on local search effectiveness, improving convergence near optima.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Variable step size based on local improvement\n                f_current = func(swarm[i])\n                eval_count += 1\n                \n                F = F_base + 0.2 * np.random.rand() * ((self.budget - eval_count) / self.budget)\n                if f_current < personal_best_scores[i]:\n                    F *= 1.1  # Increase step size for exploration\n                else:\n                    F *= 0.9  # Decrease step size for exploitation\n\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 9, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06930 with standard deviation 0.00870.", "error": "", "parent_ids": ["6bb62cb8-0117-4159-856e-60e705b35a65"], "operator": null, "metadata": {"aucs": [0.0680044642954275, 0.05934568445802124, 0.08054908269428385]}}
{"id": "7f9b4af7-f5a7-493c-b68d-78fb14d4e108", "fitness": 0.060753296003965986, "name": "EnhancedHybridPSODE", "description": "Introduce a dynamic learning strategy that adjusts the PSO acceleration coefficients based on the population diversity and convergence rate, aiming to balance exploration-exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n        c1_start, c2_start = 2.0, 2.0\n        c1_end, c2_end = 0.5, 2.5\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Dynamic adjustment of PSO acceleration coefficients\n            c1 = c1_start + (c1_end - c1_start) * (eval_count / self.budget)\n            c2 = c2_start + (c2_end - c2_start) * (eval_count / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover with adaptive strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Variable step size based on local improvement\n                f_current = func(swarm[i])\n                eval_count += 1\n                \n                F = F_base + 0.2 * np.random.rand() * ((self.budget - eval_count) / self.budget)\n                if f_current < personal_best_scores[i]:\n                    F *= 1.1  # Increase step size for exploration\n                else:\n                    F *= 0.9  # Decrease step size for exploitation\n\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06075 with standard deviation 0.00736.", "error": "", "parent_ids": ["218ffa21-6ce6-4f6e-b5bc-f536ac9e7ace"], "operator": null, "metadata": {"aucs": [0.07075324907966252, 0.05825448725682836, 0.05325215167540709]}}
{"id": "a52d297d-8bf3-49cc-8af5-f5a264c2ee40", "fitness": 0.05990293530991938, "name": "EnhancedHybridPSODE", "description": "Improve the hybrid PSO-DE algorithm by introducing a dynamic mutation strategy for DE based on swarm diversity, enhancing exploration in diverse areas and exploitation in converged areas.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive inertia weight parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8  # Base DE scaling factor\n        CR = 0.9  # Crossover probability\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Calculate swarm diversity\n            swarm_mean = np.mean(swarm, axis=0)\n            diversity = np.mean(np.linalg.norm(swarm - swarm_mean, axis=1))\n\n            # Differential Evolution mutation strategy\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                # Dynamic mutation factor based on diversity\n                F = F_base + 0.5 * np.random.rand()\n                if diversity > (ub - lb).mean() * 0.1:\n                    F *= 1.2  # Encourage exploration\n                else:\n                    F *= 0.8  # Focus on exploitation\n\n                mutant = np.clip(swarm[a] + F * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n                        # Neighborhood-based elitism\n                        neighbors = np.argsort(personal_best_scores)[:3]\n                        for neighbor in neighbors:\n                            if personal_best_scores[neighbor] > f_trial:\n                                personal_best_positions[neighbor] = trial\n                                personal_best_scores[neighbor] = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05990 with standard deviation 0.00783.", "error": "", "parent_ids": ["218ffa21-6ce6-4f6e-b5bc-f536ac9e7ace"], "operator": null, "metadata": {"aucs": [0.05578374324933144, 0.05305771235114409, 0.0708673503292826]}}
{"id": "45c27d06-7dd7-4af7-9f40-1fa58a9bb9db", "fitness": 0.07060230927348347, "name": "AdaptiveMultiPhasePSODE", "description": "Introduce an adaptive multi-phase approach to dynamically switch between exploration and exploitation by adjusting swarm and mutation strategies based on performance metrics and convergence speed.", "code": "import numpy as np\n\nclass AdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.3 * self.budget\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.2\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.8\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07060 with standard deviation 0.00674.", "error": "", "parent_ids": ["218ffa21-6ce6-4f6e-b5bc-f536ac9e7ace"], "operator": null, "metadata": {"aucs": [0.06205904513438798, 0.07121533322078899, 0.07853254946527344]}}
{"id": "ef086098-3098-4abe-ae5e-a77879a9e1e2", "fitness": 0.05396460266402603, "name": "EnhancedAdaptivePSODE", "description": "Enhance exploration and exploitation through adaptive particle swarm momentum and differential evolution strategy, dynamically modulated by convergence metrics and diversity measures to optimize early and late phases.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.9\n        CR = 0.9\n        phase_change_threshold = 0.5 * self.budget\n\n        while eval_count < self.budget:\n            # Diversity measure for adaptive weight\n            diversity = np.mean(np.std(swarm, axis=0))\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget)) * (1.0 - diversity)\n\n            # Determine phase based on current budget usage\n            if eval_count < phase_change_threshold:\n                # Enhanced exploration\n                F_adaptive = F_base * 1.5\n                c1_adaptive, c2_adaptive = c1 * 1.5, c2 * 0.5\n            else:\n                # Enhanced exploitation\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.5, c2 * 1.5\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05396 with standard deviation 0.00524.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.0530349658920547, 0.060791135385503736, 0.048067706714519653]}}
{"id": "fcd50695-79b1-4fd6-958d-a49c1088f7c6", "fitness": 0.05485587050395072, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance AdaptiveMultiPhasePSODE by integrating a dynamic learning factor approach that continuously adjusts based on swarm diversity and convergence patterns to optimize exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n\n        def learning_factor(swarm):\n            diversity = np.std(swarm, axis=0)\n            normalized_diversity = (diversity - np.min(diversity)) / (np.max(diversity) - np.min(diversity) + 1e-6)\n            return 0.5 + 0.5 * normalized_diversity\n\n        while eval_count < self.budget:\n            # Adjust adaptive parameters based on diversity\n            adaptive_learning_factor = learning_factor(swarm)\n            F_adaptive = F_base * adaptive_learning_factor\n            c1_adaptive = c1 * (1 + adaptive_learning_factor)\n            c2_adaptive = c2 * (1 - adaptive_learning_factor)\n\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05486 with standard deviation 0.00249.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.05832039213537932, 0.05261277412582266, 0.0536344452506502]}}
{"id": "23a23ed2-cd15-47b2-a853-b2853927a6bb", "fitness": 0.04658115601654248, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance the adaptive multi-phase strategy by introducing a dynamic scaling mechanism for the mutation factor and crossover rate based on diversity metrics, to improve convergence and exploration-exploitation balance.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR_base = 0.9\n        phase_change_threshold = 0.3 * self.budget\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            current_diversity = diversity_metric(swarm)\n            \n            # Determine phase based on current budget usage\n            if eval_count < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * (1.1 + 0.5 * current_diversity)\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n                CR_adaptive = CR_base * (1.2 * current_diversity)\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * (0.8 + 0.3 * current_diversity)\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n                CR_adaptive = CR_base * (0.8 * current_diversity)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04658 with standard deviation 0.00297.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.04238845471949848, 0.04848633790390011, 0.04886867542622886]}}
{"id": "60ee117b-45a3-43d4-b095-d6a9603230d0", "fitness": 0.06567107753599795, "name": "AdaptiveMultiPhasePSODE", "description": "Enhance adaptive strategy by fine-tuning exploration-exploitation phase threshold for better balance.", "code": "import numpy as np\n\nclass AdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.35 * self.budget  # Adjusted threshold from 0.3 to 0.35\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.2\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.8\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06567 with standard deviation 0.00640.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.05662852487490411, 0.06982818301852767, 0.07055652471456209]}}
{"id": "11e68a21-7d0d-48f6-ba39-0e5fe7fc72a6", "fitness": 0.06580124022261917, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance the adaptive multi-phase approach by incorporating a dynamic convergence pressure modulation based on variance across the swarm to intelligently balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Calculate the variance of the swarm to adapt phases\n            swarm_variance = np.mean(np.var(swarm, axis=0))\n            phase_threshold = 0.2 * self.budget  # Adjust threshold for phase changes\n\n            if swarm_variance > phase_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.3, c2 * 0.7\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.7, c2 * 1.3\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06580 with standard deviation 0.00557.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.05934633056268657, 0.07294361327730459, 0.06511377682786634]}}
{"id": "6875d127-0c87-4dbb-87b7-48ced545ae11", "fitness": 0.06920477709084864, "name": "AdaptiveMultiPhasePSODE", "description": "Small adjustment to the Differential Evolution mutation factor to subtly enhance exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.85\n        CR = 0.9\n        phase_change_threshold = 0.3 * self.budget\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.2\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.8\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06920 with standard deviation 0.01049.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.055590565672444026, 0.07089493098452515, 0.08112883461557674]}}
{"id": "67fbe709-ab71-4d9b-acc9-b15608c76b54", "fitness": 0.0714482222055457, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance phase transition adaptability with dynamic parameter adjustment and elite retention strategy to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget  # More frequent phase changes\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.3  # Slightly more aggressive exploration\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:  # Protect elite solutions\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07145 with standard deviation 0.00543.", "error": "", "parent_ids": ["45c27d06-7dd7-4af7-9f40-1fa58a9bb9db"], "operator": null, "metadata": {"aucs": [0.06379233851256505, 0.07477174723438107, 0.07578058086969097]}}
{"id": "e13afa6c-f8c9-4913-a2cd-eb258e896b02", "fitness": 0.0700517703421959, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Integrate modified elite retention to improve convergence by retaining top-performing particles more effectively through enhanced elite selection.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget  # More frequent phase changes\n        elite_fraction = 0.15  # Modified to retain the top 15% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.3  # Slightly more aggressive exploration\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:  # Protect elite solutions\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07005 with standard deviation 0.00816.", "error": "", "parent_ids": ["67fbe709-ab71-4d9b-acc9-b15608c76b54"], "operator": null, "metadata": {"aucs": [0.05856941089299661, 0.07483781181592775, 0.07674808831766333]}}
{"id": "af6906b8-38e1-4ac5-9ab3-d6bb42b00841", "fitness": 0.06810149462194308, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduce multi-swarm collaboration and adaptive local search to enhance global exploration and fine-tuned exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        num_swarms = 3\n        swarm_size = population_size // num_swarms\n        swarms = [np.random.uniform(lb, ub, (swarm_size, self.dim)) for _ in range(num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (swarm_size, self.dim)) for _ in range(num_swarms)]\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        global_best_positions = [np.copy(personal_best_positions[i][np.argmin(personal_best_scores[i])]) for i in range(num_swarms)]\n        global_best_scores = [np.min(personal_best_scores[i]) for i in range(num_swarms)]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * swarm_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n\n            # Multi-swarm cooperation and local search\n            for i in range(num_swarms):\n                # Particle Swarm Optimization update\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] + \n                                 c1_adaptive * r1 * (personal_best_positions[i] - swarms[i]) + \n                                 c2_adaptive * r2 * (global_best_positions[i] - swarms[i]))\n                swarms[i] += velocities[i]\n                swarms[i] = np.clip(swarms[i], lb, ub)\n\n                # Differential Evolution mutation and crossover\n                for j in range(swarm_size):\n                    if j >= elite_count:\n                        candidates = list(range(swarm_size))\n                        candidates.remove(j)\n                        a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                        mutant = np.clip(swarms[i][a] + F_adaptive * (swarms[i][b] - swarms[i][c]), lb, ub)\n                        crossover = np.random.rand(self.dim) < CR\n                        trial = np.where(crossover, mutant, swarms[i][j])\n\n                        f_trial = func(trial)\n                        eval_count += 1\n\n                        if f_trial < personal_best_scores[i][j]:\n                            personal_best_positions[i][j] = trial\n                            personal_best_scores[i][j] = f_trial\n                            if f_trial < global_best_scores[i]:\n                                global_best_positions[i] = trial\n                                global_best_scores[i] = f_trial\n\n                        if eval_count >= self.budget:\n                            break\n\n                # Multi-swarm communication\n                if np.random.rand() < 0.3:\n                    for j in range(num_swarms):\n                        if global_best_scores[j] < global_best_scores[i]:\n                            global_best_positions[i] = global_best_positions[j]\n                            global_best_scores[i] = global_best_scores[j]\n\n        # Find the best solution across all swarms\n        best_swarm_index = np.argmin(global_best_scores)\n        return {'best_position': global_best_positions[best_swarm_index], 'best_score': global_best_scores[best_swarm_index]}", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06810 with standard deviation 0.00588.", "error": "", "parent_ids": ["67fbe709-ab71-4d9b-acc9-b15608c76b54"], "operator": null, "metadata": {"aucs": [0.0751994874765356, 0.06829693895938582, 0.0608080574299078]}}
{"id": "2fd502d3-e28a-4778-9e3a-02fdc7073297", "fitness": 0.07188058494644178, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Introduce adaptive adjustment of crossover rate based on phase, enhancing exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget  # More frequent phase changes\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.3  # Slightly more aggressive exploration\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95  # Increase crossover rate during exploration\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85  # Decrease crossover rate during exploitation\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:  # Protect elite solutions\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07188 with standard deviation 0.00351.", "error": "", "parent_ids": ["67fbe709-ab71-4d9b-acc9-b15608c76b54"], "operator": null, "metadata": {"aucs": [0.06730572195630802, 0.07251220993332486, 0.07582382294969248]}}
{"id": "c5716f67-aa13-4e5b-95cd-398d9f3e055b", "fitness": 0.07122999032608186, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance convergence by adjusting the exploitation phase's crossover rate for better local search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget  # More frequent phase changes\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                # Exploration phase: prioritize exploration\n                F_adaptive = F_base * 1.3  # Slightly more aggressive exploration\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95  # Increase crossover rate during exploration\n            else:\n                # Exploitation phase: prioritize convergence\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.9  # Decrease crossover rate during exploitation\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:  # Protect elite solutions\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07123 with standard deviation 0.00469.", "error": "", "parent_ids": ["2fd502d3-e28a-4778-9e3a-02fdc7073297"], "operator": null, "metadata": {"aucs": [0.06466579990590537, 0.07365193402523329, 0.07537223704710694]}}
{"id": "cb476610-e2e8-428a-b901-3b611e6ef717", "fitness": 0.07257712575416904, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance convergence by dynamically adjusting elite_fraction based on progress towards the budget.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07258 with standard deviation 0.00616.", "error": "", "parent_ids": ["2fd502d3-e28a-4778-9e3a-02fdc7073297"], "operator": null, "metadata": {"aucs": [0.06687225625151538, 0.06972230107516553, 0.08113681993582622]}}
{"id": "e3481393-7d26-4a10-9a57-3496dedf4866", "fitness": 0.07037590897999613, "name": "ChaoticAdaptiveMultiPhasePSODE", "description": "Introduce chaos-influenced parameter tuning to enhance exploration and exploitation balance dynamically based on chaotic sequences.", "code": "import numpy as np\n\nclass ChaoticAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        \n        # Chaotic initialization\n        chaotic_sequence = self._generate_chaotic_sequence(self.budget)\n        \n        while eval_count < self.budget:\n            # Dynamic inertia weight with chaos\n            w = w_max - ((w_max - w_min) * chaotic_sequence[eval_count])\n\n            # Determine phase based on chaotic sequence\n            if chaotic_sequence[eval_count] < 0.5:\n                F_adaptive = F_base * (1.3 + chaotic_sequence[eval_count])\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * (0.7 + chaotic_sequence[eval_count])\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n            \n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * chaotic_sequence[eval_count])\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}\n\n    def _generate_chaotic_sequence(self, length, initial_value=0.7):\n        sequence = [initial_value]\n        for _ in range(1, length):\n            next_value = 4 * sequence[-1] * (1 - sequence[-1])\n            sequence.append(next_value)\n        return sequence", "configspace": "", "generation": 25, "feedback": "The algorithm ChaoticAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07038 with standard deviation 0.00831.", "error": "", "parent_ids": ["cb476610-e2e8-428a-b901-3b611e6ef717"], "operator": null, "metadata": {"aucs": [0.060552225298881046, 0.06970836202598618, 0.08086713961512115]}}
{"id": "8364c50b-02f8-4dd2-bef2-347b6ee660db", "fitness": 0.07439184466106989, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance convergence by reducing inertia weight more aggressively as evaluations progress.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3  # Changed from 0.4 to 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07439 with standard deviation 0.00470.", "error": "", "parent_ids": ["cb476610-e2e8-428a-b901-3b611e6ef717"], "operator": null, "metadata": {"aucs": [0.06978971775118858, 0.07254377059427508, 0.080842045637746]}}
{"id": "ba5d53fc-5ef5-4115-bcf8-751d521bb877", "fitness": 0.07300380261006938, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance convergence by slightly adjusting the influence of personal best positions using a reduced cognitive coefficient during later evaluations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3  # Changed from 0.4 to 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.85, c2 * 1.1  # Adjusted c1_adaptive from 0.9 to 0.85\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07300 with standard deviation 0.00556.", "error": "", "parent_ids": ["8364c50b-02f8-4dd2-bef2-347b6ee660db"], "operator": null, "metadata": {"aucs": [0.06683162970202416, 0.07187809387475341, 0.08030168425343054]}}
{"id": "7e00e01f-2e86-41ac-94b5-16fab366de9b", "fitness": 0.07064972448550777, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Refine the phase transition threshold for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.15 * self.budget  # Changed from 0.2 to 0.15\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07065 with standard deviation 0.01217.", "error": "", "parent_ids": ["8364c50b-02f8-4dd2-bef2-347b6ee660db"], "operator": null, "metadata": {"aucs": [0.05350612459704174, 0.07795500241880038, 0.0804880464406812]}}
{"id": "ba6cce99-4b06-45ac-8e1e-974408b7564e", "fitness": 0.0711178974795738, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Introduce an adaptive learning rate schedule based on current solution diversity to dynamically balance exploration and exploitation phases in the optimization process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Adaptive learning rate schedule\n            solution_std = np.std(swarm, axis=0)\n            diversity_index = np.mean(solution_std / (ub - lb))\n            if diversity_index > 0.1:\n                F_base = 0.9  # Increase exploration\n            else:\n                F_base = 0.6  # Increase exploitation\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07112 with standard deviation 0.00938.", "error": "", "parent_ids": ["8364c50b-02f8-4dd2-bef2-347b6ee660db"], "operator": null, "metadata": {"aucs": [0.0584344935846316, 0.07407947604302145, 0.08083972281106833]}}
{"id": "f9e4e186-f586-4fd2-9e9a-9d84bd1e4df5", "fitness": 0.07401592234349859, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Slightly enhance convergence by adjusting the update rule for inertia weight dynamically with respect to elite_count.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget)) + 0.05 * (elite_count / population_size)\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07402 with standard deviation 0.00453.", "error": "", "parent_ids": ["8364c50b-02f8-4dd2-bef2-347b6ee660db"], "operator": null, "metadata": {"aucs": [0.0695561697003938, 0.07225592223588351, 0.08023567509421847]}}
{"id": "bc40622d-45b6-4bfa-be92-dc5706c56965", "fitness": 0.07470170274543304, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance convergence by fine-tuning the adaptive weight decay formula.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))  # Modified line\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07470 with standard deviation 0.00448.", "error": "", "parent_ids": ["8364c50b-02f8-4dd2-bef2-347b6ee660db"], "operator": null, "metadata": {"aucs": [0.06954840793061956, 0.07407753261287531, 0.08047916769280428]}}
{"id": "92a606a5-d738-4def-a97f-058a468b6814", "fitness": 0.06810821203473912, "name": "RefinedAdaptiveMultiPhasePSODE", "description": "Integrate a multi-faceted balance strategy optimizing inertia, phase adaptivity, and elite dynamics in PSO-DE for enhanced black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.4  # Slightly increased minimum inertia weight for better exploration\n        c1, c2 = 1.7, 1.7  # Increased cognitive and social components for intensified exploration\n        F_base = 0.9  # Increased base differential weight\n        CR = 0.9\n        phase_change_threshold = 0.15 * self.budget  # More frequent phase changes\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.05 / self.budget**1.05))  # Further tuned weight decay\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.5  # More aggressive during exploration phase\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6  # More refined in exploitation phase\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction with an additional adaptive factor\n            elite_fraction = max(0.1, 0.1 + 0.15 * (eval_count / self.budget)**1.1)\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06811 with standard deviation 0.01020.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.05423768589213551, 0.07160893217792397, 0.07847801803415788]}}
{"id": "fa7a8465-1c25-42b8-95d2-821368a5a721", "fitness": 0.046041180794074786, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Introduce dynamic parameter adaptation based on swarm diversity and convergence speed to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Calculate diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            \n            # Adaptive inertia weight based on diversity\n            w = w_max - ((w_max - w_min) * (diversity / np.linalg.norm(ub - lb)))\n            \n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * (1 + diversity)  # Enhance exploration\n                c1_adaptive, c2_adaptive = c1 * (1 + diversity), c2 * (1 - diversity)\n                CR = 0.95\n            else:\n                F_adaptive = F_base * (1 - diversity)  # Enhance exploitation\n                c1_adaptive, c2_adaptive = c1 * (1 - diversity), c2 * (1 + diversity)\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04604 with standard deviation 0.00317.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.041569497763804586, 0.04848633790390011, 0.048067706714519653]}}
{"id": "43af511a-8ff8-410c-8128-ec4e2dd06627", "fitness": 0.07465258258059863, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance solution robustness by introducing a chaotic sequence in adaptive parameter adjustments for improved diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR_base = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  \n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        # Initialize a chaotic sequence using logistic map\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = 0.7  # Initial value\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = 4 * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight with chaotic sequence\n            w = w_max - ((w_max - w_min) * (eval_count**(1.02 + 0.1*chaotic_sequence[eval_count]) / self.budget**1.02))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * (1.3 + 0.1 * chaotic_sequence[eval_count])\n                c1_adaptive, c2_adaptive = c1 * (1.1 + 0.1 * chaotic_sequence[eval_count]), c2 * (0.9 - 0.1 * chaotic_sequence[eval_count])\n                CR = CR_base + 0.05 * chaotic_sequence[eval_count]\n            else:\n                F_adaptive = F_base * (0.7 - 0.1 * chaotic_sequence[eval_count])\n                c1_adaptive, c2_adaptive = c1 * (0.9 - 0.1 * chaotic_sequence[eval_count]), c2 * (1.1 + 0.1 * chaotic_sequence[eval_count])\n                CR = CR_base - 0.05 * chaotic_sequence[eval_count]\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07465 with standard deviation 0.00908.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.06187136788264924, 0.08003523127729606, 0.08205114858185059]}}
{"id": "38fa764c-493f-40f9-9f24-6e5a65ce11d8", "fitness": 0.07190777324864472, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Introduce a hierarchical adaptive inertia weight strategy that dynamically refines global and local exploration to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        \n        while eval_count < self.budget:\n            # Hierarchical adaptive inertia weight\n            w = w_max - ((w_max - w_min) * ((eval_count / self.budget) ** 2))\n            w = np.interp(np.random.rand(), [0, 1], [w_min, w_max])  # Further refine using random interpolation\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07191 with standard deviation 0.00332.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.06773600997344442, 0.07584683963260364, 0.07214047013988611]}}
{"id": "e27cd8a7-5d2d-439f-9c1d-b04a1e288a8a", "fitness": 0.07232093512196858, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Improve balance between exploration and exploitation by fine-tuning learning rates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))  # Modified line\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.15, c2 * 0.85  # Modified line\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07232 with standard deviation 0.01153.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.05624321411969635, 0.0779931274230129, 0.08272646382319648]}}
{"id": "794f7226-176d-4644-a870-8118bd47fb4c", "fitness": 0.0739879734099244, "name": "RefinedEnhancedAdaptiveMultiPhasePSODE", "description": "Improve convergence by incorporating dynamic learning parameter adjustments and elite preservation strategies.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight with exponential decay for smoother transition\n            w = w_max * (w_min / w_max)**(eval_count / self.budget)\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.4  # Slightly increased to enhance exploration\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.8\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6  # Slightly decreased for better exploitation\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Incremental increase in elite fraction for improved exploitation\n            elite_fraction = max(0.1, 0.15 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 37, "feedback": "The algorithm RefinedEnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07399 with standard deviation 0.00747.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.06352571184909706, 0.0804430018185951, 0.07799520656208103]}}
{"id": "5186f5c6-11b2-40a9-83b9-134b7cd043a7", "fitness": 0.07366711149994513, "name": "EnhancedAdaptiveMultiPhasePSODEPlus", "description": "Improve search efficiency using dynamic elite retention and inertia weight adaptation for fine-tuned exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.2\n        c1, c2 = 1.4, 1.4\n        F_base = 0.8\n        CR = 0.9\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - (w_max - w_min) * (eval_count / self.budget)\n\n            # Dynamic retention of elites\n            elite_fraction = max(0.05, 0.1 + 0.05 * (1 - (eval_count / self.budget)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Adjusting parameters based on progress\n            if eval_count < self.budget / 3:\n                F_adaptive = F_base * 1.5\n                c1_adaptive, c2_adaptive = c1 * 1.2, c2 * 0.8\n            elif eval_count < 2 * self.budget / 3:\n                F_adaptive = F_base\n                c1_adaptive, c2_adaptive = c1, c2\n            else:\n                F_adaptive = F_base * 0.5\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2 * 1.2\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07367 with standard deviation 0.00919.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.061183818159490144, 0.07676256582054142, 0.08305495051980383]}}
{"id": "d2334b50-f642-48d0-a04a-b6bf985a99a4", "fitness": 0.06522435422942723, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Fine-tune the velocity update by adjusting the random factors for improved exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))  # Modified line\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(), np.random.rand() * 1.2  # Modified line\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                    mutant = np.clip(swarm[a] + F_adaptive * (swarm[b] - swarm[c]), lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06522 with standard deviation 0.00784.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.0557702832603052, 0.06494582848716302, 0.07495695094081345]}}
{"id": "9ccbf2fe-0dbe-45a1-abf4-750142c78a59", "fitness": 0.07687864680016421, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Integrate covariance matrix adaptation to enhance exploration and exploitation balance in PSO-DE hybrid.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with CMA\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = swarm[i] + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07688 with standard deviation 0.00631.", "error": "", "parent_ids": ["bc40622d-45b6-4bfa-be92-dc5706c56965"], "operator": null, "metadata": {"aucs": [0.07970196445627509, 0.06813540925376238, 0.08279856669045516]}}
{"id": "24620323-d53f-4fd8-bd96-cc50bce3d680", "fitness": 0.06998786601397151, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Incorporate dynamic population resizing and adaptive learning rates to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        initial_population_size = 50\n        population_size = initial_population_size\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with CMA\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = swarm[i] + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n            # Dynamically resize population\n            population_size = initial_population_size + int((self.budget - eval_count) / self.budget * 20)\n            swarm = np.resize(swarm, (population_size, self.dim))\n            velocities = np.resize(velocities, (population_size, self.dim))\n            personal_best_positions = np.resize(personal_best_positions, (population_size, self.dim))\n            personal_best_scores = np.resize(personal_best_scores, population_size)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06999 with standard deviation 0.00768.", "error": "", "parent_ids": ["9ccbf2fe-0dbe-45a1-abf4-750142c78a59"], "operator": null, "metadata": {"aucs": [0.062341717313474376, 0.06713248625885049, 0.08048939446958969]}}
{"id": "3e5d1994-eb02-4827-994c-4bd96bf15cb4", "fitness": 0.07622602580497757, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Improve exploration by incorporating quantum-inspired perturbations in PSO dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            \n            # Quantum-inspired perturbation\n            q_factor = np.random.normal(0, 0.1, (population_size, self.dim))\n            velocities += q_factor\n            \n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with CMA\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = swarm[i] + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07623 with standard deviation 0.00436.", "error": "", "parent_ids": ["9ccbf2fe-0dbe-45a1-abf4-750142c78a59"], "operator": null, "metadata": {"aucs": [0.07419217214893103, 0.07219870395366945, 0.08228720131233225]}}
{"id": "d4253f7f-0ca8-4ba4-9e77-e0c96642c13c", "fitness": 0.07656537904069811, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Introduced adaptive F_base to fine-tune the exploitation-exploration balance dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8 + 0.2 * (eval_count / self.budget)  # Changed line\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))\n\n            # Determine phase based on current budget usage\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamically adjust elite_fraction\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with CMA\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = swarm[i] + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07657 with standard deviation 0.00555.", "error": "", "parent_ids": ["9ccbf2fe-0dbe-45a1-abf4-750142c78a59"], "operator": null, "metadata": {"aucs": [0.07901755362844542, 0.06887819481168356, 0.08180038868196537]}}
{"id": "7dcec7f5-5e9a-4496-af39-4ceae31bba39", "fitness": 0.07069823945835003, "name": "EnhancedAdaptiveMultiPhasePSODE", "description": "Enhance mutation strategy using Lvy flights for improved exploration and convergence in PSO-DE hybrid with CMA.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        w_max = 0.9\n        w_min = 0.3\n        c1, c2 = 1.5, 1.5\n        F_base = 0.8\n        CR = 0.9\n        phase_change_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, size=self.dim)\n            v = np.random.normal(0, sigma2, size=self.dim)\n            step = u / (np.power(np.abs(v), 1 / Lambda))\n            return step\n\n        while eval_count < self.budget:\n            w = w_max - ((w_max - w_min) * (eval_count**1.02 / self.budget**1.02))\n            if eval_count % (2 * phase_change_threshold) < phase_change_threshold:\n                F_adaptive = F_base * 1.3\n                c1_adaptive, c2_adaptive = c1 * 1.1, c2 * 0.9\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.7\n                c1_adaptive, c2_adaptive = c1 * 0.9, c2 * 1.1\n                CR = 0.85\n\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            elite_fraction = max(0.1, 0.1 + 0.1 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    levy_step = levy_flight(1.5)  # Use Lvy flight for mutation\n                    mutant = np.clip(swarm[i] + F_adaptive * (z + levy_step), lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07070 with standard deviation 0.01152.", "error": "", "parent_ids": ["9ccbf2fe-0dbe-45a1-abf4-750142c78a59"], "operator": null, "metadata": {"aucs": [0.05586586940497751, 0.07227003034923651, 0.0839588186208361]}}
{"id": "21507a1c-a12b-467e-aba7-b4e88351d353", "fitness": 0.07724639516302227, "name": "DynamicAdaptiveMultiPhasePSODE", "description": "Integrate dynamic adaptive learning rates and elite recombination into PSO-DE hybrid for enhanced convergence speed.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        adaptive_phase_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Determine phase dynamically based on performance\n            if eval_count % (2 * adaptive_phase_threshold) < adaptive_phase_threshold:\n                F_adaptive = F_base * 1.2\n                c1_adaptive, c2_adaptive = c1, c2 * 0.8\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6\n                c1_adaptive, c2_adaptive = c1 * 0.8, c2\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite fraction adjustment based on convergence rate\n            elite_fraction = max(0.1, 0.1 + 0.2 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation with elite influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 45, "feedback": "The algorithm DynamicAdaptiveMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07725 with standard deviation 0.00759.", "error": "", "parent_ids": ["9ccbf2fe-0dbe-45a1-abf4-750142c78a59"], "operator": null, "metadata": {"aucs": [0.06750115049201522, 0.07822466965180463, 0.08601336534524695]}}
{"id": "9fdef782-6494-464b-b67d-144c572c9d00", "fitness": 0.07487731044158748, "name": "EnhancedAdaptiveCMA_PSO_DE", "description": "Enhance PSO-DE hybrid by incorporating a Covariance Matrix Adaptation (CMA) strategy and adaptive exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCMA_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.2\n        c1, c2 = 2.05, 2.05\n        F_base = 0.5\n        CR_base = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # CMA parameters\n        cov_matrix = np.eye(self.dim)\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight and phase balance\n            w = w_max - ((w_max - w_min) * eval_count / self.budget)\n            phase = eval_count / self.budget\n            if phase < 0.5:\n                F_adaptive = F_base * (1 + phase)\n                CR = CR_base - 0.1 * phase\n            else:\n                F_adaptive = F_base * (2 - phase)\n                CR = CR_base + 0.1 * (phase - 0.5)\n\n            # PSO update strategy\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite-based DE mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveCMA_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07488 with standard deviation 0.00783.", "error": "", "parent_ids": ["21507a1c-a12b-467e-aba7-b4e88351d353"], "operator": null, "metadata": {"aucs": [0.06815781016405686, 0.0706205371405314, 0.08585358402017418]}}
{"id": "9a1df63c-6885-43e0-b04d-9f761cb9cda7", "fitness": 0.07146891121103867, "name": "EnhancedCoEvolutionaryPSODE", "description": "Integrate dynamic coevolutionary adaptation and elite-based covariance matrix learning into PSO-DE for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedCoEvolutionaryPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        adaptive_phase_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Dynamic inertia weight and adaptive learning factors\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            F_adaptive = F_base * (1 + np.sin(2 * np.pi * eval_count / self.budget))\n            c1_adaptive, c2_adaptive = c1 * (1 + np.cos(2 * np.pi * eval_count / self.budget)), c2\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Updated elite fraction adjustment\n            elite_fraction = max(0.1, 0.1 + 0.3 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover influenced by elite covariance\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix with elite information\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T) * (1 + np.var([personal_best_scores[i] for i in range(elite_count)]))\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedCoEvolutionaryPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07147 with standard deviation 0.00752.", "error": "", "parent_ids": ["21507a1c-a12b-467e-aba7-b4e88351d353"], "operator": null, "metadata": {"aucs": [0.06440532125251441, 0.06811347149574765, 0.08188794088485396]}}
{"id": "81acfe8d-e36c-4f3c-a0e8-025004b605b9", "fitness": 0.07761172585053307, "name": "EnhancedAdaptiveNichingPSODE", "description": "Implement adaptive niching strategies and self-adaptive parameter control in PSO-DE for robust global exploration and enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveNichingPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        adaptive_phase_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Determine phase dynamically based on performance\n            if eval_count % (2 * adaptive_phase_threshold) < adaptive_phase_threshold:\n                F_adaptive = F_base * 1.2\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with adaptive recombination strategy\n            elite_fraction = max(0.1, 0.1 + 0.2 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation with elite influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveNichingPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07761 with standard deviation 0.00456.", "error": "", "parent_ids": ["21507a1c-a12b-467e-aba7-b4e88351d353"], "operator": null, "metadata": {"aucs": [0.07230945291642632, 0.07708078660833595, 0.08344493802683695]}}
{"id": "758f3124-6db2-4659-85da-259ffca6267f", "fitness": 0.07761172585053307, "name": "RefinedAdaptiveNichingPSODE", "description": "Introduce a dynamic diversity control mechanism and adaptive elitism in PSO-DE to balance exploration and exploitation for improved global optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveNichingPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        adaptive_phase_threshold = 0.2 * self.budget\n        diversity_threshold = 0.1\n        \n        elite_fraction = 0.1  # Retain the top 10% best solutions\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Calculate diversity in the population\n            diversity = np.std(swarm, axis=0).mean()\n\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Determine phase dynamically based on performance\n            if diversity < diversity_threshold:\n                F_adaptive = F_base * 1.5  # More exploration if diversity is low\n                CR = 0.9\n            elif eval_count % (2 * adaptive_phase_threshold) < adaptive_phase_threshold:\n                F_adaptive = F_base * 1.2\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with adaptive recombination strategy\n            elite_fraction = max(0.1, 0.1 + 0.2 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # CMA-based mutation with elite influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    z = np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * z\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 49, "feedback": "The algorithm RefinedAdaptiveNichingPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07761 with standard deviation 0.00456.", "error": "", "parent_ids": ["81acfe8d-e36c-4f3c-a0e8-025004b605b9"], "operator": null, "metadata": {"aucs": [0.07230945291642632, 0.07708078660833595, 0.08344493802683695]}}
{"id": "a37715a7-b88e-4d80-8b0b-7c7a1037b83d", "fitness": 0.08459259552917824, "name": "DynamicNichingCooperativeSwarmOptimization", "description": "Dynamic Niching Cooperative Swarm Optimization: Integrate dynamic niching and cooperative behavior with adaptive parameter control for enhanced exploration and exploitation in high-dimensional spaces.", "code": "import numpy as np\n\nclass DynamicNichingCooperativeSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        adaptive_phase_threshold = 0.2 * self.budget\n        \n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        mean = np.mean(swarm, axis=0)\n        \n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Determine phase dynamically based on performance\n            if eval_count % (2 * adaptive_phase_threshold) < adaptive_phase_threshold:\n                F_adaptive = F_base * 1.2\n                CR = 0.95\n            else:\n                F_adaptive = F_base * 0.6\n                CR = 0.85\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with cooperative strategy\n            elite_fraction = max(0.1, 0.1 + 0.2 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and global influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence) / 2\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update mean and covariance matrix\n            mean = np.mean(swarm, axis=0)\n            cov_matrix = np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 50, "feedback": "The algorithm DynamicNichingCooperativeSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08459 with standard deviation 0.00228.", "error": "", "parent_ids": ["81acfe8d-e36c-4f3c-a0e8-025004b605b9"], "operator": null, "metadata": {"aucs": [0.08148495912844589, 0.08540038442974296, 0.08689244302934584]}}
{"id": "2faab50b-34f9-49b0-8cd3-d9ac5541d980", "fitness": 0.08975201538875066, "name": "EnhancedAdaptiveNichingSwarmOptimization", "description": "Enhanced Adaptive Niching Swarm Optimization: Introduce dynamic inertia weights, multi-agent cooperation, and adaptive mutation rates for improved exploration and convergence in complex landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveNichingSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        \n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with cooperative strategy\n            elite_fraction = max(0.1, 0.1 + 0.2 * (eval_count / self.budget))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and global influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveNichingSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08975 with standard deviation 0.00137.", "error": "", "parent_ids": ["a37715a7-b88e-4d80-8b0b-7c7a1037b83d"], "operator": null, "metadata": {"aucs": [0.08887829637872113, 0.09168850040844045, 0.0886892493790904]}}
{"id": "c35533a0-0a9c-4a51-ba81-f0a28a937547", "fitness": 0.08984830002079595, "name": "HybridSwarmEliteCovarianceOptimization", "description": "Hybrid Swarm-Based Optimization with Adaptive Elite Niching and Covariance Adaptation: Introduces dynamic elite niching, adaptive inertia, and covariance matrix updates to enhance exploration and convergence across diverse landscapes.", "code": "import numpy as np\n\nclass HybridSwarmEliteCovarianceOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with adaptive strategy\n            elite_fraction = 0.1 + 0.2 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 52, "feedback": "The algorithm HybridSwarmEliteCovarianceOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08985 with standard deviation 0.00112.", "error": "", "parent_ids": ["2faab50b-34f9-49b0-8cd3-d9ac5541d980"], "operator": null, "metadata": {"aucs": [0.08975813717695147, 0.09125756853339229, 0.0885291943520441]}}
{"id": "9b2f13d2-7a26-4df3-b2eb-1723dfb1ebdb", "fitness": 0.07049642992197103, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Hybrid Swarm Optimization with Adaptive Elite Niching and Dynamic Parameter Tuning: Incorporates adaptive learning rates, elite-driven mutation strategies, and dynamic exploration-exploitation balance to improve convergence speed and solution quality across diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base, CR = 0.7, 0.9\n        F_adaptive = F_base\n        elite_fraction = 0.1\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Dynamic inertia and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamic elite niching and F adaptation\n            elite_fraction = 0.1 + 0.2 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n            F_adaptive = F_base * (1 + (global_best_score / max(personal_best_scores)))\n\n            # Differential Evolution-like mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = elite_mean + F_adaptive * (global_influence - swarm[i])\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07050 with standard deviation 0.00327.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.07493815303769802, 0.06940701287921758, 0.06714412384899748]}}
{"id": "0fc34298-d989-417a-90c3-9f969705b0ac", "fitness": 0.08956705235831441, "name": "HybridSwarmEliteCovarianceOptimization", "description": "Enhanced convergence through adaptive elite niching and covariance matrix updates with improved inertia weight adjustment.", "code": "import numpy as np\n\nclass HybridSwarmEliteCovarianceOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * ((eval_count / self.budget)**1.5))  # Modified line\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with adaptive strategy\n            elite_fraction = 0.1 + 0.2 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 54, "feedback": "The algorithm HybridSwarmEliteCovarianceOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08957 with standard deviation 0.00123.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.08935353934504797, 0.091166269866501, 0.08818134786339427]}}
{"id": "e3f57fac-8c09-4061-b777-47a7542fbcfe", "fitness": 0.08970392296533485, "name": "HybridSwarmEliteCovarianceOptimization", "description": "Slightly enhance the convergence by adapting the exploitation factor through modifying the crossover rate dynamically.", "code": "import numpy as np\n\nclass HybridSwarmEliteCovarianceOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Elite niching with adaptive strategy\n            elite_fraction = 0.1 + 0.2 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    # Introducing dynamic crossover rate based on budget utilization\n                    CR_dynamic = CR - (CR - 0.5) * (eval_count / self.budget)\n                    crossover = np.random.rand(self.dim) < CR_dynamic\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 55, "feedback": "The algorithm HybridSwarmEliteCovarianceOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08970 with standard deviation 0.00106.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.08881050299047866, 0.0911915712111997, 0.08910969469432617]}}
{"id": "acb4b501-38e9-456e-aefe-55e5908ec3f5", "fitness": 0.08015051460878671, "name": "EnhancedHybridSwarmDynamicCovariance", "description": "Enhanced Hybrid Swarm Optimization with Dynamic Covariance Matrix and Adaptive Crossover: Incorporates dynamic adjustment of covariance matrix for local search, adaptive crossover based on fitness landscape, and improved elite niching to optimize function evaluations efficiently.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmDynamicCovariance:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        CR_base = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best_positions - swarm) + \n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamic elite niching based on global best improvement\n            if global_best_score < min(personal_best_scores):\n                elite_fraction += 0.05\n            else:\n                elite_fraction -= 0.05\n            elite_fraction = np.clip(elite_fraction, 0.1, 0.3)\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Adaptive crossover rate based on fitness landscape\n            CR = CR_base * (1 - (global_best_score / max(personal_best_scores)))\n\n            # Differential Evolution mutation and crossover with dynamic covariance\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n\n                if i >= elite_count:\n                    # Mutation\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix for better local search\n            cov_matrix = 0.85 * cov_matrix + 0.15 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridSwarmDynamicCovariance got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08015 with standard deviation 0.00378.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.07961580546327884, 0.0758070441688109, 0.0850286941942704]}}
{"id": "301f332f-da9b-495b-a2dc-d0e7263a5ba6", "fitness": 0.07064734893256508, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Hybrid Swarm Optimization with Adaptive Quantum-Inspired Mutation and Dynamic Neighborhood Search: Introduces quantum-inspired mutation for improved exploration and dynamic neighborhood search for enhanced convergence to refine solutions.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Quantum-inspired parameters\n        beta = 0.1\n\n        while eval_count < self.budget:\n            # Adjust inertia weight and learning coefficients\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # PSO update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Quantum-inspired mutation\n            for i in range(population_size):\n                if i < elite_count:\n                    continue\n\n                q_bit = np.random.uniform(-beta, beta, self.dim)\n                quantum_mutant = swarm[i] + q_bit * (global_best_position - swarm[i])\n                quantum_mutant = np.clip(quantum_mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, quantum_mutant, swarm[i])\n\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic neighborhood search for local refinement\n            if eval_count < self.budget:\n                for i in range(elite_count):\n                    neighbors = np.random.choice(range(population_size), size=5, replace=False)\n                    local_best = min(neighbors, key=lambda x: personal_best_scores[x])\n                    local_step = np.random.uniform(-0.1, 0.1, self.dim)\n                    local_candidate = swarm[local_best] + local_step\n                    local_candidate = np.clip(local_candidate, lb, ub)\n\n                    f_local_candidate = func(local_candidate)\n                    eval_count += 1\n\n                    if f_local_candidate < personal_best_scores[i]:\n                        personal_best_positions[i] = local_candidate\n                        personal_best_scores[i] = f_local_candidate\n                        if f_local_candidate < global_best_score:\n                            global_best_position = local_candidate\n                            global_best_score = f_local_candidate\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07065 with standard deviation 0.00516.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.07346446656742822, 0.06341225766298231, 0.07506532256728471]}}
{"id": "b90173c8-0318-4107-9044-f2de19beaf78", "fitness": 0.08993873416922542, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Hybrid Swarm Optimization with Dynamic Inertia Reduction, Adaptive Covariance, and Controlled Elite Strategy: Refines exploration and exploitation balance via progressive inertia reduction, adaptive covariance matrix scaling, and controlled elite selection, aiming to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08994 with standard deviation 0.00081.", "error": "", "parent_ids": ["c35533a0-0a9c-4a51-ba81-f0a28a937547"], "operator": null, "metadata": {"aucs": [0.08947940836943702, 0.0910731866699156, 0.08926360746832362]}}
{"id": "c007520b-212b-492e-a4e3-b1ae842148c0", "fitness": 0.08826291118939429, "name": "AdvancedHybridSwarmAlgorithm", "description": "Advanced Hybrid Swarm Algorithm with Adaptive Memory and Diversity Maintenance: Integrates adaptive memory mechanisms and diversity-preserving strategies to enhance exploration-exploitation synergy, improving convergence speed and solution robustness.", "code": "import numpy as np\n\nclass AdvancedHybridSwarmAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n        elite_fraction = 0.1\n        memory_factor = 0.5\n        elite_count = max(1, int(elite_fraction * population_size))\n        cov_matrix = np.eye(self.dim)\n\n        # Memory mechanism\n        memory_position = np.copy(global_best_position)\n        memory_score = global_best_score\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Preserve diversity by occasionally using positions from memory\n                    if np.random.rand() < memory_factor:\n                        mutant = (swarm[i] + memory_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)) / 3\n                    else:\n                        elite_positions = swarm[:elite_count]\n                        elite_mean = np.mean(elite_positions, axis=0)\n                        global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                        mutant = (elite_mean + global_influence + swarm[i]) / 3\n\n                    mutant = np.clip(mutant, lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            memory_position = global_best_position\n                            memory_score = global_best_score\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedHybridSwarmAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08826 with standard deviation 0.00219.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.08648637222681488, 0.09135525404798384, 0.08694710729338417]}}
{"id": "5c119a3a-ba9b-4073-a02e-ce4b56bdade1", "fitness": 0.06842190721743287, "name": "EnhancedHybridSwarmOptimization", "description": "Integrated Quantum-inspired Differential Evolution and Adaptive Elite Learning for enhanced convergence and diversity control.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Quantum-inspired and Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-inspired Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Quantum-inspired mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    quantum_factor = np.random.normal(size=self.dim)\n                    mutant = (elite_mean * quantum_factor + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06842 with standard deviation 0.00692.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.06049895035845476, 0.07735788620095085, 0.067408885092893]}}
{"id": "603e2c83-5b42-4b27-a2c8-e496492628e4", "fitness": 0.08993873416922542, "name": "SynergisticSwarmOptimization", "description": "Synergistic Swarm Optimization incorporates dynamic adaptive inertia, covariance-enhanced differential mutation, and stochastic elite reinforcement to boost convergence rate and solution accuracy.", "code": "import numpy as np\n\nclass SynergisticSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with stochastic elite reinforcement\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 61, "feedback": "The algorithm SynergisticSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08994 with standard deviation 0.00081.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.08947940836943702, 0.0910731866699156, 0.08926360746832362]}}
{"id": "8ac65630-0cba-49e5-841a-fe6189b9eae9", "fitness": 0.08657427819441121, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Swarm Optimization with Adaptive Elite Resampling and Dynamic Velocity Bounds: Introduces elite resampling for diversity maintenance and dynamically adaptive velocity bounds to improve convergence precision and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        # New adaptive velocity bounds\n        velocity_bounds = (ub - lb) / 10\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            velocities = np.clip(velocities, -velocity_bounds, velocity_bounds)  # Dynamic velocity bounds\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    if np.random.rand() < 0.1:  # Elite resampling with low probability\n                        elite_positions = np.random.uniform(lb, ub, (elite_count, self.dim))\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08657 with standard deviation 0.00484.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.09063566543215729, 0.07976933526610985, 0.0893178338849665]}}
{"id": "32335f19-e0e8-474f-8f97-488aac361b5e", "fitness": 0.08840651260530914, "name": "EnhancedHybridSwarmOptimization", "description": "Improved Enhanced Hybrid Swarm Optimization with Time-Varying Covariance Matrix Scaling and Random Elite Reinforcement for Enhanced Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            # Covariance matrix scaling varies over time\n            cov_matrix = (0.95 - 0.05 * (np.random.rand()/2)) * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08841 with standard deviation 0.00187.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.08811401327050716, 0.09082681479590338, 0.0862787097495169]}}
{"id": "25d2c4ed-20da-4942-869c-4710d8bb4e3a", "fitness": 0.08919408905771394, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Hybrid Swarm Optimization with Improved Elite Fraction Calculation: Refines the elite fraction calculation to enhance adaptability, providing better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - ((global_best_score / np.min(personal_best_scores)) ** 0.5))  # Modification here\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08919 with standard deviation 0.00091.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.08853683690972902, 0.09048615539171423, 0.08855927487169857]}}
{"id": "011fa820-f8b7-4272-ad89-645d5b403886", "fitness": 0.057087931199129104, "name": "EnhancedSwarmOptimization", "description": "Enhanced Swarm Optimization with Stochastic Inertia, Adaptive Learning Rates, and Hybrid Mutation: Introduces stochastic inertia for dynamic exploration, adapts learning rates based on past performance, and integrates a hybrid mutation mechanism for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Initial parameters\n        w_min, w_max = 0.3, 0.9\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        # Adaptive parameters\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Stochastic inertia for enhanced exploration\n            w = np.random.uniform(w_min, w_max)\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Hybrid mutation combining DE and PSO strategies\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Hybrid mutation with combined strategies\n                    random_candidates = np.random.choice(candidates, 3, replace=False)\n                    x1, x2, x3 = swarm[random_candidates]\n                    mutant = x1 + F_base * (x2 - x3) + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Adaptive update of covariance matrix for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05709 with standard deviation 0.00347.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.06097778063261605, 0.05256200136483358, 0.057724011599937675]}}
{"id": "9637d089-9d75-495d-9152-ab36627d4211", "fitness": 0.08839784221667561, "name": "EnhancedHybridSwarmOptimization", "description": "Enhanced Hybrid Swarm Optimization with Modified Elite Influence: Introduces a subtle yet critical adjustment in elite strategy to amplify convergence efficacy without altering the underlying algorithm structure.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        F_base = 0.7\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + 0.5*global_influence + 0.5*swarm[i]) / 2  # Adjusted influence ratio\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08840 with standard deviation 0.00250.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.08510540841127612, 0.09115917908689652, 0.08892893915185418]}}
{"id": "ab8d8c19-2539-472c-bcdd-d899303d72af", "fitness": 0.09138692722472892, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Advanced Quantum-Inspired Hybrid Swarm Optimization enhances exploration with quantum-based position updates, employs adaptive elite strategies, and integrates covariance matrix adaptation for robust convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 67, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09139 with standard deviation 0.00049.", "error": "", "parent_ids": ["b90173c8-0318-4107-9044-f2de19beaf78"], "operator": null, "metadata": {"aucs": [0.0912850898670744, 0.09203127806588651, 0.09084441374122587]}}
{"id": "aff275cd-182e-4635-acc0-87de456df5e6", "fitness": 0.09104581237578353, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced adaptive covariance update frequency for improved local search efficiency.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            if eval_count % 10 == 0:  # Change 1 line: Update frequency enhanced to every 10 evaluations\n                cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 68, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09105 with standard deviation 0.00156.", "error": "", "parent_ids": ["ab8d8c19-2539-472c-bcdd-d899303d72af"], "operator": null, "metadata": {"aucs": [0.0919025973480051, 0.09238033533140722, 0.0888545044479383]}}
{"id": "f2f82811-eea9-4eb0-87d9-b181856b9ebc", "fitness": 0.08862331910792261, "name": "EnhancedMultiverseQuantumSwarmOptimization", "description": "Enhanced Multiverse-Inspired Quantum Swarm Optimization leverages multiverse theory for exploration, adaptive quantum tunneling for diverse solution updates, and dynamic elite recombination to robustify convergence.", "code": "import numpy as np\n\nclass EnhancedMultiverseQuantumSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        # Multiverse-inspired variables\n        blackhole_tendency = 0.5\n        whitehole_tendency = 0.2\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Multiverse-inspired position update\n            for i in range(population_size):\n                if np.random.rand() < blackhole_tendency:\n                    swarm[i] = global_best_position + np.random.normal(0, 1, self.dim)\n                elif np.random.rand() < whitehole_tendency:\n                    random_idx = np.random.randint(population_size)\n                    swarm[i] = 0.5 * (swarm[i] + swarm[random_idx])\n\n            # Quantum tunneling update\n            sigma = 0.1 + 0.3 * (1 - (global_best_score / max(personal_best_scores)))\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedMultiverseQuantumSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08862 with standard deviation 0.00098.", "error": "", "parent_ids": ["ab8d8c19-2539-472c-bcdd-d899303d72af"], "operator": null, "metadata": {"aucs": [0.0899751410170514, 0.08769093117281879, 0.08820388513389765]}}
{"id": "cf78aec3-04b8-486e-a4ab-8acba65316cb", "fitness": 0.09129012491637045, "name": "QuantumEnhancedDynamicSwarmOptimization", "description": "The Quantum-Enhanced Dynamic Swarm Optimization refines exploration by incorporating adaptive quantum-centric search radius, dynamic elite recombination, and diversity-driven mutation, enhancing convergence reliability and robustness.", "code": "import numpy as np\n\nclass QuantumEnhancedDynamicSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 1.5, 1.5\n        CR = 0.85\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        diversity_threshold = 0.05\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget))\n            c2_adaptive = c2 * ((eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled fraction\n            elite_fraction = 0.1 + 0.1 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update with adaptive radius\n            sigma = 0.15 - 0.05 * (eval_count / self.budget)\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Diversity-driven mutation and elite recombination\n            diversity = np.mean(np.std(swarm, axis=0))\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + (np.random.multivariate_normal(np.zeros(self.dim), cov_matrix) if diversity < diversity_threshold else np.zeros(self.dim))\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Adapt covariance matrix for local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 70, "feedback": "The algorithm QuantumEnhancedDynamicSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09129 with standard deviation 0.00070.", "error": "", "parent_ids": ["ab8d8c19-2539-472c-bcdd-d899303d72af"], "operator": null, "metadata": {"aucs": [0.09188934819223082, 0.09166593928193001, 0.09031508727495052]}}
{"id": "4a3234fd-b115-40ba-b705-4b36eca4986b", "fitness": 0.09138692722472892, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Improved adaptive elite fraction calculation enhances exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / (max(personal_best_scores) + 1e-9)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 71, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09139 with standard deviation 0.00049.", "error": "", "parent_ids": ["ab8d8c19-2539-472c-bcdd-d899303d72af"], "operator": null, "metadata": {"aucs": [0.0912850898670744, 0.09203127806588651, 0.09084441374122587]}}
{"id": "62c26788-3702-493e-b574-34e74310461a", "fitness": 0.09143246015184399, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Hybrid Swarm Optimization by tuning covariance matrix adaptation rate for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 72, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09143 with standard deviation 0.00047.", "error": "", "parent_ids": ["ab8d8c19-2539-472c-bcdd-d899303d72af"], "operator": null, "metadata": {"aucs": [0.09091113787139726, 0.09204565561850175, 0.09134058696563296]}}
{"id": "050c38b5-8aa9-4789-be2f-8bbf9c5d6173", "fitness": 0.09143246015184399, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Added adaptive mutation rate based on convergence for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            mutation_factor = 0.5 + 0.5 * (global_best_score / max(personal_best_scores))  # Adaptive mutation rate\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 73, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09143 with standard deviation 0.00047.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.09091113787139726, 0.09204565561850175, 0.09134058696563296]}}
{"id": "718db1f1-9713-4be2-878c-93b5ff358857", "fitness": 0.07742555619930624, "name": "RotationalQuantumInspiredSwarmOptimization", "description": "Adaptive Quantum-Inspired Hybrid Swarm Optimization with Rotational Diversity Enhancement for improved global exploration and convergence.", "code": "import numpy as np\n\nclass RotationalQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    # Rotational Diversity Enhancement\n                    rotation_matrix = np.eye(self.dim)  # Initialize identity matrix\n                    angle = np.pi * (eval_count / self.budget)\n                    for j in range(self.dim - 1):\n                        rotation_matrix[j, j] = np.cos(angle)\n                        rotation_matrix[j, j + 1] = -np.sin(angle)\n                        rotation_matrix[j + 1, j] = np.sin(angle)\n                        rotation_matrix[j + 1, j + 1] = np.cos(angle)\n\n                    rotated_trial = np.dot(quantum_trial, rotation_matrix)\n                    rotated_trial = np.clip(rotated_trial, lb, ub)\n\n                    f_trial = func(rotated_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = rotated_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = rotated_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 74, "feedback": "The algorithm RotationalQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07743 with standard deviation 0.00537.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.06992470725859046, 0.08012744975495589, 0.08222451158437238]}}
{"id": "1737f085-58c2-4660-bdc2-5e86d586defa", "fitness": 0.08974610381503552, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Improved Quantum-Inspired Hybrid Swarm Optimization with Adaptive Learning Components for Enhanced Convergence and Exploration.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 60  # Increased population size for diversity\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.8, 0.2  # Adjusted inertia weight range\n        c1, c2 = 1.5, 2.5  # Modified cognitive and social coefficients\n        CR = 0.8  # Slightly reduced crossover rate\n\n        elite_fraction = 0.15  # Increased elite fraction\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**1.5)  # More aggressive reduction\n            c2_adaptive = c2 * ((eval_count / self.budget)**1.5)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Quantum-Inspired Position Update with increased stochasticity\n            sigma = 0.15\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.6, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.8 * cov_matrix + 0.2 * np.cov(swarm.T)  # Enhanced adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 75, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08975 with standard deviation 0.00094.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.08841506543777566, 0.09040231398162069, 0.09042093202571022]}}
{"id": "9c191afe-59cf-461d-b901-df0d4359b840", "fitness": 0.05721849901755053, "name": "SynergisticQuantumAdaptiveSwarmOptimization", "description": "Synergistic Quantum Adaptive Swarm Optimization with Dynamic Resource Allocation and Perturbation for enhanced exploration and convergence balance.", "code": "import numpy as np\n\nclass SynergisticQuantumAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n        \n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Dynamic elite strategy with performance-based adjustment\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update with adaptive sigma\n            sigma = 0.1 + 0.05 * (1 - eval_count / self.budget)\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    perturbation = 0.1 * np.random.standard_normal(self.dim)\n                    mutant = (elite_mean + global_influence + perturbation)\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 76, "feedback": "The algorithm SynergisticQuantumAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05722 with standard deviation 0.00106.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.05804907981987584, 0.05787681107932896, 0.0557296061534468]}}
{"id": "809be7c7-d48c-4491-8aa0-f1f4d19d241f", "fitness": 0.0883038742692424, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Improved Quantum-Inspired Hybrid Swarm Optimization by introducing dynamic learning factors and enhancing diversity with Gaussian perturbation.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n        \n        eval_count = population_size\n        \n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1_initial, c2_initial = 2.0, 2.0\n        CR = 0.9\n        \n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n        \n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        \n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            # Dynamic learning factors\n            c1_adaptive = c1_initial + (1 - eval_count / self.budget) * 0.5\n            c2_adaptive = c2_initial - (1 - eval_count / self.budget) * 0.5\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n            \n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n            \n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n            \n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n                    \n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n                    \n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n                    \n                    # Quantum-inspired trial update with Gaussian perturbation for diversity\n                    perturbation = np.random.normal(0, sigma, self.dim)\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i] + perturbation)\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n                    \n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 77, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08830 with standard deviation 0.00171.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.09031568502957599, 0.08614548182127346, 0.08845045595687773]}}
{"id": "1e8b6dac-9b0a-4b1b-a12c-59f99d3bb0ea", "fitness": 0.06970719274557409, "name": "QuantumInspiredDualAdaptiveStrategyOptimization", "description": "Quantum-Inspired Dual Adaptive Strategy Optimization enhances search diversity and local convergence by integrating dual adaptive heuristics in the quantum and differential evolution phases.", "code": "import numpy as np\n\nclass QuantumInspiredDualAdaptiveStrategyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Quantum-Inspired Position Update with dual adaptive strategy\n            sigma_initial = 0.1\n            sigma_decay = 0.99\n            sigma = sigma_initial * (sigma_decay ** (eval_count / self.budget))\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                mutant = swarm[a] + 0.8 * (swarm[b] - swarm[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, swarm[i])\n\n                # Enhanced quantum-inspired trial update\n                quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                f_trial = func(quantum_trial)\n                eval_count += 1\n\n                if f_trial < personal_best_scores[i]:\n                    personal_best_positions[i] = quantum_trial\n                    personal_best_scores[i] = f_trial\n                    if f_trial < global_best_score:\n                        global_best_position = quantum_trial\n                        global_best_score = f_trial\n\n                if eval_count >= self.budget:\n                    break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 78, "feedback": "The algorithm QuantumInspiredDualAdaptiveStrategyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06971 with standard deviation 0.00177.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.06983784880020838, 0.07180301237674691, 0.06748071705976699]}}
{"id": "9a8fd430-3c78-4b00-a516-baf1dd3ccd5d", "fitness": 0.09139367714899882, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Improve convergence by dynamically adjusting sigma and inertia weight decay for quantum-inspired and particle swarm components.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.9\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1 * (1 - eval_count / self.budget)  # Adjust sigma dynamically\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 79, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09139 with standard deviation 0.00046.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.09090520871449381, 0.09201079706035553, 0.09126502567214712]}}
{"id": "44080dd8-48f9-430b-a058-14262df61ea8", "fitness": 0.09185472474953722, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Refined Quantum-Inspired Swarm Optimization with improved crossover rate for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 80, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09185 with standard deviation 0.00080.", "error": "", "parent_ids": ["62c26788-3702-493e-b574-34e74310461a"], "operator": null, "metadata": {"aucs": [0.09276177334898217, 0.09198630991480838, 0.09081609098482113]}}
{"id": "53368a16-f7c3-4c79-9bc5-e969aae96f40", "fitness": 0.09128613475844567, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced adaptive strategy with linear decrease of crossover rate to improve exploratory capabilities.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR_max, CR_min = 0.95, 0.5  # Modified to have a decreasing crossover rate\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Linearly reduce crossover rate\n            CR = CR_max - ((CR_max - CR_min) * (eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 81, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09129 with standard deviation 0.00096.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09234485595018216, 0.09148913392388935, 0.09002441440126552]}}
{"id": "a7932aa2-860b-4abf-9275-5127e51fc53d", "fitness": 0.0915894933476366, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Adaptive Quantum-Inspired Swarm Optimization with enhanced local search through dynamic covariance scaling and selective reset of stagnated particles.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        # Dynamic scaling factors\n        dynamic_sigma = 0.1\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Update elite count dynamically\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update with dynamic scaling\n            dynamic_sigma = 0.1 + 0.3 * (1 - (global_best_score / max(personal_best_scores)))\n            quantum_positions = global_best_position + dynamic_sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    # Implement selective reset for stagnated particles\n                    if eval_count % 100 == 0:\n                        if personal_best_scores[i] > np.mean(personal_best_scores):\n                            swarm[i] = np.random.uniform(lb, ub, self.dim)\n                            personal_best_positions[i] = np.copy(swarm[i])\n                            personal_best_scores[i] = func(swarm[i])\n                            eval_count += 1\n\n                    if eval_count >= self.budget:\n                        break\n\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09159 with standard deviation 0.00138.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09279018573828224, 0.09232487829304514, 0.08965341601158239]}}
{"id": "ab32701d-c210-4034-95de-6389e0faa41d", "fitness": 0.08898795263131887, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced position update using a slightly reduced noise factor in Quantum-Inspired trial update for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.45, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 83, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08899 with standard deviation 0.00188.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08972366688717337, 0.0864133057169576, 0.09082688528982563]}}
{"id": "9fb2d30b-c324-44fb-8b2e-59f3f564cbeb", "fitness": 0.08972734530329833, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced global best update strategy using a weighted average with elite mean for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            # Improved global best update using weighted average of elite mean\n                            global_best_position = 0.7 * quantum_trial + 0.3 * elite_mean\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 84, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08973 with standard deviation 0.00223.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08953917412495715, 0.09254753438503915, 0.08709532739989867]}}
{"id": "824417ad-c6b4-41c8-974f-2efbdb8bea9f", "fitness": 0.08836336320273841, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with refined adaptive covariance and stochastic elite sampling for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with stochastic elite sampling\n            elite_fraction = 0.1 + 0.2 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n            elite_indices = np.random.choice(population_size, elite_count, replace=False)\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[elite_indices]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for improved local search\n            cov_matrix = 0.85 * cov_matrix + 0.15 * np.cov(swarm.T)  # Adjusted adaptation rate for better locality\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08836 with standard deviation 0.00125.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08950951097034954, 0.08662270771250791, 0.08895787092535778]}}
{"id": "be3ef7a9-699a-4122-9916-2dc16c8b1725", "fitness": 0.08739574646700647, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with adaptive learning rates for improved convergence in dynamic environments.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1_init, c2_init = 2.5, 1.5\n        CR = 0.9  # Crossover rate\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Learning rate adaptation\n        learning_rate_decay = 0.99\n\n        while eval_count < self.budget:\n            # Reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1 = c1_init * (learning_rate_decay ** (eval_count / self.budget))\n            c2 = c2_init * ((1 - learning_rate_decay) ** (eval_count / self.budget))\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - swarm) +\n                          c2 * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Mutant creation using elite influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    mutant = (elite_mean + swarm[i]) / 2\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08740 with standard deviation 0.00378.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09179681759280856, 0.08256051701868383, 0.08782990478952701]}}
{"id": "4cf7671f-282f-4f7c-934e-5883c0de842c", "fitness": 0.08816190211229247, "name": "EnhancedHybridQuantumInspiredSwarmOptimization", "description": "Enhanced Hybrid Quantum-Inspired Swarm Optimization integrating adaptive opposition-based learning for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        # Enhanced strategy with opposition-based learning\n        def opposition_based_generation(swarm):\n            return lb + ub - swarm\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n        \n            # Introduce opposition-based learning\n            opposition_positions = opposition_based_generation(swarm)\n            opposition_scores = np.array([func(ind) for ind in opposition_positions])\n            eval_count += population_size\n\n            for i in range(population_size):\n                if opposition_scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = opposition_positions[i]\n                    personal_best_scores[i] = opposition_scores[i]\n                    if opposition_scores[i] < global_best_score:\n                        global_best_position = opposition_positions[i]\n                        global_best_score = opposition_scores[i]\n\n            if eval_count >= self.budget:\n                break\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08816 with standard deviation 0.00118.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08971833404147245, 0.08789096217903081, 0.08687641011637415]}}
{"id": "5e591c92-bda6-4555-be8d-febd5f55b215", "fitness": 0.08859492970694242, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced quantum-inspired swarm optimization with adaptive learning rates for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update with adaptive learning rate\n                    adaptive_learning_rate = 0.5 + 0.5 * (global_best_score / max(personal_best_scores))\n                    quantum_trial = np.where(np.random.rand(self.dim) < adaptive_learning_rate, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 88, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08859 with standard deviation 0.00250.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09018174926972033, 0.08505874730831753, 0.0905442925427894]}}
{"id": "0293c20c-5047-4cb3-a71b-32c9372faaf7", "fitness": 0.09083958984633096, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Adaptive Quantum-Inspired Swarm Optimization integrating time-varying scaling factors and elite local search refinement.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.85  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n        scaling_factor_min, scaling_factor_max = 0.4, 1.0\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            scaling_factor = scaling_factor_min + ((scaling_factor_max - scaling_factor_min) * (1 - eval_count / self.budget))\n            cov_matrix = (1 - scaling_factor) * cov_matrix + scaling_factor * np.cov(swarm.T)  # Adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 89, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09084 with standard deviation 0.00022.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09084033549578441, 0.09110886669732876, 0.09056956734587973]}}
{"id": "502dcf67-6eec-4b9f-8459-1f94272069da", "fitness": 0.09120852142701708, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with strategic quantum trial update for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.7, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 90, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09121 with standard deviation 0.00111.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.091911032243288, 0.09207867109065293, 0.08963586094711029]}}
{"id": "438cbea2-8401-45ba-9ca0-dbe5e943d28b", "fitness": 0.08916606274423466, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with dynamic inertia and crossover adaptation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.15 + 0.1 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.05  # Reduced standard deviation for finer exploration\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.4, trial, quantum_positions[i])  # Adjusted for more diversity\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.85 * cov_matrix + 0.15 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08917 with standard deviation 0.00223.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08940618055161853, 0.0863254305305815, 0.09176657715050396]}}
{"id": "dc39b4f8-3f38-42de-80da-f6a836a3ce09", "fitness": 0.09105880349686139, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Incorporate adaptive mutation scaling in DE to enhance exploration without modifying other components.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutation_scale = 0.5 + 0.5 * (global_best_score / personal_best_scores[i])  # Adaptive mutation scaling\n                    mutant = (elite_mean + mutation_scale * global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 92, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09106 with standard deviation 0.00125.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.0910808956654936, 0.09258412490236223, 0.08951138992272833]}}
{"id": "41cffd80-a096-4bc0-97cb-cbf5a0ad845d", "fitness": 0.09182700928220178, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization using adaptive covariance matrix scaling for improved exploitation.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters with adaptive scaling\n        cov_matrix = np.eye(self.dim)\n        scale_factor = 1.0\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search with dynamic scaling\n            scale_factor = 0.95 + 0.05 * (1 - (global_best_score / max(personal_best_scores)))\n            cov_matrix = scale_factor * (0.9 * cov_matrix + 0.1 * np.cov(swarm.T))\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09183 with standard deviation 0.00084.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09268152755512382, 0.09211982981485911, 0.0906796704766224]}}
{"id": "221ab7cc-cf8a-46c3-8084-510bf4d605e9", "fitness": 0.09063293278931502, "name": "EnhancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with adaptive learning rates and selective restart strategy for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        CR = 0.9  # Tuned crossover rate\n        restart_threshold = 0.1  # Threshold for stagnation\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        stagnation_counter = 0\n        last_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n                            stagnation_counter = 0\n                        else:\n                            stagnation_counter += 1\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Restart strategy if stagnation is detected\n            if stagnation_counter > restart_threshold * population_size:\n                swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n                stagnation_counter = 0\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n            if abs(last_best_score - global_best_score) < 1e-6:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            last_best_score = global_best_score\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09063 with standard deviation 0.00130.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.08921942467742539, 0.09234958165521334, 0.09032979203530633]}}
{"id": "ba74e67b-e5a8-4ede-b9aa-107e2d218c24", "fitness": 0.0909136765138933, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with dynamically adjusted crossover rate for improved convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    # Dynamically adjust the crossover rate\n                    CR = 0.8 + 0.2 * (global_best_score / max(personal_best_scores))\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)  # Slightly adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 95, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09091 with standard deviation 0.00085.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09054411808360419, 0.09209069969605632, 0.09010621176201938]}}
{"id": "a5160af7-9c74-4505-be76-81faf0e13713", "fitness": 0.0902579192000967, "name": "EnhancedAdaptiveQuantumInspiredSwarmOptimization", "description": "Enhanced Adaptive Quantum-Inspired Swarm Optimization with a dynamically adjusted covariance matrix and improved quantum trial strategy for a more efficient global search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1 * (1 - eval_count / self.budget)  # Adaptive sigma\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial_prob = 0.5 + 0.5 * (1 - eval_count / self.budget)\n                    quantum_trial = np.where(np.random.rand(self.dim) < quantum_trial_prob, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.95 * cov_matrix + 0.05 * np.cov(swarm.T)  # Adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09026 with standard deviation 0.00075.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09000075119429285, 0.09127146193397118, 0.08950154447202607]}}
{"id": "a67bae38-4390-4dfa-9908-1acd48ab5546", "fitness": 0.091112367565603, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with adaptive learning rates and dynamic crossover for improved diversity.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            adaptive_CR = CR - 0.5 * (eval_count / self.budget)  # Dynamic crossover rate\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < adaptive_CR  # Apply dynamic CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            cov_matrix = 0.9 * cov_matrix + 0.1 * np.cov(swarm.T)\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 97, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09111 with standard deviation 0.00080.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09157667268890923, 0.09177433332334617, 0.0899860966845536]}}
{"id": "b59755ab-277a-46ce-a220-ad4d4f9c9c4c", "fitness": 0.09160314909795342, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced adaptive covariance matrix integration for improved local search efficiency.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        # Covariance Matrix Adaptation parameters\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            # Adaptive elite strategy with controlled elite fraction\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            # Quantum-Inspired Position Update\n            sigma = 0.1\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            # Differential Evolution mutation and crossover with covariance-enhanced recombination\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    # Combined mutation using elite and covariance influence\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    # Quantum-inspired trial update\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Update covariance matrix adaptively for better local search\n            cov_matrix = 0.8 * cov_matrix + 0.2 * np.cov(swarm.T)  # Enhanced adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 98, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09160 with standard deviation 0.00073.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09163868833334898, 0.0924755587046332, 0.09069520025587807]}}
{"id": "82885ca8-61b5-422d-a4a8-244d6bf5d386", "fitness": 0.09185935211447827, "name": "AdvancedQuantumInspiredSwarmOptimization", "description": "Enhanced Quantum-Inspired Swarm Optimization with adaptive mutation range and diversified exploration strategy.", "code": "import numpy as np\n\nclass AdvancedQuantumInspiredSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = 50\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = personal_best_scores[global_best_index]\n\n        eval_count = population_size\n\n        # Adaptive parameters\n        w_max, w_min = 0.9, 0.3\n        c1, c2 = 2.0, 2.0\n        CR = 0.95  # Adjusted crossover rate for refinement\n\n        elite_fraction = 0.1\n        elite_count = max(1, int(elite_fraction * population_size))\n\n        cov_matrix = np.eye(self.dim)\n\n        while eval_count < self.budget:\n            # Linearly reduce inertia weight\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))\n            c1_adaptive = c1 * (1 - (eval_count / self.budget)**2)\n            c2_adaptive = c2 * ((eval_count / self.budget)**2)\n\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities + \n                          c1_adaptive * r1 * (personal_best_positions - swarm) + \n                          c2_adaptive * r2 * (global_best_position - swarm))\n            swarm += velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            elite_fraction = 0.1 + 0.15 * (1 - (global_best_score / max(personal_best_scores)))\n            elite_count = max(1, int(elite_fraction * population_size))\n\n            sigma = 0.1 + 0.05 * (1 - (eval_count / self.budget))  # Adaptive mutation range\n            quantum_positions = global_best_position + sigma * np.random.standard_normal((population_size, self.dim))\n            quantum_positions = np.clip(quantum_positions, lb, ub)\n\n            for i in range(population_size):\n                if i >= elite_count:\n                    candidates = list(range(population_size))\n                    candidates.remove(i)\n\n                    elite_positions = swarm[:elite_count]\n                    elite_mean = np.mean(elite_positions, axis=0)\n                    global_influence = global_best_position + np.random.multivariate_normal(np.zeros(self.dim), cov_matrix)\n                    mutant = (elite_mean + global_influence + swarm[i]) / 3\n                    mutant = np.clip(mutant, lb, ub)\n\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, swarm[i])\n\n                    quantum_trial = np.where(np.random.rand(self.dim) < 0.5, trial, quantum_positions[i])\n\n                    f_trial = func(quantum_trial)\n                    eval_count += 1\n\n                    if f_trial < personal_best_scores[i]:\n                        personal_best_positions[i] = quantum_trial\n                        personal_best_scores[i] = f_trial\n                        if f_trial < global_best_score:\n                            global_best_position = quantum_trial\n                            global_best_score = f_trial\n\n                    if eval_count >= self.budget:\n                        break\n\n            cov_matrix = 0.85 * cov_matrix + 0.15 * np.cov(swarm.T)  # Adjusted adaptation rate\n\n        return {'best_position': global_best_position, 'best_score': global_best_score}", "configspace": "", "generation": 99, "feedback": "The algorithm AdvancedQuantumInspiredSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09186 with standard deviation 0.00050.", "error": "", "parent_ids": ["44080dd8-48f9-430b-a058-14262df61ea8"], "operator": null, "metadata": {"aucs": [0.09219553866330743, 0.0922306096090163, 0.09115190807111107]}}
