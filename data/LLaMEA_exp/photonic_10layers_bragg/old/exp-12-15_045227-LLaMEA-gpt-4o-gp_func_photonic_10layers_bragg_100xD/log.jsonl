{"id": "a90d489f-5237-4113-aca3-50a5fc79fd36", "fitness": 0.07008784676340722, "name": "HybridDEPSO", "description": "A hybrid metaheuristic algorithm combining Differential Evolution and Particle Swarm Optimization to balance exploration and exploitation in black-box optimization tasks.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n        return global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07009 with standard deviation 0.00394.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06674854508014694, 0.06790200987964001, 0.0756129853304347]}}
{"id": "5fc488c3-a9a9-4afb-bf25-a31002106d99", "fitness": 0.0701233372423438, "name": "HybridDEPSO", "description": "An enhanced hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with adaptive control parameters for improved exploration and exploitation in black-box optimization tasks.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n\n        return global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07012 with standard deviation 0.00392.", "error": "", "parent_ids": ["a90d489f-5237-4113-aca3-50a5fc79fd36"], "operator": null, "metadata": {"aucs": [0.06674854508014694, 0.06800316489214275, 0.07561830175474171]}}
{"id": "3f934429-1af2-4ed0-bcef-c39f3ba62672", "fitness": 0.0694729523111914, "name": "AdaptiveHybridDEPSO", "description": "An enhanced hybrid algorithm that integrates Adaptive Differential Evolution and Particle Swarm Optimization with dynamically adjusted parameters for effective balance between exploration and exploitation in black-box optimization tasks.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.mutation_adaptive_rate = 0.9  # Adaptive rate for mutation factor\n        self.crossover_adaptive_rate = 0.95  # Adaptive rate for crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Dynamic adjustments\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor *= self.mutation_adaptive_rate\n            self.crossover_prob *= self.crossover_adaptive_rate\n\n        return global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06947 with standard deviation 0.00162.", "error": "", "parent_ids": ["5fc488c3-a9a9-4afb-bf25-a31002106d99"], "operator": null, "metadata": {"aucs": [0.07150761639841807, 0.06937599036133812, 0.067535250173818]}}
{"id": "337a5cb3-bbcb-4ca6-80e0-4f8d335b33ec", "fitness": 0.0633715897802571, "name": "HybridDEPSO", "description": "Improving HybridDEPSO by introducing a dynamic crossover probability and a more effective velocity adjustment for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n        self.init_crossover_prob = 0.9  # New initial crossover probability\n        self.final_crossover_prob = 0.5  # New final crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            crossover_prob = self.init_crossover_prob - \\\n                             (self.init_crossover_prob - self.final_crossover_prob) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= np.tanh(np.linalg.norm(velocities, axis=1)).reshape(-1, 1)  # New velocity adjustment\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n\n        return global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06337 with standard deviation 0.00570.", "error": "", "parent_ids": ["5fc488c3-a9a9-4afb-bf25-a31002106d99"], "operator": null, "metadata": {"aucs": [0.07085388516797253, 0.05703064168691607, 0.062230242485882714]}}
{"id": "07e16fc5-2b59-4719-9222-07a3bf0a3fd4", "fitness": 0.0738395931977105, "name": "HybridDEPSO", "description": "An improved hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with a nonlinear inertia weight decay and adaptive mutation factor for enhanced convergence in black-box optimization tasks.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count)  # Nonlinear adaptation\n\n        return global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07384 with standard deviation 0.00835.", "error": "", "parent_ids": ["5fc488c3-a9a9-4afb-bf25-a31002106d99"], "operator": null, "metadata": {"aucs": [0.06788738141418915, 0.06798343492803993, 0.0856479632509024]}}
{"id": "12be563d-39a1-4bd0-9672-2c8ab83f90bd", "fitness": 0.07295861443370011, "name": "HybridDEPSO", "description": "A refined hybrid algorithm that enhances convergence by introducing adaptive parameters for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Changed for better initial exploration\n        self.cognitive_coeff = 1.7  # Slightly increased to improve personal influence\n        self.social_coeff = 1.3  # Slightly decreased to balance global influence\n        self.decay_rate = 0.98  # Adjusted decay rate for smoother transitions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.4 * np.sin(0.1 * eval_count)  # Adjusted adaptation\n\n        return global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07296 with standard deviation 0.00494.", "error": "", "parent_ids": ["07e16fc5-2b59-4719-9222-07a3bf0a3fd4"], "operator": null, "metadata": {"aucs": [0.06998554790645584, 0.06896724387779996, 0.07992305151684453]}}
{"id": "0be5a4cb-c43f-472c-bf9c-91ccd4399781", "fitness": 0.07156552028591216, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO: A refined hybrid algorithm integrating Differential Evolution, Particle Swarm Optimization, adaptive learning rates, and nonlinear components for superior convergence in diverse black-box optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.learning_rate = 0.05  # New adaptive learning rate\n        self.diversity_factor = 0.1  # New component for maintaining diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                \n                # Adding diversity-based exploration\n                diversity_term = self.diversity_factor * np.random.uniform(-1, 1, self.dim)\n                trial_vector += diversity_term\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += self.learning_rate * velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07157 with standard deviation 0.00335.", "error": "", "parent_ids": ["07e16fc5-2b59-4719-9222-07a3bf0a3fd4"], "operator": null, "metadata": {"aucs": [0.06913736715052976, 0.06926202780848834, 0.07629716589871838]}}
{"id": "1167ea8b-ca74-4dae-b271-00e7fa4ac34b", "fitness": 0.07514113114388754, "name": "HybridDEPSO", "description": "Enhanced DE-PSO hybrid with chaotic mapping for mutation factor adaptation and dynamic crossover for improved exploration.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count))  # Dynamic crossover\n\n        return global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07514 with standard deviation 0.00263.", "error": "", "parent_ids": ["07e16fc5-2b59-4719-9222-07a3bf0a3fd4"], "operator": null, "metadata": {"aucs": [0.07363427566061997, 0.07884127713180256, 0.07294784063924009]}}
{"id": "a2f38011-bd36-4bc8-93c2-d55d8bc88408", "fitness": 0.07746228737841328, "name": "HybridDEPSO", "description": "Enhanced DE-PSO hybrid with adaptive mutation factor using a logistic map and improved dynamic crossover strategy for better exploration and convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n\n        return global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07746 with standard deviation 0.00355.", "error": "", "parent_ids": ["1167ea8b-ca74-4dae-b271-00e7fa4ac34b"], "operator": null, "metadata": {"aucs": [0.07443038928372026, 0.07551412975991356, 0.08244234309160603]}}
{"id": "fabfd1ed-0734-417f-a98a-ca4971d2dbaf", "fitness": 0.0728353288718514, "name": "HybridDEPSO", "description": "Improved DE-PSO hybrid with adaptive inertia weight and enhanced mutation factor to boost convergence and exploration.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.95  # Increased decay rate for faster adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.6 + 0.3 * np.sin(0.1 * eval_count)  # Adjusted chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n\n        return global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07284 with standard deviation 0.00489.", "error": "", "parent_ids": ["a2f38011-bd36-4bc8-93c2-d55d8bc88408"], "operator": null, "metadata": {"aucs": [0.06769105520184393, 0.07941040947025813, 0.07140452194345215]}}
{"id": "eac023e1-bf1f-4818-802e-af3d46ea976a", "fitness": 0.07536657856547228, "name": "HybridDEPSO", "description": "Enhanced DE-PSO hybrid algorithm with adaptive inertia weight, chaotic mutation factor, and Lévy flights for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / L)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities + self.levy_flight(1.5)  # Added Lévy flight\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n\n        return global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07537 with standard deviation 0.00447.", "error": "", "parent_ids": ["a2f38011-bd36-4bc8-93c2-d55d8bc88408"], "operator": null, "metadata": {"aucs": [0.07008900853178712, 0.07498588444289156, 0.08102484272173816]}}
{"id": "f79c9be4-48e5-4c70-872b-9651f6223547", "fitness": 0.07864924443301465, "name": "HybridDEPSO", "description": "Improved DE-PSO hybrid with adaptive learning rate for cognitive and social coefficients to enhance convergence speed.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07865 with standard deviation 0.00439.", "error": "", "parent_ids": ["a2f38011-bd36-4bc8-93c2-d55d8bc88408"], "operator": null, "metadata": {"aucs": [0.07249829558819643, 0.0810070946192415, 0.08244234309160603]}}
{"id": "c4493e49-e159-499c-b423-5efa9b43188e", "fitness": 0.07691229804758914, "name": "HybridDEPSO", "description": "Enhanced DE-PSO hybrid with adaptive parameters and non-linear mutation factor for improved performance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.tanh(0.01 * eval_count)  # Adjusted with tanh for smoother adaptation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            # Added new line for non-linear inertia weight adjustment\n            self.inertia_weight *= (1 + 0.05 * np.sin(0.1 * eval_count))\n\n        return global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07691 with standard deviation 0.00448.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07147037844878956, 0.07682417260237184, 0.08244234309160603]}}
{"id": "94b640c0-addc-4bb6-a6f0-65f5e3019688", "fitness": 0.0698464151357963, "name": "EnhancedHybridDEPSO", "description": "Enhanced DE-PSO with self-adaptive parameter tuning utilizing agent-specific learning rates and adaptive exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.global_learning_rate = 0.1\n        self.personal_learning_rate = 0.1\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n                # Update velocities with agent-specific learning rates\n                r1, r2 = np.random.rand(2, self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.personal_learning_rate * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.global_learning_rate * r2 * (global_best_position - population[i]))\n                velocities[i] = np.clip(velocities[i], lb - population[i], ub - population[i])\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.9 - 0.5 * np.sin(0.1 * eval_count)  # Adaptive mutation adjustment\n            self.crossover_prob *= (1.0 - 0.01 * eval_count / self.budget)  # Adaptive crossover probability\n            self.global_learning_rate = 0.1 + 0.1 * np.sin(0.05 * eval_count)  # Modify global influence dynamically\n            self.personal_learning_rate = 0.1 + 0.1 * np.cos(0.05 * eval_count)  # Modify personal influence dynamically\n\n        return global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06985 with standard deviation 0.00210.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07184873333993425, 0.07075113836512847, 0.06693937370232617]}}
{"id": "8d61bc83-15b6-44d3-94b1-945cdf161411", "fitness": -Infinity, "name": "HybridDEPSO", "description": "Introduce a dynamic population size adjustment mechanism to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Dynamic population size adjustment\n            self.population_size = max(5, int(10 * self.dim * (0.5 + 0.5 * np.sin(0.01 * eval_count))))\n            population = population[:self.population_size]\n            velocities = velocities[:self.population_size]\n            personal_best_positions = personal_best_positions[:self.population_size]\n            personal_best_scores = personal_best_scores[:self.population_size]\n\n        return global_best_position", "configspace": "", "generation": 14, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {}}
{"id": "5a00cfef-3905-4e2d-81af-6ca688ea7d53", "fitness": 0.07807135743753812, "name": "HybridDEPSO", "description": "Fine-tuned chaotic adaptation in HybridDEPSO for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor * 0.9)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07807 with standard deviation 0.00510.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07130655735163682, 0.07928388133765651, 0.08362363362332104]}}
{"id": "e36f302d-28a8-41e9-9b09-d3b9681adf27", "fitness": 0.07132903028375304, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO integrating a chaotic search phase and adaptive neighborhood influence to improve exploration and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.chaotic_sequence = np.random.rand(self.population_size)\n        self.neighborhood_radius = dim * 0.1  # Adaptive neighborhood radius\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            # Chaotic search phase\n            self.chaotic_sequence = 4 * self.chaotic_sequence * (1 - self.chaotic_sequence)\n            chaotic_indexes = (self.chaotic_sequence * self.population_size).astype(int)\n            chaotic_positions = population[chaotic_indexes]\n            chaotic_scores = np.array([func(ind) for ind in chaotic_positions])\n            eval_count += self.population_size\n\n            for idx, score in enumerate(chaotic_scores):\n                if score < personal_best_scores[chaotic_indexes[idx]]:\n                    personal_best_scores[chaotic_indexes[idx]] = score\n                    personal_best_positions[chaotic_indexes[idx]] = chaotic_positions[idx]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Adaptive neighborhood influence\n            for i in range(self.population_size):\n                neighbors = np.linalg.norm(population - population[i], axis=1) < self.neighborhood_radius\n                neighborhood_best_idx = np.argmin(personal_best_scores[neighbors])\n                if personal_best_scores[neighbors][neighborhood_best_idx] < personal_best_scores[i]:\n                    population[i] = personal_best_positions[neighbors][neighborhood_best_idx]\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07133 with standard deviation 0.00446.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07260742477322024, 0.06533507467071309, 0.07604459140732578]}}
{"id": "54085e88-732c-4b72-94b7-2703504204ce", "fitness": 0.07255503779455279, "name": "EnhancedChaoticHybridDEPSO", "description": "Enhanced Chaotic HybridDEPSO with adaptive escape mechanisms and improved chaotic dynamics for diversified exploration and faster convergence.", "code": "import numpy as np\n\nclass EnhancedChaoticHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # Adaptive parameter for inertia weight\n        self.escape_velocity_factor = 1.2  # New parameter for escaping local optima\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Chaotic adaptation for mutation and crossover\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count)\n            self.mutation_factor *= self.escape_velocity_factor * (3.9 * self.mutation_factor * (1 - self.mutation_factor))\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n\n            # Adaptive learning rates\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            self.inertia_weight *= self.decay_rate\n\n            # Escape mechanism for better exploration\n            if np.random.rand() < 0.05:\n                worst_idx = np.argmax(personal_best_scores)\n                velocities[worst_idx] *= self.escape_velocity_factor\n                population[worst_idx] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedChaoticHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07256 with standard deviation 0.00192.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07073924111952601, 0.07170949173188856, 0.07521638053224378]}}
{"id": "9eb5ffaa-925e-45a8-b628-78fc973c365e", "fitness": 0.07864924442319587, "name": "HybridDEPSO", "description": "Enhanced DE-PSO with adaptive mutation and selective pressure mechanism for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate with selective pressure\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            selective_pressure = 0.7 + 0.3 * np.tanh(0.05 * eval_count)  # New line for selective pressure\n            self.social_coeff *= selective_pressure  # Apply selective pressure to social learning\n\n        return global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07865 with standard deviation 0.00439.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07249829555763787, 0.08100709462034372, 0.08244234309160603]}}
{"id": "c5cb7c21-be03-4f27-a359-44ef46976b45", "fitness": 0.0764444136587833, "name": "HybridDEPSO", "description": "Enhanced DE-PSO hybrid with adaptive parameters and chaotic feedback for convergence improvement.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n\n            # Incorporate chaotic feedback for cognitive and social coefficients\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count + np.random.uniform(-0.1, 0.1))\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count + np.random.uniform(-0.1, 0.1))\n\n        return global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07644 with standard deviation 0.00501.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07083332048849589, 0.07550145924294138, 0.08299846124491261]}}
{"id": "6c91d88a-cbd5-42e2-b226-d4eb24556236", "fitness": 0.07201202628641996, "name": "HybridDEPSO", "description": "Enhanced mutation strategy with Gaussian noise for greater exploration and diversity.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c) + np.random.normal(0, 0.1, self.dim)  # Enhanced mutation\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07201 with standard deviation 0.00534.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07800371551745489, 0.0729887720651774, 0.06504359127662762]}}
{"id": "362b0a03-31f4-4eb0-b19d-79c399b94e5c", "fitness": 0.0699534408670841, "name": "HybridDEPSO", "description": "Enhanced global exploration by introducing dynamic mutation factor scaling based on population diversity.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Dynamic mutation factor based on diversity\n            diversity = np.linalg.norm(population - global_best_position) / self.population_size\n            self.mutation_factor *= 1 + 0.1 * diversity\n\n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06995 with standard deviation 0.00303.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.06590455310496801, 0.07075538122527081, 0.0732003882710135]}}
{"id": "e23ff0e9-b280-459d-ad2b-08cbc20622e9", "fitness": 0.06020908249523623, "name": "EnhancedHybridDEPSO", "description": "Enhanced DE-PSO hybrid with adaptive chaotic map integration to improve search exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n\n            # Chaotic adaptation using a Sine map for mutation factor\n            self.mutation_factor = 0.5 + 0.5 * np.abs(np.sin(0.1 * eval_count))\n\n            # Logistic map for crossover probability adaptation\n            mu = 3.9\n            self.crossover_prob = mu * self.crossover_prob * (1 - self.crossover_prob)\n\n            # Adaptive learning rates with chaotic elements\n            self.cognitive_coeff = 2.0 + 0.5 * np.sin(0.05 * eval_count)\n            self.social_coeff = 2.0 + 0.5 * np.cos(0.05 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06021 with standard deviation 0.00125.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.06128917267438305, 0.06088708075118421, 0.058450994060141426]}}
{"id": "c434e6ab-3b4f-498f-b577-d30fc10045b1", "fitness": 0.06962820968861554, "name": "ImprovedHybridDEPSO", "description": "Adaptive DE-PSO hybrid with progressive mutation, dynamic social learning, and chaos-driven crossover for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Progressive Mutation Strategy\n            self.mutation_factor = 0.5 + 0.2 * (1 - eval_count / self.budget)  # Progressive mutation factor decrease\n            \n            # Dynamic social learning\n            if eval_count % int(self.budget / 10) == 0:\n                self.social_coeff += 0.1 * np.random.randn()  # Introduce variance to social coefficient\n\n        return global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm ImprovedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06963 with standard deviation 0.00341.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07326522782959155, 0.06506678714075032, 0.07055261409550473]}}
{"id": "1a74d025-a867-46d0-a178-11fad92d57a3", "fitness": 0.07436935067053929, "name": "HybridDEPSO", "description": "Introduced a stochastic acceleration term in velocity update for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2, r3 = np.random.rand(3, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population) +\n                          0.1 * r3)  # Added stochastic acceleration term\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map adaptation\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07437 with standard deviation 0.00609.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.06965605751450676, 0.07048816542407788, 0.08296382907303324]}}
{"id": "b8b74268-ab6c-4c52-9f59-8dc6c0bda912", "fitness": 0.07599913298219396, "name": "AdvancedHybridDEPSO", "description": "Advanced DE-PSO hybrid with adaptive chaos-based exploration, dynamic strategy parameters, and self-adaptive control to enhance convergence quality and robustness.", "code": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.eval_count = 0\n\n    def adaptive_inertia_weight(self):\n        # Linearly decrease inertia weight\n        return self.final_inertia_weight + (self.initial_inertia_weight - self.final_inertia_weight) * (self.budget - self.eval_count) / self.budget\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        self.eval_count = self.population_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            inertia_weight = self.adaptive_inertia_weight()\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * self.eval_count + 4 * np.random.random())  \n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * self.eval_count + 0.5))\n            \n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * self.eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * self.eval_count)\n\n        return global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07600 with standard deviation 0.00616.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.06766188896967928, 0.07798157836307662, 0.08235393161382598]}}
{"id": "30314c9d-19bb-4322-a2b9-d854618944fe", "fitness": 0.06861508139187444, "name": "HybridDEPSO", "description": "Enhanced HybridDEPSO with adaptive mutation strategy and diversity preservation for improved convergence.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99  # New adaptive parameter for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate  # Adaptive inertia weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + \n                                    4 * np.random.random())  # Chaotic adaptation\n            self.mutation_factor *= np.tanh(eval_count/self.budget)  # Logistic map adaptation # Changed line\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))  # Improved dynamic crossover\n            \n            # Adaptive learning rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Diversity preservation strategy\n            if eval_count % (self.population_size // 2) == 0:  # Changed line\n                unique_population = np.unique(population, axis=0)  # Changed line\n                while len(unique_population) < self.population_size:  # Changed line\n                    new_individual = np.random.uniform(lb, ub, self.dim)  # Changed line\n                    unique_population = np.append(unique_population, [new_individual], axis=0)  # Changed line\n                population = unique_population\n\n        return global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06862 with standard deviation 0.00256.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.07217813289941932, 0.06739244371460984, 0.06627466756159417]}}
{"id": "0d45db92-5a48-4c77-9e1f-9de1595c8ebd", "fitness": 0.06563338972450254, "name": "EnhancedHybridDEPSO", "description": "Enhanced hybrid DE-PSO with adaptive chaotic mutation, inertia weight scheduling, and dynamic crossover to boost exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.inertia_decay = 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight = 0.4 + (0.5 - 0.4) * np.exp(-0.01 * eval_count)\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.pi/4)\n            self.crossover_prob = 0.7 + 0.3 * np.cos(0.1 * eval_count + np.pi/4)\n            self.cognitive_coeff = 2.0 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 2.0 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06563 with standard deviation 0.00150.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.06359295129341647, 0.06614364656591531, 0.06716357131417583]}}
{"id": "af217c8c-b806-4c6e-94c7-bea011ab23b0", "fitness": 0.08135913837035473, "name": "HybridDEPSO", "description": "HybridDEPSO with adaptive mutation strategy and enhanced cooperation by using neighboring best positions.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)  # New: Best neighbor selection\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi))  # New adaptive factor\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)  # New: Adaptive with neighbor\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08136 with standard deviation 0.00381.", "error": "", "parent_ids": ["f79c9be4-48e5-4c70-872b-9651f6223547"], "operator": null, "metadata": {"aucs": [0.0772002208871303, 0.08639829655485165, 0.08047889766908223]}}
{"id": "9d7474c2-5718-4788-bba2-660aba42fdb8", "fitness": 0.08272427736216663, "name": "HybridDEPSO", "description": "Introduced a dynamic crossover probability based on evaluation count to enhance diversity and exploration.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)  # New: Best neighbor selection\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi))  # New adaptive factor\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)  # New: Adaptive with neighbor\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))  # Dynamic crossover probability\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08272 with standard deviation 0.00432.", "error": "", "parent_ids": ["af217c8c-b806-4c6e-94c7-bea011ab23b0"], "operator": null, "metadata": {"aucs": [0.07890013281718034, 0.08876613710059189, 0.08050656216872765]}}
{"id": "136c4c90-7d06-4263-9fa0-bd29f49d3ebe", "fitness": 0.08028959498713006, "name": "HybridDEPSO", "description": "Enhanced exploration by implementing a chaotic map to dynamically adjust the social coefficient.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)  # New: Best neighbor selection\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi))  # New adaptive factor\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)  # New: Adaptive with neighbor\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))  # Dynamic crossover probability\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            z = np.mod(eval_count * 0.1, 2)  # Chaotic map for social coefficient\n            self.social_coeff = 1.5 + 0.5 * np.cos(z * np.pi)\n\n        return global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08029 with standard deviation 0.00589.", "error": "", "parent_ids": ["9d7474c2-5718-4788-bba2-660aba42fdb8"], "operator": null, "metadata": {"aucs": [0.07470241011462786, 0.08843413712168069, 0.07773223772508164]}}
{"id": "95a6c20b-115c-4142-b086-efb2651eeee8", "fitness": 0.08653708871142225, "name": "EnhancedHybridDEPSO", "description": "Introduced a self-adaptive mutation factor and learning rate based on population diversity to improve convergence and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi)) * adaptive_lr\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08654 with standard deviation 0.00118.", "error": "", "parent_ids": ["9d7474c2-5718-4788-bba2-660aba42fdb8"], "operator": null, "metadata": {"aucs": [0.08640636642179456, 0.08804700784995434, 0.08515789186251788]}}
{"id": "ddeaaed9-072d-43fe-a2ee-f5023d8e5740", "fitness": 0.08653708871142225, "name": "EnhancedAdaptiveHybridDEPSO", "description": "Introduced dynamic population size, adaptive exploration-exploitation balance using Q-learning-inspired updates, and diversity-driven parameter tuning for enhanced convergence and stability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 10 * dim)\n        self.min_population_size = max(5, dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            for i in range(population_size):\n                if eval_count >= self.budget:\n                    break\n\n                idxs = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(population_size)\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi)) * adaptive_lr\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Dynamic population adjustment based on diversity\n            if diversity < 0.1:\n                population_size = max(self.min_population_size, population_size - 1)\n            elif diversity > 0.5:\n                population_size = min(self.initial_population_size, population_size + 1)\n\n            # Resize population and velocities\n            population = np.resize(population, (population_size, self.dim))\n            velocities = np.resize(velocities, (population_size, self.dim))\n            personal_best_positions = np.resize(personal_best_positions, (population_size, self.dim))\n            personal_best_scores = np.resize(personal_best_scores, population_size)\n\n        return global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08654 with standard deviation 0.00118.", "error": "", "parent_ids": ["95a6c20b-115c-4142-b086-efb2651eeee8"], "operator": null, "metadata": {"aucs": [0.08640636642179456, 0.08804700784995434, 0.08515789186251788]}}
{"id": "5b044a30-3600-464b-9058-76668169df4b", "fitness": 0.08583141033275536, "name": "ChaosEnhancedHybridDEPSO", "description": "Introduced dynamic chaos-driven coefficients and a diversity-sensitive adaptive mechanism to enhance global exploration and local exploitation.", "code": "import numpy as np\n\nclass ChaosEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi)) * adaptive_lr\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            # Introduce chaos-driven behavior for factors\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4.0 * np.random.random() + diversity)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)  # Logistic map\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count + diversity)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count + diversity)\n\n        return global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm ChaosEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08583 with standard deviation 0.00431.", "error": "", "parent_ids": ["95a6c20b-115c-4142-b086-efb2651eeee8"], "operator": null, "metadata": {"aucs": [0.07978267357429047, 0.08952304492723129, 0.08818851249674431]}}
{"id": "be4bf162-00a2-4c03-8b97-21cae5d85d88", "fitness": 0.08653708871142225, "name": "EnhancedHybridDEPSO", "description": "Enhanced diversity management and dynamic parameter tuning based on swarm entropy to improve exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity_entropy():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            entropy = -np.sum(population * np.log(population + 1e-8), axis=1).mean()\n            return diversity, entropy\n\n        while eval_count < self.budget:\n            diversity, entropy = update_diversity_entropy()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity + entropy)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                neighbor_idx = np.random.choice(self.population_size)\n                neighbor_best = personal_best_positions[neighbor_idx]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                adaptive_mutation_factor = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi)) * adaptive_lr\n                mutant_vector = neighbor_best + adaptive_mutation_factor * (mutant_vector - neighbor_best)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + 4 * np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + 0.5) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08654 with standard deviation 0.00118.", "error": "", "parent_ids": ["95a6c20b-115c-4142-b086-efb2651eeee8"], "operator": null, "metadata": {"aucs": [0.08640636642179456, 0.08804700784995434, 0.08515789186251788]}}
{"id": "951e9ced-84bb-434f-a38a-315ba8e2808e", "fitness": 0.0891080326623983, "name": "EnhancedHybridDEPSOPlusPlus", "description": "EnhancedHybridDEPSO++ incorporates adaptive learning rates and differential evolution strategies with chaos-driven mutation and crossover dynamics for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08911 with standard deviation 0.00180.", "error": "", "parent_ids": ["95a6c20b-115c-4142-b086-efb2651eeee8"], "operator": null, "metadata": {"aucs": [0.0904503200055814, 0.08656299546405388, 0.09031078251755964]}}
{"id": "df389d40-2c8d-494d-a2ed-6a873700edbd", "fitness": 0.08688421708719525, "name": "EnhancedAdaptiveDEPSOPlusPlus", "description": "EnhancedAdaptiveDEPSO++ leverages dynamic parameter tuning with a memory-based chaotic system and stochastic learning for heightened balance in exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        chaos_memory = np.random.rand(self.population_size)\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count)) + chaos_memory[i]\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n                    chaos_memory[i] = chaotic_factor\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08688 with standard deviation 0.00281.", "error": "", "parent_ids": ["951e9ced-84bb-434f-a38a-315ba8e2808e"], "operator": null, "metadata": {"aucs": [0.0837719389023781, 0.0862920088915512, 0.09058870346765646]}}
{"id": "1451a5bc-b19e-4f77-83b3-92cc36be05b0", "fitness": 0.0863185134311842, "name": "AdaptiveQuantumInspiredDEPSOPlusPlus", "description": "Adaptive Quantum-Inspired DEPSO++ employs quantum-inspired superposition for diversified exploration, enhanced with dynamic parameter control for improved balance in complex landscapes.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        def quantum_superposition(factor, pos):\n            # Quantum-inspired superposition mechanism\n            return pos + factor * np.random.uniform(-1, 1, self.dim)\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = quantum_superposition(adaptive_lr, np.copy(population[i]))\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveQuantumInspiredDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08632 with standard deviation 0.00444.", "error": "", "parent_ids": ["951e9ced-84bb-434f-a38a-315ba8e2808e"], "operator": null, "metadata": {"aucs": [0.08863399200056721, 0.08011067162396157, 0.09021087666902383]}}
{"id": "6b64ba7b-db27-4bfc-905f-faaa41144500", "fitness": 0.08573801382334774, "name": "EnhancedHybridDEPSOPlusPlus", "description": "Introduced a cosine function to dynamically adjust the crossover probability for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (0.5 + 0.4 * np.cos(0.1 * eval_count))  # Changed crossover probability\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08574 with standard deviation 0.00147.", "error": "", "parent_ids": ["951e9ced-84bb-434f-a38a-315ba8e2808e"], "operator": null, "metadata": {"aucs": [0.08401981999885233, 0.0876123134739365, 0.0855819079972544]}}
{"id": "2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03", "fitness": 0.09262259138361133, "name": "EnhancedHybridDEPSOPlusPlus", "description": "EnhancedAdaptiveDEPSO++ further refines exploration-exploitation balance with chaotic cognitive dynamics and adaptive velocity scaling.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09262 with standard deviation 0.00079.", "error": "", "parent_ids": ["951e9ced-84bb-434f-a38a-315ba8e2808e"], "operator": null, "metadata": {"aucs": [0.0936695335387695, 0.09177103939760933, 0.09242720121445513]}}
{"id": "46d53824-5d65-4de2-96da-b51751c7b9a3", "fitness": 0.09262259138361133, "name": "EnhancedHybridDEPSOPlusPlus", "description": "Improved exploration-exploitation by introducing memory-based guided search and adaptive diversity control.  ", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.diversity_threshold = 1e-5  # New line: Introduces a threshold for diversity control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            if diversity < self.diversity_threshold:  # New line: Adaptive mechanism based on diversity\n                self.crossover_prob = 0.9  # New line: Increase crossover probability if diversity is low\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09262 with standard deviation 0.00079.", "error": "", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {"aucs": [0.0936695335387695, 0.09177103939760933, 0.09242720121445513]}}
{"id": "9fbddb97-a12f-44c2-b6cd-eb9800206140", "fitness": 0.08786482147209562, "name": "QuantumInspiredDEPSO", "description": "Integrate quantum-inspired dynamics with dynamic landscape adaptation to enhance convergence by dynamically altering search behavior based on fitness landscape variations.", "code": "import numpy as np\n\nclass QuantumInspiredDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            quantum_prob = np.random.rand() * (1 - diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Quantum-inspired dynamic adaptation\n            if quantum_prob < 0.3:\n                self.mutation_factor *= np.random.rand()\n                self.crossover_prob *= np.random.rand()\n                self.cognitive_coeff *= np.random.rand()\n                self.social_coeff *= np.random.rand()\n\n        return global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm QuantumInspiredDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08786 with standard deviation 0.00176.", "error": "", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {"aucs": [0.08609973146763017, 0.087227989991564, 0.0902667429570927]}}
{"id": "c74e2c68-5202-4b19-89a4-b2dffa2d363c", "fitness": 0.0877791166840692, "name": "EnhancedHybridDEPSOPlusPlus", "description": "Adaptive Dynamic DEPSO++ optimizes exploration-exploitation with Fisher-Yates shuffling in mutation and time-variant crossover targeting.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                np.random.shuffle(idxs)  # Fisher-Yates shuffle for mutation\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + (0.1 * np.sin(eval_count)))  # Time-variant crossover\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08778 with standard deviation 0.00518.", "error": "", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {"aucs": [0.0805010013979931, 0.09066627007249928, 0.09217007858171522]}}
{"id": "309a13ba-977c-4d06-8b22-0cb323c81c44", "fitness": 0.09169795058163706, "name": "EnhancedHybridDEPSOPlusPlus", "description": "Enhance global best selection with chaotic influence for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            \n            global_best_position += chaotic_factor * (population[global_best_idx] - global_best_position)  # Chaotic influence\n\n        return global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09170 with standard deviation 0.00117.", "error": "", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {"aucs": [0.09333552138970391, 0.09065770619278968, 0.0911006241624176]}}
{"id": "50a48c37-eb25-4e8b-867b-ab5ba78cec1b", "fitness": -Infinity, "name": "RefinedHybridDEPSOPlusPlus", "description": "Introducing dynamic population resizing and adaptive inertia damping to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 10 * dim)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.inertia_decay_rate = 0.995\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = 0.5 * velocities  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Dynamic population resizing\n            if eval_count / self.budget > 0.5 and self.population_size > self.initial_population_size // 2:\n                self.population_size = max(self.initial_population_size // 2, self.population_size - 1)\n\n            # Adaptive inertia damping\n            self.inertia_weight *= self.inertia_decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 44, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (99,10) (100,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (99,10) (100,10) ')", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {}}
{"id": "8ec9ef40-eacd-42f3-948f-8b1dbcc45ee4", "fitness": 0.09266821966705645, "name": "EnhancedHybridDEPSOPlusPlus", "description": "EnhancedHybridDEPSOPlusPlus with dynamic mutation factor and improved chaotic cognitive dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)  # Improved chaotic cognitive dynamics\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor  # Chaotic cognitive dynamics\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09267 with standard deviation 0.00076.", "error": "", "parent_ids": ["2b34e4e3-c2c1-488a-b3bd-d39a2f43fc03"], "operator": null, "metadata": {"aucs": [0.09365022600332595, 0.0917886665945905, 0.09256576640325287]}}
{"id": "4d3d9968-39dc-468d-bf7f-5f8bccf01fc3", "fitness": 0.0855173107261535, "name": "EnhancedHybridDEPSOPlusPlus", "description": "EnhancedHybridDEPSOPlusPlus with selective crossover and improved adaptive velocity scaling.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                if np.random.rand() < (0.5 + 0.5 * chaotic_factor):  # Selective crossover\n                    crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                    trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.4 + 0.1 * chaotic_factor  # Improved adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08552 with standard deviation 0.00210.", "error": "", "parent_ids": ["8ec9ef40-eacd-42f3-948f-8b1dbcc45ee4"], "operator": null, "metadata": {"aucs": [0.08261279255325493, 0.08747963447103946, 0.08645950515416612]}}
{"id": "19867ccd-740d-45e2-81ad-db7497f629a8", "fitness": 0.09215397733593067, "name": "EnhancedHybridDEPSOPlusPlus", "description": "EnhancedHybridDEPSOPlusPlus with stochastic diffusion and adaptive inertia for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.sigma = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n                mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5  # Adaptive velocity scaling\n            velocities = np.clip(velocities, lb - population, ub - population)\n            stochastic_diffusion = np.random.normal(0, self.sigma, (self.population_size, self.dim))\n            population += velocities + stochastic_diffusion\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight = 0.7 * (1 - eval_count / self.budget) + 0.3 * self.inertia_weight\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09215 with standard deviation 0.00120.", "error": "", "parent_ids": ["8ec9ef40-eacd-42f3-948f-8b1dbcc45ee4"], "operator": null, "metadata": {"aucs": [0.0933631699900328, 0.09052343686736664, 0.09257532515039257]}}
{"id": "82a18d1a-5cd1-458f-8e91-8dbf945b7bcf", "fitness": 0.09284403815669058, "name": "EnhancedHybridDEPSOPlusPlusV2", "description": "Introducing adaptive multi-phase search with chaotic learning and dynamic parameter adjustments to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09284 with standard deviation 0.00030.", "error": "", "parent_ids": ["8ec9ef40-eacd-42f3-948f-8b1dbcc45ee4"], "operator": null, "metadata": {"aucs": [0.09280468724471524, 0.0932267992042316, 0.09250062802112491]}}
{"id": "797c6c3d-3e55-47ff-8488-c76378df8f35", "fitness": 0.09206281382106263, "name": "EnhancedHybridDEPSOPlusPlusV3", "description": "Introducing a self-adaptive diversity maintenance mechanism with stochastic perturbations to enhance global search and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diversity_threshold = 0.05\n        self.stochastic_perturbation_strength = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < 0.5\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            if diversity < self.diversity_threshold:\n                perturbation = self.stochastic_perturbation_strength * np.random.uniform(-1, 1, (self.population_size, self.dim))\n                population += perturbation\n                population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= 0.99\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09206 with standard deviation 0.00054.", "error": "", "parent_ids": ["82a18d1a-5cd1-458f-8e91-8dbf945b7bcf"], "operator": null, "metadata": {"aucs": [0.09283102014318911, 0.09172569376661988, 0.0916317275533789]}}
{"id": "3a9cf1d1-7ae9-4885-9142-0fb9d0c55ae2", "fitness": 0.0905555587557499, "name": "EnhancedHybridDEPSOPlusPlusV2", "description": "Introducing stochastic rank-based velocity updates and adaptive inertia weight adjustments to enhance convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            ranks = np.argsort(personal_best_scores)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5 * (1 + np.random.rand(self.population_size, 1))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate * (0.9 + 0.1 * np.sin(0.01 * eval_count))\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09056 with standard deviation 0.00154.", "error": "", "parent_ids": ["82a18d1a-5cd1-458f-8e91-8dbf945b7bcf"], "operator": null, "metadata": {"aucs": [0.09249092738732123, 0.09045824447311346, 0.08871750440681503]}}
{"id": "86c63bce-64c6-448e-8d05-509f7eed4655", "fitness": -Infinity, "name": "EnhancedDynamicDEPSO", "description": "Introducing enhanced dynamic parameter adaptation with Lévy flight for exploration and increased convergence speed using an adaptive inertia weight strategy.", "code": "import numpy as np\n\nclass EnhancedDynamicDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def levy_flight(Lambda):\n            sigma = (np.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                     (np.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.randn(self.dim) * sigma\n            v = np.random.randn(self.dim)\n            step = u / np.abs(v) ** (1 / Lambda)\n            return step\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0) + 0.01 * levy_flight(1.5)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= 0.9\n            self.mutation_factor = 0.8 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.7 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 51, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["82a18d1a-5cd1-458f-8e91-8dbf945b7bcf"], "operator": null, "metadata": {}}
{"id": "c9382c3a-d652-453b-a40d-303597aa09fa", "fitness": -Infinity, "name": "EnhancedHybridDEPSOPlusPlusV3", "description": "Introducing enhanced adaptive strategies with multi-modal learning influenced by Lévy flight for improved exploration and convergence.", "code": "import numpy as np\nimport scipy.stats\n\nclass EnhancedHybridDEPSOPlusPlusV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        def levy_flight(Lambda=1.5):\n            sigma = (scipy.stats.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                     (scipy.stats.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.normal(0, sigma, size=self.dim)\n            v = np.random.normal(0, 1, size=self.dim)\n            step = u / (abs(v) ** (1 / Lambda))\n            return step\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    levy_step = levy_flight()\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * (np.mean(population, axis=0) + levy_step)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 52, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for *: 'rv_continuous_frozen' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for *: 'rv_continuous_frozen' and 'float'\")", "parent_ids": ["82a18d1a-5cd1-458f-8e91-8dbf945b7bcf"], "operator": null, "metadata": {}}
{"id": "318400d2-e958-4ee4-982c-c20dd91c0e99", "fitness": 0.09363453477528157, "name": "EnhancedHybridDEPSOPlusPlusV2", "description": "Enhanced adaptive mutation and crossover strategies for better convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)  # Adjusted crossover probability\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09363 with standard deviation 0.00036.", "error": "", "parent_ids": ["82a18d1a-5cd1-458f-8e91-8dbf945b7bcf"], "operator": null, "metadata": {"aucs": [0.0932617769799966, 0.09352245769839551, 0.0941193696474526]}}
{"id": "bb2373ae-d7ae-4c4f-bc40-835149999bab", "fitness": -Infinity, "name": "EnhancedHybridDEPSOPlusPlusV3", "description": "Introducing adaptive population dynamics and dual mutation strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 10 * dim)\n        self.max_population_size = self.initial_population_size * 2\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.exploration_exploitation_ratio = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n\n            phase_switch = eval_count / self.budget\n            is_exploration_phase = phase_switch < self.exploration_exploitation_ratio\n\n            for i in range(population_size):\n                idxs = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector1 = a + self.mutation_factor * (b - c)\n                mutant_vector2 = global_best_position + self.mutation_factor * (a - b)\n                mutant_vector = (mutant_vector1 + mutant_vector2) / 2\n                chaotic_factor = np.sin(0.9 * (i + eval_count))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_factor * adaptive_lr\n\n                if is_exploration_phase:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + np.random.random())\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            chaotic_factor += 0.1 * np.sin(0.05 * eval_count)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            \n            # Adaptive population size adjustment\n            if eval_count < self.budget * 0.5:\n                population_size = min(self.max_population_size, int(self.initial_population_size * (1 + phase_switch)))\n            else:\n                population_size = self.initial_population_size\n\n        return global_best_position", "configspace": "", "generation": 54, "feedback": "An exception occurred: IndexError('index 105 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 105 is out of bounds for axis 0 with size 100')", "parent_ids": ["318400d2-e958-4ee4-982c-c20dd91c0e99"], "operator": null, "metadata": {}}
{"id": "a698ec61-f6a6-4e0e-87bb-17206d77f9b3", "fitness": 0.09389787249701538, "name": "EnhancedHybridDEPSOPlusPlusV3", "description": "Introducing a multi-phase adaptive learning rate and chaotic perturbation to enhance exploration-exploitation balance and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                # New adaptive mutation strategy\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09390 with standard deviation 0.00050.", "error": "", "parent_ids": ["318400d2-e958-4ee4-982c-c20dd91c0e99"], "operator": null, "metadata": {"aucs": [0.09350948958319405, 0.09357446970819006, 0.09460965819966205]}}
{"id": "771b4d1c-d0d5-43ac-b227-be678ad11536", "fitness": 0.09327620850790326, "name": "EnhancedHybridDEPSOPlusPlusV4", "description": "Introducing stochastic parameter tuning and enhanced chaotic exploration to balance global and local search.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                # New adaptive mutation strategy\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.random.rand() * chaotic_perturbation\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.cos(0.05 * eval_count) + np.random.rand())\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09328 with standard deviation 0.00086.", "error": "", "parent_ids": ["a698ec61-f6a6-4e0e-87bb-17206d77f9b3"], "operator": null, "metadata": {"aucs": [0.09295378764694018, 0.09242328520478682, 0.0944515526719828]}}
{"id": "6e80edc0-9ee6-47df-8962-5689279ca0c7", "fitness": 0.08126678906226766, "name": "EnhancedHybridDEPSOPlusPlusV3", "description": "Integrate adaptive inertia and dual chaotic perturbation to enhance convergence stability and precision.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                # New adaptive mutation strategy\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5 * chaotic_perturbation  # Line change 1\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate * (1 + chaotic_perturbation)  # Line change 2\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count) * chaotic_perturbation  # Line change 3\n\n        return global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08127 with standard deviation 0.00075.", "error": "", "parent_ids": ["a698ec61-f6a6-4e0e-87bb-17206d77f9b3"], "operator": null, "metadata": {"aucs": [0.08175433377636854, 0.08021076753741485, 0.08183526587301959]}}
{"id": "3df11efd-5860-42e1-a238-affe51377bcc", "fitness": 0.0938412221150788, "name": "EnhancedHybridDEPSOPlusPlusV4", "description": "Enhancing convergence and exploration by integrating a dynamic chaos-based mutation factor and adaptive search space scaling for improved optimization performance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOPlusPlusV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation) * (1 - eval_count / self.budget)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridDEPSOPlusPlusV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09384 with standard deviation 0.00045.", "error": "", "parent_ids": ["a698ec61-f6a6-4e0e-87bb-17206d77f9b3"], "operator": null, "metadata": {"aucs": [0.093498473384938, 0.0935551058396702, 0.09447008712062821]}}
{"id": "3a3e8b2a-5fdf-4cb7-b64c-e015375c8fa3", "fitness": 0.09375264129269674, "name": "QuantumEnhancedHybridDEPSO", "description": "Integrating quantum-inspired crossover and adaptive inertia weight mechanisms to further boost exploration and convergence efficiency.", "code": "import numpy as np\n\nclass QuantumEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.4 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                \n                # Quantum-inspired crossover\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + np.abs(np.sin(eval_count / 10)))\n                \n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * self.decay_rate)\n\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm QuantumEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09375 with standard deviation 0.00109.", "error": "", "parent_ids": ["a698ec61-f6a6-4e0e-87bb-17206d77f9b3"], "operator": null, "metadata": {"aucs": [0.094050548110854, 0.09229307394795172, 0.09491430181928451]}}
{"id": "e3f75c48-70b7-4c4e-a335-6e00f0a4d764", "fitness": 0.09389887739677723, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Leverage adaptive diversity control and swarm intelligence with a phase-driven exploration-exploitation strategy to enhance optimization efficiency.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09390 with standard deviation 0.00051.", "error": "", "parent_ids": ["a698ec61-f6a6-4e0e-87bb-17206d77f9b3"], "operator": null, "metadata": {"aucs": [0.09350247145821933, 0.09357822535864435, 0.09461593537346802]}}
{"id": "a2bb05bd-560d-4050-8019-09adc38b42ec", "fitness": 0.09389887739677723, "name": "EnhancedSwarmOptimizer", "description": "Integrate self-adaptive multiple swarm dynamics and chaotic local search to enhance exploration-exploitation balance for better optimization performance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09390 with standard deviation 0.00051.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09350247145821933, 0.09357822535864435, 0.09461593537346802]}}
{"id": "a8499159-839f-4b5d-b5d6-1af7059e348f", "fitness": 0.09316379368364332, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance swarm intelligence by integrating adaptive chaotic perturbations and refined exploration-exploitation dynamics for improved convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    chaotic_factor = np.sin(1.0 * eval_count) * adaptive_lr  # Changed line\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + chaotic_factor)  # Changed line\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.4 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)  # Changed line\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor * 0.9)  # Changed line\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.02 * eval_count) * chaotic_perturbation  # Changed line\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.02 * eval_count)  # Changed line\n\n        return global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09316 with standard deviation 0.00087.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09334402797977426, 0.09201803413275922, 0.09412931893839649]}}
{"id": "370c9858-9c82-4a28-add7-df833391c52d", "fitness": 0.09184436687930893, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance optimization efficiency by integrating adaptive population dynamics and chaotic perturbations with a nuanced exploration-exploitation balance to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.6\n        self.decay_rate = 0.98\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        self.eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while self.eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * self.eval_count) * (1.0 / (1.0 + self.eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - self.eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor *= 1.0 + 0.1 * np.sin(0.1 * self.eval_count + chaotic_perturbation)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * self.eval_count + np.pi) + np.cos(0.05 * self.eval_count))\n            self.cognitive_coeff = 1.4 + 0.5 * np.sin(0.01 * self.eval_count) * chaotic_perturbation\n            self.social_coeff = 1.6 + 0.5 * np.cos(0.01 * self.eval_count)\n\n        return global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09184 with standard deviation 0.00067.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09215500231660845, 0.09091000758582035, 0.092468090735498]}}
{"id": "dc762f70-ae54-4d91-8791-37db3c5b169f", "fitness": 0.08804122704124222, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance solution precision by integrating local search in elite members and dynamic crossover probability adjustment.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            elite_threshold = int(self.population_size * 0.2)\n            elite_indices = np.argsort(personal_best_scores)[:elite_threshold]\n\n            for i in elite_indices:\n                local_search_vector = np.random.normal(population[i], 0.01, self.dim)\n                local_search_vector = np.clip(local_search_vector, lb, ub)\n                local_search_score = func(local_search_vector)\n                eval_count += 1\n                if local_search_score < personal_best_scores[i]:\n                    personal_best_scores[i] = local_search_score\n                    personal_best_positions[i] = local_search_vector\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * np.cos(eval_count / self.budget * np.pi))\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 64, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08804 with standard deviation 0.00446.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.08937726845245497, 0.08203028318511985, 0.09271612948615182]}}
{"id": "f7d971ef-83b5-4652-9f25-597ec150945a", "fitness": 0.09384269155464238, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Slightly enhance cognitive and social coefficients for improved swarm intelligence and convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.6  # Slight adjustment\n        self.social_coeff = 1.6  # Slight adjustment\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09384 with standard deviation 0.00063.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09354124682420928, 0.09327252955287546, 0.09471429828684241]}}
{"id": "39e5fb56-e265-479d-a71f-bb72a39c5171", "fitness": 0.08706707907486522, "name": "QuantumAdaptiveSwarmOptimizer", "description": "Integrate quantum-inspired mechanisms with adaptive strategies in swarm intelligence to enhance exploration-exploitation balance and optimization performance.", "code": "import numpy as np\n\nclass QuantumAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def quantum_update():\n            quantum_bits = np.random.uniform(0, 1, (self.population_size, self.dim))\n            quantum_position = np.where(quantum_bits < 0.5, lb + (ub - lb) * np.random.rand(), global_best_position)\n            return quantum_position\n\n        while eval_count < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            quantum_position = quantum_update()\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * quantum_position[i]\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm QuantumAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08707 with standard deviation 0.00572.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09018447234737792, 0.07904236028137313, 0.0919744045958446]}}
{"id": "6458f67d-67a5-4f4a-b3ce-6f49a95762a8", "fitness": 0.07449044692633289, "name": "EnhancedSwarmOptimizer", "description": "Introduce dynamic particle interaction and adaptive inertia to enhance global exploration and convergence efficiency in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Initial higher inertia weight for enhanced exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.inertia_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.8 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_lr) * mutant_vector + adaptive_lr * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_lr) * mutant_vector + adaptive_lr * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update dynamic components\n            self.inertia_weight *= self.inertia_decay\n            self.mutation_factor = 0.5 + 0.3 * chaotic_perturbation\n            self.crossover_prob = 0.6 + 0.3 * np.abs(np.sin(0.05 * eval_count))\n\n        return global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07449 with standard deviation 0.00235.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.07430891640209725, 0.07170987018131258, 0.07745255419558883]}}
{"id": "19ca3476-2bbb-472d-89da-9777f7b17c34", "fitness": -Infinity, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Incorporate dynamic population adjustment and enhanced chaotic perturbation to bolster exploration and convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(1.2 * eval_count) * (1.0 / (1.0 + eval_count))  # Adjusted\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            if eval_count % 50 == 0:  # New population adjustment strategy\n                self.population_size = max(5, int(self.population_size * 0.95))\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n        return global_best_position", "configspace": "", "generation": 68, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (100,10) (95,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (100,10) (95,10) ')", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {}}
{"id": "35de7d83-e26a-450f-aa8e-5003c4f2e503", "fitness": 0.09330948433938802, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing adaptive velocity clamping and refined mutation factor dynamics.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocity_clamp = 0.1 + 0.4 * np.abs(np.sin(0.01 * eval_count))  # Adjust the magnitude of velocities\n            velocities = np.clip(velocities * velocity_clamp, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation) * 1.1  # Slightly adjusted mutation dynamics\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09331 with standard deviation 0.00098.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09196029765012825, 0.09371060800568187, 0.09425754736235392]}}
{"id": "81bc31f7-a5e1-49cc-84be-9d6b7a734dda", "fitness": 0.09229691088393244, "name": "EnhancedDynamicSwarmOptimizer", "description": "Utilize dynamic adaptive parameters and directional search adjustments in swarm intelligence to enhance optimization convergence and stability.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 12 * dim)\n        self.mutation_factor = 0.9\n        self.crossover_prob = 0.8\n        self.inertia_weight = 0.6\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.decay_rate = 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.1 + 0.5 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.8 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(10 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.4 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.4\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.6 + 0.4 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.6 + 0.3 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.7 + 0.4 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.7 + 0.4 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09230 with standard deviation 0.00115.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09391798722238587, 0.09151293358079338, 0.09145981184861807]}}
{"id": "bbe2ae51-51b4-4b87-9450-aaaa9606fdb4", "fitness": 0.09388730981575684, "name": "MultiPhaseChaoticSwarmOptimizer", "description": "Integrate a multi-phase learning approach with chaos-enhanced dynamic adaptation and adaptive swarm cohesion to enhance convergence efficiency.", "code": "import numpy as np\n\nclass MultiPhaseChaoticSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.5 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.4 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.4 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm MultiPhaseChaoticSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09389 with standard deviation 0.00064.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09332914051766761, 0.09354623597645917, 0.09478655295314375]}}
{"id": "64dde368-7f77-448c-b6a3-a30e2e5c5d30", "fitness": 0.09383020374366154, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Incorporate adaptive learning rate and chaos to refine exploration-exploitation balance, enhancing convergence speed.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.98  # Modified\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.exp(-diversity)  # Modified\n            chaotic_perturbation = np.sin(0.7 * eval_count) * (1.0 / (1.0 + eval_count))  # Modified\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.55 * (1 + np.tanh(4 * (0.5 - eval_count / self.budget)))  # Modified\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09383 with standard deviation 0.00054.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09346920009727211, 0.09342213315987591, 0.0945992779738366]}}
{"id": "a3c3b79f-ef68-4766-9fa0-34425e28942d", "fitness": 0.09328091364791236, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhanced adaptive swarm optimizer with dynamic inertia weight and self-adaptive exploration-exploitation balance mechanism.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.98  # Adjusted decay rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget))) * diversity # Adjusted balance using diversity\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09328 with standard deviation 0.00034.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09294667133415424, 0.09315466911326875, 0.09374140049631408]}}
{"id": "ef44ef6d-59fd-4dc5-9bee-f0d8f467b81e", "fitness": 0.08756052575305633, "name": "HybridLevySwarmOptimizer", "description": "Introduce a hybrid approach by incorporating Levy flight-based exploration and a dynamic feedback mechanism to adaptively balance exploration and exploitation, enhancing convergence speed and accuracy in optimization.", "code": "import numpy as np\n\nclass HybridLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, size=self.dim)\n            v = np.random.normal(0, sigma2, size=self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return step\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            feedback = 1.0 / (1.0 + np.exp(-10 * (diversity - 0.5)))\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * feedback\n\n                if exploration_exploitation_balance > 0.5:\n                    step = levy_flight(1.5)\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * (population[i] + step)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm HybridLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08756 with standard deviation 0.00256.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.08451816436214732, 0.09077977965715822, 0.08738363323986342]}}
{"id": "d4f9c0cf-9ace-4937-924f-8bf12c54471b", "fitness": 0.09389887739677723, "name": "RefinedAdaptiveSwarmOptimizer", "description": "Integrate adaptive learning rates, chaotic mapping, and dynamic perturbation strategies to enhance exploration-exploitation dynamics in swarm-based optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.2 + 0.3 * np.exp(-diversity)\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.5 + 0.3 * chaotic_perturbation * adaptive_lr\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.1 * eval_count + chaotic_perturbation)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm RefinedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09390 with standard deviation 0.00051.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09350247145821933, 0.09357822535864435, 0.09461593537346802]}}
{"id": "103163ac-a71a-4409-a601-3b659f48f61a", "fitness": 0.09580312355426301, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance exploration-exploitation balance by integrating chaotic dynamics with adaptive learning rate tuning and mutation strategies.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)  # Modified\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)  # Modified\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= 0.5\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.2 * np.sin(chaotic_perturbation * eval_count)  # Modified\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09580 with standard deviation 0.00109.", "error": "", "parent_ids": ["e3f75c48-70b7-4c4e-a335-6e00f0a4d764"], "operator": null, "metadata": {"aucs": [0.09439840100839714, 0.0970522068183296, 0.0959587628360623]}}
{"id": "b9c3090b-b1c4-41a9-bd59-05845897cb8f", "fitness": 0.09605862183668394, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance exploration-exploitation dynamics by incorporating fitness-based adaptive mutation and improved velocity update mechanisms.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)  # Modified\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09606 with standard deviation 0.00098.", "error": "", "parent_ids": ["103163ac-a71a-4409-a601-3b659f48f61a"], "operator": null, "metadata": {"aucs": [0.09483027191767823, 0.09722670438183867, 0.09611888921053491]}}
{"id": "65f809b6-9a34-4899-9937-9671296bc21e", "fitness": 0.09579228986699133, "name": "EnhancedChaoticSwarmOptimizer", "description": "Integrate chaos-induced variance control and adaptive hybridization for enhanced convergence precision.", "code": "import numpy as np\n\nclass EnhancedChaoticSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = 0.7 * np.cos(0.7 * eval_count)\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(personal_best_positions, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * np.tanh(diversity))\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.7 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedChaoticSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09579 with standard deviation 0.00088.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09458961824427481, 0.09610468195141997, 0.0966825694052792]}}
{"id": "bc4f6a10-fccc-49e0-a501-67815a425b65", "fitness": 0.09605862183668394, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Integrate a local search technique and adaptive diversity control to enhance convergence in multi-modal landscapes.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n            \n            # Local search enhancement\n            if eval_count < 0.75 * self.budget and diversity < 0.1:\n                local_search_pos = global_best_position + 0.1 * np.random.standard_normal(self.dim)\n                local_search_pos = np.clip(local_search_pos, lb, ub)\n                local_search_score = func(local_search_pos)\n                eval_count += 1\n                if local_search_score < personal_best_scores[global_best_idx]:\n                    global_best_position = local_search_pos\n\n        return global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09606 with standard deviation 0.00098.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09483027191767823, 0.09722670438183867, 0.09611888921053491]}}
{"id": "27d133a8-2719-407d-975b-4f54ecc45a37", "fitness": 0.08198112913798432, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance exploration-exploitation dynamics by incorporating fitness-based adaptive mutation, improved velocity update mechanisms, and adaptive crossover probability based on diversity.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1) * (1 - diversity)  # Updated\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)  # Modified\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.crossover_prob *= 1.0 - diversity * 0.1  # Updated\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08198 with standard deviation 0.00414.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.08211071047487639, 0.07685197775999264, 0.08698069917908391]}}
{"id": "3a66caf1-7dfb-4d35-aec1-36b870c3a6ac", "fitness": -Infinity, "name": "EnhancedEntropySwarmOptimizer", "description": "Integrate multi-layered adaptive chaos modulation to enhance swarm dynamics by dynamically adjusting exploration and exploitation phases based on entropy-driven diversity control and variable mutation factor.", "code": "import numpy as np\n\nclass EnhancedEntropySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity_entropy():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            prob_dist = np.histogramdd(population, bins=self.dim, range=list(zip(lb, ub)))[0].flatten()\n            prob_dist /= np.sum(prob_dist)\n            entropy = -np.sum(prob_dist * np.log(prob_dist + 1e-12))\n            return diversity, entropy\n\n        while eval_count < self.budget:\n            diversity, entropy = update_diversity_entropy()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                \n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(entropy))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 81, "feedback": "An exception occurred: MemoryError((61917364224,), dtype('int64')).", "error": "MemoryError((61917364224,), dtype('int64'))", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {}}
{"id": "906dec76-4eff-4b78-9e63-64f0594086a7", "fitness": 0.09460923815998294, "name": "RefinedAdaptiveSwarmOptimizer", "description": "Incorporate a self-adjusting adaptive mutation strategy and velocity recalibration based on diversity and convergence stages to boost optimization efficiency.", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.6\n        self.decay_rate = 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def calculate_diversity():\n            center = np.mean(population, axis=0)\n            return np.mean(np.linalg.norm(population - center, axis=1))\n\n        while eval_count < self.budget:\n            diversity = calculate_diversity()\n            chaotic_factor = np.sin(0.8 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_factor * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                balance = 0.5 * (1 + np.tanh(6 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation = 0.5 + 0.3 * np.cos(chaotic_factor)\n\n                if balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation) * mutant_vector + adaptive_mutation * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation) * mutant_vector + adaptive_mutation * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.2)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_factor * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.3 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.4 + 0.6 * np.sin(0.01 * eval_count) * chaotic_factor\n            self.social_coeff = 1.6 + 0.4 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 82, "feedback": "The algorithm RefinedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09461 with standard deviation 0.00152.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09246598310728393, 0.09555933492328095, 0.09580239644938393]}}
{"id": "24100ce8-c8c6-4ec0-b046-1189c9bba6a3", "fitness": 0.06636811735129884, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce dynamic parameter tuning with chaotic maps and neighborhood-informed mutation to enhance convergence speed and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.min_mutation_factor = 0.4\n        self.max_mutation_factor = 0.9\n        self.min_crossover_prob = 0.6\n        self.max_crossover_prob = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.tan(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + np.random.uniform(self.min_mutation_factor, self.max_mutation_factor) * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector += np.random.uniform(-0.1, 0.1) * (mutant_vector - np.mean(population, axis=0))\n                else:\n                    mutant_vector += np.random.uniform(-0.1, 0.1) * (mutant_vector - global_best_position)\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < np.random.uniform(self.min_crossover_prob, self.max_crossover_prob)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.02 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.02 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06637 with standard deviation 0.00537.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.07390215728812644, 0.06343973014713533, 0.06176246461863477]}}
{"id": "398a88a5-ad0a-4130-afb1-1ec14f20e0bd", "fitness": 0.09584167148658973, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Fine-tune adaptive parameters using dynamic chaos and diversity-driven strategies to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.05)  # Modified (4 lines)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count + 0.5)  # Modified (4 lines)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09584 with standard deviation 0.00071.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09487276541102285, 0.096122123440196, 0.09653012560855034]}}
{"id": "783baf78-07a3-4e08-80bc-28fcf0b26b99", "fitness": 0.09504848499349354, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Introduce dynamic inertia and adaptive crossover probability to enhance convergence in swarm optimization.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Changed from 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * chaotic_perturbation)  # Changed\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)  # Modified\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09505 with standard deviation 0.00083.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09392378844273286, 0.09531612763531738, 0.09590553890243037]}}
{"id": "ec75fedd-fc5e-4588-9a22-4bebd7d31b02", "fitness": 0.09466655938997315, "name": "EnhancedChaoticLevySwarmOptimizer", "description": "Introduce diversity-enhanced exploration by integrating chaotic maps and Lévy flight mechanisms to improve balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) / \n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, ((Lambda - 1) / 2))), (1 / Lambda))\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, self.dim)\n            v = np.random.normal(0, sigma2, self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return step\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                \n                levy_step = levy_flight(1.5)\n                trial_vector += levy_step * (trial_vector - global_best_position) * chaotic_perturbation\n                \n                trial_vector = np.clip(trial_vector, lb, ub)\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)  \n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedChaoticLevySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09467 with standard deviation 0.00036.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.0945339976159787, 0.09515471128775144, 0.09431096926618932]}}
{"id": "b3cec357-6336-46c8-95ca-c83b56049032", "fitness": 0.0959395939296908, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Enhance adaptive exploration-exploitation balance by incorporating sinusoidal chaotic perturbation in cognitive and social coefficients update.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)  # Modified\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count + chaotic_perturbation)  # Modified\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count + chaotic_perturbation)  # Modified\n\n        return global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09594 with standard deviation 0.00110.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09456186292329394, 0.09725726005627255, 0.0959996588095059]}}
{"id": "b9c1e308-e653-43dd-b70c-f0c6f2609487", "fitness": 0.09277519972768104, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Refine the algorithm by adjusting velocity update strategy and introducing a diversity-based adaptive step-size to enhance convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                \n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity + chaotic_perturbation))  # Modified\n            adaptive_step = 0.5 + 0.5 * np.tanh(5 * (0.5 - diversity))  # Modified\n            velocities *= adaptive_step  # Modified\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09278 with standard deviation 0.00094.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09296669574376337, 0.09154290120874531, 0.09381600223053443]}}
{"id": "997903e4-53f9-4cf0-b9d9-f0f75bd4c759", "fitness": 0.09576726656609347, "name": "ChaosAdaptiveSwarmOptimizer", "description": "Introduce a chaos-enhanced adaptive learning scheme and dynamic diversity control to improve convergence and stability.", "code": "import numpy as np\n\nclass ChaosAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.chaos_control_factor = 3.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            return np.mean(np.linalg.norm(population - mean_position, axis=1))\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob * (1 + 0.1 * chaotic_perturbation))\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity * chaotic_perturbation))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= self.chaos_control_factor * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm ChaosAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09577 with standard deviation 0.00102.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09442063294233471, 0.09597951520489179, 0.0969016515510539]}}
{"id": "dafb2080-8876-4a91-a855-88aabb548486", "fitness": 0.0959830120166435, "name": "RefinedAdaptiveSwarmOptimizer", "description": "Enhance the exploration-exploitation dynamics by integrating adaptive chaotic inertia weight and diversity-based velocity scaling mechanisms.", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_inertia = 0.5 + 0.4 * np.cos(0.1 * eval_count + np.pi) * chaotic_perturbation\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (adaptive_inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= self.decay_rate\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm RefinedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09598 with standard deviation 0.00099.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09470276671758193, 0.09710344722328546, 0.09614282210906311]}}
{"id": "b6848f8f-026b-46d4-b4d5-b5a81c6ea284", "fitness": 0.09526880837554215, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced exploratory capability by incorporating dynamic inertia weight and adaptive diversity control to optimize convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            diversification_factor = 0.5 + 0.5 * np.tanh(diversity)\n            velocities *= diversification_factor\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight = 0.4 + 0.5 * np.sin(np.pi * eval_count / self.budget)\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09527 with standard deviation 0.00083.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09414727761821218, 0.09612617807124235, 0.09553296943717193]}}
{"id": "79cc3ebc-c95c-4f81-9108-48a58fe77316", "fitness": 0.09683732316532379, "name": "ImprovedAdaptiveSwarmOptimizer", "description": "Introduce diversity-enhanced perturbation and adaptive inertia damping to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))  # Adaptive inertia damping\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm ImprovedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09684 with standard deviation 0.00169.", "error": "", "parent_ids": ["b9c3090b-b1c4-41a9-bd59-05845897cb8f"], "operator": null, "metadata": {"aucs": [0.09445448015178326, 0.09799648444503772, 0.09806100489915037]}}
{"id": "84e602fd-e45d-4864-bce7-5fb28d460819", "fitness": 0.0965614739739347, "name": "QuantumChaoticSwarmOptimizer", "description": "Introduce quantum-inspired solutions and chaotic search mechanisms to improve convergence and exploration-exploitation balance in swarm optimization.", "code": "import numpy as np\n\nclass QuantumChaoticSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        def quantum_behavior(position, global_best):\n            q = np.random.rand(self.dim)\n            return position + np.sign(q - 0.5) * 0.1 * np.abs(global_best - position) * np.log(1 + 1/q)\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            chaotic_perturbation = np.sin(0.9 * eval_count) * (1.0 / (1.0 + eval_count))\n            adaptive_lr = 0.3 + 0.2 * np.sin(chaotic_perturbation * eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                mutant_vector = quantum_behavior(mutant_vector, global_best_position)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(chaotic_perturbation)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))  # Adaptive inertia damping\n            self.mutation_factor = 0.5 + 0.5 * np.sin(chaotic_perturbation * eval_count)\n            self.mutation_factor *= 3.9 * self.mutation_factor * (1 - self.mutation_factor)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count + np.pi) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count) * chaotic_perturbation\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm QuantumChaoticSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09656 with standard deviation 0.00107.", "error": "", "parent_ids": ["79cc3ebc-c95c-4f81-9108-48a58fe77316"], "operator": null, "metadata": {"aucs": [0.09694381694206744, 0.09509847923672166, 0.097642125743015]}}
{"id": "2749a7ea-7d1a-4d86-a828-ae93e28cf4f7", "fitness": 0.09692068546561257, "name": "EnhancedDynamicSwarmOptimizer", "description": "Exploit dynamic learning rates and enhanced diversity mechanisms to further optimize exploration and exploitation balance in swarm-based optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.sin(eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(eval_count / self.budget)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))  # Adaptive inertia damping\n            self.mutation_factor = 0.5 + 0.5 * np.sin(eval_count / self.budget)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09692 with standard deviation 0.00104.", "error": "", "parent_ids": ["79cc3ebc-c95c-4f81-9108-48a58fe77316"], "operator": null, "metadata": {"aucs": [0.09545448024931236, 0.09751041957425532, 0.09779715657327004]}}
{"id": "f5a0ca53-156b-4206-8beb-bf83b40674c9", "fitness": 0.09691469664018237, "name": "EnhancedDynamicSwarmOptimizer", "description": "Incorporate adaptive velocity scaling and diversity-driven mutation rate adjustment to enhance convergence and robustness in swarm-based optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.sin(eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(eval_count / self.budget)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))  # Adaptive inertia damping\n            self.mutation_factor = 0.5 + 0.4 * np.sin(eval_count / self.budget)  # Increased mutation adaptivity\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09691 with standard deviation 0.00102.", "error": "", "parent_ids": ["2749a7ea-7d1a-4d86-a828-ae93e28cf4f7"], "operator": null, "metadata": {"aucs": [0.09548952547464684, 0.09742925304834449, 0.09782531139755579]}}
{"id": "7b278d06-cc91-4ad0-be8c-a7d175f15580", "fitness": 0.09691882740534048, "name": "EnhancedDynamicSwarmOptimizer", "description": "Introduce adaptive mutation and crossover mechanisms based on historical performance to enhance convergence in dynamic swarm optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n        self.adaptive_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.sin(eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(eval_count / self.budget)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n                    self.adaptive_history.append(trial_score)  # Track improvement\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies based on historical performance\n            improvement_rate = np.mean(np.diff(self.adaptive_history[-10:])) if len(self.adaptive_history) >= 10 else 0\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))\n            self.mutation_factor = 0.5 + 0.5 * np.sin(eval_count / self.budget) + 0.1 * improvement_rate\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count)) - 0.1 * improvement_rate\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09692 with standard deviation 0.00104.", "error": "", "parent_ids": ["2749a7ea-7d1a-4d86-a828-ae93e28cf4f7"], "operator": null, "metadata": {"aucs": [0.09545513755344515, 0.09750418808930628, 0.09779715657327004]}}
{"id": "12a2be51-5b46-4fea-a604-4e6886a9d3e8", "fitness": 0.09683109037700288, "name": "EnhancedDynamicSwarmOptimizer", "description": "Leverage adaptive multi-phase velocity updates and diversity-driven parameter tuning for superior balance in exploration and exploitation within swarm-based optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.sin(eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(eval_count / self.budget)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))  # Adaptive inertia damping\n            self.mutation_factor = 0.5 + 0.5 * np.sin(eval_count / self.budget)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n            # Implement adaptive multi-phase strategy\n            if eval_count / self.budget < 0.3:\n                self.inertia_weight = max(0.4, self.inertia_weight * 1.05)\n                self.cognitive_coeff = min(2.0, self.cognitive_coeff * 1.1)\n            elif eval_count / self.budget < 0.7:\n                self.social_coeff = max(1.5, self.social_coeff * 0.9)\n            else:\n                self.mutation_factor = min(1.0, self.mutation_factor * 1.1)\n                self.crossover_prob = max(0.6, self.crossover_prob * 0.95)\n\n        return global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09683 with standard deviation 0.00093.", "error": "", "parent_ids": ["2749a7ea-7d1a-4d86-a828-ae93e28cf4f7"], "operator": null, "metadata": {"aucs": [0.09553767919395473, 0.0972670805582031, 0.09768851137885082]}}
{"id": "97a61522-6cd6-4a11-b412-341c26191af7", "fitness": 0.09603672832228734, "name": "EnhancedDynamicSwarmOptimizer", "description": "Improve convergence by enhancing exploration during early stages and refining adaptive strategies.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.7  # Change 1\n        self.crossover_prob = 0.75  # Change 2\n        self.inertia_weight = 0.85  # Change 3\n        self.cognitive_coeff = 1.7  # Change 4\n        self.social_coeff = 1.3  # Change 5\n        self.decay_rate = 0.98  # Change 6\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.5 + 0.2 * np.sin(eval_count / self.budget)  # Change 7\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.25 * np.cos(eval_count / self.budget)  # Change 8\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.15 * diversity)  # Change 9\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))\n            self.mutation_factor = 0.55 + 0.45 * np.sin(eval_count / self.budget)  # Change 10\n            self.crossover_prob = 0.55 + 0.35 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.7 + 0.4 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.3 + 0.4 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09604 with standard deviation 0.00117.", "error": "", "parent_ids": ["2749a7ea-7d1a-4d86-a828-ae93e28cf4f7"], "operator": null, "metadata": {"aucs": [0.0945432897772085, 0.09616634150392267, 0.09740055368573086]}}
{"id": "ec7c8e02-90b6-481a-8f97-dd3aedfab9f4", "fitness": 0.09692068546561257, "name": "HybridDiversityDrivenOptimizer", "description": "Introduce a hybrid of Differential Evolution and Particle Swarm Optimization with adaptive diversity-driven mutation and velocity control for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDiversityDrivenOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.decay_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        eval_count = self.population_size\n\n        def update_diversity():\n            mean_position = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - mean_position, axis=1))\n            return diversity\n\n        while eval_count < self.budget:\n            diversity = update_diversity()\n            adaptive_lr = 0.3 + 0.2 * np.sin(eval_count / self.budget)\n\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.mutation_factor * (b - c)\n\n                exploration_exploitation_balance = 0.5 * (1 + np.tanh(5 * (0.5 - eval_count / self.budget)))\n                adaptive_mutation_factor = 0.6 + 0.2 * np.cos(eval_count / self.budget)\n\n                if exploration_exploitation_balance > 0.5:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * np.mean(population, axis=0)\n                else:\n                    mutant_vector = (1 - adaptive_mutation_factor) * mutant_vector + adaptive_mutation_factor * global_best_position\n\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                trial_vector = np.copy(population[i])\n                crossover_mask = np.random.rand(self.dim) < (self.crossover_prob + 0.1 * diversity)\n                trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                if trial_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = trial_vector\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            velocities *= (0.5 + 0.5 * np.tanh(diversity))\n            velocities = np.clip(velocities, lb - population, ub - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Update strategies\n            self.inertia_weight *= (self.decay_rate - 0.3 * np.tanh(diversity))\n            self.mutation_factor = 0.5 + 0.5 * np.sin(eval_count / self.budget)\n            self.crossover_prob = 0.5 + 0.4 * np.abs(np.sin(0.1 * eval_count) + np.cos(0.05 * eval_count))\n            self.cognitive_coeff = 1.5 + 0.5 * np.sin(0.01 * eval_count)\n            self.social_coeff = 1.5 + 0.5 * np.cos(0.01 * eval_count)\n\n        return global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm HybridDiversityDrivenOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09692 with standard deviation 0.00104.", "error": "", "parent_ids": ["2749a7ea-7d1a-4d86-a828-ae93e28cf4f7"], "operator": null, "metadata": {"aucs": [0.09545448024931236, 0.09751041957425532, 0.09779715657327004]}}
