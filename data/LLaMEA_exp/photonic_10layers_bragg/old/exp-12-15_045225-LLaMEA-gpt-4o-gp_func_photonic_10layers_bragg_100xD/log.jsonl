{"id": "f2794d8a-088f-476e-9a06-ea3d019a8fe0", "fitness": 0.07541530603849782, "name": "HybridPSO_SA", "description": "A hybrid swarm-based optimization algorithm combining particle swarm optimization and simulated annealing for enhanced global search and local refinement.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Update velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply simulated annealing for local refinement\n                if np.random.rand() < np.exp(-(score - personal_best_scores[i]) / self.temperature):\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07542 with standard deviation 0.00574.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08330254688582517, 0.06979439830911716, 0.07314897292055111]}}
{"id": "fb0773b1-9638-447a-9193-d3d6708ca7e9", "fitness": 0.07541530603849782, "name": "HybridPSO_SA", "description": "An improved hybrid optimization algorithm combining particle swarm optimization with enhanced velocity update and adaptive cooling in simulated annealing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.9  # cooling rate, lowered to enhance search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Update velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply simulated annealing for local refinement\n                if np.random.rand() < np.exp(-(score - personal_best_scores[i]) / (self.temperature * (1 + 0.01 * evals))):  # Added adaptive cooling\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07542 with standard deviation 0.00574.", "error": "", "parent_ids": ["f2794d8a-088f-476e-9a06-ea3d019a8fe0"], "operator": null, "metadata": {"aucs": [0.08330254688582517, 0.06979439830911716, 0.07314897292055111]}}
{"id": "ee0317cc-af88-4be1-9ec4-d07bd561c1ea", "fitness": 0.07542761605703933, "name": "HybridPSO_SA", "description": "A refined hybrid optimization algorithm incorporating adaptive inertia weight and temperature updates for enhanced search efficiency and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.5   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Update velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply simulated annealing for local refinement\n                if np.random.rand() < np.exp(-(score - personal_best_scores[i]) / self.temperature):\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate + 0.001  # Slightly adjust cooling rate\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07543 with standard deviation 0.00576.", "error": "", "parent_ids": ["f2794d8a-088f-476e-9a06-ea3d019a8fe0"], "operator": null, "metadata": {"aucs": [0.08333947694144972, 0.06979439830911716, 0.07314897292055111]}}
{"id": "8ad4d230-4719-4e37-b3f7-50d24b0610bd", "fitness": 0.07876611842321768, "name": "EnhancedHybridPSO_SA", "description": "A hybrid optimization algorithm combining Particle Swarm Optimization with adaptive inertia and enhanced Simulated Annealing for improved convergence and diversification.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.5   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / self.temperature) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07877 with standard deviation 0.00443.", "error": "", "parent_ids": ["ee0317cc-af88-4be1-9ec4-d07bd561c1ea"], "operator": null, "metadata": {"aucs": [0.08369237757179548, 0.07294757322251977, 0.07965840447533779]}}
{"id": "4daf882a-6e2a-46a8-8d0c-4e55e801dff3", "fitness": 0.08426392754374441, "name": "AdvancedHybridPSO_SA", "description": "An advanced hybrid optimization algorithm integrating Particle Swarm Optimization with dynamic social-cognitive balance and enhanced Simulated Annealing using adaptive parameter tuning for superior convergence and exploration.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / self.temperature) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm AdvancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08426 with standard deviation 0.00291.", "error": "", "parent_ids": ["8ad4d230-4719-4e37-b3f7-50d24b0610bd"], "operator": null, "metadata": {"aucs": [0.08814459508388162, 0.08113347605088428, 0.08351371149646736]}}
{"id": "b8904fab-89ff-4066-b655-b71c14b64670", "fitness": 0.057159599235957814, "name": "RefinedHybridPSO_SAMod", "description": "A novel hybrid optimizer combining Adaptive Particle Swarm Optimization with a Modified Simulated Annealing mechanism, incorporating nonlinear velocity update and stochastic acceptance for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SAMod:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.w = 0.9  # initial inertia weight\n        self.temperature = 100.0\n        self.cooling_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                velocities[i] = np.tanh(velocities[i])  # Nonlinear transformation for velocity\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply modified simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / (self.temperature + 1e-9)) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.5 * np.sin((evals / self.budget) * np.pi / 2)  # Nonlinear adaptive inertia weight\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm RefinedHybridPSO_SAMod got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05716 with standard deviation 0.00379.", "error": "", "parent_ids": ["4daf882a-6e2a-46a8-8d0c-4e55e801dff3"], "operator": null, "metadata": {"aucs": [0.0537137172517288, 0.06244001059050852, 0.05532506986563612]}}
{"id": "fbca28fe-f540-4270-a633-c756e7cc3bc6", "fitness": 0.08426392754374441, "name": "AdvancedHybridPSO_SA", "description": "A refined hybrid optimization approach integrating Particle Swarm Optimization with adaptive parameter tuning and a greedy local search strategy to enhance convergence and exploration efficiency.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / self.temperature) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best with a greedy approach\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n                else:\n                    global_best_score = min(global_best_score, score)\n\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm AdvancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08426 with standard deviation 0.00291.", "error": "", "parent_ids": ["4daf882a-6e2a-46a8-8d0c-4e55e801dff3"], "operator": null, "metadata": {"aucs": [0.08814459508388162, 0.08113347605088428, 0.08351371149646736]}}
{"id": "b5968c7b-0409-4242-aaea-db63105a0d9f", "fitness": 0.08418904603926651, "name": "AdvancedHybridPSO_SA", "description": "Enhanced hybrid optimization algorithm that integrates adaptive learning rate adjustment and additional local search strategies for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / (self.temperature / 2)) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.3 * (1 - evals / self.budget)  # More aggressive adaptive inertia weight\n            self.temperature *= (self.cooling_rate - 0.01)  # Slightly faster cooling rate\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm AdvancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08419 with standard deviation 0.00431.", "error": "", "parent_ids": ["4daf882a-6e2a-46a8-8d0c-4e55e801dff3"], "operator": null, "metadata": {"aucs": [0.08950207460717319, 0.07894669670478638, 0.08411836680583995]}}
{"id": "1577de94-bf05-462a-9fde-e38b2554d2ff", "fitness": 0.08426392754374441, "name": "AdvancedHybridPSO_SA_Improved", "description": "A hybrid optimization algorithm integrating Particle Swarm Optimization with adaptive social-cognitive balance, enhanced Simulated Annealing with dynamic cooling, and a diversity preservation mechanism for improved exploration and convergence in dynamic environments.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_SA_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.w = 0.5   # inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.diversity_threshold = 0.1  # diversity preservation threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evals = self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing for local refinement\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / self.temperature) if delta_score > 0 else 1.0\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Adaptive inertia weight\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)\n\n            # Dynamic cooling schedule\n            self.temperature *= self.cooling_rate * (1 + 0.1 * (evals / self.budget))\n\n            # Diversity preservation\n            diversity = np.mean(np.std(particles, axis=0))\n            if diversity < self.diversity_threshold:\n                random_particles = np.random.uniform(low=lb, high=ub, size=(self.population_size // 10, self.dim))\n                particles[:self.population_size // 10] = random_particles\n                velocities[:self.population_size // 10] = np.random.uniform(size=(self.population_size // 10, self.dim)) * (ub - lb) / 20.0\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm AdvancedHybridPSO_SA_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08426 with standard deviation 0.00291.", "error": "", "parent_ids": ["4daf882a-6e2a-46a8-8d0c-4e55e801dff3"], "operator": null, "metadata": {"aucs": [0.08814459508388162, 0.08113347605088428, 0.08351371149646736]}}
{"id": "aaa45932-8a99-422e-8e3e-2141e45baf71", "fitness": 0.08508608058232321, "name": "RefinedHybridPSO_SA", "description": "An advanced hybrid optimization algorithm combining Particle Swarm Optimization with adaptive inertia weight and enhanced Simulated Annealing incorporating stochastic tunneling and adaptive population size for efficient convergence and exploration.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["4daf882a-6e2a-46a8-8d0c-4e55e801dff3"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "40d46fae-f817-41ef-a6b5-29e11a84adcb", "fitness": 0.08508608058232321, "name": "RefinedHybridPSO_SA", "description": "Enhanced Particle Swarm Optimization with Adaptive Learning Factor and Dynamic Boundary Control to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget) + 1.5  # adjusted adaptive learning factor\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "84f6ea9a-fc25-4d6a-a631-a669be821cf8", "fitness": 0.08508608058232321, "name": "RefinedHybridPSO_SA", "description": "An enhanced hybrid optimization algorithm integrating adaptive Particle Swarm Optimization with Simulated Annealing and stochastic tunneling to improve convergence and exploration efficiency with dynamic search granularity.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.9  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "bdfcebf3-8a7f-41b0-9a86-a83949cf012d", "fitness": 0.08508608058232321, "name": "EnhancedHybridPSO_SA", "description": "A further refined hybrid algorithm integrating Particle Swarm Optimization with dynamic adaptive inertia, progressive Simulated Annealing, and quantum-inspired tunneling for optimized search space exploration and accelerated convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.93  # refined cooling rate\n        self.quantum_tunneling_factor = 0.15  # enhanced factor for quantum tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best if better\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with quantum-inspired tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.quantum_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "6f19a9fa-1f64-4614-b2e2-e91b760ac65f", "fitness": 0.08508608058232321, "name": "RefinedHybridPSO_SA", "description": "An enhanced hybrid optimization algorithm refining Particle Swarm Optimization and Simulated Annealing with dynamic parameter adjustment for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.93  # enhanced cooling rate (changed)\n        self.stochastic_tunneling_factor = 0.15  # factor for stochastic tunneling (changed)\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                acceptance_prob = np.exp(-delta_score / self.temperature) if delta_score > 0 else 1.0  # changed\n                if np.random.rand() < acceptance_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "3a619e45-502d-4448-a2c9-30c1e2dcde2f", "fitness": 0.08223607108952484, "name": "EnhancedPSO_SA_DynamicMutation", "description": "Enhanced Particle Swarm Optimization with Dynamic Mutation and Adaptive Simulated Annealing for Improved Exploration and Convergence Control.", "code": "import numpy as np\n\nclass EnhancedPSO_SA_DynamicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.stochastic_tunneling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def dynamic_mutation(self, particle, lb, ub, evals):\n        mutation_rate = 0.1 * (1 - evals / self.budget)\n        if np.random.rand() < mutation_rate:\n            mutation_vector = np.random.uniform(low=lb, high=ub, size=self.dim)\n            return np.clip(particle + mutation_vector * 0.1, lb, ub)\n        return particle\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Apply dynamic mutation\n                particles[i] = self.dynamic_mutation(particles[i], lb, ub, evals)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedPSO_SA_DynamicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08224 with standard deviation 0.00705.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.08890163127027595, 0.08532012176036297, 0.07248646023793559]}}
{"id": "e6a60f9e-a267-4607-810e-861d8c613c55", "fitness": 0.07265509883833947, "name": "EnhancedHybridPSO_SA_Chaos", "description": "Enhanced hybrid algorithm integrating dynamic parameter adaptation in Particle Swarm Optimization and Simulated Annealing with a novel strategy employing chaos theory, aiming for diversified exploration and accelerated convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SA_Chaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.stochastic_tunneling_factor = 0.1\n        self.chaos_coefficient = 0.7  # Coefficient for chaotic perturbation\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def chaotic_mapping(self, x):\n        return self.chaos_coefficient * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n        chaos_map = np.random.rand(self.dim)\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Chaotic perturbation for enhanced exploration\n                chaos_map = self.chaotic_mapping(chaos_map)\n                particles[i] += 0.1 * (chaos_map - 0.5) * (ub - lb)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSO_SA_Chaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07266 with standard deviation 0.00664.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.06626259119856637, 0.0698956415604175, 0.08180706375603453]}}
{"id": "a996d2a8-20e5-4b21-a6f8-7b3132f2d8b3", "fitness": 0.08103965252253993, "name": "RefinedHybridPSO_SA", "description": "A refined hybrid optimization algorithm leveraging dynamic adaptive coefficients and a hierarchical annealing strategy for enhanced convergence efficiency and exploration.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.93  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.15  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.5 - self.initial_c2) * (evals / self.budget)  # Adjust social coefficient\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.6 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08104 with standard deviation 0.00599.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.08950366698365197, 0.07686702302452997, 0.07674826755943787]}}
{"id": "0e549806-c356-420d-902b-06cc751c17e6", "fitness": 0.08508608058232321, "name": "RefinedHybridPSO_SA", "description": "An enhanced hybrid algorithm leveraging adaptive learning rates and a dynamic restart strategy to optimize convergence and escape local optima in complex spaces.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n            # Dynamic restart strategy to escape local optima\n            if evals % (self.budget // 4) == 0:  # Restart every quarter of the budget\n                particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n                velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00637.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.09075989967811993, 0.07619558225254652, 0.0883027598163032]}}
{"id": "b2a9cb21-ce58-449a-aa25-ea95ea910922", "fitness": 0.08287641772474963, "name": "EnhancedHybridPSO_SA", "description": "A novel hybrid optimization algorithm integrating Particle Swarm Optimization with dynamic inertia weight, adaptive social-cognitive coefficients, and enhanced Simulated Annealing with adaptive temperature scaling and multi-start strategy to improve global exploration and local exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n        self.multi_start_attempts = 5  # attempts for multi-start strategy\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def adaptive_temperature(self, evals):\n        return self.temperature * (1 - evals / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        best_global_solution = None\n        best_global_score = float('inf')\n\n        for attempt in range(self.multi_start_attempts):\n            particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n            velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n            personal_best = particles.copy()\n            personal_best_scores = np.array([func(p) for p in personal_best])\n            global_best_index = np.argmin(personal_best_scores)\n            global_best = personal_best[global_best_index]\n            global_best_score = personal_best_scores[global_best_index]\n            evals += self.initial_population_size\n\n            while evals < self.budget / self.multi_start_attempts:\n                population_size = self.adaptive_population_size(evals)\n                temperature = self.adaptive_temperature(evals)\n                for i in range(population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    c1 = self.initial_c1 * (1 - evals / self.budget)\n                    c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                    velocities[i] = (self.initial_w * velocities[i] +\n                                     c1 * r1 * (personal_best[i] - particles[i]) +\n                                     c2 * r2 * (global_best - particles[i]))\n                    particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                    # Evaluate new position\n                    score = func(particles[i])\n                    evals += 1\n                    if evals >= self.budget / self.multi_start_attempts:\n                        break\n\n                    # Update personal best\n                    if score < personal_best_scores[i]:\n                        personal_best[i] = particles[i]\n                        personal_best_scores[i] = score\n\n                    # Apply enhanced simulated annealing with adaptive temperature scaling\n                    delta_score = score - personal_best_scores[i]\n                    tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score / temperature) if delta_score > 0 else 1.0\n                    if np.random.rand() < tunneling_prob:\n                        personal_best[i] = particles[i]\n                        personal_best_scores[i] = score\n\n                    # Update global best\n                    if score < global_best_score:\n                        global_best = particles[i]\n                        global_best_score = score\n\n                self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n\n            # Multi-start to update best global solution\n            if global_best_score < best_global_score:\n                best_global_solution = global_best\n                best_global_score = global_best_score\n\n        return best_global_solution", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08288 with standard deviation 0.00489.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.08516015740344218, 0.07607544203958738, 0.08739365373121932]}}
{"id": "27cde8d7-9c35-46c7-852a-97653c31b604", "fitness": 0.0919267116509453, "name": "RefinedHybridPSO_SA", "description": "An advanced hybrid optimization algorithm that improves exploration by introducing adaptive velocity scaling in Particle Swarm Optimization, combined with enhanced Simulated Annealing.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.5 + 0.5 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09193 with standard deviation 0.00292.", "error": "", "parent_ids": ["aaa45932-8a99-422e-8e3e-2141e45baf71"], "operator": null, "metadata": {"aucs": [0.08870325713012839, 0.09578170725248847, 0.09129517057021908]}}
{"id": "9a4590b8-b041-4dc5-b3a7-08fbb783eaf2", "fitness": 0.0927914970485801, "name": "RefinedHybridPSO_SA", "description": "Introduced particle diversity enhancement by applying random perturbations, thus maintaining exploration throughout the optimization process.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.5 + 0.5 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                # Apply random perturbation to enhance exploration\n                particles[i] = np.clip(particles[i] + velocities[i] + np.random.normal(0, 0.1, self.dim), lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09279 with standard deviation 0.00331.", "error": "", "parent_ids": ["27cde8d7-9c35-46c7-852a-97653c31b604"], "operator": null, "metadata": {"aucs": [0.09629115843131386, 0.09374191323404713, 0.08834141948037932]}}
{"id": "63622602-e69b-4cef-8daa-a1331e945395", "fitness": 0.09267517157484806, "name": "RefinedHybridPSO_SA", "description": "Improved exploration by adjusting the random perturbation scale adaptively based on remaining budget.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.5  # starting cognitive coefficient\n        self.initial_c2 = 0.5  # starting social coefficient\n        self.initial_w = 0.9   # initial inertia weight\n        self.temperature = 100.0  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # enhanced cooling rate\n        self.stochastic_tunneling_factor = 0.1  # factor for stochastic tunneling\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.5 + 0.5 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                # Apply adaptive random perturbation to enhance exploration\n                perturbation_scale = 0.1 * (1 - evals / self.budget)\n                particles[i] = np.clip(particles[i] + velocities[i] + np.random.normal(0, perturbation_scale, self.dim), lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Apply enhanced simulated annealing with stochastic tunneling\n                delta_score = score - personal_best_scores[i]\n                tunneling_prob = np.exp(-self.stochastic_tunneling_factor * delta_score) if delta_score > 0 else 1.0\n                if np.random.rand() < tunneling_prob:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09268 with standard deviation 0.00340.", "error": "", "parent_ids": ["9a4590b8-b041-4dc5-b3a7-08fbb783eaf2"], "operator": null, "metadata": {"aucs": [0.09620005709460411, 0.09374049260536432, 0.08808496502457575]}}
{"id": "ba1cf5d1-15af-46fe-87d9-671ed655e551", "fitness": 0.09399880697842482, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with Adaptive Dynamic Parameters and Contextual Learning for optimal convergence through strategic learning of successful particle behaviors.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.00249.", "error": "", "parent_ids": ["9a4590b8-b041-4dc5-b3a7-08fbb783eaf2"], "operator": null, "metadata": {"aucs": [0.09751772717253304, 0.09231848129639575, 0.09216021246634565]}}
{"id": "0c0791dc-cfb7-4324-9771-228d342ef155", "fitness": -Infinity, "name": "MultiSwarmAdaptiveLearningPSO", "description": "Enhanced Adaptive Learning PSO with Multi-Swarm Strategy and Gradient-Inspired Learning for improved exploration and convergence by leveraging diverse swarm interactions and gradient approximations.", "code": "import numpy as np\n\nclass MultiSwarmAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.num_swarms = 3  # Introducing multiple swarms\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def gradient_approximation(self, particles, scores):\n        # Simple gradient approximation using finite differences\n        gradients = np.zeros_like(particles)\n        h = 1e-5\n        for i in range(particles.shape[0]):\n            for j in range(self.dim):\n                x_plus_h = particles[i].copy()\n                x_plus_h[j] += h\n                gradients[i, j] = (func(x_plus_h) - scores[i]) / h\n        return gradients\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        populations = [np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0 for _ in range(self.num_swarms)]\n        personal_best = [pop.copy() for pop in populations]\n        personal_best_scores = [np.array([func(p) for p in pop]) for pop in personal_best]\n        global_best_index = [np.argmin(scores) for scores in personal_best_scores]\n        global_best = [personal_best[swarm][index] for swarm, index in enumerate(global_best_index)]\n        global_best_score = [scores[index] for scores, index in zip(personal_best_scores, global_best_index)]\n        evals += self.initial_population_size * self.num_swarms\n\n        while evals < self.budget:\n            for swarm in range(self.num_swarms):\n                population_size = self.adaptive_population_size(evals)\n                for i in range(population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    c1 = self.initial_c1 * (1 - evals / self.budget)\n                    c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                    velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                    velocities[swarm][i] = (self.initial_w * velocities[swarm][i] +\n                                            c1 * r1 * (personal_best[swarm][i] - populations[swarm][i]) +\n                                            c2 * r2 * (global_best[swarm] - populations[swarm][i])) * velocity_scaling\n                    populations[swarm][i] = np.clip(populations[swarm][i] + velocities[swarm][i], lb, ub)\n\n                    # Evaluate new position\n                    score = func(populations[swarm][i])\n                    evals += 1\n                    if evals >= self.budget:\n                        break\n\n                    # Update personal best\n                    if score < personal_best_scores[swarm][i]:\n                        personal_best[swarm][i] = populations[swarm][i]\n                        personal_best_scores[swarm][i] = score\n\n                    # Gradient-inspired learning: adjust position using gradient approximation\n                    if np.random.rand() < self.learning_rate:\n                        gradients = self.gradient_approximation(populations[swarm], personal_best_scores[swarm])\n                        populations[swarm][i] -= self.learning_rate * gradients[i]\n                        populations[swarm][i] = np.clip(populations[swarm][i], lb, ub)\n                        score = func(populations[swarm][i])\n                        evals += 1\n\n                    # Update global best\n                    if score < global_best_score[swarm]:\n                        global_best[swarm] = populations[swarm][i]\n                        global_best_score[swarm] = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        # Select the best solution across all swarms\n        best_swarm_index = np.argmin(global_best_score)\n        return global_best[best_swarm_index]", "configspace": "", "generation": 23, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["ba1cf5d1-15af-46fe-87d9-671ed655e551"], "operator": null, "metadata": {}}
{"id": "53733192-dd51-44e3-bf2b-7b994dce50b1", "fitness": 0.09299863267062651, "name": "SynergisticAdaptivePSO", "description": "Synergistic Particle Swarm Optimization with Adaptive Diversity Maintenance and Dynamic Neighborhoods for enhanced global exploration and convergence stability.", "code": "import numpy as np\n\nclass SynergisticAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 50\n        self.c1 = 2.0\n        self.c2 = 1.0\n        self.w = 0.9\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.diversity_threshold = 0.001\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.init_population_size * (1 - evals / self.budget)))\n\n    def calculate_diversity(self, particles):\n        return np.mean(np.std(particles, axis=0))\n\n    def dynamically_adjust_neighborhood(self, particles, global_best, evals):\n        diversity = self.calculate_diversity(particles)\n        if diversity < self.diversity_threshold:\n            # Widen the neighborhood if diversity is low\n            return global_best + np.random.randn(self.dim) * np.mean(np.abs(particles - global_best), axis=0)\n        else:\n            # Otherwise, refine around the current global best\n            return global_best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.init_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.init_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.init_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.c1 * (1 - evals / self.budget)\n                c2 = self.c2 + (2.0 - self.c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: adaptive neighborhood strategy\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    particles[i] = np.clip(self.dynamically_adjust_neighborhood(particles, global_best, evals), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)\n            self.cooling_rate *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm SynergisticAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09300 with standard deviation 0.00110.", "error": "", "parent_ids": ["ba1cf5d1-15af-46fe-87d9-671ed655e551"], "operator": null, "metadata": {"aucs": [0.09300752967369119, 0.09164295495169894, 0.09434541338648939]}}
{"id": "def06a01-05d0-41fe-b55f-388b3682ded5", "fitness": 0.08863981164582102, "name": "RefinedAdaptiveLearningPSO", "description": "Leveraging dynamic swarm intelligence with adaptive learning rates and strategic diversification, this refined PSO variant enhances global exploration and convergence efficiency.", "code": "import numpy as np\n\nclass RefinedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1_start = 2.5    # Increased cognitive coefficient for better exploration\n        self.c2_start = 0.5    # Lowered initial social coefficient to reduce premature convergence\n        self.w_start = 0.9     # Initial inertia weight\n        self.cooling_rate = 0.99 # Enhanced cooling rate for consistent global exploration\n        self.learning_rate = 0.15 # Higher learning rate for faster contextual learning\n        self.diversification_rate = 0.1 # Additional diversification rate for avoiding local optima\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 50.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.c1_start * (1 - evals / self.budget)\n                c2 = self.c2_start + (2.0 - self.c2_start) * (evals / self.budget)\n                velocity_scaling = 0.7 + 0.3 * np.random.rand() * (1 - evals / self.budget)  # Enhanced adaptive velocity scaling\n                velocities[i] = (self.w_start * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Diversification strategy\n                if np.random.rand() < self.diversification_rate:\n                    particles[i] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.w_start = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.cooling_rate *= 0.98  # Gradual cooling for more refined search\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm RefinedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08864 with standard deviation 0.00414.", "error": "", "parent_ids": ["ba1cf5d1-15af-46fe-87d9-671ed655e551"], "operator": null, "metadata": {"aucs": [0.08625702836936278, 0.08520229189107376, 0.09446011467702653]}}
{"id": "ad463ea4-650f-45eb-8545-babdff3c93f8", "fitness": 0.09390446949029496, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with context-aware inertia and social adaptation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (1.5 - self.initial_c2) * (evals / self.budget)  # Adjusted social coefficient\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)  # Adjusted adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09390 with standard deviation 0.00139.", "error": "", "parent_ids": ["ba1cf5d1-15af-46fe-87d9-671ed655e551"], "operator": null, "metadata": {"aucs": [0.09289923057885274, 0.09586925956468972, 0.09294491832734242]}}
{"id": "0bf79eee-4604-48ea-ba91-0be340438112", "fitness": 0.0952266187913519, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with Adaptive Dynamic Parameters and Contextual Learning for optimal convergence with improved learning rate dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09523 with standard deviation 0.00272.", "error": "", "parent_ids": ["ba1cf5d1-15af-46fe-87d9-671ed655e551"], "operator": null, "metadata": {"aucs": [0.09874636684352989, 0.09480356419213087, 0.09212992533839492]}}
{"id": "c5e87dc9-7b22-40c5-a756-0dfd1f66ceaf", "fitness": 0.09291130856252357, "name": "EnhancedAdaptiveLearningPSO", "description": "Fine-tuning EnhancedAdaptiveLearningPSO by adjusting learning dynamics for improved convergence stability and performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.normal(0, 0.5, self.dim) * np.abs(global_best - particles[i]), lb, ub)  # Slight adjustment for exploration\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09291 with standard deviation 0.00558.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09853376543189007, 0.09490370749061472, 0.08529645276506592]}}
{"id": "5071c49b-f3f2-464f-9d9d-b230155d95f4", "fitness": 0.09473408354119928, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with Adaptive Multi-tiered Learning and temperature-sensitive velocity adjustments to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.97 # faster cooling rate for precise global-local exploration\n        self.learning_rate = 0.15 # increased learning rate for enhanced contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            temp_factor = np.exp(-self.temperature / 100.0) # temperature-sensitive velocity scaling\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * temp_factor\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                multi_tiered_learning = np.random.rand() < self.learning_rate * (1 - evals / self.budget)\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n                elif multi_tiered_learning:\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09473 with standard deviation 0.00102.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09518376506980364, 0.09569344933221346, 0.09332503622158073]}}
{"id": "0a6948dd-a1ac-46a7-ba26-cc3a1e083b20", "fitness": 0.09436959203689792, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with Dynamic Population Adjustment and Adaptive Velocity Control for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.cooling_rate = 0.98 \n        self.learning_rate = 0.1 \n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.5 + 0.5 * np.random.rand() * (1 - evals / self.budget)  # Slightly increased\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.3 + 0.6 * (1 - evals / self.budget)  # More adaptable inertia weight\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09437 with standard deviation 0.00220.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09126545545644926, 0.09596806864779828, 0.0958752520064462]}}
{"id": "064a7022-55ba-43c1-b60c-2460a8c1b1e2", "fitness": 0.09507135285868058, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with improved velocity scaling for greater exploration during early iterations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.8 * np.random.rand() * (1 - evals / self.budget)  # Improved velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09507 with standard deviation 0.00113.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09652886766079227, 0.09490358117471764, 0.09378160974053185]}}
{"id": "43594f80-b5ee-4d34-94dc-f48766a59208", "fitness": 0.0952266187913519, "name": "EnhancedAdaptiveLearningPSO", "description": "Improved velocity update mechanism with adaptive cognitive and social factors for Enhanced Adaptive Learning PSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.5 - 1.5) * (evals / self.budget)  # Slightly modified adaptive social coefficient\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget)  # Adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09523 with standard deviation 0.00272.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09874636684352989, 0.09480356419213087, 0.09212992533839492]}}
{"id": "f4846d14-c341-4a70-beb2-df6dd6402c70", "fitness": 0.09529151649748661, "name": "EnhancedAdaptiveLearningPSO", "description": "Enhanced Particle Swarm Optimization with dynamic inertia weight adjustment for improved convergence speed and better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0    # adjusted starting cognitive coefficient to encourage personal exploration\n        self.initial_c2 = 1.0    # adjusted starting social coefficient for balanced social influence\n        self.initial_w = 0.9     # initial inertia weight\n        self.temperature = 100.0 # initial temperature for simulated annealing\n        self.cooling_rate = 0.98 # enhanced cooling rate for better global exploration\n        self.learning_rate = 0.1 # learning rate for contextual learning\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Contextual learning: learn from global best when stuck\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    particles[i] = np.clip(global_best + np.random.randn(self.dim) * np.abs(global_best - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)  # Modified adaptive inertia weight\n            self.temperature *= self.cooling_rate  # Cooling down the temperature\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09529 with standard deviation 0.00246.", "error": "", "parent_ids": ["0bf79eee-4604-48ea-ba91-0be340438112"], "operator": null, "metadata": {"aucs": [0.09869433132154115, 0.09420721248553188, 0.0929730056853868]}}
{"id": "866beabb-7f62-4e3e-bf9f-2e5268ad056f", "fitness": 0.09610131998962368, "name": "QuantumEnhancedPSO", "description": "Incorporating Quantum-inspired Particle Swarm Optimization with a dynamic neighborhood topology to enhance global exploration and local exploitation balance.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Quantum-inspired stochastic jump\n                if np.random.rand() < self.quantum_factor:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09610 with standard deviation 0.00169.", "error": "", "parent_ids": ["f4846d14-c341-4a70-beb2-df6dd6402c70"], "operator": null, "metadata": {"aucs": [0.0978989289950829, 0.09656443675890658, 0.09384059421488156]}}
{"id": "eee28ab6-ddf4-4d31-8780-852b5d51459f", "fitness": 0.07828700104493458, "name": "EnhancedQuantumPSO", "description": "Enhancing Quantum-PSO by integrating Levy flight for diverse exploration and adaptive inertia for convergence acceleration in a dynamic landscape.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.inertia_weight = 0.9\n        self.quantum_factor = 0.05\n        self.levy_factor = 0.1\n        self.learning_rate = 0.1\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            for i in range(self.initial_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.initial_c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.initial_c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < self.quantum_factor:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < self.levy_factor:\n                    particles[i] += self.levy_flight(self.dim) * (ub - lb) / 10.0\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.inertia_weight = 0.5 + 0.4 * (1 - evals / self.budget)\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07829 with standard deviation 0.00465.", "error": "", "parent_ids": ["866beabb-7f62-4e3e-bf9f-2e5268ad056f"], "operator": null, "metadata": {"aucs": [0.07209138210854349, 0.07948330182198793, 0.08328631920427232]}}
{"id": "58f2152f-75eb-484c-80fd-22826d1dc520", "fitness": 0.08906975906433401, "name": "EnhancedQuantumPSO", "description": "Introducing adaptive inertia weight and multi-swarm cooperation in Quantum-Enhanced Particle Swarm Optimization to promote efficient search through enhanced exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.initial_w = 0.9\n        self.quantum_factor = 0.05\n        self.cooling_rate = 0.98\n        self.swarm_count = 3  # Number of swarms for multi-swarm strategy\n        self.swarm_sizes = [self.initial_population_size // self.swarm_count] * self.swarm_count\n\n    def adaptive_inertia_weight(self, evals):\n        return 0.4 + 0.5 * (1 - evals / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        swarms = [np.random.uniform(low=lb, high=ub, size=(size, self.dim))\n                  for size in self.swarm_sizes]\n        velocities = [np.random.uniform(size=(size, self.dim)) * (ub - lb) / 20.0\n                      for size in self.swarm_sizes]\n        personal_best = [swarm.copy() for swarm in swarms]\n        personal_best_scores = [np.array([func(p) for p in swarm]) for swarm in personal_best]\n        global_best_index = [np.argmin(scores) for scores in personal_best_scores]\n        global_best = [personal_best[i][global_best_index[i]] for i in range(self.swarm_count)]\n        global_best_score = [personal_best_scores[i][global_best_index[i]] for i in range(self.swarm_count)]\n        evals += sum(self.swarm_sizes)\n\n        while evals < self.budget:\n            for swarm_id in range(self.swarm_count):\n                for i in range(self.swarm_sizes[swarm_id]):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    w = self.adaptive_inertia_weight(evals)\n                    c1 = self.initial_c1 * (1 - evals / self.budget)\n                    c2 = self.initial_c2 * (evals / self.budget)\n                    velocities[swarm_id][i] = (w * velocities[swarm_id][i] +\n                                               c1 * r1 * (personal_best[swarm_id][i] - swarms[swarm_id][i]) +\n                                               c2 * r2 * (global_best[swarm_id] - swarms[swarm_id][i]))\n                    swarms[swarm_id][i] = np.clip(swarms[swarm_id][i] + velocities[swarm_id][i], lb, ub)\n\n                    if np.random.rand() < self.quantum_factor:\n                        swarms[swarm_id][i] = np.clip(global_best[swarm_id] + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                    score = func(swarms[swarm_id][i])\n                    evals += 1\n                    if evals >= self.budget:\n                        break\n\n                    if score < personal_best_scores[swarm_id][i]:\n                        personal_best[swarm_id][i] = swarms[swarm_id][i]\n                        personal_best_scores[swarm_id][i] = score\n\n                    if score < global_best_score[swarm_id]:\n                        global_best[swarm_id] = swarms[swarm_id][i]\n                        global_best_score[swarm_id] = score\n\n            if evals % 100 == 0:  # Swap global best across swarms periodically\n                for i in range(self.swarm_count):\n                    for j in range(i + 1, self.swarm_count):\n                        if global_best_score[j] < global_best_score[i]:\n                            global_best[i], global_best[j] = global_best[j], global_best[i]\n                            global_best_score[i], global_best_score[j] = global_best_score[j], global_best_score[i]\n\n        return min(global_best, key=lambda b: func(b))", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08907 with standard deviation 0.00093.", "error": "", "parent_ids": ["866beabb-7f62-4e3e-bf9f-2e5268ad056f"], "operator": null, "metadata": {"aucs": [0.08916715496438798, 0.09015257589623005, 0.087889546332384]}}
{"id": "99942fb5-4328-4ac7-8976-8de31cc5b8c0", "fitness": 0.09610987323814606, "name": "QuantumEnhancedPSO", "description": "Enhanced Quantum-PSO with adaptive quantum factor for better exploration-exploitation trade-off and improved convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09611 with standard deviation 0.00176.", "error": "", "parent_ids": ["866beabb-7f62-4e3e-bf9f-2e5268ad056f"], "operator": null, "metadata": {"aucs": [0.09820305654003625, 0.09621918622051484, 0.09390737695388707]}}
{"id": "800488d1-5d71-4258-bde4-7f125e2e0007", "fitness": 0.0815149162583267, "name": "QuantumEnhancedPSO", "description": "Enhanced Quantum-PSO with adaptive population scaling, chaotic map initialization, and differential strategy for improved exploration-exploitation and convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def chaotic_initialization(self, size, lb, ub):\n        # Use logistic map for chaotic initialization\n        x = np.random.rand(size, self.dim)\n        chaotic_sequence = 4 * x * (1 - x)  # Logistic map\n        return lb + (ub - lb) * chaotic_sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = self.chaotic_initialization(self.initial_population_size, lb, ub)\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 * (1 - evals / self.budget) + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand()\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    rand_indices = np.random.choice(range(population_size), 3, replace=False)\n                    a, b, c = personal_best[rand_indices]\n                    trial_vector = np.clip(a + 0.5 * (b - c), lb, ub)\n                    trial_score = func(trial_vector)\n                    evals += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best[i] = trial_vector\n                        personal_best_scores[i] = trial_score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08151 with standard deviation 0.00200.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.08172628671973248, 0.08384754419514684, 0.0789709178601008]}}
{"id": "63dabdd2-10e7-452b-9569-4ec86b21b914", "fitness": 0.0891341306930521, "name": "QuantumEnhancedPSO", "description": "Introduce a dynamic inertia weight adjustment based on evaluation progress to enhance convergence behavior.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (0.7 + 0.2 * (1 - evals / self.budget)) * velocities[i] + \\\n                                 c1 * r1 * (personal_best[i] - particles[i]) + \\\n                                 c2 * r2 * (global_best - particles[i]) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08913 with standard deviation 0.00154.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.08703484920688731, 0.09067415797583078, 0.08969338489643819]}}
{"id": "3ebc601a-d39a-4b48-ba9a-85677a4433c7", "fitness": 0.09502918192028931, "name": "QuantumEnhancedPSO", "description": "Enhanced Quantum-PSO with fine-tuned adaptive quantum factor and dynamic inertia weight for better convergence.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.07  # Slightly increased quantum factor for enhanced stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09503 with standard deviation 0.00250.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.09804591755604553, 0.09193224522886678, 0.09510938297595561]}}
{"id": "9a94c390-8822-4cde-be09-7f0651f1df1a", "fitness": 0.09588656818915871, "name": "QuantumEnhancedPSO", "description": "Quantum-PSO with dynamic adaptive mechanisms for better convergence through multi-scale exploration and exploitation.", "code": "import numpy as np\n\nclass QuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Improved neighborhood exploration using elite selection\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    elite_set_indices = np.argsort(personal_best_scores)[:5]\n                    elite_best = min(elite_set_indices, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[elite_best] + np.random.randn(self.dim) * np.abs(personal_best[elite_best] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm QuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09589 with standard deviation 0.00142.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.09700127488630583, 0.09387661321458762, 0.09678181646658268]}}
{"id": "2e1fc38f-3de7-455c-b4a4-8f5bc677876e", "fitness": 0.0888496420089322, "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with adaptive inertia and neighborhood influence for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.initial_w = 0.9\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 * (evals / self.budget)\n                w = self.initial_w * (0.5 + 0.5 * np.random.rand())\n\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n                # Neighborhood influence for exploration\n                if np.random.rand() < 0.1:\n                    neighbors = np.random.choice(population_size, 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n            self.initial_w *= 0.99  # Gradual reduction of inertia\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08885 with standard deviation 0.00117.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.08870357291155695, 0.087497542928487, 0.09034781018675264]}}
{"id": "473baa27-0a12-4d19-a87a-12f418f8eb15", "fitness": 0.06928012660693694, "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum-PSO with dynamic inertia, neighborhood topology, and gradient ascent mechanisms for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 1.5\n        self.initial_c2 = 1.5\n        self.initial_w = 0.9\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.inertia_damping = 0.99\n        self.neighborhood_size = 5\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def dynamic_inertia(self, evals):\n        return self.initial_w * (self.inertia_damping ** (evals / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            inertia = self.dynamic_inertia(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 * (1 + evals / self.budget)\n                velocities[i] = (inertia * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    neighbors = np.random.choice(range(population_size), self.neighborhood_size, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06928 with standard deviation 0.00152.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.06786030001942067, 0.07138854270658135, 0.06859153709480881]}}
{"id": "6d557f7f-4135-4857-9b02-1fd33d8bf444", "fitness": 0.09645443765069191, "name": "HybridQuantumPSO", "description": "Hybrid Quantum-PSO with Dual Adaptive Mechanisms for Efficient Resource Utilization and Convergence.", "code": "import numpy as np\n\nclass HybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm HybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09645 with standard deviation 0.00232.", "error": "", "parent_ids": ["99942fb5-4328-4ac7-8976-8de31cc5b8c0"], "operator": null, "metadata": {"aucs": [0.09915828028794238, 0.09670668440479857, 0.09349834825933478]}}
{"id": "3cef44db-4eff-4672-837a-fe5f331af7e6", "fitness": 0.0960183269138456, "name": "EnhancedHybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Reinforced Neighborhood Learning and Adaptive Quantum Jumps for Improved Convergence and Efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n        self.learning_enhancement_factor = 1.2  # Increased learning rate for better exploration\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Enhanced adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget) * self.learning_enhancement_factor\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Reinforced dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget) * self.learning_enhancement_factor:\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09602 with standard deviation 0.00179.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.0985116018559552, 0.09514478566246976, 0.09439859322311184]}}
{"id": "e095404f-5fa4-4006-bd73-9396ffa9fec7", "fitness": 0.09121960972370442, "name": "EnhancedHybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Self-Adaptive Strategies for Improved Convergence and Exploration.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.max_quantum_factor = 0.1  # Increased for enhanced exploration\n        self.min_quantum_factor = 0.01\n        self.w_max = 0.9\n        self.w_min = 0.4\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget) + 0.5\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget) + 0.5\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.min_quantum_factor + (self.max_quantum_factor - self.min_quantum_factor) * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Self-adaptive inertia weight adjustment\n            self.initial_w = self.w_min + (self.w_max - self.w_min) * (1 - evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09122 with standard deviation 0.00239.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.093166748036287, 0.08785454328622799, 0.0926375378485983]}}
{"id": "0f686355-c17f-4859-8ba0-90c1c249a48c", "fitness": 0.0882501167228273, "name": "HybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Adaptive Quantum Jumps and Scaled Global Influence for Improved Convergence.", "code": "import numpy as np\n\nclass HybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.1  # Increased Quantum factor for more frequent stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * np.exp(-evals / self.budget)  # Exponential decay for quantum factor\n                if np.random.rand() < adaptive_qf:\n                    jump_size = np.random.normal(size=self.dim) * (ub - lb) / 5.0  # Scaled jump size\n                    particles[i] = np.clip(global_best + jump_size, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n        \n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm HybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08825 with standard deviation 0.00212.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.08623203512095934, 0.09118125779937458, 0.087337057248148]}}
{"id": "43aafbe7-3832-4b6e-9ed3-707da175530d", "fitness": 0.0925773848022694, "name": "EnhancedHybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Dynamic Quantum Jumps and Adaptive Learning for Improved Convergence Efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Enhanced adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * np.exp(-evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    jump_direction = (np.random.rand(self.dim) < 0.5).astype(int) * 2 - 1\n                    particles[i] = np.clip(global_best + jump_direction * np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for adaptive learning\n                if np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment and cooling schedule\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09258 with standard deviation 0.00339.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09602137074488426, 0.08797458715731432, 0.09373619650460963]}}
{"id": "f7954273-e358-4209-bbbc-ca2cd92b3d44", "fitness": 0.09603749176398368, "name": "EnhancedHybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO leveraging Adaptive Memory Structures and Quantum Communication for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n        self.memory_size = 5  # Memory to keep track of best solutions\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        memory = [global_best.copy() for _ in range(self.memory_size)]\n        memory_scores = [global_best_score for _ in range(self.memory_size)]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    memory_best = memory[np.argmin(memory_scores)]\n                    particles[i] = np.clip(memory_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best and memory\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n                    memory.pop()\n                    memory.insert(0, global_best.copy())\n                    memory_scores.pop()\n                    memory_scores.insert(0, global_best_score)\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09604 with standard deviation 0.00186.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.0979074426278177, 0.09670668440479857, 0.09349834825933478]}}
{"id": "55e70705-9210-4dee-bcf7-a65b57ab111c", "fitness": 0.09484355280287234, "name": "HybridQuantumPSO", "description": "Enhanced learning rate adaptation inspired by dynamic environmental feedback for improved convergence.", "code": "import numpy as np\n\nclass HybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * np.sin(np.pi * evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm HybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09484 with standard deviation 0.00078.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09426709067384043, 0.09431826892732365, 0.09594529880745295]}}
{"id": "96397043-c557-4446-ad95-3cf5dd89f18c", "fitness": 0.09482173192605255, "name": "EnhancedQuantumPSO", "description": "Enhanced Quantum-PSO with Dynamic Learning and Adaptive Quantum Jumps for Improved Convergence and Efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09482 with standard deviation 0.00098.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09612661956161628, 0.09375058909872436, 0.09458798711781702]}}
{"id": "08265050-a655-40f7-943e-3b4d5c9bf48b", "fitness": 0.09500861480787996, "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum-PSO with Enhanced Dynamic Swarming and Quantum Jumps for Improved Convergence and Solution Quality.", "code": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n        self.turbulence_factor = 0.1  # Factor for introducing turbulence in exploration\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Introduce turbulence for enhanced exploration\n                if np.random.rand() < self.turbulence_factor * (1 - evals / self.budget):\n                    particles[i] += np.random.normal(size=self.dim) * (ub - lb) * 0.1\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09501 with standard deviation 0.00137.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09572030304852097, 0.09309110627100092, 0.09621443510411798]}}
{"id": "e540d4ee-f6b4-443d-a187-dd35fe4a3039", "fitness": 0.09630484661646284, "name": "HybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Improved Dynamic Inertia Weight and Quantum Jump Frequency for Better Convergence.", "code": "import numpy as np\n\nclass HybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump with increased frequency\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget) * 1.2\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Dynamic neighborhood topology for learning\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: Adjusted rotational inertia weight\n            self.initial_w = 0.5 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm HybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09630 with standard deviation 0.00226.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09887785306590446, 0.09337086392630245, 0.09666582285718162]}}
{"id": "cb3252bc-4852-474c-abe1-76b27207de15", "fitness": 0.0931813741723494, "name": "EnhancedHybridQuantumPSO", "description": "Enhanced Hybrid Quantum-PSO with Adaptive Perturbation and Dynamic Neighborhood Exploration for Improved Convergence and Solution Quality.", "code": "import numpy as np\n\nclass EnhancedHybridQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05  # Quantum factor for stochastic jumps\n\n    def adaptive_population_size(self, evals):\n        return max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Adaptive quantum-inspired stochastic jump\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Enhanced dynamic neighborhood exploration\n                if np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    perturbation = np.random.normal(size=self.dim) * np.abs(personal_best[best_neighbor] - particles[i])\n                    particles[i] = np.clip(personal_best[best_neighbor] + perturbation, lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                # Update global best\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            # Dual adaptive mechanism: rotational inertia weight adjustment\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedHybridQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09318 with standard deviation 0.00300.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09422964968448821, 0.08910117512250726, 0.09621329771005271]}}
{"id": "8ebd10b5-2ca2-4d01-8392-cfd3c9003b07", "fitness": 0.09649447456744513, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum-PSO with Dynamic Topology and Multi-Scale Exploration for Improved Optimization Efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09649 with standard deviation 0.00227.", "error": "", "parent_ids": ["6d557f7f-4135-4857-9b02-1fd33d8bf444"], "operator": null, "metadata": {"aucs": [0.09916214261709566, 0.09671143397906368, 0.09360984710617604]}}
{"id": "916be348-2b45-40d0-9c81-01e325705a73", "fitness": 0.09459843806384109, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Quantum PSO with Dynamic Tuning and Gradient-Based Local Search for Superior Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 5.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n                if np.random.rand() < 0.1:\n                    gradient = np.random.normal(0, 1, self.dim)\n                    particles[i] -= self.scaling_factor * gradient\n                    particles[i] = np.clip(particles[i], lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09460 with standard deviation 0.00357.", "error": "", "parent_ids": ["8ebd10b5-2ca2-4d01-8392-cfd3c9003b07"], "operator": null, "metadata": {"aucs": [0.08965847102724622, 0.09796549172106384, 0.0961713514432132]}}
{"id": "fc56b88c-6b6e-431d-be12-efdff23355d1", "fitness": 0.09503162128476976, "name": "RefinedEnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum-PSO refined with a Self-Adjusting Temperature Mechanism and Improved Local Search for Enhanced Convergence.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temp_init = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n        self.temperature = self.temp_init\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def self_adjusting_temperature(self, evals):\n        return self.temp_init * (1 - (evals / self.budget)**2)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            self.temperature = self.self_adjusting_temperature(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - (evals / self.budget)**2)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * ((evals / self.budget)**2)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - (evals / self.budget)**2)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - (evals / self.budget)**2)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - (evals / self.budget)**2):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - (evals / self.budget)**2) * np.cos(np.pi * evals / self.budget)\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedEnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09503 with standard deviation 0.00281.", "error": "", "parent_ids": ["8ebd10b5-2ca2-4d01-8392-cfd3c9003b07"], "operator": null, "metadata": {"aucs": [0.09686567095036747, 0.09716408766568452, 0.09106510523825728]}}
{"id": "edb7a860-7add-4ade-9da2-f0b0061df77f", "fitness": 0.08887488453223473, "name": "EnhancedDynamicQuantumPSO", "description": "Enhanced Dynamic Quantum-PSO with Adaptive Quantum Factor and Neighborhood Learning for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 1.5  # Adjusted to balance exploration and exploitation\n        self.initial_c2 = 1.5  # Adjusted to balance exploration and exploitation\n        self.initial_w = 0.7   # Adjusted for better convergence\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Slightly increased for gradual temperature decrease\n        self.learning_rate = 0.15  # Increased for more aggressive neighborhood learning\n        self.quantum_factor = 0.07  # Enhanced quantum factor for exploration\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(20, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 5.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedDynamicQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08887 with standard deviation 0.00224.", "error": "", "parent_ids": ["8ebd10b5-2ca2-4d01-8392-cfd3c9003b07"], "operator": null, "metadata": {"aucs": [0.0881416271696418, 0.09190597051203175, 0.08657705591503062]}}
{"id": "bfb35030-dd6c-4250-83f3-185f91871daa", "fitness": 0.08907427462753303, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum-PSO with Dynamic Cooling and Strategic Memory for Superior Convergence.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 1.8\n        self.initial_c2 = 2.2\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.97\n        self.quantum_factor = 0.08\n        self.memory_factor = 0.05\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.memory_factor * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08907 with standard deviation 0.00434.", "error": "", "parent_ids": ["8ebd10b5-2ca2-4d01-8392-cfd3c9003b07"], "operator": null, "metadata": {"aucs": [0.08360577888052834, 0.0894079652255011, 0.09420907977656967]}}
{"id": "eba5cded-f414-41ef-aacb-44f8b3696053", "fitness": 0.09701415691200825, "name": "EnhancedAdaptiveQuantumPSO", "description": "Improved inertia weight adjustment for enhanced convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Adjusted inertia weight calculation\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09701 with standard deviation 0.00161.", "error": "", "parent_ids": ["8ebd10b5-2ca2-4d01-8392-cfd3c9003b07"], "operator": null, "metadata": {"aucs": [0.09888395718624499, 0.09721187816997534, 0.09494663537980441]}}
{"id": "8d76de88-5e03-44bf-8690-6e1acf85e898", "fitness": 0.08064532650077612, "name": "HybridQuantumSimulatedAnnealingPSO", "description": "Hybrid Quantum PSO with Simulated Annealing for enhanced exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass HybridQuantumSimulatedAnnealingPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.5\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.95\n        self.quantum_factor = 0.1\n        self.learning_rate = 0.05\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            temperature_factor = np.exp(-evals / self.budget) * self.temperature\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 * (1 + evals / (2 * self.budget))\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n\n                if np.random.rand() < self.quantum_factor:\n                    quantum_jump = np.random.normal(size=self.dim) * temperature_factor\n                    particles[i] = np.clip(global_best + quantum_jump, lb, ub)\n                else:\n                    particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm HybridQuantumSimulatedAnnealingPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08065 with standard deviation 0.00171.", "error": "", "parent_ids": ["eba5cded-f414-41ef-aacb-44f8b3696053"], "operator": null, "metadata": {"aucs": [0.07937243147687711, 0.07950784721370596, 0.08305570081174529]}}
{"id": "863c428b-7fea-42f1-b203-8fb501491160", "fitness": 0.09587376771843803, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced convergence by dynamically adjusting learning rate during iterations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Adjusted inertia weight calculation\n            self.temperature *= self.cooling_rate\n            self.learning_rate = 0.1 + 0.3 * (evals / self.budget)  # Adjusted learning rate dynamically\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09587 with standard deviation 0.00195.", "error": "", "parent_ids": ["eba5cded-f414-41ef-aacb-44f8b3696053"], "operator": null, "metadata": {"aucs": [0.09850832655568842, 0.09383745075622996, 0.09527552584339571]}}
{"id": "51496cd1-c066-42c0-92fc-e9399d3b32aa", "fitness": 0.09626598668656716, "name": "EnhancedAdaptiveQuantumPSO", "description": "Introduced a dynamic adaptation of the cognitive component to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                c1 += 0.1 * np.sin(np.pi * evals / self.budget)  # Dynamic adaptation of the cognitive component\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Adjusted inertia weight calculation\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09627 with standard deviation 0.00191.", "error": "", "parent_ids": ["eba5cded-f414-41ef-aacb-44f8b3696053"], "operator": null, "metadata": {"aucs": [0.09861871271794997, 0.09623662145365397, 0.09394262588809754]}}
{"id": "8b21acfe-60c9-4333-a2dc-acf7f4a0105d", "fitness": 0.0950963620128098, "name": "EnhancedAdaptiveQuantumPSO", "description": "Improved adaptive quantum factor to enhance diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget) * np.sin(np.pi * evals / (2 * self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Adjusted inertia weight calculation\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.00178.", "error": "", "parent_ids": ["eba5cded-f414-41ef-aacb-44f8b3696053"], "operator": null, "metadata": {"aucs": [0.09752027729099244, 0.09331601968430736, 0.0944527890631296]}}
{"id": "abf21b4c-b472-4aa8-b939-1f4758e83691", "fitness": 0.09755036032115842, "name": "EnhancedAdaptiveQuantumPSO", "description": "Introduced a self-adaptive mutation mechanism to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Self-adaptive mutation mechanism\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09755 with standard deviation 0.00179.", "error": "", "parent_ids": ["eba5cded-f414-41ef-aacb-44f8b3696053"], "operator": null, "metadata": {"aucs": [0.09768622485191125, 0.09529941315974211, 0.09966544295182189]}}
{"id": "b0852508-c161-4f82-a557-3fc3a273489c", "fitness": 0.09698776833831042, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced inertia weight adaptation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Self-adaptive mutation mechanism\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.sin(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09699 with standard deviation 0.00185.", "error": "", "parent_ids": ["abf21b4c-b472-4aa8-b939-1f4758e83691"], "operator": null, "metadata": {"aucs": [0.09649687127341844, 0.09500848574630649, 0.09945794799520635]}}
{"id": "623d69b5-0d91-4c84-b0e7-e4f9fdc94615", "fitness": 0.09755036032115842, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced the exploration-exploitation balance through dynamic learning rates and adaptive quantum factors for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                dynamic_learning_rate = self.learning_rate * (1 - evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Self-adaptive mutation mechanism\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                # Enhanced learning from neighbors with dynamic learning rate\n                if score > personal_best_scores[i] and np.random.rand() < dynamic_learning_rate:\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09755 with standard deviation 0.00179.", "error": "", "parent_ids": ["abf21b4c-b472-4aa8-b939-1f4758e83691"], "operator": null, "metadata": {"aucs": [0.09768622485191125, 0.09529941315974211, 0.09966544295182189]}}
{"id": "4f5562bc-ddb7-46f6-83ff-c868a44d0cfa", "fitness": 0.09755036032115842, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced exploration by introducing stochastic weight adjustment in the velocity update.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Self-adaptive mutation mechanism\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09755 with standard deviation 0.00179.", "error": "", "parent_ids": ["abf21b4c-b472-4aa8-b939-1f4758e83691"], "operator": null, "metadata": {"aucs": [0.09768622485191125, 0.09529941315974211, 0.09966544295182189]}}
{"id": "e756d301-880a-41e8-938d-dafa161f4320", "fitness": -Infinity, "name": "RefinedAdaptiveQuantumPSO", "description": "Enhanced exploration with dynamic learning rate and adaptive mutation strength based on evaluation progression.", "code": "import numpy as np\n\nclass RefinedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.base_learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def adaptive_learning_rate(self, evals):\n        return self.base_learning_rate * (1 + 0.5 * np.sin(np.pi * evals / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            learning_rate = self.adaptive_learning_rate(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                # Refined self-adaptive mutation mechanism\n                mutation_strength = (ub - lb) / 20.0 * (1 - evals / self.budget)\n                if np.random.rand() < mutation_strength:\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < learning_rate:\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["abf21b4c-b472-4aa8-b939-1f4758e83691"], "operator": null, "metadata": {}}
{"id": "eacfba16-daac-43e7-8a40-56368358e967", "fitness": 0.09778167781840696, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Neighborhood Learning improves convergence by dynamically learning from neighboring particles.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09778 with standard deviation 0.00147.", "error": "", "parent_ids": ["abf21b4c-b472-4aa8-b939-1f4758e83691"], "operator": null, "metadata": {"aucs": [0.09779556008136026, 0.09597866622209061, 0.09957080715177002]}}
{"id": "698d2440-f283-46c9-ae2c-78898b3c6bf3", "fitness": 0.09531931867372863, "name": "QuantumEnhancedDynamicSwarmOptimization", "description": "Quantum-Enhanced Dynamic Swarm Optimization with Adaptive Learning balances exploration and exploitation by integrating adaptive learning rates and quantum perturbations.", "code": "import numpy as np\n\nclass QuantumEnhancedDynamicSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.base_learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.velocity_scaling_factor = 0.6\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = self.velocity_scaling_factor * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                adaptive_learning_rate = self.base_learning_rate * np.exp(-evals/self.budget)\n                if score > personal_best_scores[i] and np.random.rand() < adaptive_learning_rate:\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm QuantumEnhancedDynamicSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09532 with standard deviation 0.00346.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09045795107989552, 0.09822334390126874, 0.09727666104002164]}}
{"id": "f4653274-d084-4e10-9b49-4ff91384cb25", "fitness": 0.0694488785727904, "name": "ImprovedQuantumPSO", "description": "Improved Quantum PSO with Dynamic Neighborhood and Adaptive Inertia enhances exploration and exploitation through adaptive inertia weight adjustment, quantum perturbation, and dynamic neighborhood learning.", "code": "import numpy as np\n\nclass ImprovedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.quantum_factor = 0.05\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n            for i in range(self.initial_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < self.quantum_factor:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 20.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate:\n                    new_neighbors = np.random.choice(range(self.initial_population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm ImprovedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06945 with standard deviation 0.00782.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.0763640139205296, 0.07345958137719477, 0.05852304042064682]}}
{"id": "30074cd7-dbec-4fe4-bb55-ae32f69df3ce", "fitness": 0.0960684075729094, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Adaptive Learning Rate allows for finer control of convergence by adjusting learning rate based on progress.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.learning_rate = 0.05 + 0.15 * (1 - evals / self.budget)  # Adjusted learning rate\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09607 with standard deviation 0.00209.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09394414234227622, 0.09534426862870415, 0.0989168117477478]}}
{"id": "7db51f0d-eab8-4444-81cf-ff5ffe536472", "fitness": 0.09777959402418779, "name": "EnhancedAdaptiveQuantumPSO", "description": "Improved Adaptive Quantum PSO with Dynamic Neighborhood and Temperature-Based Mutation for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength * (self.temperature / 100)\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09778 with standard deviation 0.00162.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09770267095271279, 0.0958318577594286, 0.09980425336042198]}}
{"id": "d3548825-8673-4dc2-af8e-f4fbda7b31e2", "fitness": 0.09774875842752777, "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood Search optimizes convergence through refined quantum exploration and adaptive velocity learning.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.quantum_factor = 0.05\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09775 with standard deviation 0.00147.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09769680190872265, 0.09597866622209061, 0.09957080715177002]}}
{"id": "4554d992-28b9-41c3-9ef1-2cc342bd6308", "fitness": 0.097767955741356, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Temperature-Sensitive Quantum Factor refines the balance between exploration and exploitation by adapting the quantum factor based on temperature.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (self.temperature / 100.0)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09777 with standard deviation 0.00160.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09757550589917041, 0.09591581854510933, 0.09981254277978824]}}
{"id": "7fa3e7a6-460f-4470-8f9a-6b067fd0bca0", "fitness": 0.09668216664601799, "name": "QuantumInspiredAdaptivePSO", "description": "Quantum-Inspired Adaptive PSO integrates quantum behavior with dynamic neighborhood and mutation strategies; improves exploration and convergence balance.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.2\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * 0.5 * (1 + np.cos(np.pi * evals / self.budget))\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    exploration_magnitude = np.sin(np.pi * evals / self.budget)\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * exploration_magnitude * (ub - lb) / 10.0, lb, ub)\n                \n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm QuantumInspiredAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09668 with standard deviation 0.00053.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09666734739073646, 0.09603753848647167, 0.09734161406084585]}}
{"id": "54aab874-70f1-4a55-a85a-0c6227592943", "fitness": 0.09778167781840696, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Neighborhood Learning improves convergence by dynamically learning from neighboring particles with an adaptive cooling rate for temperature.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate * (1 - evals / self.budget)  # Adaptive cooling rate change\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09778 with standard deviation 0.00147.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09779556008136026, 0.09597866622209061, 0.09957080715177002]}}
{"id": "3e65599d-6172-4684-a2e4-472cbd75cc94", "fitness": 0.09541196945832604, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Neighborhood Learning further improves convergence by adjusting the velocity scaling factor dynamically based on the current temperature.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * (1 - self.temperature / 100.0) * (1 - evals / self.budget)  # Adjusted line\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09541 with standard deviation 0.00148.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09461724372321367, 0.09748350786190019, 0.09413515678986428]}}
{"id": "c8e283c1-780d-4e3d-ac2a-0e319b7825dd", "fitness": 0.09245410448176272, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Dynamic Quantum PSO with Improved Velocity Update enhances exploration by introducing cosine-based velocity scaling.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.cos(np.pi * evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09245 with standard deviation 0.00378.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09656696733032555, 0.0933493522631067, 0.08744599385185592]}}
{"id": "af2e0ea9-78ee-4599-84ae-b706beb1bba2", "fitness": 0.08976096392143618, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Optimized Velocity Perturbation for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                velocities[i] *= np.random.uniform(0.8, 1.2)  # New perturbation\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08976 with standard deviation 0.00360.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09382244490136027, 0.08507863107850244, 0.09038181578444582]}}
{"id": "92a7157b-f3ad-45c7-b184-909fcfebc981", "fitness": 0.09619507693156726, "name": "EnhancedAdaptiveQuantumPSO", "description": "Improved Adaptive Quantum PSO with Selective Mutation employs selective mutation based on fitness variance to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                fitness_variance = np.var(personal_best_scores[:population_size])\n                if np.random.rand() < (1 - evals / self.budget) * (fitness_variance / (fitness_variance + 1)):\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09620 with standard deviation 0.00094.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09730944484421389, 0.09500113963173296, 0.09627464631875493]}}
{"id": "64ad06be-7db1-4402-b8e6-996735c6b477", "fitness": 0.09706351114692553, "name": "EnhancedAdaptiveQuantumPSO", "description": "Slightly adjusted the mutation strategy to enhance exploration by introducing a sinusoidal component in mutation strength.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget) * (1 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09706 with standard deviation 0.00195.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09692466314511694, 0.09474453486227041, 0.09952133543338926]}}
{"id": "1342db4e-2310-4d7e-b169-877e48d0219b", "fitness": 0.09733576778194153, "name": "EnhancedAdaptiveQuantumPSO", "description": "Introduced a non-linear dynamic adjustment to the inertia weight for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * np.sin(np.pi * evals / self.budget)  # Updated line\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09734 with standard deviation 0.00093.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.0973625080811229, 0.09617895407391375, 0.09846584119078794]}}
{"id": "60be0045-9683-4a37-a1fd-411602663658", "fitness": 0.095674646300882, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with improved velocity update boosts exploration by introducing a random scaling factor in the velocity update.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)  # Added r3\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                random_scaling = 0.5 + 0.5 * np.random.rand()  # New Random scaling factor\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling * random_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09567 with standard deviation 0.00040.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09515986922726005, 0.09571556239842194, 0.096148507276964]}}
{"id": "14d652f0-d4ac-4ce0-9d7b-9eeb2a600bb1", "fitness": 0.07342021205424865, "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired PSO with Neighborhood-Based Perturbation refines convergence by incorporating adaptive particle influence and strategic perturbations.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.0\n        self.c2_initial = 2.0\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.learning_rate = 0.1\n        self.quantum_factor_initial = 0.1\n        self.quantum_factor_final = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(size=(self.population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.population_size\n\n        while evals < self.budget:\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - evals / self.budget)\n            c1 = self.c1_initial * (1 - evals / self.budget)\n            c2 = self.c2_initial + (2.0 - self.c2_initial) * (evals / self.budget)\n            quantum_factor = self.quantum_factor_final + (self.quantum_factor_initial - self.quantum_factor_final) * (1 - evals / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < quantum_factor:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n                \n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    neighbors = np.random.choice(range(self.population_size), 3, replace=False)\n                    best_neighbor = min(neighbors, key=lambda n: personal_best_scores[n])\n                    perturbation = np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i])\n                    particles[i] = np.clip(personal_best[best_neighbor] + perturbation, lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07342 with standard deviation 0.00711.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.08291654280270266, 0.07153834471985865, 0.06580574864018462]}}
{"id": "75bf9c30-c508-4237-b221-80c8144836b5", "fitness": 0.0882776152939287, "name": "DynamicHierarchicalAdaptivePSO", "description": "Dynamic Hierarchical Adaptive PSO with Randomized Quantum Adaptation optimizes convergence by leveraging hierarchical learning and randomized quantum effects.", "code": "import numpy as np\n\nclass DynamicHierarchicalAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 1.5\n        self.initial_c2 = 1.5\n        self.initial_w = 0.8\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.hierarchy_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def hierarchical_learning(self, particles, personal_best, personal_best_scores, evals):\n        if np.random.rand() < self.hierarchy_factor * (1 - evals / self.budget):\n            best_indices = np.argsort(personal_best_scores)[:3]\n            for i in range(len(particles)):\n                particles[i] = np.mean(personal_best[best_indices], axis=0)\n        return particles\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            particles = self.hierarchical_learning(particles, personal_best, personal_best_scores, evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 self.initial_c1 * r1 * (personal_best[i] - particles[i]) +\n                                 self.initial_c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < self.quantum_factor:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicHierarchicalAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08828 with standard deviation 0.00421.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.08969764495114074, 0.08255675650775363, 0.09257844442289176]}}
{"id": "a52aeb9b-8974-46ea-a01b-c31e25f48b60", "fitness": 0.09778167781840696, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Precision Control uses adaptive precision and dynamic neighborhood learning to improve convergence and precision as the search progresses.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n        self.precision_factor = 0.02  # New parameter for dynamic precision\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09778 with standard deviation 0.00147.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09779556008136026, 0.09597866622209061, 0.09957080715177002]}}
{"id": "43d1627e-fd26-4662-9255-2f683dc40c20", "fitness": 0.09205829331880515, "name": "QuantumInspiredMultiSwarmPSO", "description": "Quantum-Inspired Multi-Swarm PSO with Dynamic Topology and Adaptive Mutation improves exploration and exploitation through dynamic swarm interactions and adaptive mutation strategies.", "code": "import numpy as np\n\nclass QuantumInspiredMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.quantum_factor = 0.1\n        self.mutation_rate = 0.1\n        self.alpha = 0.5\n        self.beta = 0.9\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            adaptive_qf = self.quantum_factor * (1 - evals / self.budget)\n            adaptive_mutation = self.mutation_rate * (1 - evals / self.budget)\n            \n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - (evals / self.budget) ** self.alpha)\n                c2 = self.initial_c2 * ((evals / self.budget) ** self.beta)\n                \n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * (0.5 + 0.5 * np.random.rand())\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < adaptive_mutation:\n                    mutation_strength = (ub - lb) / 10.0 * (1 - evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.4 + 0.5 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm QuantumInspiredMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09206 with standard deviation 0.00101.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09121707220850706, 0.0914780528714676, 0.09347975487644078]}}
{"id": "da6ca68b-9c6c-4fa4-a9b4-652c8a617f1f", "fitness": 0.09042476783078486, "name": "DynamicQuantumInspiredPSO", "description": "Dynamic Quantum-Inspired PSO with Adaptive Learning Rate leverages dynamically adjusted quantum factors and adaptive mutation rates for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / (2 * self.budget))\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / (2 * self.budget))\n                velocity_scaling = 0.4 + 0.6 * np.random.rand()\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * np.cos(np.pi * evals / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                mutation_strength = (ub - lb) / 20.0 * np.exp(-evals / self.budget)\n                particles[i] += np.random.randn(self.dim) * mutation_strength\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * np.cos(np.pi * evals / self.budget)\n            self.initial_c1 *= self.cooling_rate\n            self.initial_c2 *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm DynamicQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09042 with standard deviation 0.00359.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.0883180837166252, 0.09547679812326282, 0.08747942165246658]}}
{"id": "ddee614d-305b-470c-abf8-f22d81654cc0", "fitness": 0.09783223515235943, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Neighborhood Learning improves convergence by adjusting the quantum factor based on exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))  # Modified line\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09783 with standard deviation 0.00160.", "error": "", "parent_ids": ["eacfba16-daac-43e7-8a40-56368358e967"], "operator": null, "metadata": {"aucs": [0.09764826986782182, 0.0959750429819437, 0.09987339260731276]}}
{"id": "530624a2-91ef-42ec-b32d-84b932d76201", "fitness": 0.0928250195425887, "name": "ImprovedAdaptiveQuantumPSO", "description": "Improved Adaptive Quantum PSO with Multi-phase Exploration integrates adaptive population resizing and phase-based exploration to enhance global and local search efficiency dynamically.", "code": "import numpy as np\n\nclass ImprovedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            exploration_phase = evals < self.budget * 0.5\n            \n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if exploration_phase:\n                    if np.random.rand() < 0.5:\n                        particles[i] += np.random.normal(loc=0, scale=0.1 * (ub - lb), size=self.dim)\n                        particles[i] = np.clip(particles[i], lb, ub)\n\n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm ImprovedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09283 with standard deviation 0.00117.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.0915910820869359, 0.09440394826797027, 0.09248002827285995]}}
{"id": "f9bbd790-8e43-490b-8f4b-72edded85f45", "fitness": 0.09624451422165836, "name": "EnhancedAdaptiveQuantumPSO", "description": "Adjusted dynamic neighborhood learning mechanism to prefer better-performing particles for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n]) if np.random.rand() < 0.7 else max(new_neighbors, key=lambda n: personal_best_scores[n])  # Modified line\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09624 with standard deviation 0.00224.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09636224626085188, 0.0934483868308651, 0.09892290957325811]}}
{"id": "6703ba27-dcdf-4f3c-afba-8eecd035cfdd", "fitness": 0.09467330885741891, "name": "QuantumGuidedAdaptivePSO", "description": "Quantum-Guided Adaptive PSO enhances convergence by leveraging dynamic quantum factors, adaptive mutation strengths, and population diversity control for efficient exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumGuidedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * ((self.budget - evals) / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm QuantumGuidedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09467 with standard deviation 0.00091.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09355351264758716, 0.09468832374411684, 0.09577809018055272]}}
{"id": "f887fea9-9eed-4d88-838b-f87527206e29", "fitness": 0.09783223515235943, "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood and Perturbation Adjusts quantum factor and introduces perturbations based on convergence rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    perturbation = np.random.normal(size=self.dim) * (ub - lb) / 10.0\n                    particles[i] = np.clip(global_best + perturbation, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09783 with standard deviation 0.00160.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09764826986782182, 0.0959750429819437, 0.09987339260731276]}}
{"id": "2a3d7fc4-1c31-4fe9-944a-5bd86a796deb", "fitness": 0.09321956459826253, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Improved Mutation Strategy enhances diversity by refining mutation strength scaling based on the convergence rate.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))  # Modified line\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * np.log(evals + 1) / np.log(self.budget + 1)  # Modified line\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09322 with standard deviation 0.00152.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09108423969140922, 0.09407149179407004, 0.09450296230930832]}}
{"id": "a97b2481-c30b-4ca3-8c3d-56386878579d", "fitness": 0.09398960660499293, "name": "EnhancedAdaptiveQuantumPSO", "description": "Enhanced Adaptive Quantum PSO with Dynamic Neighborhood updates by introducing non-linear velocity scaling for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (np.sin(np.pi * evals / self.budget))  # Modified line\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.00273.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09524004457319779, 0.09019883361012271, 0.09652994163165829]}}
{"id": "3e6e65a7-5210-4712-bb49-5254302b33a9", "fitness": 0.09770235086532138, "name": "QuantumInspiredAdaptivePSO", "description": "Quantum-Inspired Adaptive PSO with Sigmoid-based Dynamic Quantum Factor utilizes a sigmoid function to adjust quantum factor dynamically for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * self.sigmoid((self.budget - 2 * evals) / self.budget)\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (evals / self.budget)\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm QuantumInspiredAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09770 with standard deviation 0.00170.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09780015645865581, 0.09557006005553503, 0.0997368360817733]}}
{"id": "8a2665c8-35b2-4f5a-9e85-48ca1bfb4a6f", "fitness": 0.0953748117204289, "name": "EnhancedAdaptiveQuantumPSO", "description": "Improved convergence by dynamically adjusting mutation strength based on inverse cosine function of evaluations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 1.0\n        self.initial_w = 0.9\n        self.temperature = 100.0\n        self.cooling_rate = 0.98\n        self.learning_rate = 0.1\n        self.quantum_factor = 0.05\n        self.scaling_factor = 0.1\n\n    def adaptive_population_size(self, evals):\n        return max(10, int(self.initial_population_size * (1 - evals / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        particles = np.random.uniform(low=lb, high=ub, size=(self.initial_population_size, self.dim))\n        velocities = np.random.uniform(size=(self.initial_population_size, self.dim)) * (ub - lb) / 20.0\n        personal_best = particles.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals += self.initial_population_size\n\n        while evals < self.budget:\n            population_size = self.adaptive_population_size(evals)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = self.initial_c1 * (1 - evals / self.budget)\n                c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evals / self.budget)\n                velocity_scaling = 0.4 + 0.6 * np.random.rand() * (1 - evals / self.budget)\n                velocities[i] = (self.initial_w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i])) * velocity_scaling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                adaptive_qf = self.quantum_factor * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                if np.random.rand() < adaptive_qf:\n                    particles[i] = np.clip(global_best + np.random.normal(size=self.dim) * (ub - lb) / 10.0, lb, ub)\n\n                if np.random.rand() < (1 - evals / self.budget):\n                    mutation_strength = (ub - lb) / 20.0 * (1 - np.cos(np.pi * evals / self.budget))  # Modified line\n                    particles[i] += np.random.randn(self.dim) * mutation_strength\n                    particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n                if score < personal_best_scores[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_scores[i] = score\n\n                if score > personal_best_scores[i] and np.random.rand() < self.learning_rate * (1 - evals / self.budget):\n                    new_neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    best_neighbor = min(new_neighbors, key=lambda n: personal_best_scores[n])\n                    particles[i] = np.clip(personal_best[best_neighbor] + np.random.randn(self.dim) * 0.5 * np.abs(personal_best[best_neighbor] - particles[i]), lb, ub)\n                    score = func(particles[i])\n                    evals += 1\n\n                if score < global_best_score:\n                    global_best = particles[i]\n                    global_best_score = score\n\n            self.initial_w = 0.5 + 0.4 * (1 - evals / self.budget) * np.cos(np.pi * evals / self.budget)\n            self.temperature *= self.cooling_rate\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09537 with standard deviation 0.00228.", "error": "", "parent_ids": ["ddee614d-305b-470c-abf8-f22d81654cc0"], "operator": null, "metadata": {"aucs": [0.09424680260148566, 0.09332483978308115, 0.09855279277671991]}}
