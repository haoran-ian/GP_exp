{"id": "59de2180-49d4-4633-a8d6-3975dc027204", "fitness": 0.09754473795076501, "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution for adaptive exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09754 with standard deviation 0.05000.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.160455944747531, 0.1759809542240467, 0.15977297271196889, 0.08594193586186327, 0.08206468320200311, 0.06461351546265959, 0.06077630543966461, 0.045794752285889806, 0.04250157762125817]}}
{"id": "fce3b875-8adb-49fa-b2c5-d89c9cee3b91", "fitness": 0.09317377514677197, "name": "HybridPSODE", "description": "Enhanced HybridPSODE using dynamic inertia weight and elitism for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed initial inertia_weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - eval_count) / self.budget  # Dynamic inertia_weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        elitism_selection = np.argsort(personal_best_scores)[:self.population_size // 10]  # Added elitism\n        return global_best_position, global_best_score, personal_best_positions[elitism_selection]  # Return elite solutions", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09317 with standard deviation 0.04799.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15148303740372737, 0.1674766978781307, 0.15312557518715275, 0.08654358052299338, 0.07940004781166177, 0.06405898713285352, 0.05897399794210845, 0.034350483559674294, 0.043151568882645486]}}
{"id": "278f048e-283a-4f29-917f-a1e0d436b005", "fitness": 0.08963679291556267, "name": "AdaptiveHybridPSODE", "description": "Adaptive Hybrid PSODE with dynamic parameter tuning and elitism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.elite_fraction = 0.1  # Fraction of elites in the population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update inertia weight dynamically\n            self.inertia_weight = 0.4 + (0.5 * (self.budget - eval_count) / self.budget)\n            \n            # Sort population by personal best scores and retain elites\n            elite_count = max(1, int(self.elite_fraction * self.population_size))\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elites = personal_best_positions[elite_indices]\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Replace worst solutions with elites\n            worst_indices = np.argsort(personal_best_scores)[-elite_count:]\n            population[worst_indices] = elites\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08964 with standard deviation 0.04967.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.1662395327868872, 0.14582046937979887, 0.08594193586186327, 0.08392848604595482, 0.066088362037798, 0.04980206557582467, 0.026405787363450894, 0.03213240735328349]}}
{"id": "d77c2fec-bc01-47f4-8c64-41e126a17ca9", "fitness": 0.08686299157970111, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameter tuning and chaotic initialization for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_weight_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization using Logistic Map\n        chaotic_seq = np.random.rand(self.population_size, self.dim)\n        chaotic_seq = 4 * chaotic_seq * (1 - chaotic_seq)\n        population = lb + (ub - lb) * chaotic_seq\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight *= self.inertia_weight_decay\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08686 with standard deviation 0.04465.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.14372401511231891, 0.14983300329210303, 0.1485010063520621, 0.06385832450300111, 0.07234968779049267, 0.07668934297846375, 0.037238015096463184, 0.037743236945346204, 0.05183029214705903]}}
{"id": "793b518f-b336-435f-b679-fc38638779d0", "fitness": 0.09001191914643097, "name": "HybridPSODE", "description": "An enhanced PSO-DE hybrid with adaptive parameter tuning and chaotic initialization for improved convergence in black box optimization.  ", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim) * np.sin(np.linspace(0, np.pi, self.population_size)[:, None])\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09001 with standard deviation 0.04451.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15145308143401837, 0.14104692631413496, 0.15873892612071416, 0.0649599798116659, 0.08214669473966107, 0.07204139588606862, 0.047899351781964805, 0.04100919721855867, 0.05081171901109216]}}
{"id": "a91021fa-da94-4174-9488-d3a740d2c0ed", "fitness": 0.09403049085112081, "name": "HybridPSODE", "description": "A dynamic hybrid metaheuristic integrating Particle Swarm Optimization, Differential Evolution, and adaptive inertia weight tuning for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia weight for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight decay\n            self.inertia_weight *= self.inertia_decay\n            self.inertia_weight = max(0.4, self.inertia_weight)  # Ensure it doesn't go below 0.4\n\n            # PSO Component with adaptive inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09403 with standard deviation 0.04506.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15400538671451391, 0.16610614381970956, 0.14277874325208884, 0.08594193586186327, 0.08514698758135542, 0.06631176201099753, 0.0484513595801187, 0.04572646711301531, 0.05180563172642472]}}
{"id": "dd5f8f56-0f3c-471e-b24c-f7bef776baa0", "fitness": 0.09379010267107475, "name": "HybridPSODE", "description": "An enhanced hybrid of Particle Swarm Optimization and Differential Evolution introducing adaptive parameters to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.729  # Changed to improve convergence\n        self.cognitive_coeff = 1.49445  # Adjusted for better exploration\n        self.social_coeff = 1.49445  # Adjusted for better exploitation\n        self.mutation_factor = 0.9  # Increased for better diversity\n        self.crossover_rate = 0.95  # Increased for more trial acceptance\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09379 with standard deviation 0.04586.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15160158399266543, 0.16610614381970956, 0.14210033104815767, 0.08594193586186327, 0.07940004781166177, 0.07989049469397769, 0.0670148249360174, 0.045331786862516266, 0.026723775013103745]}}
{"id": "8fbc20c9-9237-434a-b4b6-7c361fdf6f8a", "fitness": 0.09751685827786293, "name": "HybridPSODEPlus", "description": "HybridPSODE+: Enhancing exploration with adaptive parameters and global information sharing for robust black box optimization.", "code": "import numpy as np\n\nclass HybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coeff_initial = 2.0\n        self.cognitive_coeff_final = 1.0\n        self.social_coeff_initial = 2.0\n        self.social_coeff_final = 1.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia and coefficients\n            inertia_weight = self.inertia_weight_initial - (\n                (self.inertia_weight_initial - self.inertia_weight_final) * eval_count / self.budget\n            )\n            cognitive_coeff = self.cognitive_coeff_initial - (\n                (self.cognitive_coeff_initial - self.cognitive_coeff_final) * eval_count / self.budget\n            )\n            social_coeff = self.social_coeff_initial - (\n                (self.social_coeff_initial - self.social_coeff_final) * eval_count / self.budget\n            )\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          cognitive_coeff * r1 * (personal_best_positions - population) +\n                          social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with global information sharing\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                \n                # Introduce global information\n                if np.random.rand() < 0.5:\n                    mutant += 0.1 * (global_best_position - mutant)\n                \n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09752 with standard deviation 0.04455.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15206600435800754, 0.08834468425518205, 0.09040111493319725, 0.08175846318111746, 0.05577564358136211, 0.04186731367505103, 0.05096026686193644]}}
{"id": "d5c7fc60-0a12-404d-bffe-910601063e87", "fitness": 0.09284743128061611, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE integrates adaptive inertia and mutation strategies to dynamically balance exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.49618\n        self.social_coeff = 1.49618\n        self.initial_mutation_factor = 0.9\n        self.final_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Calculate adaptive inertia weight and mutation factor\n            inertia_weight = self.initial_inertia_weight - (\n                self.initial_inertia_weight - self.final_inertia_weight) * (eval_count / self.budget)\n            mutation_factor = self.initial_mutation_factor - (\n                self.initial_mutation_factor - self.final_mutation_factor) * (eval_count / self.budget)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09285 with standard deviation 0.04558.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1438375086694309, 0.08594193586186327, 0.07940004781166177, 0.06408527964555899, 0.06607258210805644, 0.035307564137549985, 0.04450372963651117]}}
{"id": "f5cd939f-8bad-46de-b4f0-a70bcf673780", "fitness": 0.09515815888042507, "name": "HybridPSODE", "description": "Enhanced HybridPSODE by integrating adaptive parameter tuning and elite preservation strategies for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                self.mutation_factor = 0.8 - 0.5 * (eval_count / self.budget)  # Adaptive DE mutation factor\n                self.inertia_weight = 0.9 - 0.4 * (eval_count / self.budget)  # Adaptive PSO inertia weight\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Elite Preservation\n            elite_idx = np.argmin(personal_best_scores)\n            population[elite_idx] = global_best_position  # Preserve elite in population\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09516 with standard deviation 0.04896.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15701809175900672, 0.16721705308858315, 0.16011233075985787, 0.08594193586186327, 0.07940004781166177, 0.06862917597111917, 0.05120353728003779, 0.046440423164210154, 0.04046083422748581]}}
{"id": "a707730a-5b7b-4b84-b339-11777694ed17", "fitness": 0.09125481378193562, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and dynamic population management for improved convergence efficiency in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            self.inertia_weight *= 0.99  # Adaptive reduction\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with Dynamic Population\n            new_population = []\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                \n                new_population.append(trial)\n\n            # Dynamic population adjustment\n            if eval_count < self.budget and len(new_population) < self.population_size:\n                additional = self.population_size - len(new_population)\n                new_population.extend(np.random.uniform(lb, ub, (additional, self.dim)))\n\n            population = np.array(new_population)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09125 with standard deviation 0.05149.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.1528417896961327, 0.16610614381970956, 0.1583470933001121, 0.08617857283084651, 0.08260928906700304, 0.064891348854759, 0.04980206557582467, 0.028384613539749415, 0.03213240735328349]}}
{"id": "ffdee526-c185-4e97-a7c0-c6e8381f32d7", "fitness": 0.09645224389928514, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE: Introducing adaptive parameters and chaotic maps to improve exploration-exploitation balance and convergence speed in hybrid Particle Swarm Optimization and Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def chaotic_sequence(self, length):\n        sequence = np.empty(length)\n        sequence[0] = np.random.rand()\n        for i in range(1, length):\n            sequence[i] = 4.0 * sequence[i-1] * (1.0 - sequence[i-1])\n        return sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        chaos = self.chaotic_sequence(self.population_size)\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia_weight *= 0.99\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Adaptive DE Component with Chaotic Map\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                chaotic_factor = chaos[i] * self.mutation_factor\n                mutant = np.clip(x1 + chaotic_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09645 with standard deviation 0.04244.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15393224601710076, 0.16610614381970956, 0.1417131137614075, 0.08594193586186327, 0.08069143741199314, 0.06169836279835783, 0.06068967596686936, 0.07101263591092344, 0.04628464354534134]}}
{"id": "74942b89-0b0f-458e-a418-f87a3459b921", "fitness": 0.09449563090672315, "name": "HybridMetaOpt", "description": "HybridMetaOpt: An enhanced hybrid metaheuristic integrating adaptive Particle Swarm Optimization and Differential Evolution with dynamic parameter tuning for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridMetaOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_damping = 0.99\n        self.mutation_damping = 0.995\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with dynamic inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia_weight * self.velocities +\n                               self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                               self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + self.velocities, lb, ub)\n\n            # DE Component with dynamic mutation factor\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Update parameters dynamically\n            self.inertia_weight *= self.inertia_damping\n            self.mutation_factor *= self.mutation_damping\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm HybridMetaOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09450 with standard deviation 0.04770.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.16551091590737188, 0.16903743852290365, 0.1418133740301496, 0.08594193586186327, 0.07940004781166177, 0.06352314136907267, 0.04782562947364366, 0.046774584420799514, 0.0506336107630424]}}
{"id": "1efc074a-869f-46a1-ad7e-cf35f5671d4e", "fitness": 0.09345869673166737, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic incorporating momentum-based adaptive inertia and dynamic crossover rate for enhanced exploration-exploitation in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Adjusted for momentum-based approach\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            dynamic_crossover_rate = 0.5 + 0.5 * np.random.rand()  # Dynamic crossover rate\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09346 with standard deviation 0.04549.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.15146635617106485, 0.16610614381970956, 0.14466096727207234, 0.08594193586186327, 0.07940004781166177, 0.06902054047485762, 0.051857103365384405, 0.03342780416930158, 0.059247371639090995]}}
{"id": "dcd186d2-0011-4ba5-aa5f-90ecf6236178", "fitness": 0.09427874673216917, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and dynamic mutation factor to improve convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            \n            self.inertia_weight *= 0.99  # Adaptive inertia weight\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        self.mutation_factor *= 0.95  # Dynamic mutation factor adjustment\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09428 with standard deviation 0.04663.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15643279145115907, 0.08594193586186327, 0.0810009177535389, 0.058714896100893865, 0.050074605263422, 0.04922801887627237, 0.050637321627460596]}}
{"id": "ea8adc7b-46cf-46d1-92cd-9f8073a86f94", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and dynamic population for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.inertia_damp = 0.99\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.dynamic_pop = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight *= self.inertia_damp\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            new_population = []\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                new_population.append(trial if trial_score < personal_best_scores[i] else population[i])\n\n                if eval_count >= self.budget:\n                    break\n\n            if self.dynamic_pop and eval_count + self.population_size < self.budget:\n                population_size_increase = min(10, self.budget - eval_count)\n                new_individuals = np.random.uniform(lb, ub, (population_size_increase, self.dim))\n                population = np.vstack((np.array(new_population), new_individuals))\n                velocities = np.vstack((velocities, np.zeros((population_size_increase, self.dim))))\n                personal_best_positions = np.vstack((personal_best_positions, new_individuals))\n                personal_best_scores = np.append(personal_best_scores, [func(ind) for ind in new_individuals])\n                eval_count += population_size_increase\n            else:\n                population = np.array(new_population)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (100,10) (110,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (100,10) (110,10) ')", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {}}
{"id": "75dbf803-a6a6-423b-a186-a5c76ca43024", "fitness": 0.1116736335928105, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7  # Changed from 0.5 to 0.7\n        self.cognitive_coeff = 2.0  # Changed from 1.5 to 2.0\n        self.social_coeff = 1.7  # Changed from 1.5 to 1.7\n        self.mutation_factor = 0.9  # Changed from 0.8 to 0.9\n        self.crossover_rate = 0.95  # Changed from 0.9 to 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11167 with standard deviation 0.08931.", "error": "", "parent_ids": ["59de2180-49d4-4633-a8d6-3975dc027204"], "operator": null, "metadata": {"aucs": [0.3303541101155314, 0.16610614381970956, 0.15488090735419402, 0.08594193586186327, 0.07940004781166177, 0.061575977381685965, 0.05989556068309354, 0.03192436488618344, 0.034983654421371635]}}
{"id": "f3c1d293-d770-43c9-b2f5-2980582f3451", "fitness": 0.0898943980508938, "name": "EnhancedHybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization, Differential Evolution, and a dynamic adaptive mechanism to balance exploration and exploitation for improved convergence on black box optimization problems.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (iteration / max_iterations)\n            \n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            iteration += 1\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08989 with standard deviation 0.05247.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1587832987462633, 0.16610614381970956, 0.1518797825901892, 0.08594193586186327, 0.07940004781166177, 0.06491810244248508, 0.03295260820771073, 0.045866092506973155, 0.023201570471188204]}}
{"id": "2d7e84fc-bc50-455d-95a1-bf40401ea17f", "fitness": 0.09038784908660431, "name": "AdvancedHybridPSODE", "description": "A novel extension of HybridPSODE introducing dynamic inertia weight adjustment and elite selection to enhance exploration-exploitation balance and convergence speed in black box optimization.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.inertia_min = 0.4  # Minimum inertia weight\n        self.inertia_max = 0.9  # Maximum inertia weight\n        self.cognitive_coeff = 2.05\n        self.social_coeff = 1.95\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with elite selection\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09039 with standard deviation 0.04876.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15437077533701082, 0.16610614381970956, 0.14152690030160886, 0.08594193586186327, 0.07940004781166177, 0.07415958116554167, 0.04522558925534881, 0.030902557030720423, 0.03585711119597368]}}
{"id": "8af9745f-6a07-4e3a-be69-932fbe03443d", "fitness": 0.09060481594669305, "name": "ImprovedHybridPSODE", "description": "A refined hybrid metaheuristic integrating Particle Swarm Optimization and Differential Evolution with adaptive parameter tuning based on convergence feedback to enhance performance in black box optimization.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.inertia_damping = 0.99  # New: Damping factor for inertia weight\n        self.adaptive_threshold = 0.05  # New: Convergence threshold for adaptivity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        last_global_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # Adaptive parameter adjustment based on convergence\n            if np.abs(global_best_score - last_global_best_score) < self.adaptive_threshold:\n                self.inertia_weight *= self.inertia_damping\n                self.mutation_factor *= (1 + np.random.uniform(-0.1, 0.1))\n                self.crossover_rate *= (1 + np.random.uniform(-0.1, 0.1))\n\n            last_global_best_score = global_best_score\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09060 with standard deviation 0.05005.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16027492949472144, 0.16610614381970956, 0.14029611998461766, 0.08594193586186327, 0.07940004781166177, 0.07535145226397844, 0.04764359209121749, 0.029047095992133176, 0.03138202620033459]}}
{"id": "bca64a77-064e-4abf-8e0b-89cb3798c1eb", "fitness": 0.09008677097100395, "name": "HybridPSODERefined", "description": "A refined hybrid metaheuristic leveraging shuffled crossover and dynamic parameter adaptation in Particle Swarm Optimization and Differential Evolution to enhance convergence on black box optimization problems.", "code": "import numpy as np\n\nclass HybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Adjusted for more exploration\n        self.cognitive_coeff = 2.1  # Slightly increased for better local search\n        self.social_coeff = 1.9  # Increased for more global influence\n        self.mutation_factor = 0.85  # Adjusted for balance between exploration and exploitation\n        self.crossover_rate = 0.9  # Adjusted crossover rate\n        self.inertia_dampening = 0.99  # New factor for dynamic adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with dynamic inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_dampening  # Update inertia weight\n\n            # DE Component with shuffled crossover\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):  # Ensure at least one point is crossed\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09009 with standard deviation 0.05184.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1519614330867367, 0.16610614381970956, 0.15708497743912586, 0.08594193586186327, 0.07940004781166177, 0.06804607726420919, 0.03955092441606256, 0.028377432026249316, 0.03431196701341732]}}
{"id": "fc57e886-75e7-4989-8ae7-3467d4207bb8", "fitness": 0.09357006636768227, "name": "AdaptiveHybridPSODE", "description": "A robust hybrid strategy integrating Adaptive PSO with a self-adaptive DE, incorporating a dynamic inertia weight and mutation factor for balanced exploration-exploitation in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.weight_decay = 0.99  # Decay factor for inertia weight\n        self.mutation_adapt_factor = 0.05  # Adaptation factor for mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight *= self.weight_decay\n\n            # Self-adaptive DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                        # Adapt mutation factor based on success\n                        self.mutation_factor = min(1.0, self.mutation_factor + self.mutation_adapt_factor)\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09357 with standard deviation 0.04880.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.157080869509301, 0.16610614381970956, 0.15372563402510497, 0.08594193586186327, 0.07947246430109456, 0.06351465344615914, 0.061826252828888206, 0.03754982575664634, 0.03691281776037336]}}
{"id": "f0ba28d7-2d8a-4b8b-b639-0c88f86b77a4", "fitness": 0.09295490229820295, "name": "EnhancedHybridPSODE", "description": "Introducing a strategy that incorporates adaptive velocity control and dynamic mutation factor adjustment to enhance exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor_base = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.inertia_weight * (1 - eval_count / self.budget)\n\n            # PSO Component with adaptive velocity\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with dynamic mutation factor\n            mutation_factor = self.mutation_factor_base + 0.2 * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09295 with standard deviation 0.04667.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1511145903785872, 0.08594193586186327, 0.07940004781166177, 0.06154220271417321, 0.05546016655909347, 0.040100920043695476, 0.046556023659839685]}}
{"id": "4ce372f1-3f1d-45b3-ac11-1c8241f36796", "fitness": 0.09510365247045906, "name": "EnhancedHybridPSODE", "description": "An advanced hybrid metaheuristic that leverages adaptive learning for Particle Swarm Optimization and Differential Evolution with dynamical parameter tuning to enhance convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Increased to enhance exploration\n        self.cognitive_coeff = 1.5  # Adjusted to balance exploration-exploitation\n        self.social_coeff = 1.5  # Adjusted for better global exploration\n        self.mutation_factor = 0.8  # Reduced for more stable DE mutations\n        self.crossover_rate = 0.9  # Balanced to maintain diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        adaptive_w = self.inertia_weight\n        adaptive_mutation_factor = self.mutation_factor\n\n        while eval_count < self.budget:\n            # Adaptively adjust inertia weight\n            adaptive_w = 0.9 - 0.5 * (eval_count / self.budget)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (adaptive_w * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with adaptive mutation factor\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                adaptive_mutation_factor = self.mutation_factor + 0.1 * (1 - eval_count / self.budget)\n                mutant = np.clip(x1 + adaptive_mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.04640.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15365451185701073, 0.16829942626531402, 0.1493797985297186, 0.08594193586186327, 0.07940004781166177, 0.0703000726834081, 0.0674115327834659, 0.04467893322163108, 0.03686661322005802]}}
{"id": "2f4609c6-76f1-49b8-a677-fcac78d82eff", "fitness": 0.08635692924670856, "name": "HybridPSODE", "description": "An improved hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments and periodic re-evaluation for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.6  # Changed from 0.7 to 0.6\n        self.cognitive_coeff = 2.1  # Changed from 2.0 to 2.1\n        self.social_coeff = 1.8  # Changed from 1.7 to 1.8\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n        self.reevaluation_interval = 10  # Introduced for periodic re-evaluation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count % self.reevaluation_interval == 0:  # Added periodic re-evaluation\n                    reevaluated_scores = np.array([func(ind) for ind in personal_best_positions])\n                    improved_idx = reevaluated_scores < personal_best_scores\n                    personal_best_scores[improved_idx] = reevaluated_scores[improved_idx]\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08636 with standard deviation 0.05045.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.140018901019756, 0.08594193586186327, 0.07940004781166177, 0.05568283596374557, 0.03242013403917121, 0.026202435322045692, 0.04106783954722104]}}
{"id": "3f22c8a3-ab39-4837-9113-a4ace6f98f20", "fitness": 0.09331656812457902, "name": "ImprovedHybridPSODE", "description": "An improved hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive inertia weight and dynamic population resizing for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(100, self.budget // 5)\n        self.final_population_size = max(20, self.budget // 10)\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = population_size\n\n        while eval_count < self.budget:\n            inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (eval_count / self.budget))\n            if eval_count % (self.budget // 10) == 0:\n                population_size = max(self.final_population_size, population_size - 1)\n\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(population_size):\n                candidates = np.random.choice(population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09332 with standard deviation 0.04956.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15804527713105077, 0.16610614381970956, 0.1533428221658959, 0.08594193586186327, 0.07940004781166177, 0.0715812587475323, 0.05656352288181321, 0.032138057699593436, 0.036730047002090926]}}
{"id": "3ee3eeb3-1d2e-4bf5-a3c3-90267ac9954f", "fitness": 0.09181794882412767, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments and local search strategies for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities + \n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 5, replace=False) # Changed from 3 to 5\n                x1, x2, x3 = population[candidates[:3]]\n                x4, x5 = population[candidates[3:]] # Added local competition candidates\n                if func(x4) < func(x5):  # Local search strategy\n                    x3 = x4\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09182 with standard deviation 0.04840.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1532207311841619, 0.08594193586186327, 0.07940004781166177, 0.06527134191594663, 0.045152456006766206, 0.037957306871705176, 0.04293948611013154]}}
{"id": "b7012338-c7fa-411e-a18d-b6f773b95d06", "fitness": 0.09397738411462216, "name": "EnhancedAdaptivePSODE", "description": "A novel hybrid metaheuristic named Enhanced Adaptive PSODE, integrating Particle Swarm Optimization with Differential Evolution and dynamic inertia adjustment for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Increased from 0.7 to 0.9 for exploration\n        self.cognitive_coeff = 1.5  # Changed from 2.0 to 1.5 for balanced learning\n        self.social_coeff = 1.9  # Changed from 1.7 to 1.9 for better cooperation\n        self.mutation_factor = 0.8  # Changed from 0.9 to 0.8 for diversity\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9 for stability\n        self.inertia_damping = 0.99  # New parameter for inertia adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialized randomly\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            self.inertia_weight *= self.inertia_damping\n            \n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09398 with standard deviation 0.04771.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15541496054183657, 0.16838193234240262, 0.1481385160227181, 0.08594193586186327, 0.08026552684625765, 0.06915402392319636, 0.03242013403917121, 0.063854955333017, 0.04222447212113667]}}
{"id": "8187e81c-1fb9-4587-b097-841a20b5dd27", "fitness": 0.09252293547455043, "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid metaheuristic algorithm that dynamically adjusts PSO and DE parameters based on convergence rate feedback to enhance exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.adaptation_threshold = int(0.1 * self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        last_global_best_score = global_best_score\n\n        while eval_count < self.budget:\n            if eval_count % self.adaptation_threshold == 0:\n                score_diff = last_global_best_score - global_best_score\n                if score_diff < 1e-5:  # Check for stagnation\n                    self.inertia_weight *= 0.9  # Encourage exploration\n                    self.mutation_factor *= 1.1  # Increase DE exploration\n                else:\n                    self.inertia_weight *= 1.1  # Encourage exploitation\n                    self.mutation_factor *= 0.9  # Increase DE exploitation\n                last_global_best_score = global_best_score\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09252 with standard deviation 0.05065.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15110783739244904, 0.16921166510293395, 0.15742259001883485, 0.08595211443137862, 0.07964698365904099, 0.06701765393148107, 0.06145265415832124, 0.02649890844882241, 0.03439601212769172]}}
{"id": "9b544c7e-4cf4-48ad-ba7e-3d79fb0afb4c", "fitness": 0.0943177955068133, "name": "AdaptiveHybridPSODE", "description": "A novel adaptive hybrid algorithm that combines Particle Swarm Optimization and Differential Evolution with dynamic parameter tuning based on convergence speed and diversity monitoring for enhanced black box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def _dynamic_tuning(self, improvement_rate):\n        if improvement_rate > 0.02:  # Rapid improvement\n            self.inertia_weight = min(1.2, self.inertia_weight + 0.1)\n            self.cognitive_coeff = max(1.0, self.cognitive_coeff - 0.1)\n        else:  # Slow improvement or stagnation\n            self.inertia_weight = max(0.4, self.inertia_weight - 0.1)\n            self.cognitive_coeff = min(2.4, self.cognitive_coeff + 0.1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        prev_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic parameter tuning based on convergence speed\n            improvement_rate = (prev_best_score - global_best_score) / abs(prev_best_score)\n            self._dynamic_tuning(improvement_rate)\n            prev_best_score = global_best_score\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09432 with standard deviation 0.04947.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16424549018013357, 0.16610614381970956, 0.15190311977156623, 0.08594193586186327, 0.07940004781166177, 0.07176889620432714, 0.04655196168231479, 0.040939382201994445, 0.04200318202774889]}}
{"id": "f55ff026-de4d-4106-a174-b054328ed1dc", "fitness": 0.10180976218317081, "name": "AdaptiveHybridPSODE", "description": "This algorithm, AdaptiveHybridPSODE, introduces adaptive mutation and crossover rates based on the population's diversity to enhance convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(population, axis=0))\n            adaptive_mutation_factor = self.base_mutation_factor * (1 + diversity)\n            adaptive_crossover_rate = self.base_crossover_rate * (1 - diversity)\n            \n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + adaptive_mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10181 with standard deviation 0.04172.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.16028165701453745, 0.08594193586186327, 0.08789671064168281, 0.07142017891682306, 0.07661691345371935, 0.05342281978233476, 0.06422941032266416]}}
{"id": "f76a8151-2527-4c08-bbf7-638bb3437031", "fitness": 0.08967435606264285, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and mutation to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 (line 7)\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.7  # Changed from 0.9 to 0.7 (line 10)\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Adaptive inertia weight (new line)\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Changed from constant to adaptive (line 45)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08967 with standard deviation 0.04977.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.1699048768472402, 0.14561938187614798, 0.08594193586186327, 0.07940004781166177, 0.06301269762929662, 0.040164253909636405, 0.030532772279379228, 0.04212114851335724]}}
{"id": "2e9f955f-c32e-484c-8a08-00063431f7ae", "fitness": 0.09526764784251708, "name": "FusionPSODE", "description": "FusionPSODE: A refined fusion of Particle Swarm Optimization and Differential Evolution with dynamic strategy selection and adaptive parameter tuning for enhanced convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass FusionPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.strategy_switch_threshold = 0.5  # New parameter for dynamic strategy change\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        iteration = 0\n\n        while eval_count < self.budget:\n            iteration += 1\n            # Dynamic inertia weight adjustment\n            inertia_weight = self.inertia_weight * (1 - (iteration / (self.budget / self.population_size)))\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with dynamic strategy selection\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutation_factor = self.mutation_factor if np.random.rand() > self.strategy_switch_threshold else self.mutation_factor / 2\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm FusionPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09527 with standard deviation 0.04710.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15764384392210706, 0.16610614381970956, 0.15266455713673888, 0.08594193586186327, 0.07940004781166177, 0.055220610120377045, 0.06629401943812074, 0.05993930166644601, 0.034198370805629374]}}
{"id": "95f8f30f-e133-4d18-99f3-94c619925aeb", "fitness": 0.09112019962136653, "name": "EnhancedHybridPSODE", "description": "An adaptive multi-strategy hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with a stochastic restart mechanism for enhanced exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.8  # Adaptive inertia weight starting higher\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.8  # Slightly increased social coefficient\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.stagnation_threshold = self.population_size * 5\n        self.restart_probability = 0.1  # Introduced restart mechanism\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    stagnation_counter = 0\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Check for stagnation and potential restart\n            stagnation_counter += 1\n            if stagnation_counter > self.stagnation_threshold:\n                if np.random.rand() < self.restart_probability:\n                    # Reset the population to explore new areas\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    personal_best_positions = np.copy(population)\n                    personal_best_scores = np.array([func(ind) for ind in population])\n                    global_best_idx = np.argmin(personal_best_scores)\n                    global_best_position = personal_best_positions[global_best_idx]\n                    global_best_score = personal_best_scores[global_best_idx]\n                    stagnation_counter = 0\n\n            # Adapt inertia weight for better exploration/exploitation\n            self.inertia_weight = 0.6 + 0.4 * (1 - eval_count / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09112 with standard deviation 0.05169.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16349094341865977, 0.16618612792349663, 0.14851901233372666, 0.08594193586186327, 0.07940004781166177, 0.06399857910448814, 0.05235847448930153, 0.026202435322045692, 0.03398424032705527]}}
{"id": "35ab1302-7ea5-463c-8c94-b2bf040a8f48", "fitness": 0.09326533124134512, "name": "HybridPSODE", "description": "Incorporating a dynamic inertia weight and adaptive crossover rate to enhance exploration and exploitation in the HybridPSODE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            inertia_weight = 0.5 + (0.9 - 0.5) * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09327 with standard deviation 0.04795.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15475323667256968, 0.08594193586186327, 0.07940004781166177, 0.06923713187796965, 0.05784225392597486, 0.02991311991759904, 0.04582202144955527]}}
{"id": "a4c7eaad-77e3-406e-a95b-08103c0df6d9", "fitness": 0.09522455104599296, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive velocity control and diversity preservation to improve exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.9  # Adjusted crossover rate from 0.95 to 0.9 to preserve diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        dynamic_inertia_weight = self.inertia_weight  # Start with constant inertia weight\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight based on budget usage\n            dynamic_inertia_weight = self.inertia_weight * (1 - eval_count / self.budget)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (dynamic_inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09522 with standard deviation 0.04722.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15728904869241345, 0.16610614381970956, 0.1533428221658959, 0.0866359344687847, 0.07940004781166177, 0.07328553104947955, 0.0509790658465179, 0.04416034410991854, 0.04582202144955527]}}
{"id": "8e9a49d3-9040-4498-ab6e-ac39aac67af7", "fitness": 0.09303202352966669, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic of PSO and DE with enhanced exploration via dynamic coefficients for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 1.8  # Changed from 2.0 to 1.8\n        self.social_coeff = 2.1  # Changed from 1.7 to 2.1\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09303 with standard deviation 0.04997.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16033329291615428, 0.16610614381970956, 0.15254904774734046, 0.08594193586186327, 0.07940004781166177, 0.06774388073954396, 0.0556707546996017, 0.034684793606143405, 0.034858314564981785]}}
{"id": "afd4a061-8083-4d04-9aa5-d274fa43a46c", "fitness": -Infinity, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments for improved convergence in black box optimization, featuring dynamic population size adjustment and improved exploration.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(100, self.budget // 5)  # Changed from population_size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(population_size):\n                candidates = np.random.choice(population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Dynamic population size adjustment\n            if eval_count % (self.budget // 10) == 0:\n                population_size = max(10, int(population_size * 0.9))  # Reduce population\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (90,10) (100,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (90,10) (100,10) ')", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {}}
{"id": "982cb819-9510-42b0-b168-e950ffe2a392", "fitness": 0.10981435343563964, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with further adaptive parameter tuning for enhanced exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.8  # Changed from 0.7 to 0.8\n        self.cognitive_coeff = 2.1  # Changed from 2.0 to 2.1\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10981 with standard deviation 0.08812.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.3218668364794802, 0.16686448836195067, 0.15591002045968305, 0.08594193586186327, 0.07940004781166177, 0.07079657778246806, 0.044033883951749675, 0.028761550780402767, 0.034753839431497235]}}
{"id": "61fc7e2f-47ca-4e45-b4fe-2276e02d8bfe", "fitness": 0.08869460411654298, "name": "HybridPSODE", "description": "Improved hybrid metaheuristic combining adaptive Particle Swarm Optimization and Differential Evolution using dynamic coefficients adjustment for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.2  # Changed from 2.0 to 2.2\n        self.social_coeff = 1.5  # Changed from 1.7 to 1.5\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08869 with standard deviation 0.05000.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15086016911292777, 0.16610614381970956, 0.1420897860641861, 0.08594193586186327, 0.0844216456994783, 0.07110727280703122, 0.03407365159208531, 0.03272218874360511, 0.030928643348000162]}}
{"id": "c3ad670d-6a6d-4b74-bac8-6111dffd5a95", "fitness": 0.09304389858417313, "name": "RefinedHybridPSODE", "description": "Introducing a multi-phase strategy that alternates between exploration and exploitation phases with adaptive inertia and crossover adjustments to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.exploration_phase_ratio = 0.5  # 50% of budget for exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        exploration_limit = int(self.budget * self.exploration_phase_ratio)\n        \n        while eval_count < self.budget:\n            if eval_count < exploration_limit:\n                # Exploration Phase - Emphasize exploration\n                self.inertia_weight = 0.9  # Higher inertia to explore\n                self.crossover_rate = 0.9  # Lower crossover rate\n            else:\n                # Exploitation Phase - Focus on local refinement\n                self.inertia_weight = 0.4  # Lower inertia for more exploitation\n                self.crossover_rate = 0.98  # Higher crossover rate to refine\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09304 with standard deviation 0.04780.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1505425636294334, 0.16610614381970956, 0.15361677461578993, 0.08594193586186327, 0.07940004781166177, 0.06350224832520823, 0.06246656171790754, 0.029996790026429188, 0.04582202144955527]}}
{"id": "583b0e05-49c1-4c25-aace-5eac121de289", "fitness": 0.09508771913374908, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic inertia weight and adaptive mutation factor for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.6  # Changed from 0.9 to 0.6\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - eval_count) / self.budget  # Dynamic inertia weight\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                adaptive_mutation_factor = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n                mutant = np.clip(x1 + adaptive_mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09509 with standard deviation 0.05154.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16469762775669172, 0.16610614381970956, 0.162715755859835, 0.08594193586186327, 0.07940004781166177, 0.060912099683467114, 0.062026730913036676, 0.029888322976543202, 0.04410080752093348]}}
{"id": "0c88bc75-2f2d-44c8-b1b2-ae80eed866d3", "fitness": 0.09221645063798971, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments and increased mutation factor for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7  # Changed from 0.5 to 0.7\n        self.cognitive_coeff = 2.0  # Changed from 1.5 to 2.0\n        self.social_coeff = 1.7  # Changed from 1.5 to 1.7\n        self.mutation_factor = 0.95  # Changed from 0.9 to 0.95\n        self.crossover_rate = 0.95  # Changed from 0.9 to 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09222 with standard deviation 0.05211.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16589686114958868, 0.16610614381970956, 0.15233436387209376, 0.08594193586186327, 0.07940004781166177, 0.06806517082219776, 0.04665064494169391, 0.030966304672967904, 0.034586582790130715]}}
{"id": "3560b152-c759-495e-91c7-5c7cba82ef51", "fitness": 0.09331656812457902, "name": "HybridPSODE", "description": "An improved hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with dynamic inertia weight adjustment for enhanced exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            w = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * (eval_count / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09332 with standard deviation 0.04956.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15804527713105077, 0.16610614381970956, 0.1533428221658959, 0.08594193586186327, 0.07940004781166177, 0.0715812587475323, 0.05656352288181321, 0.032138057699593436, 0.036730047002090926]}}
{"id": "ad7224e8-fd87-4bd5-a20c-1cc464b5de6c", "fitness": 0.09278793174042439, "name": "HybridPSODE", "description": "An adaptive hybrid metaheuristic augmenting Particle Swarm Optimization and Differential Evolution with a dynamic learning strategy and enhanced exploration-exploitation balance for optimized convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Increased for better exploration\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0  # Increased to enhance global attraction\n        self.mutation_factor = 0.7  # Reduced for finer differential mutation\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.1  # New parameter for dynamic adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb) / 2\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with Dynamic Adaptation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        \n                        # Dynamic adaptation of parameters based on learning rate\n                        self.inertia_weight *= (1 - self.learning_rate)\n                        self.cognitive_coeff *= (1 + self.learning_rate)\n                        self.social_coeff *= (1 - self.learning_rate)\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09279 with standard deviation 0.05108.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.16576640057550718, 0.08594193586186327, 0.07940004781166177, 0.06669492120646137, 0.03890901130816493, 0.029048268587059223, 0.05285256665818938]}}
{"id": "af76c642-5bca-4f75-bf59-4112ff4a86fa", "fitness": 0.09236309096024478, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic integrating Particle Swarm Optimization and Differential Evolution with slight tuning of parameter settings for improved black box optimization performance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.8  # Changed from 0.7 to 0.8\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09236 with standard deviation 0.04865.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15556453161411632, 0.16686448836195067, 0.14826582249179154, 0.08594193586186327, 0.07940004781166177, 0.07029670924025744, 0.053636661681112585, 0.036543782147952175, 0.034753839431497235]}}
{"id": "46a46c83-82c4-423a-8996-c04cb25310cd", "fitness": 0.09448676838460318, "name": "HybridPSODE", "description": "An innovative hybrid metaheuristic combining Particle Swarm Optimization, Differential Evolution, and dynamic diversity control to enhance exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.diversity_threshold = 0.1  # New parameter for diversity control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        def calculate_diversity(population):\n            return np.mean(np.std(population, axis=0))\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate diversity\n            diversity = calculate_diversity(population)\n            if diversity < self.diversity_threshold:\n                self.inertia_weight *= 1.1  # Increase exploration\n            else:\n                self.inertia_weight *= 0.9  # Increase exploitation\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09449 with standard deviation 0.04832.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15811780849712986, 0.16610614381970956, 0.15351056615179381, 0.08594193586186327, 0.08086214196467967, 0.0732368017635171, 0.04521849069821049, 0.03862514937284334, 0.04876187733168158]}}
{"id": "6e50b840-d9fe-4ed5-b83c-7c43e6ae18ef", "fitness": 0.09451302286848758, "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid metaheuristic that dynamically adjusts parameters of Particle Swarm Optimization and Differential Evolution based on population diversity to enhance convergence on black box optimization problems.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def _adaptive_params(self, population, func_vals):\n        diversity = np.std(population, axis=0).mean()\n        if diversity < 0.1:\n            self.inertia_weight *= 0.9\n            self.mutation_factor *= 1.1\n        elif diversity > 0.3:\n            self.inertia_weight *= 1.1\n            self.mutation_factor *= 0.9\n        self.inertia_weight = np.clip(self.inertia_weight, 0.4, 0.9)\n        self.mutation_factor = np.clip(self.mutation_factor, 0.5, 1.0)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self._adaptive_params(population, personal_best_scores)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09451 with standard deviation 0.05152.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15765762998552912, 0.16610614381970956, 0.1613338464737597, 0.08594193586186327, 0.0980039154976603, 0.06425904844193342, 0.04668798179205225, 0.032986390535922894, 0.037640313407957704]}}
{"id": "d5abd30f-40c0-41a5-955f-6c373ab62a7b", "fitness": 0.08727854780694495, "name": "HybridPSODE", "description": "HybridPSODE with dynamic adjustment of parameters and random restart mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.2  # Changed from 2.0 to 2.2\n        self.social_coeff = 1.5  # Changed from 1.7 to 1.5\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        restart_threshold = 0.05  # Added line for random restart\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Random Restart Mechanism\n            if np.random.rand() < restart_threshold:\n                random_restart_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                population = np.where(np.random.rand(self.population_size, self.dim) < 0.1, random_restart_population, population)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08728 with standard deviation 0.04997.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15085458495025628, 0.16610614381970956, 0.14003452999928911, 0.08594193586186327, 0.08007491647018827, 0.06301327388807254, 0.03407365159208531, 0.033008308682279996, 0.03239958499876028]}}
{"id": "30a7c3e2-22f2-480e-8dcb-b2243efdcc5f", "fitness": 0.09744274929160478, "name": "HybridPSODEAdvanced", "description": "An advanced hybrid metaheuristic using adaptive learning strategies and chaos theory to enhance Particle Swarm Optimization and Differential Evolution synergy for robust black box optimization.", "code": "import numpy as np\n\nclass HybridPSODEAdvanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.chaotic_seq = self._init_chaotic_sequence()\n    \n    def _init_chaotic_sequence(self):\n        # Initialize chaotic sequence using logistic map\n        seq = np.zeros(self.budget)\n        seq[0] = 0.5  # Initial value\n        for i in range(1, self.budget):\n            seq[i] = 4 * seq[i-1] * (1 - seq[i-1])\n        return seq\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            self.inertia_weight = 0.4 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO Component with Chaotic Influence\n            r1 = self.chaotic_seq[eval_count:self.population_size+eval_count].reshape(-1, 1)\n            r2 = np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with Adaptive Mutation Factor\n            adaptive_mutation = self.mutation_factor * (1 - (eval_count / self.budget))\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + adaptive_mutation * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSODEAdvanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09744 with standard deviation 0.04704.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16386919297370117, 0.16610614381970956, 0.14949265542943124, 0.08653410921650517, 0.08549312348362514, 0.0697397702153304, 0.07543768875662893, 0.04172182564600668, 0.038590234083504704]}}
{"id": "430eb646-bdbf-42cf-b3a2-325e3b309353", "fitness": 0.09051527429689721, "name": "EnhancedHybridPSODE_SA", "description": "A novel metaheuristic combining Particle Swarm Optimization, Differential Evolution, and Simulated Annealing with dynamic parameter tuning based on performance feedback for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.temperature = 100  # Initial temperature for Simulated Annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic parameter adjustment based on current performance\n            self.inertia_weight = max(0.4, self.inertia_weight * (1 - (global_best_score / np.mean(personal_best_scores))))\n            self.temperature *= self.cooling_rate\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                # Simulated Annealing acceptance criterion\n                if trial_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp((personal_best_scores[i] - trial_score) / self.temperature):\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedHybridPSODE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09052 with standard deviation 0.05224.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15066340980673554, 0.16610614381970956, 0.15955310410359436, 0.08594193586186327, 0.07940004781166177, 0.07455862247803136, 0.037398311594807665, 0.026202435322045692, 0.034813457873625664]}}
{"id": "18c3d309-a430-4f88-ae12-ec5d1138575c", "fitness": 0.09489656375483746, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization with adaptive velocity control and Differential Evolution with dynamic crossover rate, enhancing exploration and exploitation balance for optimal black box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Increased to enhance exploration\n        self.cognitive_coeff = 2.1  # Slightly increased for better local search\n        self.social_coeff = 1.6  # Slightly decreased for more individual variety\n        self.mutation_factor = 0.9  # Retained for strong mutation\n        self.crossover_rate = 0.9  # Initialize lower and adapt dynamically\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            adapt_cr = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < adapt_cr\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09490 with standard deviation 0.05112.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16748819966262063, 0.16790201518373304, 0.08851523863227506, 0.07940004781166177, 0.06936325514976471, 0.06987942940791791, 0.028451232344118282, 0.03269756576624283]}}
{"id": "3459eb38-acfa-4a0d-b9e8-706022c1f87a", "fitness": 0.09262856048089912, "name": "AdaptiveNeighborhoodPSODE", "description": "Introducing Adaptive Neighborhood PSODE for enhanced exploration-exploitation balance by incorporating local neighborhood information to dynamically adjust particle velocities and mutation strategies.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.neighborhood_size = max(2, self.population_size // 10)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive neighborhood selection\n            neighbors = np.random.choice(self.population_size, (self.population_size, self.neighborhood_size), replace=True)\n\n            for i in range(self.population_size):\n                # Neighborhood best\n                neighborhood_scores = personal_best_scores[neighbors[i]]\n                neighborhood_best_idx = neighbors[i][np.argmin(neighborhood_scores)]\n                neighborhood_best_position = personal_best_positions[neighborhood_best_idx]\n\n                # PSO Component with neighborhood best\n                r1, r2 = np.random.rand(2, self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (neighborhood_best_position - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveNeighborhoodPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09263 with standard deviation 0.04742.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1545760516256981, 0.16610614381970956, 0.1459827195248502, 0.08594193586186327, 0.08656606432202141, 0.06397812435939876, 0.041315126844929995, 0.04347388796577645, 0.04571699000384444]}}
{"id": "0ff78ade-28db-4bea-af0c-cf98e3ad2519", "fitness": 0.094573781787482, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with enhanced initialization for improved exploration in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7  \n        self.cognitive_coeff = 2.0  \n        self.social_coeff = 1.7  \n        self.mutation_factor = 0.9  \n        self.crossover_rate = 0.95  \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Enhanced initialization using a normal distribution centered around the midpoint\n        midpoint = (lb + ub) / 2\n        population = np.random.normal(midpoint, (ub - lb) / 4, (self.population_size, self.dim))\n        np.clip(population, lb, ub, out=population)\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09457 with standard deviation 0.04501.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1583592685138726, 0.1653623703936098, 0.14365419129134027, 0.07397272672050748, 0.07378394411921418, 0.0631878437893858, 0.05190413255608284, 0.041009447352516104, 0.07993011135080896]}}
{"id": "e6b27379-b230-4edd-a928-438dddf599ca", "fitness": 0.09331656812457902, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic inertia weight adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7  # Changed from 0.5 to 0.7\n        self.cognitive_coeff = 2.0  # Changed from 1.5 to 2.0\n        self.social_coeff = 1.7  # Changed from 1.5 to 1.7\n        self.mutation_factor = 0.9  # Changed from 0.8 to 0.9\n        self.crossover_rate = 0.95  # Changed from 0.9 to 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic inertia weight adjustment\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09332 with standard deviation 0.04956.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15804527713105077, 0.16610614381970956, 0.1533428221658959, 0.08594193586186327, 0.07940004781166177, 0.0715812587475323, 0.05656352288181321, 0.032138057699593436, 0.036730047002090926]}}
{"id": "f8168feb-2e1f-47a1-9007-92294e3bcc0b", "fitness": 0.08869460411654298, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with dynamic adaptive parameters for improved exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.2  # Changed from 2.0 to 2.2\n        self.social_coeff = 1.5  # Changed from 1.7 to 1.5\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08869 with standard deviation 0.05000.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15086016911292777, 0.16610614381970956, 0.1420897860641861, 0.08594193586186327, 0.0844216456994783, 0.07110727280703122, 0.03407365159208531, 0.03272218874360511, 0.030928643348000162]}}
{"id": "8123cb7e-cf59-4808-b03d-ced1ad10b629", "fitness": 0.09536264501654797, "name": "HybridPSODE", "description": "A further refined HybridPSODE with improved random sampling and dynamic parameter tuning for better convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.6  # Changed from 0.7 to 0.6\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.5  # Changed from 1.7 to 1.5\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n        self.adaptive_rate = 0.05  # New adaptive rate parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        # Update inertia weight and mutation factor dynamically\n                        self.inertia_weight = max(0.3, self.inertia_weight - self.adaptive_rate)\n                        self.mutation_factor = min(1.0, self.mutation_factor + self.adaptive_rate)\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09536 with standard deviation 0.04868.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16848507530977852, 0.16610614381970956, 0.1454580860050113, 0.08594193586186327, 0.07940004781166177, 0.0703441153574913, 0.0679900201245851, 0.0377842009266689, 0.03675417993216201]}}
{"id": "22e342f4-aab5-4405-9760-fdf6084ccc65", "fitness": 0.09598421683816218, "name": "HybridPSODE", "description": "Introducing adaptive inertia weight and differential evolution strategy to enhance the exploration-exploitation balance in HybridPSODE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_inertia = 0.4 + 0.5 * (self.budget - eval_count) / self.budget  # New adaptive inertia\n            velocities = (adaptive_inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09598 with standard deviation 0.04734.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16686448836195067, 0.16294380862410296, 0.08594193586186327, 0.07940004781166177, 0.07230211125939157, 0.05364758531417113, 0.04361324306820347, 0.04877264140691184]}}
{"id": "2f9e2d8d-3996-44a6-a9fa-aac0e3ccef99", "fitness": 0.09375016606665787, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic enhancing exploration by introducing dynamic inertia weight and adaptive crossover rate to improve convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia_weight *= 0.99  # Added dynamic inertia weight adjustment\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                self.crossover_rate = 0.95 + 0.05 * np.random.rand()  # Added adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09375 with standard deviation 0.05286.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.17481318704212045, 0.16640492680290797, 0.14833033953807828, 0.08594193586186327, 0.0800777877084774, 0.07857679774820359, 0.0356672726891889, 0.040040038576657944, 0.03389920863242302]}}
{"id": "0ce58e39-2f06-4c73-b706-a52412df41f0", "fitness": 0.09348628002644403, "name": "AdvancedHybridPSODE", "description": "An advanced hybrid metaheuristic that leverages dynamic adjustment of Particle Swarm Optimization and Differential Evolution parameters based on convergence feedback to enhance global exploration and local exploitation in black box optimization.  ", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Dynamically adjusted\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.delta = 0.1  # Convergence threshold for dynamic adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        previous_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # Adapt inertia weight based on convergence\n            if np.abs(global_best_score - previous_best_score) < self.delta:\n                self.inertia_weight *= 0.97\n            else:\n                self.inertia_weight = min(0.9, self.inertia_weight * 1.03)\n            previous_best_score = global_best_score\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09349 with standard deviation 0.04958.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16028137298787626, 0.16610614381970956, 0.1533428221658959, 0.08594193586186327, 0.07940004781166177, 0.0642403243668388, 0.059247494218629515, 0.0377805863530738, 0.035035792652447384]}}
{"id": "5fce222b-2281-4b98-bed3-39602ce876a5", "fitness": 0.08719377693510366, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic integrating Particle Swarm Optimization and Differential Evolution with dynamic adaptation of parameters based on population diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.initial_inertia_weight = 0.7\n        self.final_inertia_weight = 0.4\n        self.initial_cognitive_coeff = 2.0\n        self.initial_social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight based on iteration\n            inertia_weight = self.initial_inertia_weight - (\n                (self.initial_inertia_weight - self.final_inertia_weight) * (iteration / max_iterations)\n            )\n\n            # Dynamic coefficient adaptation based on diversity\n            diversity = np.mean(np.std(population, axis=0))\n            cognitive_coeff = self.initial_cognitive_coeff * (1 + 0.5 * diversity)\n            social_coeff = self.initial_social_coeff * (1 - 0.5 * diversity)\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          cognitive_coeff * r1 * (personal_best_positions - population) +\n                          social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08719 with standard deviation 0.05238.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15152846044154367, 0.16610614381970956, 0.1468685286253033, 0.08594193586186327, 0.07940004781166177, 0.06919709429046172, 0.035084753004625546, 0.026202435322045692, 0.02441459323871842]}}
{"id": "c890bc24-8293-4358-b7b5-e7efe57c4d71", "fitness": 0.0928581492435666, "name": "EnhancedHybridPSODE", "description": "A refined hybrid approach combining PSO and DE, incorporating adaptive inertia and mutation strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n        self.adaptive_factor = 0.995  # New adaptive factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adaptive strategy\n            self.inertia_weight *= self.adaptive_factor\n            self.mutation_factor *= self.adaptive_factor\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09286 with standard deviation 0.04907.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15422059202935756, 0.16686448836195067, 0.15249380475931051, 0.08594193586186327, 0.07940004781166177, 0.07029670924025744, 0.058736524673658086, 0.031392009968255086, 0.036377230485785006]}}
{"id": "fd9ea191-6832-4b1f-9972-6d2b1c883c12", "fitness": 0.0936576488424957, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive inertia weight and mutation strategy for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= 0.99  # Adaptive inertia weight adjustment\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09366 with standard deviation 0.04849.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1534300817617601, 0.16686448836195067, 0.15086447710806483, 0.08594193586186327, 0.08803958376252297, 0.07135678475091223, 0.0584309280568267, 0.031966608330372015, 0.036023951588188496]}}
{"id": "f916bb24-0b8b-4c8c-abcd-8dd58367f7fa", "fitness": 0.08992349310440195, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic integrating Particle Swarm Optimization and Differential Evolution with enhanced stochastic processes to improve convergence reliability in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.8  # Changed from 0.7 to 0.8\n        self.cognitive_coeff = 2.2  # Changed from 2.0 to 2.2\n        self.social_coeff = 1.8  # Changed from 1.7 to 1.8\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08992 with standard deviation 0.05020.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15194552478527146, 0.16610614381970956, 0.14667055561160958, 0.08594193586186327, 0.07940004781166177, 0.07706632810032632, 0.03242013403917121, 0.026250085820077373, 0.04351068208992703]}}
{"id": "c1b423c5-f1b3-4602-b7c8-30e07317642e", "fitness": 0.08764874842592817, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with dynamic parameter tuning based on population diversity for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0))\n\n            # Dynamic parameter tuning\n            inertia_weight = 0.5 + 0.2 * diversity\n            social_coeff = 1.5 + 0.5 * (1 - diversity)\n            mutation_factor = 0.8 + 0.1 * diversity\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08765 with standard deviation 0.05369.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15986712190204722, 0.16610614381970956, 0.14738790571186833, 0.0867426335132434, 0.07940004781166177, 0.06156315323033601, 0.03242013403917121, 0.03027631194666902, 0.02507528385864699]}}
{"id": "dfc64069-8b29-496c-afc3-762f2495b6e6", "fitness": -Infinity, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic integrating Particle Swarm Optimization and Differential Evolution with adaptive inertia weight and dynamic population size for enhanced exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = min(100, self.budget // 5)\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.base_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = population_size\n\n        while eval_count < self.budget:\n            # Dynamic Inertia Weight\n            inertia_weight = (self.inertia_weight_max - self.inertia_weight_min) * \\\n                             (self.budget - eval_count) / self.budget + self.inertia_weight_min\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(population_size):\n                candidates = np.random.choice(population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic Population Size Adjustment\n            if eval_count < self.budget / 2:\n                population_size = min(self.base_population_size + eval_count // 10, self.budget // 2)\n                population = population[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (120,10) (100,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (120,10) (100,10) ')", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {}}
{"id": "f95017da-b6b8-4180-b0a0-5ee868f458b7", "fitness": 0.1107336359736155, "name": "HybridPSODE", "description": "HybridPSODE with enhanced diversity by incorporating a random restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.restart_threshold = np.inf  # Changed from fixed value to np.inf\n        self.max_patience = 10  # Added line for patience in stagnation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        stagnation_counter = 0  # Added line for stagnation detection\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset on improvement\n\n                if eval_count >= self.budget:\n                    break\n\n            stagnation_counter += 1\n            if stagnation_counter > self.max_patience:  # Added line for restart mechanism\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                stagnation_counter = 0\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11073 with standard deviation 0.08702.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.32189413154277635, 0.16610614381970956, 0.15488090735419402, 0.08594193586186327, 0.07940004781166177, 0.061575977381685965, 0.05989556068309354, 0.03192436488618344, 0.034983654421371635]}}
{"id": "ebfae576-4efa-4b60-92a1-c5f9aca86645", "fitness": -Infinity, "name": "RefinedHybridPSODE", "description": "A refined hybrid algorithm combining PSO and DE with dynamic population resizing and adaptive learning rates to enhance exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(100, self.budget // 5)\n        self.min_population_size = max(10, self.budget // 50)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.5\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        eval_count = population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            for i in range(population_size):\n                if eval_count >= self.budget:\n                    break\n\n                candidates = np.random.choice(population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n            population_size = max(self.min_population_size, int(self.initial_population_size * (1 - eval_count / self.budget)))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (80,10) (100,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (80,10) (100,10) ')", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {}}
{"id": "8afd19fa-0a53-460d-a284-a595a202ffad", "fitness": 0.11001683078108791, "name": "HybridPSODE", "description": "Introducing diversity in the DE mutation process by adjusting mutation vector selection and trial vector evaluation sequence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7  # Changed from 0.5 to 0.7\n        self.cognitive_coeff = 2.0  # Changed from 1.5 to 2.0\n        self.social_coeff = 1.7  # Changed from 1.5 to 1.7\n        self.mutation_factor = 0.9  # Changed from 0.8 to 0.9\n        self.crossover_rate = 0.95  # Changed from 0.9 to 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x3 - x2), lb, ub)  # Adjust mutation direction\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11002 with standard deviation 0.08859.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.3254028550658926, 0.16610614381970956, 0.15102445863332015, 0.09242140222896023, 0.07940004781166177, 0.06532790776093533, 0.041430914343848824, 0.040205070747364235, 0.02883267661809852]}}
{"id": "ff6d4418-0192-4b41-a7e1-dd32541c93d6", "fitness": 0.09585670157966013, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic with enhanced exploration using adaptive inertia weight and mutation factor adjustment for improved black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.8  # Changed from 0.9 to 0.8\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_inertia = 0.9 - 0.5 * (eval_count / self.budget)  # Adaptive inertia weight\n            velocities = (adaptive_inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                adaptive_mutation = self.mutation_factor * (0.5 + 0.5 * np.random.rand())  # Adaptive mutation factor\n                mutant = np.clip(x1 + adaptive_mutation * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09586 with standard deviation 0.04728.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1512646308170511, 0.16610614381970956, 0.15569936541779805, 0.09729306913983593, 0.08364501003817615, 0.07098681957474318, 0.057316159830952174, 0.03380977631459603, 0.04658933926407893]}}
{"id": "6af8ae07-81c8-44e7-b9d9-6b9a91186b24", "fitness": 0.09250646122709577, "name": "DynamicHybridPSODE", "description": "A novel hybrid metaheuristic algorithm that dynamically adjusts inertia weight and mutation factor based on convergence progress, combining Particle Swarm Optimization and Differential Evolution for enhanced performance in black box optimization.", "code": "import numpy as np\n\nclass DynamicHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.initial_mutation_factor = 1.0\n        self.final_mutation_factor = 0.5\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic adjustment of inertia weight and mutation factor\n            progress = eval_count / self.budget\n            inertia_weight = (self.final_inertia_weight - self.initial_inertia_weight) * progress + self.initial_inertia_weight\n            mutation_factor = (self.final_mutation_factor - self.initial_mutation_factor) * progress + self.initial_mutation_factor\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm DynamicHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09251 with standard deviation 0.04761.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15055566787030894, 0.08594193586186327, 0.07940004781166177, 0.07198311875330854, 0.05374123815509935, 0.03448951584991189, 0.039968393086795784]}}
{"id": "78029011-8f10-46f0-b6df-7a4f697a0609", "fitness": 0.09367616387360364, "name": "HybridPSODE", "description": "Improved HybridPSODE with adaptive inertia weight and dynamic crossover for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * (1 - eval_count / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                # Dynamic crossover rate\n                dynamic_crossover = self.crossover_rate - 0.1 * (eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09368 with standard deviation 0.04907.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15667400974752843, 0.16610614381970956, 0.1533428221658959, 0.08594193586186327, 0.0891104840737037, 0.06635434770344906, 0.04446590179091736, 0.03968588991980093, 0.04140393977956458]}}
{"id": "356179d2-4a01-40db-88a3-5786bb12ad38", "fitness": 0.0944560156326815, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with adaptive parameter adjustments and chaotic initialization strategy for improved exploration in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.6  # Changed from 0.7 to 0.6\n        self.cognitive_coeff = 1.8  # Changed from 2.0 to 1.8\n        self.social_coeff = 1.9  # Changed from 1.7 to 1.9\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.9  # Changed from 0.95 to 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic Initialization\n        population = lb + (ub - lb) * np.random.rand(1, self.population_size, self.dim).mean(axis=0)\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09446 with standard deviation 0.04656.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.15265155083053938, 0.08594193586186327, 0.07940004781166177, 0.06818383874762168, 0.07082998507342009, 0.03562139830004585, 0.04099715041406893]}}
{"id": "f8a33cb0-2f49-4230-8ea6-b8b13fcaf6ad", "fitness": 0.0964571162620957, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic that tunes particle velocities based on convergence rate and adapts the mutation strategy for enhanced black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 1.8  # Changed from 2.0 to 1.8\n        self.social_coeff = 1.5  # Changed from 1.7 to 1.5\n        self.mutation_factor = 0.85  # Changed from 0.9 to 0.85\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09646 with standard deviation 0.05060.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16954433203638175, 0.16771198652894104, 0.14854424925370446, 0.08594193586186327, 0.07940004781166177, 0.07723684410351483, 0.07910861282951698, 0.03690357572087666, 0.023722462212400597]}}
{"id": "9034231f-adbd-460c-915e-35e75854859b", "fitness": 0.09714837134931456, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic integrating Particle Swarm Optimization with Differential Evolution, enhanced by adaptive inertia weights and mutation strategies to improve performance on black box optimization tasks.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 2.05\n        self.social_coeff = 1.95\n        self.mutation_factor_min = 0.5\n        self.mutation_factor_max = 0.9\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (self.budget - eval_count) / self.budget + self.final_inertia_weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            mutation_factor = (self.mutation_factor_max - self.mutation_factor_min) * \\\n                              np.exp(-4 * eval_count / self.budget) + self.mutation_factor_min\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09715 with standard deviation 0.04260.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1513019477798444, 0.16610614381970956, 0.14205841204076475, 0.08594193586186327, 0.09012579838549228, 0.0846300615858705, 0.04974480996992414, 0.05466639235490711, 0.049759840345455]}}
{"id": "583d5a6b-bb8d-4048-8ebd-faf94886734e", "fitness": -Infinity, "name": "HybridPSODE", "description": "Introducing adaptive inertia weight and mutation factor scheduling in HybridPSODE for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Starting inertia weight for exploration\n        self.inertia_weight_min = 0.4  # Minimum inertia weight for exploitation\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor_max = 0.9  # Starting mutation factor for exploration\n        self.mutation_factor_min = 0.4  # Minimum mutation factor for exploitation\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update inertia weight and mutation factor based on progress\n            progress_ratio = eval_count / self.budget\n            self.inertia_weight = (self.inertia_weight_max - self.inertia_weight_min) * (1 - progress_ratio) + self.inertia_weight_min\n            mutation_factor = (self.mutation_factor_max - self.mutation_factor_min) * (1 - progress_ratio) + self.mutation_factor_min\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "An exception occurred: AttributeError(\"'HybridPSODE' object has no attribute 'inertia_weight_max'\").", "error": "AttributeError(\"'HybridPSODE' object has no attribute 'inertia_weight_max'\")", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {}}
{"id": "86f4d179-f48e-42d9-bd4a-8b9036ae0255", "fitness": 0.1051725775855291, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic combining Particle Swarm Optimization and Differential Evolution with dynamic population size adjustment and adaptive mutation rates for enhanced exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic population size adjustment\n            if eval_count > self.budget // 2:\n                self.population_size = max(10, self.population_size // 2)\n                population = population[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with adaptive mutation factor\n            adaptive_mutation = self.mutation_factor * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + adaptive_mutation * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10517 with standard deviation 0.06261.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.23699410011896804, 0.16610614381970956, 0.15862910158816212, 0.08594193586186327, 0.07940004781166177, 0.06540984242372383, 0.05073558476265272, 0.055114752765741626, 0.048221689117278976]}}
{"id": "0a6dd243-1e92-41d0-ba2c-7421f18f4ad9", "fitness": 0.09652860572884364, "name": "EAPSDE", "description": "Enhanced Adaptive Particle Swarm Differential Evolution (EAPSDE) integrates adaptive inertia weight and dynamic crossover strategy to balance exploration and exploitation, improving convergence in black box optimization.", "code": "import numpy as np\n\nclass EAPSDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia weight for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight decreases over time for more exploitation\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - eval_count) / self.budget\n            \n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with dynamic crossover strategy\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate - 0.3 * eval_count / self.budget\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EAPSDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09653 with standard deviation 0.04689.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15814885295936243, 0.16610614381970956, 0.1552989665286787, 0.08594193586186327, 0.07940004781166177, 0.07383450589180884, 0.0637871917109405, 0.04413924129922553, 0.04210056567634213]}}
{"id": "248abe02-0210-4f7a-a439-2c9f577cfd4b", "fitness": 0.09295458145460704, "name": "AdvancedHybridPSODE", "description": "An advanced hybrid metaheuristic combining Particle Swarm Optimization, Differential Evolution, and Adaptive Differential Evolution with dynamic adaptive parameters and population resizing for enhanced efficiency in black box optimization.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n        self.adaptive_mutation_factor = 0.5 + np.random.rand() / 2\n        self.dynamic_scaling_factor = 0.1 + np.random.rand() / 10\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with Adaptive Parameters\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component with Adaptive Mutation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.adaptive_mutation_factor * (x2 - x3), lb, ub)\n                \n                # Adaptive Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic Population Resizing\n            if eval_count < self.budget / 2 and self.population_size < int(self.budget / 10):\n                self.population_size += int(self.dynamic_scaling_factor * self.population_size)\n                velocities = np.concatenate(\n                    (velocities, np.zeros((self.population_size - velocities.shape[0], self.dim))), axis=0)\n                personal_best_positions = np.concatenate(\n                    (personal_best_positions, np.random.uniform(lb, ub, (self.population_size - personal_best_positions.shape[0], self.dim))), axis=0)\n                personal_best_scores = np.concatenate(\n                    (personal_best_scores, np.array([func(ind) for ind in personal_best_positions[-(self.population_size - len(personal_best_scores)):]])), axis=0)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09295 with standard deviation 0.04732.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16269476999687282, 0.1444655819464281, 0.16509021155091896, 0.06804541197846581, 0.07736509646902134, 0.07334264378314925, 0.05228276295907586, 0.05769614474531637, 0.035608609662214796]}}
{"id": "b1032668-90b9-4389-a2f0-1810287c379d", "fitness": 0.09167705484178709, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic that incorporates a dynamic inertia weight adjustment strategy for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamically adjust the inertia weight\n            self.inertia_weight = 0.9 - 0.7 * (eval_count / self.budget)\n            \n            # PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09168 with standard deviation 0.04962.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.15319547869396177, 0.16610614381970956, 0.1533428221658959, 0.08602202094408484, 0.07940004781166177, 0.06553007727510363, 0.054569801893953995, 0.031510858854717494, 0.0354162421169949]}}
{"id": "5e214ff2-dae3-458b-9dde-4adfc97e5a0c", "fitness": 0.09016109151290534, "name": "HybridPSODE", "description": "Introduce a dynamic inertia weight strategy and elite recombination to enhance convergence in HybridPSODE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 1.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            self.inertia_weight *= 0.99  # New line\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                elite_candidate = population[global_best_idx]  # New line\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3) + 0.1 * (elite_candidate - x1), lb, ub)  # Modified line\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09016 with standard deviation 0.05139.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.16071727902059474, 0.16834962366607575, 0.14460630914732964, 0.08594193586186327, 0.07940004781166177, 0.06585578148117666, 0.03242013403917121, 0.03366938583513113, 0.04048932675314387]}}
{"id": "5fb4a302-5051-46da-84ea-99b2e5f5aded", "fitness": 0.1152472450408675, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and learning coefficients, integrating a local search mechanism for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99  # Decay factor for inertia\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay  # Decay the inertia weight\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11525 with standard deviation 0.04050.", "error": "", "parent_ids": ["75dbf803-a6a6-423b-a186-a5c76ca43024"], "operator": null, "metadata": {"aucs": [0.1566822151574584, 0.16610614381970956, 0.15266500413636475, 0.10261161073425118, 0.10517757844598552, 0.08356142794157595, 0.1528532107440066, 0.06051670343916138, 0.057051310949294165]}}
{"id": "6e9d9af0-1a25-4ad4-ba22-811fb086f89b", "fitness": 0.11583548161517615, "name": "EnhancedHybridPSODE", "description": "Introduced a decay factor to the mutation factor for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99  # Decay factor for inertia\n        self.mutation_decay = 0.995  # Decay factor for mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay  # Decay the inertia weight\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay  # Decay mutation factor\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11584 with standard deviation 0.04056.", "error": "", "parent_ids": ["5fb4a302-5051-46da-84ea-99b2e5f5aded"], "operator": null, "metadata": {"aucs": [0.1554859551352512, 0.16610614381970956, 0.15517587241964126, 0.10261161073425118, 0.10925641590585888, 0.08356142794157595, 0.1528532107440066, 0.060417386886996494, 0.057051310949294165]}}
{"id": "dcb86a3e-7322-4c25-998b-368983931bf1", "fitness": 0.1027135011297549, "name": "EnhancedHybridPSOAnnealing", "description": "Integrated a temperature-based simulated annealing component to enhance the exploration phase and improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSOAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.temperature = 1.0\n        self.temperature_decay = 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, self.temperature, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score or np.exp((global_best_score - local_score) / self.temperature) > np.random.rand():\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n            self.temperature *= self.temperature_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridPSOAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10271 with standard deviation 0.04159.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.15155217351434835, 0.16610614381970956, 0.15304547255181933, 0.08594193586186327, 0.08038198646527395, 0.06964014697524223, 0.10938600273699539, 0.05338762094733873, 0.05498002729520324]}}
{"id": "5eb1cadf-20bd-462f-b978-ac80915c8b5a", "fitness": 0.11299997435322637, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive dynamics using fitness-based inertia and mutation adjustments for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.fitness_weight = 0.5  # Weight to adjust inertia based on fitness\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            inertia_adjustment = self.fitness_weight * (personal_best_scores - global_best_score)\n            adaptive_inertia = np.clip(self.inertia_weight + inertia_adjustment, 0.4, 0.9)\n            velocities = (adaptive_inertia[:, np.newaxis] * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adapt mutation factor based on fitness\n            fitness_diff = np.maximum(1e-10, personal_best_scores - global_best_score)\n            adaptive_mutation_factor = self.mutation_factor * (1 + 0.5 * np.tanh(fitness_diff / np.std(personal_best_scores)))\n            self.mutation_factor = np.mean(adaptive_mutation_factor) * self.mutation_decay\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11300 with standard deviation 0.04359.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.15127339948928764, 0.16610614381970956, 0.1628017298165494, 0.10261161073425118, 0.09281498011198364, 0.08356142794157595, 0.1528532107440066, 0.04792595557237922, 0.057051310949294165]}}
{"id": "17595855-b7bb-4b6f-988d-2d39c2af9766", "fitness": 0.10706127898669883, "name": "AdaptiveLearningHybridPSO", "description": "Introduced a novel adaptive learning rate mechanism to dynamically adjust search behavior based on convergence progress, improving exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLearningHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.1  # Initial learning rate for adaptation\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive learning rate adjustment\n            progress = (self.budget - eval_count) / self.budget\n            self.learning_rate = 0.1 + (0.9 * (1 - progress))\n\n            # PSO Component with adaptive inertia and learning rate\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + self.learning_rate * velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveLearningHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10706 with standard deviation 0.04055.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.15522445658513795, 0.16610614381970956, 0.15616315761868504, 0.10792348985603606, 0.10150476013320875, 0.0847876549960227, 0.07932890097494638, 0.06409623593133973, 0.04841671096520328]}}
{"id": "59d782c7-e789-4562-bed7-e6c94ee4defc", "fitness": 0.11424233475623938, "name": "AdaptiveHybridPSODE", "description": "Introduced adaptive learning rates for the cognitive and social coefficients to dynamically adjust exploration and exploitation over time.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99  # Decay factor for inertia\n        self.mutation_decay = 0.995  # Decay factor for mutation\n        self.cognitive_decay = 0.98  # Decay factor for cognitive coefficient\n        self.social_growth = 1.02  # Growth factor for social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia and learning rates\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay  # Decay the inertia weight\n            self.cognitive_coeff *= self.cognitive_decay  # Decay the cognitive coefficient\n            self.social_coeff *= self.social_growth  # Grow the social coefficient\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay  # Decay mutation factor\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11424 with standard deviation 0.04063.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.16000855618577192, 0.16610614381970956, 0.1498991507388172, 0.10261161073425118, 0.09112205467928303, 0.08356142794157595, 0.1528532107440066, 0.06496754701344487, 0.057051310949294165]}}
{"id": "27a1c04b-3da0-4b50-ba4a-0a86b3f4f03a", "fitness": 0.10253969341073296, "name": "EnhancedHybridPSODE", "description": "Improved exploration by adding dynamic adjustment to the crossover rate based on evaluation count.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9  # Start with a higher inertia for exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99  # Decay factor for inertia\n        self.mutation_decay = 0.995  # Decay factor for mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Component with adaptive inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay  # Decay the inertia weight\n\n            # DE Component with local search\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                # Dynamic adjustment to the crossover rate based on evaluation count\n                self.crossover_rate = 0.9 - 0.5 * (eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Local search around the best solution found so far\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay  # Decay mutation factor\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10254 with standard deviation 0.04463.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.1527680929054933, 0.16610614381970956, 0.16278044433083305, 0.10261161073425118, 0.08907456586857943, 0.07838493038951933, 0.07932890097494638, 0.04884465052063813, 0.04295790115262632]}}
{"id": "a85450a8-bf5c-4509-8f35-7084a794ec08", "fitness": 0.11611855127940308, "name": "EnhancedHybridPSODE_AdaptiveSocialLearning", "description": "EnhancedHybridPSODE with Adaptive Social Learning: Incorporates dynamic social learning rates to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveSocialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995  # Decay factor for social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay  # Decay the social coefficient\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveSocialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11612 with standard deviation 0.04114.", "error": "", "parent_ids": ["6e9d9af0-1a25-4ad4-ba22-811fb086f89b"], "operator": null, "metadata": {"aucs": [0.1520524650957883, 0.17172376275875478, 0.15592733131267134, 0.10261161073425118, 0.10913771712904552, 0.08356142794157595, 0.1528532107440066, 0.060148124849239926, 0.057051310949294165]}}
{"id": "e7589dcd-9605-4f06-9ba2-cf61439cd8fb", "fitness": 0.11400002063770016, "name": "EnhancedHybridPSODE_AdaptiveSocialLearning_LocalSearch", "description": "EnhancedHybridPSODE with Adaptive Social Learning and Local Search: Adds a local search step when stagnation is detected, improving convergence on challenging landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveSocialLearning_LocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995\n        self.stagnation_threshold = 10  # Threshold for stagnation detection\n        self.local_search_intensity = 5  # Number of local search steps\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count, stagnation_count = self.population_size, 0\n        last_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_count = 0\n                    else:\n                        stagnation_count += 1\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n                        stagnation_count = 0\n\n            # Local Search for Stagnation\n            if stagnation_count > self.stagnation_threshold:\n                for _ in range(self.local_search_intensity):\n                    local_trial = np.clip(global_best_position + np.random.normal(0, 0.1, self.dim), lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n                        stagnation_count = 0\n                        break\n                stagnation_count = 0  # Reset stagnation count after local search\n\n            self.mutation_factor *= self.mutation_decay\n            \n            if global_best_score < last_best_score:\n                last_best_score = global_best_score\n                stagnation_count = 0\n            else:\n                stagnation_count += 1\n            \n            if eval_count >= self.budget:\n                break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveSocialLearning_LocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11400 with standard deviation 0.04322.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.16586742637443963, 0.16610614381970956, 0.1503848678303088, 0.10247638767193457, 0.09677029244206703, 0.08348686292243346, 0.1528532107440066, 0.05100368298510771, 0.057051310949294165]}}
{"id": "a88f51e1-6927-4acc-94ec-1c558f03e785", "fitness": 0.10996358012568623, "name": "EnhancedHybridPSODE_DynamicAdaptive", "description": "EnhancedHybridPSODE with Dynamic Adaptive Mechanisms: Introduces dynamic adaptation of inertia weight and mutation strategy across iterations for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_DynamicAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_min = 0.4\n        self.mutation_min = 0.5\n        self.social_coeff_min = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamic PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Adaptive inertia weight and social coefficient\n            self.inertia_weight = max(self.inertia_min, 0.9 - 0.5 * (eval_count / self.budget))\n            self.social_coeff = max(self.social_coeff_min, 1.5 - 0.5 * (eval_count / self.budget))\n\n            # DE Component with dynamic mutation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                dynamic_mutation = self.mutation_min + (self.mutation_factor - self.mutation_min) * (self.budget - eval_count) / self.budget\n                mutant = np.clip(x1 + dynamic_mutation * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridPSODE_DynamicAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10996 with standard deviation 0.04219.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.15130312674011503, 0.16610614381970956, 0.14169120399747248, 0.10261161073425118, 0.08585756197408623, 0.09109491709216044, 0.15208650359721676, 0.04365438683375655, 0.05526676634240779]}}
{"id": "59d48f82-05e2-4b6d-bc77-2dc3ab5b259c", "fitness": 0.11358476681396897, "name": "EnhancedHybridPSODE_AdaptiveInertiaMutation", "description": "Introduce Adaptive Inertia Decay and Dynamic Mutation Strategies to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveInertiaMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n        initial_mutation_factor = self.mutation_factor\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            stagnation_ratio = eval_count / self.budget\n            self.inertia_weight = max(0.4, self.inertia_weight * (1 - stagnation_ratio))\n\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.social_coeff *= self.social_coeff_decay\n\n            # DE Component with Dynamic Mutation Strategy\n            mutation_adjustment = 1 + stagnation_ratio\n            self.mutation_factor = initial_mutation_factor * mutation_adjustment\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveInertiaMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11358 with standard deviation 0.04172.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.17003380345656016, 0.14950139780186666, 0.11066381012543713, 0.08907456586857943, 0.09624522412090797, 0.15069024842066858, 0.04365438683375655, 0.062027374862741236]}}
{"id": "d4b76c7c-19f2-4186-bbff-f24b5b04a92d", "fitness": 0.1141057118016983, "name": "OptimizedHybridPSODE_StochasticGradientInertia", "description": "OptimizedHybridPSODE_StochasticGradientInertia: Refines inertia weight dynamically using stochastic gradient information to enhance convergence speed and stability.", "code": "import numpy as np\n\nclass OptimizedHybridPSODE_StochasticGradientInertia:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995\n        self.learning_rate = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # Stochastic Gradient Component for Inertia Weight Adjustment\n            gradient_estimates = np.random.normal(0, 0.1, population.shape)\n            inertia_adjustment = self.learning_rate * np.mean(np.abs(gradient_estimates), axis=0)\n            self.inertia_weight = np.clip(self.inertia_weight - inertia_adjustment, 0.4, 0.9)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm OptimizedHybridPSODE_StochasticGradientInertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11411 with standard deviation 0.03343.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.15272143125785465, 0.1702918008529356, 0.15648676268379258, 0.10305973871965057, 0.09374427623411441, 0.07443519017405165, 0.09045950008471892, 0.09739653257443226, 0.08835617363373405]}}
{"id": "4e1ea2a9-cb65-4aba-8a73-7a666179fab3", "fitness": 0.10970397444910267, "name": "EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedLocalSearch", "description": "EnhancedHybridPSODE with Adaptive Social Learning and Randomized Local Search: Introduces randomized local search to further exploit local optima and improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995\n        self.local_search_prob = 0.1  # Probability of performing local search\n        self.local_search_radius = 0.1  # Radius for local search perturbation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < self.local_search_prob:\n                    # Randomized Local Search\n                    perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10970 with standard deviation 0.03825.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.1588114020996585, 0.16610614381970956, 0.1543905672329362, 0.11450332503117355, 0.10010458455249638, 0.07973757891201017, 0.06272524981622463, 0.07249909398695187, 0.07845782459076311]}}
{"id": "d2850db5-66c3-45dd-bb24-c97daed3072c", "fitness": 0.11522277872020276, "name": "EnhancedHybridPSODE_AdaptiveSocialLearning", "description": "Refines the EnhancedHybridPSODE by adjusting mutation decay during iterations to maintain diversity longer.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveSocialLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.998  # Adjusted mutation decay\n        self.social_coeff_decay = 0.995  # Decay factor for social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay  # Decay the social coefficient\n\n            # DE Component\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveSocialLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11522 with standard deviation 0.04016.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.15414827064748515, 0.16610614381970956, 0.15237209295388654, 0.1028351642822658, 0.1078351993189407, 0.08356142794157595, 0.1528532107440066, 0.060242187824660176, 0.057051310949294165]}}
{"id": "cb5cef20-573f-45e1-a08c-b76661c2f359", "fitness": 0.10424014401990248, "name": "EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedNeighborhood", "description": "EnhancedHybridPSODE with Adaptive Social Learning and Randomized Neighborhood: Introduces neighborhood-based local search to improve convergence by enhancing exploration in promising areas.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.mutation_decay = 0.995\n        self.social_coeff_decay = 0.995\n        self.neighborhood_size = max(2, self.population_size // 20)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # DE Component with Randomized Neighborhood\n            for i in range(self.population_size):\n                neighbors = np.random.choice(np.delete(np.arange(self.population_size), i), self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: personal_best_scores[x])\n                \n                candidates = np.random.choice(neighbors, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < 0.1:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            self.mutation_factor *= self.mutation_decay\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridPSODE_AdaptiveSocialLearning_RandomizedNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10424 with standard deviation 0.03904.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.1506049426146573, 0.16610614381970956, 0.15013524693805347, 0.10174087456290448, 0.09092207425966081, 0.09001199318250419, 0.06487260905845516, 0.06923945941475673, 0.05452795232842056]}}
{"id": "306c9baa-f118-48da-9cda-b4a0f4053fc3", "fitness": 0.11619476362205727, "name": "AdaptiveHybridPSODE_EnhancedMutation", "description": "AdaptiveHybridPSO-DE with Enhanced Mutation: Integrates adaptive mutation strategies dynamically adjusting to different optimization landscapes to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE_EnhancedMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.social_coeff_decay = 0.995\n        self.mutation_factor_min = 0.4  # Minimum value for mutation factor\n        self.mutation_factor_max = 0.9  # Maximum value for mutation factor\n        self.random_walk_prob = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # Enhanced Mutation Strategy\n            self.mutation_factor = self.mutation_factor_min + \\\n                                   (self.mutation_factor_max - self.mutation_factor_min) * \\\n                                   (1 - eval_count / self.budget)\n\n            # DE Component with enhanced mutation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Random walk for enhanced exploration\n                if eval_count < self.budget and np.random.rand() < self.random_walk_prob:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm AdaptiveHybridPSODE_EnhancedMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11619 with standard deviation 0.04253.", "error": "", "parent_ids": ["a85450a8-bf5c-4509-8f35-7084a794ec08"], "operator": null, "metadata": {"aucs": [0.15406628481181872, 0.16610614381970956, 0.1626727783509252, 0.1164636014316911, 0.10918195041996004, 0.08343587020397525, 0.1478493202955039, 0.04666813367131262, 0.05930878959361918]}}
{"id": "42d6117e-0fdc-4971-9948-7849a079c32e", "fitness": 0.10164530176390868, "name": "AdaptiveHybridPSODE_EnhancedMutation", "description": "Introduced limited local search by adjusting random walk probability for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE_EnhancedMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.social_coeff_decay = 0.995\n        self.mutation_factor_min = 0.4  # Minimum value for mutation factor\n        self.mutation_factor_max = 0.9  # Maximum value for mutation factor\n        self.random_walk_prob = 0.05  # Adjusted for improved balance\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            # Enhanced Mutation Strategy\n            self.mutation_factor = self.mutation_factor_min + \\\n                                   (self.mutation_factor_max - self.mutation_factor_min) * \\\n                                   (1 - eval_count / self.budget)\n\n            # DE Component with enhanced mutation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Random walk for enhanced exploration\n                if eval_count < self.budget and np.random.rand() < self.random_walk_prob:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveHybridPSODE_EnhancedMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10165 with standard deviation 0.04215.", "error": "", "parent_ids": ["306c9baa-f118-48da-9cda-b4a0f4053fc3"], "operator": null, "metadata": {"aucs": [0.15172134585226305, 0.16610614381970956, 0.14499467306381786, 0.11509546961705963, 0.0914455970775595, 0.07588344411979953, 0.04336855729619182, 0.07113721350193891, 0.0550552715268382]}}
{"id": "811e34b4-5275-4cd3-a40b-1f74d3849b62", "fitness": 0.1148770560622304, "name": "AdaptiveHybridPSODE_EnhancedMutation", "description": "Incorporates a decay strategy for the cognitive coefficient to improve exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE_EnhancedMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.social_coeff_decay = 0.995\n        self.mutation_factor_min = 0.4\n        self.mutation_factor_max = 0.9\n        self.random_walk_prob = 0.1\n        self.cognitive_coeff_decay = 0.995  # New line 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO Component\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n            self.cognitive_coeff *= self.cognitive_coeff_decay  # New line 2\n\n            # Enhanced Mutation Strategy\n            self.mutation_factor = self.mutation_factor_min + \\\n                                   (self.mutation_factor_max - self.mutation_factor_min) * \\\n                                   (1 - eval_count / self.budget)\n\n            # DE Component with enhanced mutation\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                # Random walk for enhanced exploration\n                if eval_count < self.budget and np.random.rand() < self.random_walk_prob:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveHybridPSODE_EnhancedMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11488 with standard deviation 0.04150.", "error": "", "parent_ids": ["306c9baa-f118-48da-9cda-b4a0f4053fc3"], "operator": null, "metadata": {"aucs": [0.15616341134226253, 0.16610614381970956, 0.14623122931681942, 0.1164636014316911, 0.11379344125895918, 0.08432318066775235, 0.1478493202955039, 0.04365438683375655, 0.05930878959361918]}}
{"id": "28e72545-05f5-4518-aecc-c0d814c09b0b", "fitness": 0.1091226268782321, "name": "AdaptiveHybridPSODE_DynamicLearningLocalSearch", "description": "AdaptiveHybridPSO-DE with Dynamic Learning Rate and Local Search: Enhances convergence by incorporating adaptive learning rates for PSO and a local search mechanism to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE_DynamicLearningLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_decay = 0.99\n        self.social_coeff_decay = 0.995\n        self.mutation_factor_min = 0.4\n        self.mutation_factor_max = 0.9\n        self.random_walk_prob = 0.1\n        self.local_search_intensity = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_cognitive_coeff = self.cognitive_coeff * (1 - eval_count / self.budget)\n            adaptive_social_coeff = self.social_coeff * (eval_count / self.budget)\n            velocities = (self.inertia_weight * velocities +\n                          adaptive_cognitive_coeff * r1 * (personal_best_positions - population) +\n                          adaptive_social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n            self.inertia_weight *= self.inertia_decay\n            self.social_coeff *= self.social_coeff_decay\n\n            self.mutation_factor = self.mutation_factor_min + \\\n                                   (self.mutation_factor_max - self.mutation_factor_min) * \\\n                                   (1 - eval_count / self.budget)\n\n            for i in range(self.population_size):\n                candidates = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[candidates]\n                mutant = np.clip(x1 + self.mutation_factor * (x2 - x3), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n                if eval_count < self.budget and np.random.rand() < self.random_walk_prob:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n\n                if eval_count >= self.budget:\n                    break\n\n            # Local Search Enhancement\n            if (eval_count < self.budget) and (np.random.rand() < 0.5):\n                for _ in range(self.local_search_intensity):\n                    local_perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(global_best_position + local_perturbation, lb, ub)\n                    local_score = func(local_trial)\n                    eval_count += 1\n                    if local_score < global_best_score:\n                        global_best_position = local_trial\n                        global_best_score = local_score\n                    if eval_count >= self.budget:\n                        break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveHybridPSODE_DynamicLearningLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10912 with standard deviation 0.03667.", "error": "", "parent_ids": ["306c9baa-f118-48da-9cda-b4a0f4053fc3"], "operator": null, "metadata": {"aucs": [0.1515277167863036, 0.16610614381970956, 0.15586747370152887, 0.10261161073425118, 0.09445569964549994, 0.08820388071291951, 0.0938685139761638, 0.06309377270310268, 0.06636882982460968]}}
