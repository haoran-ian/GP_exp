{"id": "11ca1835-7ad2-41ef-b994-01a80cb4415a", "fitness": 0.72115, "name": "HybridPSO_DE", "description": "A hybrid Particle Swarm Optimization (PSO) with Differential Evolution (DE) mutation strategy for enhanced exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Apply DE mutation strategy\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.69885, 0.7138, 0.7598, 0.6838500000000001, 0.7138, 0.7598, 0.6838500000000001, 0.7138, 0.7598, 0.6838500000000001, 0.7138, 0.7598, 0.69885, 0.7138, 0.7598]}}
{"id": "9e063c64-e60a-413e-992b-87a4d82f53e9", "fitness": 0.7937, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive inertia weight for better convergence rate.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["11ca1835-7ad2-41ef-b994-01a80cb4415a"], "operator": null, "metadata": {"aucs": [0.804, 0.76135, 0.81575, 0.804, 0.76135, 0.81575, 0.804, 0.76135, 0.81575, 0.804, 0.76135, 0.81575, 0.804, 0.76135, 0.81575]}}
{"id": "76f67e40-9236-493c-9edb-e08e53ae65e5", "fitness": 0.8263666666666666, "name": "HybridPSO_DE", "description": "Hybrid PSO-DE with adaptive social coefficient and enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["9e063c64-e60a-413e-992b-87a4d82f53e9"], "operator": null, "metadata": {"aucs": [0.82555, 0.81365, 0.8399, 0.82555, 0.81365, 0.8399, 0.82555, 0.81365, 0.8399, 0.82555, 0.81365, 0.8399, 0.82555, 0.81365, 0.8399]}}
{"id": "2553e7d8-7b47-43ba-903b-0becf372a867", "fitness": 0.8219166666666666, "name": "HybridPSO_DE", "description": "Refined Hybrid PSO-DE with inertia weight decay and dynamic crossover rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.98)  # Adjusted inertia weight decay\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                self.CR = 0.8 + (self.budget - evaluations) / (5 * self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["76f67e40-9236-493c-9edb-e08e53ae65e5"], "operator": null, "metadata": {"aucs": [0.8437, 0.83125, 0.7908, 0.8437, 0.83125, 0.7908, 0.8437, 0.83125, 0.7908, 0.8437, 0.83125, 0.7908, 0.8437, 0.83125, 0.7908]}}
{"id": "545ccd00-c756-492c-9cdf-155e41763f95", "fitness": 0.80765, "name": "HybridPSO_DE", "description": "Introduced gradual increase in the cognitive coefficient for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            self.cognitive_coeff = 1.5 + 0.1 * evaluations / self.budget  # Gradually increase cognitive coefficient\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["76f67e40-9236-493c-9edb-e08e53ae65e5"], "operator": null, "metadata": {"aucs": [0.7979499999999999, 0.81155, 0.81345, 0.7979499999999999, 0.81155, 0.81345, 0.7979499999999999, 0.81155, 0.81345, 0.7979499999999999, 0.81155, 0.81345, 0.7979499999999999, 0.81155, 0.81345]}}
{"id": "086909ed-5581-478e-9c8e-3018567e5dd1", "fitness": 0.8348666666666666, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive F factor for improved mutation control.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["76f67e40-9236-493c-9edb-e08e53ae65e5"], "operator": null, "metadata": {"aucs": [0.8388, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277]}}
{"id": "ee3d7ed7-d6ed-4264-924c-bde2eeb34c42", "fitness": 0.7113933333333332, "name": "HybridPSO_DE", "description": "Refined Hybrid PSO-DE with dynamic social coefficient and adaptive F factor for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.2 + 0.3 * (self.budget - evaluations) / self.budget  # Increased range for dynamic social coefficient\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.15 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.50005, 0.79955, 0.8439, 0.50005, 0.79955, 0.7973, 0.50005, 0.79955, 0.8439, 0.50005, 0.79955, 0.8439, 0.50005, 0.79955, 0.8439]}}
{"id": "3425e65e-1487-44ee-828c-135dd1c84465", "fitness": 0.8309999999999998, "name": "HybridPSO_DE", "description": "Refined PSO-DE with dynamic cognitive coefficient and enhanced DE crossover for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)\n\n            self.F = 0.8 - 0.4 * evaluations / self.budget\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR + 0.1, mutant, self.population[i])  # Enhanced DE crossover\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            self.cognitive_coeff = 1.5 - 0.1 * evaluations / self.budget  # Dynamic cognitive coefficient\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.83395, 0.81115, 0.8479, 0.83395, 0.81115, 0.8479, 0.83395, 0.81115, 0.8479, 0.83395, 0.81115, 0.8479, 0.83395, 0.81115, 0.8479]}}
{"id": "11c7d8b9-3853-45f0-8c63-62738dda3dbc", "fitness": 0.8050666666666667, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive social coefficient and modified DE mutation strategy for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.7 - 0.3 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.4 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.80615, 0.7952, 0.81385, 0.80615, 0.7952, 0.81385, 0.80615, 0.7952, 0.81385, 0.80615, 0.7952, 0.81385, 0.80615, 0.7952, 0.81385]}}
{"id": "906014cb-9bfd-4529-b720-57aa23f367bc", "fitness": 0.671886106697077, "name": "HybridPSO_DE", "description": "Adaptive velocity adjustment and improved crossover strategy for efficient convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR + 0.05, mutant, self.population[i])  # Slightly improved crossover\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.42 on the real problem.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.08110916383511779, 0.9892603169104645, 0.9452888393456487]}}
{"id": "e204bf56-0a5a-4ab7-a8fa-4d1d4ef13e32", "fitness": 0.8173, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with dynamic cognitive coefficient for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            # Added dynamic cognitive coefficient for balanced convergence\n            self.cognitive_coeff = 1.5 - 0.1 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.81125, 0.79175, 0.8489, 0.81125, 0.79175, 0.8489, 0.81125, 0.79175, 0.8489, 0.81125, 0.79175, 0.8489, 0.81125, 0.79175, 0.8489]}}
{"id": "d1a26603-8d50-4228-aa30-00d1a59d2da7", "fitness": 0.7296499999999999, "name": "HybridPSO_DE", "description": "Improved inertia weight decay and increased cognitive coefficient for faster convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.85  # Reduced initial inertia weight for better exploration\n        self.cognitive_coeff = 1.7  # Increased cognitive coefficient for enhanced local search\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)\n\n            self.F = 0.8 - 0.4 * evaluations / self.budget\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.16 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.50005, 0.86185, 0.8270500000000001, 0.50005, 0.86185, 0.8270500000000001, 0.50005, 0.86185, 0.8270500000000001, 0.50005, 0.86185, 0.8270500000000001, 0.50005, 0.86185, 0.8270500000000001]}}
{"id": "57335a56-b921-416d-8b60-8912619f463d", "fitness": 0.8116666666666668, "name": "HybridPSO_DE", "description": "Refined Hybrid PSO-DE with an optimized adaptive F factor and dynamic population size adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.7 - 0.2 * evaluations / self.budget  # Adjusted adaptive F factor range\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n                        \n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8190999999999999, 0.766, 0.8499, 0.8190999999999999, 0.766, 0.8499, 0.8190999999999999, 0.766, 0.8499, 0.8190999999999999, 0.766, 0.8499, 0.8190999999999999, 0.766, 0.8499]}}
{"id": "5db91311-6545-4647-94a7-1bef13461521", "fitness": 0.8046666666666666, "name": "HybridPSO_DE", "description": "Incorporate dynamic crossover probability in DE for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Adaptive CR factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349]}}
{"id": "5638761f-e8d2-43c8-b324-9c597c7d3463", "fitness": 0.8302999999999999, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with improved exploration by optimizing CR and dynamic social coefficient adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.7  # Crossover probability (Changed from 0.9 to 0.7)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.2 + 0.3 * (self.budget - evaluations) / self.budget  # Changed adaptation\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8431, 0.8299, 0.8179, 0.8431, 0.8299, 0.8179, 0.8431, 0.8299, 0.8179, 0.8431, 0.8299, 0.8179, 0.8431, 0.8299, 0.8179]}}
{"id": "67ef4edb-00f9-43bf-8581-f61fabada9c2", "fitness": 0.8040999999999998, "name": "HybridPSO_DE", "description": "Improved exploration with modified mutation strategy and dynamic cognitive coefficient adjustment.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c + np.random.normal(0, 0.1, self.dim)), self.lower_bound, self.upper_bound)  # Added Gaussian noise\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8159, 0.7655000000000001, 0.8309, 0.8159, 0.7655000000000001, 0.8309, 0.8159, 0.7655000000000001, 0.8309, 0.8159, 0.7655000000000001, 0.8309, 0.8159, 0.7655000000000001, 0.8309]}}
{"id": "cb4c8b1c-2a36-4b9e-8195-92f2ab7fb50b", "fitness": 0.8170999999999999, "name": "HybridPSO_DE", "description": "Introduced adaptive cognitive coefficient to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            \n            # Adaptive cognitive coefficient\n            self.cognitive_coeff = 1.5 + 0.1 * (evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565]}}
{"id": "786767ef-64a2-46df-b305-f30b82447875", "fitness": 0.70885, "name": "HybridPSO_DE", "description": "Further enhanced Hybrid PSO-DE with adaptive social coefficient for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.2 * np.sin(np.pi * evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.15 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.50005, 0.8031, 0.8234, 0.50005, 0.8031, 0.8234, 0.50005, 0.8031, 0.8234, 0.50005, 0.8031, 0.8234, 0.50005, 0.8031, 0.8234]}}
{"id": "50dd980c-92c4-4b9b-bcdd-080712c50a35", "fitness": 0.8202166666666668, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive cognitive factor for improved convergence and dynamic crossover probability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            self.CR = 0.5 + 0.4 * evaluations / self.budget  # Dynamic crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            self.cognitive_coeff = 1.6 - 0.1 * evaluations / self.budget  # Adaptive cognitive factor\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8069, 0.81385, 0.8399, 0.8069, 0.81385, 0.8399, 0.8069, 0.81385, 0.8399, 0.8069, 0.81385, 0.8399, 0.8069, 0.81385, 0.8399]}}
{"id": "d22abbfd-713a-451f-9cb0-a794a5db7971", "fitness": 0.1590682169097862, "name": "HybridPSO_DE", "description": "Adaptive inertia weight with dynamic crossover rate for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            self.CR = 0.9 - 0.5 * evaluations / self.budget  # Dynamic crossover rate\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.08 on the real problem.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.07454325294073738, 0.273694042161314, 0.1289673556273072]}}
{"id": "4c2008a6-d2c4-4f5d-ba23-80b13a9e0919", "fitness": 0.8314133333333333, "name": "HybridPSO_DE", "description": "HybridPSO_DE with adaptive social coefficient and enhanced DE crossover for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR * (1 + 0.05 * evaluations / self.budget), mutant, self.population[i])  # Adjusted crossover probability\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.15 * (self.budget - evaluations) / self.budget  # Adjusted social coefficient\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8248, 0.81675, 0.8439, 0.8248, 0.8314, 0.8439, 0.8248, 0.8314, 0.8439, 0.8248, 0.8314, 0.8439, 0.8248, 0.81675, 0.8439]}}
{"id": "1d9fea25-b047-452b-bc98-4866a49e583d", "fitness": 0.8046666666666666, "name": "HybridPSO_DE", "description": "Improved mutation strategy by incorporating dynamic crossover probability for enhanced exploration and exploitation balance.  ", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            self.CR = 0.5 + 0.4 * (self.budget - evaluations) / self.budget  # Dynamic CR adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349, 0.7951, 0.784, 0.8349]}}
{"id": "31252bb8-e999-4096-8b25-d62b1776f719", "fitness": 0.8170999999999999, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with dynamic cognitive coefficient adjustment to improve exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update coefficients for improved convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            self.cognitive_coeff = 1.5 + 0.1 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 22, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565, 0.81195, 0.8137, 0.82565]}}
{"id": "0ae09291-815e-4afe-9890-a809199e2c7c", "fitness": 0.7587166666666668, "name": "HybridPSO_DE", "description": "Optimized inertia weight adaptation and social coefficient for improved convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.995)  # Modified adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.2 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.7696000000000001, 0.7712, 0.73535, 0.7696000000000001, 0.7712, 0.73535, 0.7696000000000001, 0.7712, 0.73535, 0.7696000000000001, 0.7712, 0.73535, 0.7696000000000001, 0.7712, 0.73535]}}
{"id": "d77e0cdd-542a-48b1-ba82-927c998d1364", "fitness": 0.8181999999999999, "name": "HybridPSO_DE", "description": "Improved particle swarm dynamics by adjusting social and cognitive coefficients for enhanced global exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.7  # Changed cognitive coefficient\n        self.social_coeff = 1.3  # Changed social coefficient\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)\n\n            self.F = 0.8 - 0.4 * evaluations / self.budget\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8220000000000001, 0.8074, 0.8251999999999999, 0.8220000000000001, 0.8074, 0.8251999999999999, 0.8220000000000001, 0.8074, 0.8251999999999999, 0.8220000000000001, 0.8074, 0.8251999999999999, 0.8220000000000001, 0.8074, 0.8251999999999999]}}
{"id": "5b598028-367e-4aff-8a35-6d31cfae7202", "fitness": 0.8248333333333335, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive cognitive and social coefficients for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n            \n            # Adaptive cognitive and social coefficients\n            self.cognitive_coeff = 1.5 + 0.2 * evaluations / self.budget\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 25, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.80705, 0.80555, 0.8619, 0.80705, 0.80555, 0.8619, 0.80705, 0.80555, 0.8619, 0.80705, 0.80555, 0.8619, 0.80705, 0.80555, 0.8619]}}
{"id": "7384f559-510f-4129-a4cc-9365a37c41e3", "fitness": 0.8348666666666666, "name": "HybridPSO_DE", "description": "Improved Hybrid PSO-DE with adaptive velocity damping for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)\n\n            self.F = 0.8 - 0.4 * evaluations / self.budget\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n            # Added adaptive velocity damping to enhance exploration-exploitation balance\n            if evaluations > self.budget * 0.7:\n                self.velocity *= 0.9\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8388, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277, 0.8268, 0.8477, 0.8277]}}
{"id": "43a9d3e0-46d8-44d2-844d-17b974d601aa", "fitness": 0.8110833333333335, "name": "HybridPSO_DE", "description": "Refined Hybrid PSO-DE with adjusted social coefficient for better exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.7  # Adjusted initial social coefficient\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.8 + 0.1 * (self.budget - evaluations) / self.budget  # Changed increment for social coefficient\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8215, 0.78505, 0.8250500000000001, 0.8215, 0.7878000000000001, 0.8250500000000001, 0.8215, 0.7878000000000001, 0.8250500000000001, 0.8215, 0.7878000000000001, 0.8250500000000001, 0.8215, 0.78505, 0.8250500000000001]}}
{"id": "d4b00560-fd83-4db7-ab3e-3757eb8d73f4", "fitness": 0.6815833333333334, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive F factor and refined convergence control using dynamic population size adjustment.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n            # Dynamically adjust population size for convergence\n            if evaluations % 10 == 0:\n                self.population_size = max(10, int(20 * (self.budget - evaluations) / self.budget))\n                self.population = np.clip(self.population[:self.population_size], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.11 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.83295, 0.6225499999999999, 0.58925, 0.83295, 0.6225499999999999, 0.58925, 0.83295, 0.6225499999999999, 0.58925, 0.83295, 0.6225499999999999, 0.58925, 0.83295, 0.6225499999999999, 0.58925]}}
{"id": "b97e93b8-3614-4c0f-b237-8aa74c375884", "fitness": 0.6668556430085643, "name": "MultiSwarmPSO_DE", "description": "Multi-Swarm PSO-DE with adaptive hybridization to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass MultiSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.swarm_count = 3  # Added multiple swarms\n        self.inertia_weight = 0.9  \n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  \n        self.CR = 0.9  \n        \n        # Initialize populations for multiple swarms\n        self.populations = [np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim)) for _ in range(self.swarm_count)]\n        self.velocities = [np.random.uniform(-1, 1, (self.population_size, self.dim)) for _ in range(self.swarm_count)]\n        \n        self.personal_best_position = [np.copy(pop) for pop in self.populations]\n        self.personal_best_value = [np.full(self.population_size, float('inf')) for _ in range(self.swarm_count)]\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the populations for each swarm\n            for swarm in range(self.swarm_count):\n                for i in range(self.population_size):\n                    value = func(self.populations[swarm][i])\n                    evaluations += 1\n                    if value < self.personal_best_value[swarm][i]:\n                        self.personal_best_value[swarm][i] = value\n                        self.personal_best_position[swarm][i] = self.populations[swarm][i]\n                    if value < self.global_best_value:\n                        self.global_best_value = value\n                        self.global_best_position = self.populations[swarm][i]\n\n                # Update velocity and position based on PSO for each swarm\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                for i in range(self.population_size):\n                    self.velocities[swarm][i] = (self.inertia_weight * self.velocities[swarm][i] +\n                                                 self.cognitive_coeff * r1 * (self.personal_best_position[swarm][i] - self.populations[swarm][i]) +\n                                                 self.social_coeff * r2 * (self.global_best_position - self.populations[swarm][i]))\n                    self.populations[swarm][i] = np.clip(self.populations[swarm][i] + self.velocities[swarm][i], self.lower_bound, self.upper_bound)\n\n                # Apply DE mutation strategy with adaptive F\n                self.F = 0.8 - 0.4 * evaluations / self.budget\n                for i in range(self.population_size):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.populations[swarm][np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                    trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.populations[swarm][i])\n                    trial_value = func(trial)\n                    evaluations += 1\n                    if trial_value < self.personal_best_value[swarm][i]:\n                        self.populations[swarm][i] = trial\n                        self.personal_best_value[swarm][i] = trial_value\n                        self.personal_best_position[swarm][i] = trial\n                        if trial_value < self.global_best_value:\n                            self.global_best_value = trial_value\n                            self.global_best_position = trial\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  \n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 29, "feedback": "The algorithm MultiSwarmPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.39 on the real problem.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.9199244583065151, 0.11811337684266587, 0.962529093876512]}}
{"id": "745a0e53-2520-4d34-a1b3-f526366387df", "fitness": 0.8118999999999998, "name": "HybridPSO_DE", "description": "Introduce Gaussian perturbation in DE mutation for enhanced diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), self.lower_bound, self.upper_bound)  # Introduce Gaussian perturbation\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.77925, 0.80115, 0.8553, 0.77925, 0.80115, 0.8553, 0.77925, 0.80115, 0.8553, 0.77925, 0.80115, 0.8553, 0.77925, 0.80115, 0.8553]}}
{"id": "7ae56f1e-5928-4553-8dc6-d95ad6dd15d6", "fitness": 0.8035333333333334, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive F factor and improved cognitive coefficient for better local exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.7  # Increased cognitive coefficient for better local exploration\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.80105, 0.81755, 0.792, 0.80105, 0.81755, 0.792, 0.80105, 0.81755, 0.792, 0.80105, 0.81755, 0.792, 0.80105, 0.81755, 0.792]}}
{"id": "7e9c35dd-29be-4d65-acd1-094f0a7cc8bf", "fitness": 0.7289833333333333, "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with dynamically adjusted CR for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            self.CR = 0.5 + 0.4 * evaluations / self.budget  # Adaptive CR for exploration and convergence\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.16 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.50005, 0.836, 0.8509, 0.50005, 0.836, 0.8509, 0.50005, 0.836, 0.8509, 0.50005, 0.836, 0.8509, 0.50005, 0.836, 0.8509]}}
{"id": "785c36a1-2fb1-43ee-91b8-7353889d2c10", "fitness": 0.69305, "name": "HybridPSO_DE", "description": "Improved Hybrid PSO-DE by enhancing the adaptive F factor's impact and refining velocity update for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Added adaptive inertia weight adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.9 - 0.5 * evaluations / self.budget  # Enhanced adaptive F factor impact\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 33, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.14 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.50005, 0.81165, 0.76745, 0.50005, 0.81165, 0.76745, 0.50005, 0.81165, 0.76745, 0.50005, 0.81165, 0.76745, 0.50005, 0.81165, 0.76745]}}
{"id": "4033f96a-01a0-4c33-8aed-2e5f75057e45", "fitness": 0.8588666666666668, "name": "HybridPSO_DE", "description": "Improved adaptive inertia weight decay and dynamic crossover probability for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * 0.98)  # Slightly adjusted adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["086909ed-5581-478e-9c8e-3018567e5dd1"], "operator": null, "metadata": {"aucs": [0.8755, 0.8455, 0.8556, 0.8755, 0.8455, 0.8556, 0.8755, 0.8455, 0.8556, 0.8755, 0.8455, 0.8556, 0.8755, 0.8455, 0.8556]}}
{"id": "02c96c69-4cf5-49ba-bde3-0f13e738f072", "fitness": 0.8789833333333333, "name": "HybridPSO_DE", "description": "Introduce non-linear adaptive adjustments for social coefficient and inertia weight to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.8 - 0.4 * evaluations / self.budget  # Adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * (self.budget - evaluations) / self.budget + 0.05 * np.sin(evaluations)  # Non-linear adjustment of social coefficient\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 35, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["4033f96a-01a0-4c33-8aed-2e5f75057e45"], "operator": null, "metadata": {"aucs": [0.8996500000000001, 0.8815, 0.8558, 0.8996500000000001, 0.8815, 0.8558, 0.8996500000000001, 0.8815, 0.8558, 0.8996500000000001, 0.8815, 0.8558, 0.8996500000000001, 0.8815, 0.8558]}}
{"id": "0660f4b6-1a00-455e-a0d4-906444704257", "fitness": 0.8801, "name": "HybridPSO_DE", "description": "Introduce adaptive mutation factor and dynamic social coefficient to optimize convergence and exploration balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["02c96c69-4cf5-49ba-bde3-0f13e738f072"], "operator": null, "metadata": {"aucs": [0.88595, 0.8624499999999999, 0.8919, 0.88595, 0.8624499999999999, 0.8919, 0.88595, 0.8624499999999999, 0.8919, 0.88595, 0.8624499999999999, 0.8919, 0.88595, 0.8624499999999999, 0.8919]}}
{"id": "fc632568-ae68-479e-a9f9-039988d775eb", "fitness": 0.7625166666666666, "name": "HybridPSO_DE", "description": "Introduce non-linear damping factor for social coefficient and adaptive velocity scaling for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.sin(evaluations * 2 * np.pi / self.budget)  # Non-linear adjustment using sine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.19 on similar problems with similar landscape features.", "error": "", "parent_ids": ["0660f4b6-1a00-455e-a0d4-906444704257"], "operator": null, "metadata": {"aucs": [0.50005, 0.8992, 0.8859, 0.50005, 0.8992, 0.8859, 0.50005, 0.8992, 0.8919, 0.50005, 0.8992, 0.8919, 0.50005, 0.8992, 0.8859]}}
{"id": "37770c1a-8df2-4ec9-bbc9-0b2b6fa95aa7", "fitness": 0.8866666666666667, "name": "HybridPSO_DE", "description": "Enhance exploration by adding dynamic velocity scaling and improve convergence speed with refined inertia weight adaptation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 2)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["0660f4b6-1a00-455e-a0d4-906444704257"], "operator": null, "metadata": {"aucs": [0.8829, 0.8899, 0.8993, 0.8829, 0.8899, 0.8993, 0.8829, 0.85965, 0.8993, 0.8829, 0.85965, 0.8993, 0.8829, 0.8899, 0.8993]}}
{"id": "8f300efd-45d0-49a1-b65f-1b6fe9049e10", "fitness": 0.6892813666964713, "name": "HybridPSO_DE", "description": "Hybridize with an enhanced DE adaptive mutation strategy and refined PSO social dynamics.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.2 * np.sin(evaluations))  # Increased dynamic velocity scaling\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 2)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.6 * np.cos(evaluations * np.pi / self.budget)  # Increased adaptation range for F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.41 on the real problem.", "error": "", "parent_ids": ["37770c1a-8df2-4ec9-bbc9-0b2b6fa95aa7"], "operator": null, "metadata": {"aucs": [0.10809241633702626, 0.991096082245166, 0.9686556015072221]}}
{"id": "a9151fbd-159e-40a3-8c1f-fbc8e4b3876c", "fitness": 0.8875499999999998, "name": "HybridPSO_DE", "description": "Introduce adaptive cognitive coefficient scaling and dynamic velocity perturbation to enhance convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 2)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 40, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["37770c1a-8df2-4ec9-bbc9-0b2b6fa95aa7"], "operator": null, "metadata": {"aucs": [0.87535, 0.8954, 0.8919, 0.87535, 0.8954, 0.8919, 0.87535, 0.8954, 0.8919, 0.87535, 0.8954, 0.8919, 0.87535, 0.8954, 0.8919]}}
{"id": "ffad5553-4f8b-4ef0-b90d-0c837f2c91ac", "fitness": 0.8844333333333336, "name": "HybridPSO_DE", "description": "Introduce adaptive inertia weight decay and a dynamic damping factor for enhanced convergence control.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 2) * (1 - evaluations / self.budget)))  # Enhanced inertia weight decay\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["a9151fbd-159e-40a3-8c1f-fbc8e4b3876c"], "operator": null, "metadata": {"aucs": [0.8839, 0.8975, 0.8719, 0.8839, 0.8975, 0.8719, 0.8839, 0.8975, 0.8719, 0.8839, 0.8975, 0.8719, 0.8839, 0.8975, 0.8719]}}
{"id": "c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723", "fitness": 0.8989433333333332, "name": "HybridPSO_DE", "description": "Enhance convergence by introducing a dynamic inertia weight reduction based on evaluations and fine-tuning the DE mutation strategy.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["a9151fbd-159e-40a3-8c1f-fbc8e4b3876c"], "operator": null, "metadata": {"aucs": [0.89365, 0.90995, 0.90955, 0.89365, 0.88275, 0.90955, 0.89365, 0.88275, 0.90955, 0.89365, 0.88275, 0.90955, 0.89365, 0.90995, 0.90955]}}
{"id": "ca7c95a8-10b3-4956-be05-3c4d57e9852a", "fitness": 0.8870900000000002, "name": "HybridPSO_DE", "description": "Introduce a sinusoidal adaptive update for the cognitive coefficient to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            # Introduce sinusoidal adaptive update for cognitive coefficient\n            self.cognitive_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / (2 * self.budget))  # New line added\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.8877, 0.8912, 0.8893, 0.8877, 0.87965, 0.8893, 0.8877, 0.87965, 0.8893, 0.8877, 0.87965, 0.8893, 0.8877, 0.8912, 0.8893]}}
{"id": "e16b1b29-face-48f0-9eef-027e638c82fd", "fitness": 0.7464833333333333, "name": "HybridPSO_DE", "description": "Improve the balance between exploration and exploitation by refining velocity update and adaptive F factor.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.2 * np.sin(evaluations))  # Adjusted sine factor\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.3 * np.cos(evaluations * np.pi / self.budget)  # Adjusted adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 44, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.17 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.50005, 0.87185, 0.86755, 0.50005, 0.87185, 0.86755, 0.50005, 0.87185, 0.86755, 0.50005, 0.87185, 0.86755, 0.50005, 0.87185, 0.86755]}}
{"id": "a71e9e35-c189-4f3f-b3bc-fa0be432dd53", "fitness": 0.8844333333333336, "name": "HybridPSO_DE", "description": "Improve exploration and exploitation balance by dynamically adjusting velocity based on local and global search trends.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                dynamic_factor = 1 + 0.1 * np.sin(evaluations * 2)  # Adjusting the multiplier dynamically\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * dynamic_factor\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.84955, 0.90225, 0.9015, 0.84955, 0.90225, 0.9015, 0.84955, 0.90225, 0.9015, 0.84955, 0.90225, 0.9015, 0.84955, 0.90225, 0.9015]}}
{"id": "9ca055f1-f271-4f6d-b411-cf2d073b6a93", "fitness": 0.1667166666666666, "name": "HybridPSO_DE", "description": "Introduce a Lvy flight mechanism in PSO for enhanced exploration and adaptively adjust the cognitive coefficient for better local search balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5  # Original cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                levy_step = np.random.standard_cauchy(self.dim)  # Lvy flight step\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations)) + 0.1 * levy_step\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social and cognitive coefficients for better exploration-exploitation balance\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)\n            self.cognitive_coeff = 1.5 - 0.1 * np.sin(evaluations * np.pi / self.budget)  # Adaptive cognitive coefficient\n\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "9625aa93-2bca-41de-bd81-9e5e37e65bd2", "fitness": 0.8528666666666667, "name": "HybridPSO_DE", "description": "Introduce adaptive cognitive coefficients, non-linear inertia weight reduction, and enhanced DE trial selection to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            adaptive_cognition = 1.0 + 0.5 * np.cos(evaluations * np.pi / self.budget)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    adaptive_cognition * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i], self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.2, self.inertia_weight * (0.94 + 0.04 * np.cos(evaluations * np.pi / (2 * self.budget))))\n            self.F = 0.5 + 0.5 * np.cos(evaluations * np.pi / (2 * self.budget))\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                if np.random.rand() < 0.1:\n                    trial = mutant\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 47, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.86125, 0.85555, 0.8418, 0.86125, 0.85555, 0.8418, 0.86125, 0.85555, 0.8418, 0.86125, 0.85555, 0.8418, 0.86125, 0.85555, 0.8418]}}
{"id": "df16b129-f347-4f0d-9a9d-7c3968f10087", "fitness": 0.8820333333333334, "name": "HybridPSO_DE", "description": "Further refine convergence by making the velocity update formula adapt based on the evaluation count, introducing a small stochastic noise factor.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations) + 0.01*np.random.randn(self.dim))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.8931, 0.85795, 0.89505, 0.8931, 0.85795, 0.89505, 0.8931, 0.85795, 0.89505, 0.8931, 0.85795, 0.89505, 0.8931, 0.85795, 0.89505]}}
{"id": "ce0b06c2-a4ff-4aaf-ab37-e6939d969637", "fitness": 0.1754038091514365, "name": "HybridPSO_DE", "description": "Enhanced dynamic adaptation of parameters and hybridization, along with improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.7  # Adjusted cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.15 * np.sin(evaluations))  # Increased impact factor\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.05 * np.sin(evaluations * 3)))  # Adjusted non-linear adaptive inertia weight\n\n            self.F = 0.7 + 0.3 * np.cos(evaluations * np.pi / self.budget)  # Adjusted adaptive F factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.15 * np.cos(evaluations * np.pi / self.budget)  # Adjusted dynamic adjustment\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.01 on the real problem.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.19316543276167164, 0.17466912238020182, 0.15837687231243602]}}
{"id": "6d79d634-3dc7-46bd-bcd1-e5f7353d9471", "fitness": 0.8934333333333332, "name": "HybridPSO_DE", "description": "Introduce adaptive learning factors in PSO for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    (self.social_coeff - 0.05 * np.cos(evaluations)) * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.87125, 0.8811, 0.92795, 0.87125, 0.8811, 0.92795, 0.87125, 0.8811, 0.92795, 0.87125, 0.8811, 0.92795, 0.87125, 0.8811, 0.92795]}}
{"id": "7c7b0a1f-ffc4-45c2-ab1e-afc0c83778d3", "fitness": 0.8942999999999998, "name": "HybridPSO_DE", "description": "Improve convergence by introducing inertia weight deceleration based on budget usage and adjusting social coefficient adaptively with sine scheduling.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.93 + 0.03 * np.sin(evaluations * 3)))  # Minor adjustment\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # Changed to sine scheduling\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 51, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.88145, 0.9057, 0.89575, 0.88145, 0.9057, 0.89575, 0.88145, 0.9057, 0.89575, 0.88145, 0.9057, 0.89575, 0.88145, 0.9057, 0.89575]}}
{"id": "4c770fbd-2a67-4580-b5f5-2ff309eaed89", "fitness": 0.9034333333333335, "name": "HybridPSO_DE", "description": "Refine the HybridPSO_DE by adjusting the population size dynamically and adding a fitness diversity check for more robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["c0fc00c3-6e86-46c5-9d1e-5ea2cbc7c723"], "operator": null, "metadata": {"aucs": [0.9198, 0.77545, 0.925, 0.9198, 0.8967, 0.925, 0.9198, 0.8967, 0.925, 0.9198, 0.8967, 0.925, 0.9198, 0.86195, 0.925]}}
{"id": "3afbe932-0731-4ae7-b385-6581b3a5c742", "fitness": 0.9078433333333332, "name": "HybridPSO_DE", "description": "Introduce a small sinusoidal component to the cognitive coefficient for enhanced exploratory capabilities.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["4c770fbd-2a67-4580-b5f5-2ff309eaed89"], "operator": null, "metadata": {"aucs": [0.90725, 0.9232, 0.91795, 0.90725, 0.88175, 0.91795, 0.90725, 0.88175, 0.91795, 0.90725, 0.88175, 0.91795, 0.90725, 0.9232, 0.91795]}}
{"id": "59e07288-6405-46bf-b793-134418578cf2", "fitness": 0.1667166666666666, "name": "HybridPSO_DE", "description": "Introduce dynamic adjustment of the inertia weight based on diversity metrics for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            diversity = np.std(self.population)  # New line added: calculate diversity of population\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)) * (1 + 0.1 * diversity))  # Modified line\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["3afbe932-0731-4ae7-b385-6581b3a5c742"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "9987c2d6-7dd8-4660-bff3-d291ed113f09", "fitness": 0.9063166666666667, "name": "HybridPSO_DE", "description": "Introduce oscillatory component to the social coefficient for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    (self.social_coeff + 0.05 * np.sin(evaluations)) * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["3afbe932-0731-4ae7-b385-6581b3a5c742"], "operator": null, "metadata": {"aucs": [0.94045, 0.8684000000000001, 0.9101, 0.94045, 0.8684000000000001, 0.9101, 0.94045, 0.8684000000000001, 0.9101, 0.94045, 0.8684000000000001, 0.9101, 0.94045, 0.8684000000000001, 0.9101]}}
{"id": "9fa22d5e-4af2-4dbe-bb7e-46e6e94c35c7", "fitness": 0.9001833333333332, "name": "HybridPSO_DE", "description": "Introduce a small cosinusoidal component to the social coefficient for diversified convergence behavior.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    (self.social_coeff + 0.05 * np.cos(evaluations)) * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget)  # Adaptive F factor using cosine scheduling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["3afbe932-0731-4ae7-b385-6581b3a5c742"], "operator": null, "metadata": {"aucs": [0.9177, 0.90535, 0.8775, 0.9177, 0.90535, 0.8775, 0.9177, 0.90535, 0.8775, 0.9177, 0.90535, 0.8775, 0.9177, 0.90535, 0.8775]}}
{"id": "61a9100d-7d73-457a-92cb-37d9abcb39b5", "fitness": 0.9246133333333333, "name": "HybridPSO_DE", "description": "Enhance the global exploration by adjusting the mutation strategy with a sinusoidal component on the differential weight.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 57, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["3afbe932-0731-4ae7-b385-6581b3a5c742"], "operator": null, "metadata": {"aucs": [0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92465, 0.9221]}}
{"id": "3c631fb2-0628-4b0e-9aa1-77be84e185aa", "fitness": 0.9164499999999999, "name": "HybridPSO_DE", "description": "Refine the mutation strategy by adding a small random noise to enhance exploration further.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.01, self.dim), self.lower_bound, self.upper_bound)  # Added small random noise\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.91945, 0.9283, 0.9016, 0.91945, 0.9283, 0.9016, 0.91945, 0.9283, 0.9016, 0.91945, 0.9283, 0.9016, 0.91945, 0.9283, 0.9016]}}
{"id": "26769928-c2ea-406b-8662-a71ee040cfaa", "fitness": 0.6974046055143305, "name": "HybridPSO_DE", "description": "Enhance convergence by incorporating adaptive scaling for velocity and a dynamic global best update strategy.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget) \n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n            \n            if evaluations % 50 == 0:\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:\n                    self.population_size = min(self.population_size + 5, 30)\n                else:\n                    self.population_size = max(self.population_size - 5, 15)\n            \n            # Adaptive velocity scaling based on convergence speed\n            if evaluations % 20 == 0:  # Every 20 evaluations\n                recent_diversity = np.std(self.population, axis=0).mean()  # Mean diversity\n                self.velocity *= 1.2 if recent_diversity < 0.5 else 0.8  # Scale velocity\n\n            # Dynamic global best update strategy\n            if evaluations % 100 == 0 and diversity < 1e-3:  # If diversity is low, randomize part of the population\n                self.population[np.random.randint(self.population_size)] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)  \n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 59, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.40 on the real problem.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9879737223071514, 0.9679393400086198, 0.13630075422722043]}}
{"id": "6c663d1b-5879-4bd7-9aac-04e235041597", "fitness": 0.1667166666666666, "name": "HybridPSO_DE", "description": "Introduce a small randomness to the global best position to potentially escape local optima.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))\n\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n\n            if evaluations % 50 == 0:\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:\n                    self.population_size = min(self.population_size + 5, 30)\n                else:\n                    self.population_size = max(self.population_size - 5, 15)\n\n            # Introduce small randomness to the global best position\n            self.global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 60, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "44096a93-8a37-4b04-ad1b-04b80c848e6e", "fitness": 0.9246133333333333, "name": "HybridPSO_DE", "description": "Introduce a feedback mechanism for adaptive parameter tuning based on relative improvement in personal best values.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n        last_personal_best_value = np.copy(self.personal_best_value)\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n            \n            # Feedback mechanism to adapt F based on personal best improvement\n            improvement_rate = np.mean(np.abs(last_personal_best_value - self.personal_best_value) / last_personal_best_value)\n            self.F *= 1 + 0.1 * improvement_rate  # Adjust F based on improvement rate\n            last_personal_best_value = np.copy(self.personal_best_value)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 61, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92845, 0.9221, 0.92405, 0.92465, 0.9221]}}
{"id": "7a373d46-bb62-4852-afdc-4c5568404b1f", "fitness": 0.9052166666666667, "name": "HybridPSO_DE", "description": "Introduce a non-linear dynamic adjustment on the cognitive coefficient to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n            # Non-linear dynamic adjustment for cognitive coefficient\n            self.cognitive_coeff = 1.5 + 0.2 * np.sin(evaluations * np.pi / self.budget)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015]}}
{"id": "758969a8-e13e-42b7-b586-2f0d8c35bb06", "fitness": 0.9177, "name": "HybridPSO_DE", "description": "Introduce a quadratic term in the inertia weight modulation for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3) + 0.01 * evaluations/self.budget))  # Added quadratic term\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 63, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9158, 0.9164, 0.9209, 0.9158, 0.9164, 0.9209, 0.9158, 0.9164, 0.9209, 0.9158, 0.9164, 0.9209, 0.9158, 0.9164, 0.9209]}}
{"id": "64336641-5358-4598-9e47-cfaf5606f17c", "fitness": 0.9189333333333334, "name": "HybridPSO_DE", "description": "Enhance local exploration by introducing a dynamic scaling factor in the velocity update equation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations) * np.abs(np.sin(evaluations * np.pi / self.budget)))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 64, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9298, 0.93205, 0.89495, 0.9298, 0.93205, 0.89495, 0.9298, 0.93205, 0.89495, 0.9298, 0.93205, 0.89495, 0.9298, 0.93205, 0.89495]}}
{"id": "317ddd03-b9d6-48fe-aeb2-8f7f34a73086", "fitness": 0.8901500000000001, "name": "HybridPSO_DE", "description": "Fine-tune the dynamic population size adjustment frequency for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 40 == 0:  # Check every 40 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 65, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.91225, 0.8773, 0.8809, 0.91225, 0.8773, 0.8809, 0.91225, 0.8773, 0.8809, 0.91225, 0.8773, 0.8809, 0.91225, 0.8773, 0.8809]}}
{"id": "141f5455-79c2-4c91-92f5-7beb6aa6378d", "fitness": 0.9140166666666665, "name": "HybridPSO_DE", "description": "Fine-tune the inertia weight decay for improved balance between exploration and exploitation in the search process.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.94 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 66, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.91705, 0.9116, 0.9134, 0.91705, 0.9116, 0.9134, 0.91705, 0.9116, 0.9134, 0.91705, 0.9116, 0.9134, 0.91705, 0.9116, 0.9134]}}
{"id": "51318b9b-5805-430b-b193-3689b96d9a10", "fitness": 0.7760833333333331, "name": "HybridPSO_DE", "description": "Introduce a dynamic adjustment to the cognitive coefficient to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic adjustment to cognitive coefficient\n            self.cognitive_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # Adjust cognitive coefficient for exploration/exploitation\n\n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 67, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.20 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.50005, 0.91645, 0.9117500000000001, 0.50005, 0.91645, 0.9117500000000001, 0.50005, 0.91645, 0.9117500000000001, 0.50005, 0.91645, 0.9117500000000001, 0.50005, 0.91645, 0.9117500000000001]}}
{"id": "6ee7aa2d-0207-4a46-a838-6f00ff95126b", "fitness": 0.8983833333333333, "name": "HybridPSO_DE", "description": "Introduce a non-linear time-varying social coefficient for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    (self.social_coeff + 0.1 * np.sin(evaluations)) * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 68, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9044, 0.8912, 0.89955, 0.9044, 0.8912, 0.89955, 0.9044, 0.8912, 0.89955, 0.9044, 0.8912, 0.89955, 0.9044, 0.8912, 0.89955]}}
{"id": "66999385-cc44-4254-ae70-b95056fdadc8", "fitness": 0.6743686200756637, "name": "HybridPSO_DE", "description": "Enhance adaptive capability by modifying the inertia weight adjustment with a dynamic sinusoidal influence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3) + 0.02 * np.cos(evaluations * 2)))  # Modified inertia weight with an additional cosine component\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 69, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.44 on the real problem.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9908320357603103, 0.05788449163383591, 0.974389332832845]}}
{"id": "92ca8ab5-ce2c-45d6-96c3-d2bdd189e637", "fitness": 0.9218833333333334, "name": "HybridPSO_DE", "description": "Enhance exploitation by modifying inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.90 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight with refined factor\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 70, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.92875, 0.9268, 0.9101, 0.92875, 0.9268, 0.9101, 0.92875, 0.9268, 0.9101, 0.92875, 0.9268, 0.9101, 0.92875, 0.9268, 0.9101]}}
{"id": "059b68b1-383b-44b8-8831-0b3c3f9f3e23", "fitness": 0.7725333333333334, "name": "HybridPSO_DE", "description": "Introduce a sinusoidal adjustment to the cognitive coefficient for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) + 0.02 * np.cos(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77 with standard deviation 0.19 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.50005, 0.88765, 0.9299, 0.50005, 0.88765, 0.9299, 0.50005, 0.88765, 0.9299, 0.50005, 0.88765, 0.9299, 0.50005, 0.88765, 0.9299]}}
{"id": "96416947-9b81-4bd6-9144-bb36bfdbe390", "fitness": 0.8948666666666666, "name": "HybridPSO_DE", "description": "Introduce a sinusoidal component to adjust the cognitive coefficient for improved dynamic behavior.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations * np.pi / self.budget)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9121, 0.86365, 0.90885, 0.9121, 0.86365, 0.90885, 0.9121, 0.86365, 0.90885, 0.9121, 0.86365, 0.90885, 0.9121, 0.86365, 0.90885]}}
{"id": "92dd6377-ff87-4dbf-9745-89695115205b", "fitness": 0.8508666666666667, "name": "HybridPSO_DE", "description": "Refine the inertia weight update to incorporate a tangent-based function for improved adaptability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.tan(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 73, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.8612, 0.8049999999999999, 0.8864, 0.8612, 0.8049999999999999, 0.8864, 0.8612, 0.8049999999999999, 0.8864, 0.8612, 0.8049999999999999, 0.8864, 0.8612, 0.8049999999999999, 0.8864]}}
{"id": "27cf1324-7754-490a-b623-b89025819729", "fitness": 0.9052166666666667, "name": "HybridPSO_DE", "description": "Introduce dynamic adjustment of cognitive coefficient using sine function for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n                \n            # Dynamic cognitive coefficient adjustment\n            self.cognitive_coeff = 1.5 + 0.2 * np.sin(evaluations * np.pi / self.budget)  # New line\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 74, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015, 0.9037, 0.8918, 0.92015]}}
{"id": "e9b84305-8e92-428f-b9ae-d9e40b54eaf2", "fitness": 0.9093166666666669, "name": "HybridPSO_DE", "description": "Introduce an adaptive sinusoidal component in the cognitive coefficient to enhance local exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) + 0.05 * np.cos(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))\n\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n            \n            if evaluations % 50 == 0:\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:\n                    self.population_size = min(self.population_size + 5, 30)\n                else:\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 75, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9075, 0.92655, 0.8939, 0.9075, 0.92655, 0.8939, 0.9075, 0.92655, 0.8939, 0.9075, 0.92655, 0.8939, 0.9075, 0.92655, 0.8939]}}
{"id": "026ae69c-a045-4028-9eb7-e8c7c85770d4", "fitness": 0.9228333333333333, "name": "HybridPSO_DE", "description": "Refine the sinusoidal component in the mutation strategy to enhance convergence by adding a dynamic frequency multiplier.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations * 2)  # Adaptive F factor with dynamic frequency sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 76, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.92745, 0.90715, 0.9339, 0.92745, 0.90715, 0.9339, 0.92745, 0.90715, 0.9339, 0.92745, 0.90715, 0.9339, 0.92745, 0.90715, 0.9339]}}
{"id": "ca1325dd-6589-4970-b105-b095ec83e46a", "fitness": 0.8906166666666667, "name": "HybridPSO_DE", "description": "Modify the sinusoidal component of the social coefficient to enhance convergence precision.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations)) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # Dynamic adjustment using sine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 77, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9218999999999999, 0.83865, 0.9113, 0.9218999999999999, 0.83865, 0.9113, 0.9218999999999999, 0.83865, 0.9113, 0.9218999999999999, 0.83865, 0.9113, 0.9218999999999999, 0.83865, 0.9113]}}
{"id": "d8efa51f-d8a1-4194-aa41-3db47f055537", "fitness": 0.9278333333333332, "name": "HybridPSO_DE", "description": "Integrate a stochastic sinusoidal component in the cognitive coefficient to further enhance exploration dynamics.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 78, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["61a9100d-7d73-457a-92cb-37d9abcb39b5"], "operator": null, "metadata": {"aucs": [0.9264, 0.9422, 0.9149, 0.9264, 0.9422, 0.9149, 0.9264, 0.9422, 0.9149, 0.9264, 0.9422, 0.9149, 0.9264, 0.9422, 0.9149]}}
{"id": "c57d3f1d-b45f-4837-8dfa-2bcbf2e067ed", "fitness": 0.15257874939121482, "name": "HybridPSO_DE", "description": "Introduce a dynamic inertia weight to better balance exploration and exploitation during the search process.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3) + 0.01 * np.cos(evaluations)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["d8efa51f-d8a1-4194-aa41-3db47f055537"], "operator": null, "metadata": {"aucs": [0.13033776815195852, 0.16839714943009254, 0.15900133059159338]}}
{"id": "ab01008e-ba6d-4828-a842-6a8197587f26", "fitness": 0.76985, "name": "HybridPSO_DE", "description": "Integrate a dynamic adjustment for cognitive and social coefficients to improve convergence by adapting to function evaluations.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n            # Dynamic cognitive coefficient adjustment\n            self.cognitive_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # Dynamic adjustment using sine\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77 with standard deviation 0.19 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d8efa51f-d8a1-4194-aa41-3db47f055537"], "operator": null, "metadata": {"aucs": [0.50005, 0.88765, 0.9218500000000001, 0.50005, 0.88765, 0.9218500000000001, 0.50005, 0.88765, 0.9218500000000001, 0.50005, 0.88765, 0.9218500000000001, 0.50005, 0.88765, 0.9218500000000001]}}
{"id": "cba67a06-ea2e-4859-ac86-1f437dc962cf", "fitness": 0.7788166666666666, "name": "HybridPSO_DE", "description": "Utilize a dynamic mutation scaling factor in the DE strategy to enhance adaptability to varying problem landscapes.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.95 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations) * (1 + 0.1 * np.cos(evaluations / 2))  # Adaptive F with enhanced dynamics\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 81, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.20 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d8efa51f-d8a1-4194-aa41-3db47f055537"], "operator": null, "metadata": {"aucs": [0.50005, 0.9252, 0.9112, 0.50005, 0.9252, 0.9112, 0.50005, 0.9252, 0.9112, 0.50005, 0.9252, 0.9112, 0.50005, 0.9252, 0.9112]}}
{"id": "ace25757-fead-4c7b-ba7a-0752d4f9a91f", "fitness": 0.9304733333333334, "name": "HybridPSO_DE", "description": "Enhance convergence by adjusting inertia weight reduction to a more aggressive decrease pattern to encourage faster convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 82, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d8efa51f-d8a1-4194-aa41-3db47f055537"], "operator": null, "metadata": {"aucs": [0.9207, 0.89975, 0.94565, 0.9207, 0.94195, 0.94565, 0.9207, 0.94195, 0.94565, 0.9207, 0.94195, 0.94565, 0.9207, 0.89975, 0.94565]}}
{"id": "71eabbe2-ef46-4430-80fa-5b7203d3f0d4", "fitness": 0.9184999999999997, "name": "HybridPSO_DE", "description": "Introduce a dynamic social coefficient adjustment with a sinusoidal function to enhance convergence speed and maintain diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Dynamic adjustment using cosine and sinusoidal function\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 83, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.89825, 0.9233, 0.9339500000000001, 0.89825, 0.9233, 0.9339500000000001, 0.89825, 0.9233, 0.9339500000000001, 0.89825, 0.9233, 0.9339500000000001, 0.89825, 0.9233, 0.9339500000000001]}}
{"id": "8fa063a8-0621-4669-93cd-acab028fd077", "fitness": 0.9253500000000002, "name": "HybridPSO_DE", "description": "Refine inertia weight reduction strategy by introducing a cosine-based dynamic scaling factor for enhanced adaptability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.cos(evaluations * np.pi / self.budget)))  # Cosine-based dynamic scaling\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 84, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.91595, 0.9227, 0.9374, 0.91595, 0.9227, 0.9374, 0.91595, 0.9227, 0.9374, 0.91595, 0.9227, 0.9374, 0.91595, 0.9227, 0.9374]}}
{"id": "308584d1-b87e-4beb-a7bf-6a7043980e24", "fitness": 0.9122833333333331, "name": "HybridPSO_DE", "description": "Fine-tune social coefficient oscillation to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.15 * np.cos(evaluations * np.pi / self.budget)  # Enhanced dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 85, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.90735, 0.89645, 0.93305, 0.90735, 0.89645, 0.93305, 0.90735, 0.89645, 0.93305, 0.90735, 0.89645, 0.93305, 0.90735, 0.89645, 0.93305]}}
{"id": "0d5561f8-48cb-4d26-878e-32508b8c785c", "fitness": 0.9273833333333333, "name": "HybridPSO_DE", "description": "Improve convergence by enhancing adaptive crossover probability with a more dynamic sine-based adjustment.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * np.sin(evaluations * np.pi / self.budget)  # More dynamic sine-based adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 86, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.91565, 0.92085, 0.94565, 0.91565, 0.92085, 0.94565, 0.91565, 0.92085, 0.94565, 0.91565, 0.92085, 0.94565, 0.91565, 0.92085, 0.94565]}}
{"id": "fa9b63d2-a1f9-4745-a879-d6607474c632", "fitness": 0.9177833333333335, "name": "HybridPSO_DE", "description": "Enhance convergence by introducing a dynamic personal coefficient adjustment using a sine-based pattern for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n\n            # Dynamic personal coefficient adjustment\n            self.cognitive_coeff = 1.5 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # New dynamic adjustment\n\n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 87, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.8862, 0.91775, 0.9494, 0.8862, 0.91775, 0.9494, 0.8862, 0.91775, 0.9494, 0.8862, 0.91775, 0.9494, 0.8862, 0.91775, 0.9494]}}
{"id": "7230bc13-33fd-4736-9189-63cd30b66794", "fitness": 0.7869433333333334, "name": "HybridPSO_DE", "description": "Improve convergence by altering the inertia weight's sinusoidal adjustment factor for more stability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.02 * np.sin(evaluations * 2)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 88, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79 with standard deviation 0.20 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.50005, 0.92935, 0.92955, 0.50005, 0.92935, 0.92955, 0.50005, 0.93405, 0.92955, 0.50005, 0.93405, 0.92955, 0.50005, 0.92935, 0.92955]}}
{"id": "b354ec1f-b587-4d15-b18b-063ef258602c", "fitness": 0.481204928200176, "name": "HybridPSO_DE", "description": "Refine convergence speed by introducing a dynamic social coefficient that accelerates convergence when the global best value remains unchanged for multiple iterations.  ", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n        self.no_change_counter = 0  # Counter for no change in global best value\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n                    self.no_change_counter = 0  # Reset counter if global best changes\n                else:\n                    self.no_change_counter += 1  # Increment counter if no change\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            if self.no_change_counter > 10:  # Increase social coefficient if no improvement after 10 iterations\n                self.social_coeff = min(2.0, self.social_coeff + 0.1)\n            else:\n                self.social_coeff = max(1.5, self.social_coeff - 0.1)\n\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 89, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.35 on the real problem.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.9765403180985676, 0.21568581360892947, 0.2513886528930309]}}
{"id": "aaa2b89b-e846-4caa-9dc5-2f0cd0fe7a26", "fitness": 0.9088166666666666, "name": "HybridPSO_DE", "description": "Fine-tune exploration-exploitation balance by dynamically adjusting inertia weight and population size based on the evaluation phase.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3))) + 0.01 * (evaluations / self.budget)  # Non-linear adaptive inertia weight with phase-based adjustment\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 90, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.88915, 0.9074, 0.9299, 0.88915, 0.9074, 0.9299, 0.88915, 0.9074, 0.9299, 0.88915, 0.9074, 0.9299, 0.88915, 0.9074, 0.9299]}}
{"id": "cdb81449-3e65-41cf-b5dc-70e3e97be65a", "fitness": 0.9181666666666666, "name": "HybridPSO_DE", "description": "Introduce dynamic inertia weight based on cosine function for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.cos(evaluations)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 91, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.92645, 0.8996, 0.92845, 0.92645, 0.8996, 0.92845, 0.92645, 0.8996, 0.92845, 0.92645, 0.8996, 0.92845, 0.92645, 0.8996, 0.92845]}}
{"id": "5e8ed856-ce18-46bf-a912-fe8db7741fd7", "fitness": 0.8877499999999999, "name": "HybridPSO_DE", "description": "Introduce a dynamic adjustment for the DE mutation factor `F` to better balance exploration and exploitation, enhancing adaptation to diverse landscapes.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.1 * np.sin(evaluations * np.pi / (2 * self.budget))  # Enhanced F adaptation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 92, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.8307, 0.92225, 0.9103, 0.8307, 0.92225, 0.9103, 0.8307, 0.92225, 0.9103, 0.8307, 0.92225, 0.9103, 0.8307, 0.92225, 0.9103]}}
{"id": "783beaed-49ba-4c2f-87a2-4ce9a68f9d28", "fitness": 0.9310666666666667, "name": "HybridPSO_DE", "description": "Further enhance convergence by slightly increasing the cognitive coefficient to boost local search efficiency.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 93, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ace25757-fead-4c7b-ba7a-0752d4f9a91f"], "operator": null, "metadata": {"aucs": [0.92945, 0.9189, 0.94485, 0.92945, 0.9189, 0.94485, 0.92945, 0.9189, 0.94485, 0.92945, 0.9189, 0.94485, 0.92945, 0.9189, 0.94485]}}
{"id": "1332449b-081c-48f5-a86d-365a66335b5d", "fitness": 0.1667166666666666, "name": "HybridPSO_DE", "description": "Enhance the algorithm by introducing adaptive mutation in PSO velocity for improved exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i]) + \n                                    np.random.uniform(-0.1, 0.1, self.dim)) * (1 + 0.1 * np.sin(evaluations))  # Adaptive mutation added\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 94, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["783beaed-49ba-4c2f-87a2-4ce9a68f9d28"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "2af66393-bedb-4cf9-8afe-b1b9feaa2c61", "fitness": 0.9160166666666668, "name": "HybridPSO_DE", "description": "Enhance global and local search balance using adaptive population size and inertia weight, with finer control over exploration-exploitation via dynamic adjustment of cognitive and social coefficients.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.55\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n            \n            if evaluations % 30 == 0:  # More frequent population size check\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-4:  # Adjust threshold for more sensitivity\n                    self.population_size = min(self.population_size + 5, 30)\n                else:\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 95, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["783beaed-49ba-4c2f-87a2-4ce9a68f9d28"], "operator": null, "metadata": {"aucs": [0.89005, 0.9307, 0.9273, 0.89005, 0.9307, 0.9273, 0.89005, 0.9307, 0.9273, 0.89005, 0.9307, 0.9273, 0.89005, 0.9307, 0.9273]}}
{"id": "99fb6a38-6450-40ec-b013-9683f73dba94", "fitness": 0.9294500000000002, "name": "HybridPSO_DE", "description": "Enhance exploration by adjusting the sinusoidal component in velocity update and refine DE crossover adaptively.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations * 0.5) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR * (0.8 + 0.2 * np.sin(evaluations)), mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 96, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["783beaed-49ba-4c2f-87a2-4ce9a68f9d28"], "operator": null, "metadata": {"aucs": [0.9253, 0.9174, 0.94565, 0.9253, 0.9174, 0.94565, 0.9253, 0.9174, 0.94565, 0.9253, 0.9174, 0.94565, 0.9253, 0.9174, 0.94565]}}
{"id": "3e970c86-c882-495c-a598-c57fcfc8c430", "fitness": 0.9368666666666666, "name": "HybridPSO_DE", "description": "Add non-linear damping to velocity to improve convergence by reducing oscillations near optimal regions.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations)) * (0.9 + 0.1 * np.cos(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 97, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["783beaed-49ba-4c2f-87a2-4ce9a68f9d28"], "operator": null, "metadata": {"aucs": [0.9339500000000001, 0.9325, 0.94415, 0.9339500000000001, 0.9325, 0.94415, 0.9339500000000001, 0.9325, 0.94415, 0.9339500000000001, 0.9325, 0.94415, 0.9339500000000001, 0.9325, 0.94415]}}
{"id": "ff3d563f-e65e-4efc-b286-d219d2faf768", "fitness": 0.9220133333333332, "name": "HybridPSO_DE", "description": "Introduce a dynamic adjustment to the cognitive coefficient to improve convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff + 0.05 * np.sin(evaluations) * np.random.rand()) * r1 * (self.personal_best_position[i] - self.population[i]) +\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations)) * (0.9 + 0.1 * np.cos(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget\n            \n            # Dynamic adjustment of cognitive coefficient\n            self.cognitive_coeff = 1.55 + 0.1 * np.sin(evaluations * 2 * np.pi / self.budget)  # New dynamic adjustment\n\n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:\n                    self.population_size = min(self.population_size + 5, 30)\n                else:\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 98, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["3e970c86-c882-495c-a598-c57fcfc8c430"], "operator": null, "metadata": {"aucs": [0.90915, 0.91265, 0.9419, 0.90915, 0.91265, 0.9419, 0.90915, 0.91265, 0.94775, 0.90915, 0.91265, 0.94775, 0.90915, 0.91265, 0.9419]}}
{"id": "10332839-5184-4294-9181-29367fa216a4", "fitness": 0.09116772053351115, "name": "HybridPSO_DE", "description": "Introduce adaptive personal coefficient adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Changed initial inertia weight\n        self.cognitive_coeff = 1.55  # Slightly increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.F = 0.5  # Differential Evolution mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.population)\n        self.personal_best_value = np.full(self.population_size, float('inf'))\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                value = func(self.population[i])\n                evaluations += 1\n                if value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = value\n                    self.personal_best_position[i] = self.population[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.population[i]\n\n            # Update velocity and position based on PSO\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            for i in range(self.population_size):\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (self.cognitive_coeff * (0.5 + evaluations/self.budget)) * r1 * (self.personal_best_position[i] - self.population[i]) +  # Adaptive personal coefficient\n                                    self.social_coeff * r2 * (self.global_best_position - self.population[i])) * (1 + 0.1 * np.sin(evaluations)) * (0.9 + 0.1 * np.cos(evaluations))\n                self.population[i] = np.clip(self.population[i] + self.velocity[i] * (1 + 0.05 * np.cos(evaluations)), self.lower_bound, self.upper_bound)\n\n            # Adaptively reduce inertia weight\n            self.inertia_weight = max(0.3, self.inertia_weight * (0.9 + 0.03 * np.sin(evaluations * 3)))  # Non-linear adaptive inertia weight\n\n            # Apply DE mutation strategy with adaptive F\n            self.F = 0.6 + 0.4 * np.cos(evaluations * np.pi / self.budget) + 0.05 * np.sin(evaluations)  # Adaptive F factor with sinusoidal enhancement\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, self.population[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < self.personal_best_value[i]:\n                    self.population[i] = trial\n                    self.personal_best_value[i] = trial_value\n                    self.personal_best_position[i] = trial\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n            # Update social coefficient for faster convergence\n            self.social_coeff = 1.5 + 0.1 * np.cos(evaluations * np.pi / self.budget)  # Dynamic adjustment using cosine\n            # Adaptively adjust crossover probability\n            self.CR = 0.9 - 0.4 * evaluations / self.budget  # Add adaptive crossover probability adjustment\n            \n            # Dynamic population size adjustment based on fitness diversity\n            if evaluations % 50 == 0:  # Check every 50 evaluations\n                diversity = np.std(self.personal_best_value)\n                if diversity < 1e-3:  # If diversity is low, increase population size for exploration\n                    self.population_size = min(self.population_size + 5, 30)\n                else:  # If diversity is sufficient, reduce for exploitation\n                    self.population_size = max(self.population_size - 5, 15)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 99, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["3e970c86-c882-495c-a598-c57fcfc8c430"], "operator": null, "metadata": {"aucs": [0.07144184859965585, 0.07907084180615165, 0.12299047119472595]}}
