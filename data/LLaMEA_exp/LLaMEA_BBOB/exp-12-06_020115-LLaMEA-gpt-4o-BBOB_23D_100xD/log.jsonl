{"id": "2e7e71c9-c7b7-43d0-bfc9-9e67b3823bc1", "fitness": 0.02042450082752033, "name": "PSO_DE_Optimizer", "description": "A hybrid Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithm that dynamically adjusts exploration and exploitation for efficient search in diverse landscapes.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best = position[global_best_index]\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            if np.min(fitness) < np.min(personal_best_fitness):\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best = personal_best[global_best_index]\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.00573819854154789, 0.00043478260869567187, 0.00965495229765545, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04154629858811898, 0.05688270111068172, 0.046066643664324336, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04919077734956767, 0.045456408443178, 0.05394446799662567, 0.08266205719317288, 0.09775944198261488, 0.08778988967800738, 0.04367433178863567, 0.03978421212773675, 0.0466795600332629, 0.07944847983933179, 0.07824177234048257, 0.08556579797566155, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.01769209175921549, 0.013156267002098154, 0.014647536770501235, 0.014784446157482867, 0.011756747781681898, 0.012261707460562543, 0.14032001148890105, 0.14046311142602608, 0.13539614878438766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "a6a885ef-2488-44d1-8cda-6adb648eca3d", "fitness": 0.019484600887239436, "name": "PSO_DE_Optimizer", "description": "Introduce dynamic inertia weight adjustment in PSO for better convergence control.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # initial inertia weight\n        self.final_inertia_weight = 0.4  # final inertia weight\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        # Dynamic inertia weight adjustment\n        inertia_weight = (self.inertia_weight - self.final_inertia_weight) * (self.budget - self.fitness_evaluations) / self.budget + self.final_inertia_weight\n        new_velocity = inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best = position[global_best_index]\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            if np.min(fitness) < np.min(personal_best_fitness):\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best = personal_best[global_best_index]\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["2e7e71c9-c7b7-43d0-bfc9-9e67b3823bc1"], "operator": null, "metadata": {"aucs": [0.0015984392446234397, 0.00043478260869567187, 0.003778645116311874, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04008203513262154, 0.05393337334146531, 0.036855979528050864, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05409059645687475, 0.052582297958172486, 0.047905641765340734, 0.08601360489860954, 0.09517706975674534, 0.08444490656385928, 0.04125262837614585, 0.03926894804369463, 0.03125289571175771, 0.0697965204023192, 0.07598598548049484, 0.07616874526454842, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.01589504094000349, 0.01271087404494109, 0.01363994008244529, 0.014331058323631352, 0.011399321086167813, 0.011503178047636897, 0.13115786834742027, 0.14158477186343765, 0.14048089810391895, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "bfd00015-4e5f-4eaf-a1fa-781b58cdd74f", "fitness": 0.02030595860108418, "name": "PSO_DE_Optimizer", "description": "Enhanced mutation strategy in Differential Evolution for improved exploration and convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c] * np.random.rand())\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best = position[global_best_index]\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            if np.min(fitness) < np.min(personal_best_fitness):\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best = personal_best[global_best_index]\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["2e7e71c9-c7b7-43d0-bfc9-9e67b3823bc1"], "operator": null, "metadata": {"aucs": [0.01332667448148861, 0.00043478260869567187, 0.008466976633481949, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.03875725775631711, 0.05541934072774424, 0.04742923458289483, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.046214020842017645, 0.055897752928087296, 0.0487571897294522, 0.08296071175921638, 0.09670305304931948, 0.08778988967800738, 0.04323825991981978, 0.03608174459458591, 0.04032972619675368, 0.07711154161981693, 0.07635654359606714, 0.07841868664377216, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.017148778820192834, 0.014185416406454432, 0.015020214937845888, 0.014784446157482867, 0.012004455163758032, 0.011413238365380662, 0.14055243196074174, 0.1447178739896896, 0.1389435587376716, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "164b8ff0-52fc-40bf-a307-d2d668b2f88e", "fitness": 0.030627427843097372, "name": "PSO_DE_Optimizer", "description": "A refined PSO-DE optimizer with adaptive parameters and elitism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["2e7e71c9-c7b7-43d0-bfc9-9e67b3823bc1"], "operator": null, "metadata": {"aucs": [0.010599668673803908, 0.013772657891900852, 0.006945513114361979, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6134613660491695, 0.02393414819896056, 0.04360653599913389, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045442625061546504, 0.06352664368864913, 0.04596524281011749, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05303131826430596, 0.04672760993313241, 0.0519039228211311, 0.08601360489860954, 0.098657113815939, 0.09166410889202581, 0.038975264522282504, 0.044073196345538745, 0.04471252381625024, 0.07472263397136336, 0.08177463764279014, 0.08371018473971714, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02446401028568057, 0.01918349595856217, 0.01614546457320276, 0.018009582770303734, 0.014972638672516636, 0.01752068670096396, 0.1344953313923083, 0.14158477186343765, 0.13731743177008715, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "f2e35ea3-bb3d-46c0-a3d9-86d44637a891", "fitness": 0.026933255744282604, "name": "PSO_DE_Optimizer", "description": "Enhanced selection strategy by integrating elitism in DE mutation for improved convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        elite_index = np.argmin(fitness)  # Select the elite particle\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Integrate the elite particle in DE mutation\n            mutant_vector = position[elite_index] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["164b8ff0-52fc-40bf-a307-d2d668b2f88e"], "operator": null, "metadata": {"aucs": [0.0045109278921589, 0.002914454342503481, 0.014121541534425353, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.326991928733369, 0.01673323358788381, 0.08115547902365805, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048545004836680894, 0.05733022329880599, 0.04840029755177, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05521345361823948, 0.05082752416622849, 0.05266498344588455, 0.08437784367890822, 0.0978361979863176, 0.09124723623651376, 0.04161112713530557, 0.040682633707484706, 0.04123578801145256, 0.07398661459653988, 0.08182070109466211, 0.09214093596013517, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02277412192667505, 0.012035353604852417, 0.018694084632723373, 0.015408380419367096, 0.01288775070766146, 0.014080396112971849, 0.138660259247681, 0.1442176511336053, 0.1378274157986641, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "cd7e0575-4614-49f6-869e-c7cf4f4f608b", "fitness": 0.031068488292241292, "name": "PSO_DE_Optimizer", "description": "Improved adaptive strategy for inertia weight based on budget utilization to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["164b8ff0-52fc-40bf-a307-d2d668b2f88e"], "operator": null, "metadata": {"aucs": [0.017026492274291316, 0.011373252698807734, 0.014678355692394729, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6134768829082441, 0.024030761828888636, 0.04365968083241889, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.047972576894307895, 0.06959549259520137, 0.0504690038339447, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.052900001377585326, 0.04934422638545699, 0.053594553579735305, 0.08663852392140459, 0.10170395541034616, 0.09077313103260976, 0.03776599121397539, 0.04014978410435821, 0.04302491970963318, 0.07158336608048732, 0.08043806087109084, 0.0782883667221208, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02754207960773014, 0.023780956803428732, 0.01738463614919039, 0.021392111575293526, 0.014524613651327734, 0.01715656283196354, 0.12953584527406947, 0.1432440816458337, 0.14562201997001456, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1", "fitness": 0.038586947978877705, "name": "PSO_DE_Optimizer", "description": "Enhanced balance between exploration and exploitation by adjusting the cognitive and social coefficients adaptively.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        # Change: Adjust cognitive and social coefficients adaptively\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["cd7e0575-4614-49f6-869e-c7cf4f4f608b"], "operator": null, "metadata": {"aucs": [0.006078087465550608, 0.0046783755237342906, 0.014534218826831147, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144382592978388, 0.058116026310244484, 0.6003442596720215, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0455206344011555, 0.06226020859331327, 0.04490201398366622, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0498671980372315, 0.048408654655550554, 0.0531148261130594, 0.0823389382192844, 0.10033828736473738, 0.08750755810886579, 0.04084406904627924, 0.044542288326975155, 0.03983251740483196, 0.07002143128253924, 0.08446574045506938, 0.08074247909565457, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02086028466404055, 0.014915233644248183, 0.0156944341528944, 0.017279671558174003, 0.015402186498129078, 0.016537123315114033, 0.1495291500089465, 0.137579401676183, 0.1393058272118124, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "1864c4ca-d9e7-46cb-bd7d-bd692213db86", "fitness": 0.028308929705507087, "name": "PSO_DE_Optimizer", "description": "Introduce adaptive mutation factor adjustment based on fitness evaluations to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        # Change: Adjust cognitive and social coefficients adaptively\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            self.mutation_factor = 0.5 + 0.3 * (self.fitness_evaluations / self.budget)  # Adaptive mutation factor\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1"], "operator": null, "metadata": {"aucs": [0.007218704615459592, 0.0031221190798773613, 0.014379926874646842, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0514815218359308, 0.049358063028195565, 0.43681465466900316, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04594246397653223, 0.05602568823921361, 0.049779934973669504, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05538076744670217, 0.0601280021420052, 0.046391542908710615, 0.08320975831145894, 0.09228988963484008, 0.08779755362050468, 0.05120611311375323, 0.03888861120796461, 0.03661886930190017, 0.07544592198931732, 0.0844597296115458, 0.07906476452160505, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.019376068418590187, 0.015899790283134152, 0.017797018440307233, 0.016992985364404523, 0.01224283527258041, 0.014241299824110154, 0.1459661111652487, 0.13743475531039384, 0.13502660404968625, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "bc5ad5c3-e5db-4ecc-a21f-c04e3ab3a3d6", "fitness": 0.023240323068338467, "name": "PSO_DE_Optimizer", "description": "Further refine exploration-exploitation balance by slightly reducing mutation factor to enhance convergence speed.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.7  # Slightly reduced for enhanced convergence\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        # Change: Adjust cognitive and social coefficients adaptively\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1"], "operator": null, "metadata": {"aucs": [0.006197565802373295, 0.009701592341911702, 0.022424770516844217, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0511528268803354, 0.058045106275144476, 0.04713491470845754, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04714781968901127, 0.05993430732492511, 0.051238849976864564, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0499808085911293, 0.045086637488237935, 0.052135405109492106, 0.08533803235214554, 0.09621799390927188, 0.08933814515503513, 0.04628205985475231, 0.038677158686173274, 0.041335487999578535, 0.07205865224971231, 0.0844597296115458, 0.0805500241345779, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028239819754460438, 0.015138194050255738, 0.017226264859789286, 0.016376157259034407, 0.014644715454703916, 0.015079146316262393, 0.13662053685527709, 0.13647987907580084, 0.1407997890720476, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "627a75b9-353b-4878-b2fa-c64ea994eac5", "fitness": 0.029456965362866707, "name": "PSO_DE_Optimizer", "description": "Fine-tune the crossover probability adaptively to maintain the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Change: Adaptively adjust crossover probability\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1"], "operator": null, "metadata": {"aucs": [0.006814239620907991, 0.0044056147976390125, 0.021636727118488852, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05450359931074733, 0.5096858157043501, 0.046517510502999015, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048547046207568, 0.06512011723849076, 0.040538458188838944, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971776456059773, 0.048388814078595854, 0.05106658478720838, 0.08148308905991797, 0.09924237477587883, 0.08664143672012259, 0.041672330011396364, 0.042780007841574874, 0.0387382765005615, 0.07225918511186413, 0.083794068283914, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021545988041743236, 0.020451138429845916, 0.01994544160057732, 0.01660608897100746, 0.012336281581247222, 0.015228151517771127, 0.13652128427865684, 0.14687713163212168, 0.13852203894618131, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "41b5d4f7-e816-48b6-bfc1-ce14c4ab17a6", "fitness": 0.03095018507334036, "name": "PSO_DE_Optimizer", "description": "Incorporating adaptive scaling in mutation factor for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9  # Changed for adaptive strategy\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))  # Adaptive inertia weight\n        # Change: Adjust cognitive and social coefficients adaptively\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Change: Incorporating adaptive scaling\n            adaptive_mutation_factor = self.mutation_factor * (1 + (self.fitness_evaluations / self.budget))\n            mutant_vector = position[a] + adaptive_mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored for clarity\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)  # Refactored call\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1"], "operator": null, "metadata": {"aucs": [0.007759285790530535, 0.010231458899984558, 0.02202599979253872, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6142964000977025, 0.021915493997941793, 0.05785466088813973, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.049208146264631214, 0.0688747445966208, 0.04818300584298574, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048975103797483044, 0.046151166579875835, 0.04961339211140614, 0.08830064796175674, 0.09967172435650118, 0.08382217532992997, 0.042344481786462884, 0.03909657402851929, 0.03919698178136766, 0.0712048765422888, 0.0844597296115458, 0.08103455107095314, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.031553914518005266, 0.01341025309234578, 0.01580286125295849, 0.022413692786095285, 0.0153763245852222, 0.016039606677009988, 0.13382532914415324, 0.1429161490050349, 0.14459372352529642, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "cb8e747a-90de-4bd1-a1f3-d85bd80aebd1", "fitness": 0.03903762001420482, "name": "PSO_DE_Optimizer", "description": "Improved PSO-DE balance by adjusting mutation factor dynamically based on evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["c5561e3a-eaeb-4a61-92a9-7ed6c8113fa1"], "operator": null, "metadata": {"aucs": [0.006197441818336924, 0.005024138769498365, 0.013810061306103849, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144359714598948, 0.05810658173691263, 0.6174460205735597, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05022620755581064, 0.06849515465838685, 0.046316096417832964, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05404445158407467, 0.04468035072656851, 0.052699464619288094, 0.08609203380334984, 0.10361836059965779, 0.08765546500259103, 0.043723748583196276, 0.047657086459886644, 0.03741254428500829, 0.06982675567717544, 0.08458332158190285, 0.08092882785031263, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02789996189202315, 0.015113241021984192, 0.016610516748646442, 0.02021586299086664, 0.015171437529862608, 0.016672381933530933, 0.1373293547049147, 0.13909668808175046, 0.13135824148460074, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "9715219b-469c-43ef-9e60-544dc78dad80", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Enhanced PSO-DE by dynamically updating crossover probability based on fitness progress.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Update crossover probability dynamically based on fitness evaluations\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "5ee528cd-eca1-4f97-a8ef-ae0d61c17ddb", "fitness": 0.025319497257567197, "name": "PSO_DE_Optimizer", "description": "Enhance the algorithm by dynamically adapting the crossover probability based on the fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Change: Adapt crossover probability based on fitness evaluations\n            self.crossover_prob = 0.9 * (1 - (self.fitness_evaluations / self.budget))\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.011731706895542593, 0.009045535213587308, 0.01707983795630852, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05461945312685046, 0.02511374681496703, 0.24294054293934542, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04579204731973252, 0.06625040344897648, 0.04818447106490942, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04849900122046169, 0.04936630534392128, 0.059189717457556634, 0.08240792822739007, 0.09772237313731102, 0.08644707452333122, 0.0393183488965817, 0.03439592801169733, 0.04013479361411809, 0.074948028190164, 0.07983587437682438, 0.07970126992995064, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02568189207661442, 0.013292248412298813, 0.018282241718351022, 0.016536542409195998, 0.01222352558695583, 0.01842606883927045, 0.13519476281833798, 0.13526162719028645, 0.1371196362187812, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "2d53373e-af2a-49f3-b525-3443e65a2074", "fitness": 0.03879116551935508, "name": "PSO_DE_Optimizer", "description": "Enhanced mutation factor adaptation by considering both fitness evaluations and improvement rates to refine global convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations and improvement rate\n            improvement_rate = (np.mean(fitness) - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget) * improvement_rate\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.008669601899615076, 0.004940525618733593, 0.013142140645535094, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144412735453932, 0.05812365870259284, 0.6018810892050734, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04492811522713491, 0.06544432684843127, 0.0468706876548205, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04741671956247795, 0.051228608095938544, 0.051098408444678056, 0.08243643850497884, 0.10115656965489095, 0.08726661608771336, 0.04464761555512531, 0.04531785566841395, 0.036893000780331864, 0.07074568712886864, 0.0844597296115458, 0.0811662067980885, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022042768630952447, 0.02130713311322996, 0.01638254674565187, 0.016685895236214443, 0.016327862911833968, 0.016820414767803382, 0.13387784213966758, 0.1502593791119704, 0.138724329930642, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "7affe522-0b75-4969-bcfd-f4cd63d2a7ff", "fitness": 0.03553245438902491, "name": "PSO_DE_Optimizer", "description": "Adjust the mutation factor in DE based on the cosine function to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on cosine function\n            self.mutation_factor = 0.8 + 0.2 * np.cos(np.pi * (self.fitness_evaluations / self.budget))\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.006646475882533975, 0.0064640076370940935, 0.01588863290492204, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5629120825759075, 0.025030050803662496, 0.44236057711436116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05014585249673775, 0.06521675086986223, 0.05274210491431053, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04502777290923132, 0.06638845139796534, 0.05280931364528463, 0.08263857353699022, 0.09783672502950569, 0.08964443591936389, 0.0463650862770838, 0.03915493286758276, 0.03700459204163731, 0.07171649739315145, 0.0844597296115458, 0.07934498845825821, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022878545993290644, 0.014042319281479254, 0.017086379784895023, 0.015210884329203256, 0.016217850592216698, 0.016315535809445114, 0.13649235962657247, 0.1446660926566532, 0.1373682440838272, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "c0b84672-a4f3-4ef2-9d90-0b826d2a3027", "fitness": 0.03897494025475913, "name": "PSO_DE_Optimizer", "description": "Fine-tune mutation factor adjustment to enhance fitness exploration near budget limits.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor more aggressively near end of budget\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget) ** 1.5\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.0065260566123385155, 0.006345255268715655, 0.012821048072626073, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144436567728334, 0.058121100277634175, 0.6022696032804571, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04940001735322486, 0.06846519639730475, 0.046040185312077986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045018422790978674, 0.05122834131583498, 0.052017251756119376, 0.08328270077397759, 0.10036601304157122, 0.09204090877567561, 0.04108057285063493, 0.046043958225485904, 0.0401921703333854, 0.06978095800706141, 0.0844597296115458, 0.08074247909565457, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020754903551708614, 0.021520712548037002, 0.01660239705956268, 0.016030640820561715, 0.015115682552713117, 0.016560949916188727, 0.14119064309608764, 0.15337412740679446, 0.1360991459006473, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "25c1f958-010c-4bad-882a-e305ad6b4519", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Enhanced exploitation by dynamically adjusting crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Adjust crossover probability\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "b63b8815-f919-4a28-8501-0870a2d8f2a9", "fitness": 0.02413234009389931, "name": "PSO_DE_Optimizer", "description": "Enhance PSO-DE optimizer by mildly increasing the crossover probability factor.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.95  # Increased crossover probability\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.010560185703778036, 0.012865442373435454, 0.019680518191668606, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051604021949186674, 0.07151756492974826, 0.042573860185330936, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048873738678808176, 0.06911689442909486, 0.04857153451085672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04607841005386015, 0.04860834491398591, 0.060697433747916696, 0.08445491101908575, 0.1041761971820554, 0.08994929736501, 0.04397516506034982, 0.034521009347158516, 0.03681930971514957, 0.07246185580858966, 0.0844597296115458, 0.08216270155237493, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020560362070427773, 0.016292455570732778, 0.026107977206441202, 0.01894255925625221, 0.015848344564354577, 0.016768427948483322, 0.1428488908771306, 0.1480247849406312, 0.15014568843208853, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "27abf615-2dc1-4992-8cb6-eb4279453d3f", "fitness": 0.038886306580190405, "name": "PSO_DE_Optimizer", "description": "Adjust the mutation factor to be a function of both fitness evaluations and convergence progress.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations and convergence progress\n            convergence_progress = np.mean(fitness) / (np.min(fitness) + 1e-9)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget) * convergence_progress\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.010218901828139004, 0.008599561523450094, 0.014275534256166789, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144313356070397, 0.058115790127575506, 0.6175820407627544, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045180104687968625, 0.06344336392057748, 0.04327872594340476, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04986606608759325, 0.049635099491125434, 0.050180042769400246, 0.08361757150176152, 0.09898637232326923, 0.08868099297505816, 0.044709434590977426, 0.04121709716144739, 0.04059743101156987, 0.07054847552364485, 0.08456056660726141, 0.07847922811323538, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028417649059787387, 0.015116826226520663, 0.0166161359627629, 0.019611317007572127, 0.01527387823709081, 0.015401098651968037, 0.13563558615726157, 0.14485975761534353, 0.1344172184767637, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "0dd0cd8a-3fd0-4259-9f83-a9a4c32c4086", "fitness": 0.02413234009389931, "name": "PSO_DE_Optimizer", "description": "Refine PSO-DE by increasing crossover probability for enhanced exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.95  # Increased crossover probability\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.010560185703778036, 0.012865442373435454, 0.019680518191668606, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051604021949186674, 0.07151756492974826, 0.042573860185330936, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048873738678808176, 0.06911689442909486, 0.04857153451085672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04607841005386015, 0.04860834491398591, 0.060697433747916696, 0.08445491101908575, 0.1041761971820554, 0.08994929736501, 0.04397516506034982, 0.034521009347158516, 0.03681930971514957, 0.07246185580858966, 0.0844597296115458, 0.08216270155237493, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020560362070427773, 0.016292455570732778, 0.026107977206441202, 0.01894255925625221, 0.015848344564354577, 0.016768427948483322, 0.1428488908771306, 0.1480247849406312, 0.15014568843208853, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "3f18a3c9-e5fa-4887-a964-6f7514230f47", "fitness": 0.023249985234452798, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration balance by adjusting initial positions to ensure diverse starting points.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        # Ensure diverse starting points by extending initial position range\n        position = np.random.uniform(self.lower_bound - 1.0, self.upper_bound + 1.0, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.005115317128866481, 0.005331413049922129, 0.006418869813739736, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.19403128962470562, 0.029319949147810553, 0.03449535591801989, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0385211032051741, 0.05561723699884091, 0.04299924987066239, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05604750035386741, 0.05740746769993843, 0.05431092225721901, 0.08634348479988463, 0.09238196744658145, 0.08248480345771936, 0.036283677305906425, 0.036703908308985844, 0.031361813387579374, 0.05888878589882329, 0.06758094848348972, 0.07492052039635366, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.01611513368700912, 0.015132646672338934, 0.014028009147681875, 0.01280889225546833, 0.011892449198526611, 0.011588717995924758, 0.14669091589886307, 0.13963879358367148, 0.1412769243218086, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "d7641657-d691-44e6-b861-1868d003b980", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Enhanced DE by altering crossover probability based on fitness evaluations to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "486b967b-36da-4b21-85a2-23d3476b29bb", "fitness": 0.030667310775743868, "name": "PSO_DE_Optimizer", "description": "Enhanced velocity update mechanism by introducing adaptive strategy for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        # Introducing adaptive inertia weight based on evaluation progress\n        new_velocity = (0.5 + 0.4 * np.random.rand()) * (self.inertia_weight * velocity + cognitive_velocity + social_velocity)\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.05288235577323652, 0.050619099129704526, 0.044041228716117264, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05042713557739442, 0.02596484454642234, 0.037913038445137714, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.004515272554854399, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.07878736794342056, 0.10431915271783032, 0.07535977511363556, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05497266667669698, 0.04980066557248253, 0.05672242310701969, 0.10200082450281434, 0.10151398203237971, 0.10727605344256452, 0.05658655701704207, 0.04181426775355224, 0.056752511957163576, 0.09750832546435784, 0.10614946863350505, 0.0981416503634639, 0.00043478260869567187, 0.06713667706630355, 0.030598441663854947, 0.04154643144606229, 0.041110168246999534, 0.045758988217243446, 0.033107454567733785, 0.037549843773995284, 0.02305579651265799, 0.13356318201090256, 0.14109819597448992, 0.14249600759338799, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "75dca89d-a2de-4c88-b8d1-8c9df5d8b9b3", "fitness": -Infinity, "name": "PSO_DE_Optimizer", "description": "Enhanced PSO-DE by adaptively adjusting population size and introducing a learning rate for velocity updates.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.learning_rate = 0.5  # New addition for adaptive velocity updates\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity * self.learning_rate  # Adjusted with learning rate\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            self.num_particles = max(20, int(50 * (1 - self.fitness_evaluations / self.budget)))  # Adaptive population size\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (48,23) (50,23) ').", "error": "ValueError('operands could not be broadcast together with shapes (48,23) (50,23) ')", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {}}
{"id": "98fb276d-d895-4ac9-89f9-42f009fdbfed", "fitness": 0.030333839225698895, "name": "PSO_DE_Optimizer", "description": "Improved PSO-DE by dynamically adjusting the crossover probability based on evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Adjust crossover probability\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.01432243632273189, 0.004146362940450232, 0.022972544823155472, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5649799146205976, 0.057050474433150034, 0.04647477067383177, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04789726335973954, 0.06791325853833985, 0.04172327055640601, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0476389656538887, 0.0485965779282056, 0.053904042404407826, 0.08335967562985547, 0.10168994372106666, 0.08852697437815416, 0.042390360520372594, 0.047657086459886644, 0.04197971427574554, 0.07121101790929096, 0.08338747668229207, 0.07866852051234552, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021943382533339606, 0.014120383495554334, 0.014766963515065124, 0.016897263642365545, 0.012121215178181877, 0.015138142296413748, 0.13993682007386343, 0.1360290536642661, 0.1383316779421384, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "2ed0633e-23ec-4260-9cb4-7dd71329fac7", "fitness": 0.02904599544844444, "name": "PSO_DE_Optimizer", "description": "Enhance mutation adaptability by incorporating a pressure factor based on personal best improvements.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations and personal best improvement\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget) + 0.1 * np.min(fitness)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.009416315491102556, 0.014446219368864255, 0.025177392161590983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.47887535820864335, 0.027001716666233522, 0.0420259018500414, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04459162500824043, 0.06562052272506824, 0.052304204572709456, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04774101010095799, 0.05243573364544696, 0.05195975126410124, 0.08236413651655372, 0.09845920565106336, 0.08945442966313477, 0.039917199939539016, 0.03699940206137342, 0.0391726205421683, 0.07445382318939708, 0.08447230706597053, 0.08045229365176532, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.023782122045541754, 0.015050601377772588, 0.02411093821777921, 0.019877115591009353, 0.01647143277584573, 0.016587319283775215, 0.1426740572775972, 0.13688593544407113, 0.14027011136542333, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "17d9a0ab-0aab-4591-9fc9-9f4f8aede2b3", "fitness": 0.030949927232395105, "name": "PSO_DE_Optimizer", "description": "Enhanced PSO-DE by optimizing velocity scaling through adaptive inertia weight limits.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.7 - (0.4 * (self.fitness_evaluations / self.budget))  # Modified this line\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.021010599645871264, 0.01385030595026504, 0.02273954864038763, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.404083783340337, 0.020387568050491023, 0.1890835931018109, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.049928974710101715, 0.07259871310207433, 0.06088610405821682, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05613061587167023, 0.056771584169073575, 0.058308466514608526, 0.08601114997680681, 0.10000930081151238, 0.09264836490508233, 0.046934394151066705, 0.03172011136219144, 0.03962678782261897, 0.07864052222489115, 0.09254956422994143, 0.07833193189145826, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022340684902017793, 0.017694169077289934, 0.024962627563523965, 0.017035608986213813, 0.015890661304676867, 0.016477117681754527, 0.14891395455659684, 0.13530734451259507, 0.1392597380520828, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "e13377c6-71db-4b1d-a2ca-7fe08116d244", "fitness": 0.03045277828789155, "name": "PSO_DE_Optimizer", "description": "Enhance inertia weight decay for refined velocity updates and balance exploration-exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.92 - (0.7 * (self.fitness_evaluations / self.budget))  # Adjusted line\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.012006127511093312, 0.010276680390075899, 0.011888404566438804, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144067668486288, 0.02589994770781434, 0.04377368892140432, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0453913902627866, 0.06196447217919898, 0.0468146635233192, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04719136391209677, 0.05227558037505731, 0.046732512129771364, 0.08621201488960373, 0.09678766687362839, 0.08688831773787509, 0.044492003625165366, 0.046387096173080566, 0.04388400623267896, 0.07485964945193757, 0.08025171355606997, 0.07575637821163084, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0205042192550271, 0.013474047601777506, 0.01610698108393893, 0.018593103007843115, 0.015422796313093512, 0.015708897237563857, 0.14143733820307425, 0.14224519794289792, 0.13670614143840087, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "c7b31708-75cb-41d6-8e77-17cacd1e8ca2", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Enhanced mutation strategy by incorporating adaptive crossover probability adjustment.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Adaptive crossover adjustment\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "baf72d8d-f08c-4e21-b878-d286f010bd8c", "fitness": 0.02935224432128795, "name": "PSO_DE_Optimizer", "description": "Enhanced velocity update by introducing adaptive inertia weight based on particle convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        convergence_factor = np.mean(np.linalg.norm(personal_best - position, axis=1)) / self.dim\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget)) * convergence_factor\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.005426750742556052, 0.00383919745453154, 0.014524485208365134, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.566376358988391, 0.026325468241736982, 0.04400911724391576, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0441541480212132, 0.059246832141827466, 0.0375979857948564, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05626825345152475, 0.0466723836042684, 0.05367470673153352, 0.0878878111258633, 0.09703436797607157, 0.09276056739483585, 0.04071991500478278, 0.04808114749124459, 0.034543803355468916, 0.07221559773797803, 0.07797297064665121, 0.07980669937341767, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02171318737847383, 0.01668534228385521, 0.014653205840656991, 0.015832427680728567, 0.012760952036565354, 0.014520019069064305, 0.13711763404062127, 0.1378750779703023, 0.1348043075362122, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "86b4655e-67c4-4c63-994f-f4d231270d07", "fitness": 0.029860823673520047, "name": "PSO_DE_Optimizer", "description": "Adjusts the inertia weight non-linearly for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        # Updated inertia weight calculation\n        self.inertia_weight = 0.9 * (1 - (self.fitness_evaluations / self.budget)**2)\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.00792349526855618, 0.015477002109142712, 0.01377635357513085, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5657196223308056, 0.02664621271929124, 0.04425099978897995, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04789079522229378, 0.06177067621105636, 0.04077043343198372, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0530617577983572, 0.04711973764598398, 0.04982417877362122, 0.08434186702828161, 0.09681024956482975, 0.0924551103529011, 0.04016391723742285, 0.047025502033838484, 0.03287865102004295, 0.07335288996468137, 0.07838194699638501, 0.08274331599708895, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.018245130424116573, 0.01456233386691208, 0.015571164824200623, 0.028282276555844366, 0.013707017565301571, 0.014929175044415044, 0.1381828801431112, 0.14932665070037954, 0.1365270907332694, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "9e80adf2-f8e6-4ed0-b7cf-afac73a66b2d", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Enhanced PSO-DE by dynamically adjusting crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adjust crossover probability dynamically based on fitness evaluations\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "af2bf4d8-ba5f-4e28-8c26-7b32d055590f", "fitness": 0.023214205430971475, "name": "PSO_DE_Optimizer", "description": "Enhance exploration by integrating Lvy flight strategy into particle velocity updates.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        levy_flight = np.random.normal(size=(self.num_particles, self.dim))  # Added Lvy flight component\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity + levy_flight\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.0039284898044495975, 0.00430433173781497, 0.0018759876932045172, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0634286282846862, 0.07822119043708264, 0.061386814825520664, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05000256395417557, 0.06117927015852909, 0.048860379126861586, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05114428996715614, 0.05139415312526541, 0.05055287750928039, 0.08840731868335017, 0.10195666408606185, 0.085087361874297, 0.03472687183821821, 0.04272698563588584, 0.03697630191028778, 0.07016986417760385, 0.08031552194745062, 0.06649913167745902, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02012781424494947, 0.01591217862549732, 0.01765467287695688, 0.012942667643182859, 0.015524094124374166, 0.014522806138669075, 0.13792193613332204, 0.14577386797937653, 0.1396368852437586, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "0159cafc-3693-4c87-8268-7c59bd216534", "fitness": 0.022650065843882905, "name": "PSO_DE_Optimizer", "description": "Hybrid PSO-DE optimizer with adaptive parameters and enhanced crossover mechanism for improved convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.7  # Adjusted\n        self.crossover_prob = 0.9\n        self.adapt_factor = 0.05  # New adaptive factor\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best = position.copy()  # Added\n        self.global_best = None  # Added\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Modified\n        self.cognitive_coef = 2.0 - (0.8 * (self.fitness_evaluations / self.budget))  # Modified\n        self.social_coef = 2.0 + (0.5 * (self.fitness_evaluations / self.budget))  # Modified\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.5 + (0.3 * (self.fitness_evaluations / self.budget))  # Modified\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < (self.crossover_prob + self.adapt_factor)  # Modified\n            trial_vector = np.where(crossover, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector  # Ensure personal best update\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        self.global_best = personal_best[global_best_index]  # Updated\n        return self.global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, self.personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, self.personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            self.personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, self.personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.00043478260869567187, 0.00043478260869567187, 0.026259266939874237, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.061814742522875776, 0.0011378482663799705, 0.03291650046587724, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.049639381910416835, 0.06856024945106642, 0.059845798196707545, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05274627220665262, 0.048882470617899854, 0.048909651748939686, 0.07933641521285584, 0.09698338119144156, 0.08614577806623835, 0.050122161452321734, 0.0396535833426811, 0.04469678556394707, 0.07115168211970735, 0.07442427771281213, 0.07966738660442907, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.016693047373074532, 0.02759288570535301, 0.017572263141503397, 0.01426445242483898, 0.012379405644265762, 0.012958338776268064, 0.14220334165583026, 0.15063890402321145, 0.14447803363948986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "3c4f6141-d7c8-4626-8237-cb1291380831", "fitness": 0.031069671531149194, "name": "PSO_DE_Optimizer", "description": "Refine mutation factor update by incorporating historical best fitness to improve convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations and historical best fitness\n            self.mutation_factor = 0.8 + 0.2 * ((np.min(fitness) - np.min(fitness[:i+1])) / (self.budget if np.min(fitness[:i+1]) == 0 else np.min(fitness[:i+1])))\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.009354233425553415, 0.008957664461599513, 0.010745863324479354, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05308222748775693, 0.05811774562386285, 0.6003204577540067, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04980635013922696, 0.06962626578356279, 0.049779658209130995, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05101134371767779, 0.05235192363164398, 0.054138745069785554, 0.08719791867197824, 0.10052394918596785, 0.08988934583511332, 0.04340812094267166, 0.03434414942639552, 0.04055783879977892, 0.07077538691562035, 0.0844597296115458, 0.07945098458189848, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020863124245400377, 0.015100280925590459, 0.015682030368050826, 0.016828799120514493, 0.014654103181891087, 0.016519492102310296, 0.13884566399433906, 0.14128887484924113, 0.14107320929092892, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "f287114d-8498-4e0f-a7b9-e7c350095333", "fitness": 0.03577301999587328, "name": "PSO_DE_Optimizer", "description": "Improved PSO-DE balance by dynamically adjusting both mutation factor and crossover probability based on evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8  # Original definition left unchanged; adjustment is applied elsewhere\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.2 * (self.fitness_evaluations / self.budget)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # New adjustment\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.007001246576606612, 0.004872969876611899, 0.023325856119002397, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054637821968632205, 0.510754086964669, 0.480023289129368, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05067079910051431, 0.06659600213762329, 0.04468373859890107, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04976224243103522, 0.04864350172478582, 0.05306493454492445, 0.09114700584059288, 0.09902541646618535, 0.08491032509106233, 0.04635615298833495, 0.04810686388727414, 0.04136492610000464, 0.07567502196354103, 0.08377976657723518, 0.08033681219750233, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02321863482897535, 0.016396321725013596, 0.01652038698455982, 0.016836219063911417, 0.01203842258817489, 0.015299258648129643, 0.1406158235429018, 0.1384522877305977, 0.13328043474098672, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "12eb189a-f1b8-4db5-8efd-68980df51c3c", "fitness": 0.03920640913380582, "name": "PSO_DE_Optimizer", "description": "Slightly adjusted the mutation factor's upper bound to 0.25 for better exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["cb8e747a-90de-4bd1-a1f3-d85bd80aebd1"], "operator": null, "metadata": {"aucs": [0.005032068894034292, 0.006180443912761957, 0.012634054395039174, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144360191089083, 0.058113564422811015, 0.6174673065534986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04967654955464562, 0.06936771842230294, 0.04678982292355005, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05455401680054406, 0.05117559255787296, 0.05148822520762697, 0.08799074828596931, 0.09963450876003066, 0.08499233618504387, 0.041980245364970026, 0.047494768435878854, 0.043997103303267227, 0.0701820022010049, 0.0844597296115458, 0.08103359023824275, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02853672097708604, 0.015524812509580932, 0.016731274417825848, 0.01677382356503687, 0.014788309095620011, 0.015546630034911635, 0.1364139156027021, 0.13746721530677775, 0.14413747141971, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "f1d8e0c4-d34e-454a-b194-782d71a930a6", "fitness": 0.03602854102381251, "name": "PSO_DE_Optimizer", "description": "Dynamically adjusted the crossover probability for enhanced diversity and exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.0059997968562849335, 0.004224755217429155, 0.022835462373103188, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054671849839621034, 0.5107849910702507, 0.4863168431984344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051859555164204596, 0.0669760826450001, 0.04819599319893986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04905698535165637, 0.053197638772000566, 0.04961339211140614, 0.08910587126566871, 0.10390482267302004, 0.08998545364104693, 0.04275182539149269, 0.047494768435878854, 0.03858296989004306, 0.0754492878635522, 0.08327393677554917, 0.08600449555107803, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.023774778164523003, 0.01632713666281549, 0.01894463897282528, 0.016521214626612823, 0.012463788529091024, 0.01491285818204413, 0.13747339066036457, 0.13466706403392947, 0.14042243703141655, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "f050b0b4-8325-40ed-b029-1d2042f1d47b", "fitness": 0.03602854102381251, "name": "PSO_DE_Optimizer", "description": "Introduced a dynamic adjustment to the crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)  # Altered\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # New line altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.0059997968562849335, 0.004224755217429155, 0.022835462373103188, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054671849839621034, 0.5107849910702507, 0.4863168431984344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051859555164204596, 0.0669760826450001, 0.04819599319893986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04905698535165637, 0.053197638772000566, 0.04961339211140614, 0.08910587126566871, 0.10390482267302004, 0.08998545364104693, 0.04275182539149269, 0.047494768435878854, 0.03858296989004306, 0.0754492878635522, 0.08327393677554917, 0.08600449555107803, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.023774778164523003, 0.01632713666281549, 0.01894463897282528, 0.016521214626612823, 0.012463788529091024, 0.01491285818204413, 0.13747339066036457, 0.13466706403392947, 0.14042243703141655, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "316292ee-ea99-427a-9370-727d98a09701", "fitness": 0.03920640913380582, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive inertia weight to balance exploration and exploitation dynamically based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adjust mutation factor dynamically based on fitness evaluations\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.005032068894034292, 0.006180443912761957, 0.012634054395039174, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144360191089083, 0.058113564422811015, 0.6174673065534986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04967654955464562, 0.06936771842230294, 0.04678982292355005, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05455401680054406, 0.05117559255787296, 0.05148822520762697, 0.08799074828596931, 0.09963450876003066, 0.08499233618504387, 0.041980245364970026, 0.047494768435878854, 0.043997103303267227, 0.0701820022010049, 0.0844597296115458, 0.08103359023824275, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02853672097708604, 0.015524812509580932, 0.016731274417825848, 0.01677382356503687, 0.014788309095620011, 0.015546630034911635, 0.1364139156027021, 0.13746721530677775, 0.14413747141971, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "7175907f-af7d-4a29-8265-8fcc50795263", "fitness": 0.03602854102381251, "name": "PSO_DE_Optimizer", "description": "Dynamically adjust crossover probability in differential evolution to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Changed\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.0059997968562849335, 0.004224755217429155, 0.022835462373103188, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.054671849839621034, 0.5107849910702507, 0.4863168431984344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051859555164204596, 0.0669760826450001, 0.04819599319893986, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04905698535165637, 0.053197638772000566, 0.04961339211140614, 0.08910587126566871, 0.10390482267302004, 0.08998545364104693, 0.04275182539149269, 0.047494768435878854, 0.03858296989004306, 0.0754492878635522, 0.08327393677554917, 0.08600449555107803, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.023774778164523003, 0.01632713666281549, 0.01894463897282528, 0.016521214626612823, 0.012463788529091024, 0.01491285818204413, 0.13747339066036457, 0.13466706403392947, 0.14042243703141655, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "8351a12a-297b-4491-a4b4-775b8c6c3776", "fitness": 0.030111012567020073, "name": "PSO_DE_Optimizer", "description": "Added adaptive crossover probability to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adaptive crossover probability\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.013642909422012961, 0.0042385295658154964, 0.023115321677988576, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5648260395254073, 0.05774462765293742, 0.046482176515834306, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04823240225237857, 0.06591040772700285, 0.04297946198268798, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04748063631130184, 0.043721325019045576, 0.04968100198219205, 0.08345803024884424, 0.09909060232618128, 0.08587475689094848, 0.04404264743905317, 0.049090228720441775, 0.037740308401044476, 0.07503168603974764, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022350806418863334, 0.013259403793313362, 0.014639952979837334, 0.018651580146395896, 0.013050254827729701, 0.015352923205221969, 0.13514968314193365, 0.1361765689480997, 0.13461417403128118, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "d88b7afd-6441-4fad-be97-54030ee67ed6", "fitness": 0.02953884842382966, "name": "PSO_DE_Optimizer", "description": "Improved exploration by using non-linear inertia weight decay for better convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget) ** 2)  # Altered\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.25 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.003987630454683533, 0.0026600155554973304, 0.012128870612497566, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144452266924889, 0.02640675955392846, 0.04429299496811456, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05220043741592428, 0.05744617148334641, 0.04349810731122605, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.056787558702001695, 0.0461254382900651, 0.050032982357882894, 0.07758876321100816, 0.10203424380361803, 0.08566363052495884, 0.04025866591213623, 0.04754470735620009, 0.03338037648473724, 0.0717530055409733, 0.07507579249657881, 0.0665782048456488, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.01566970004428281, 0.012230609314415997, 0.014637988436699723, 0.015495066767435506, 0.01262499764074676, 0.014342914645562588, 0.14070882548058639, 0.14065131489811866, 0.13228521614915245, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "5ed844e2-9f8c-4f28-9c08-3851ca7aee78", "fitness": 0.03940624191662986, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting the upper bound of the mutation factor.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["12eb189a-f1b8-4db5-8efd-68980df51c3c"], "operator": null, "metadata": {"aucs": [0.007447590842238561, 0.012548146320796594, 0.013726530511179114, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144261726710325, 0.058187746479202995, 0.6175277303241047, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048198825366218556, 0.06903571499996397, 0.05225028018914912, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05155870847940569, 0.051934174775416175, 0.051394847637524554, 0.08645676879065145, 0.10197923813366783, 0.08813894310286108, 0.040828154740378264, 0.04695166699960385, 0.041658565796460656, 0.07048072612881218, 0.0844597296115458, 0.08074247909565457, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028147951755318146, 0.01570349294699136, 0.016401427725831197, 0.016031538067141082, 0.014861438237617208, 0.015332469484521827, 0.1340818209469311, 0.1445388972353353, 0.143956771036576, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "36005743-f9d4-490f-9e11-59bfe9f2e6d7", "fitness": 0.022952686293754094, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting both the upper and lower bounds of the mutation factor.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's bounds for better exploration\n            self.mutation_factor = 0.7 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00846560001051433, 0.006087715188419995, 0.012317425596214182, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051133016757985206, 0.058050538009936536, 0.04716021073229926, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04673340241542445, 0.0655966538831545, 0.04348256557522012, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04489905339922862, 0.04311943411143271, 0.04970747649883456, 0.08416172159809099, 0.09806628902722525, 0.0891777303232365, 0.04303960710453614, 0.04339215154171261, 0.04903191014393804, 0.07202672046298153, 0.08356840965491286, 0.08034579558204391, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02822708148500508, 0.014803965230875238, 0.016581443986362854, 0.018376633522831365, 0.016548259457173975, 0.015058637399409047, 0.13313714277475064, 0.14105294948642144, 0.1309830026249048, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "76e96e48-d332-4852-a362-78b803311870", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Improved convergence by fine-tuning the crossover probability to adaptively increase exploration.  ", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "0d152756-f19f-4867-96b7-7bcf99035fec", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Introduced a dynamic crossover probability to balance exploration and exploitation as the search progresses.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "e7e008d8-cb95-402c-8fe3-9b3719652943", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by further adjusting the crossover probability to increase diversity in later stages.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "54170969-0b79-47a2-aa85-660069977257", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting the crossover probability based on evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "5c25f39a-35a7-44a8-aec5-755cd3bef494", "fitness": 0.025848701242286817, "name": "PSO_DE_Optimizer", "description": "Enhanced mutation strategy by introducing a variance factor to reduce the effect of random deviations.  ", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        variance_factor = 0.1  # Introduced variance factor\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * ((position[b] - position[c]) * variance_factor)\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.006203826793989675, 0.004163258080281507, 0.010475290041240037, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.29607042594126, 0.023116821860451497, 0.033658352873106256, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04906540374569923, 0.05490186017925902, 0.04727397097304442, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.050383122549691794, 0.04642161013762447, 0.05181166580746044, 0.08341147225261603, 0.10412230929682487, 0.09063196492883951, 0.04781484893385313, 0.03706829744918039, 0.04122813675475756, 0.07717913587498948, 0.08405372601403305, 0.07948111368695865, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020555153468677312, 0.01598797971951471, 0.021120945049346584, 0.015135353905796567, 0.012737802555552236, 0.01553776062428014, 0.1404032209181929, 0.147224977489969, 0.1356058119729423, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "fb26a6aa-4d1b-4f7a-b151-349418efa048", "fitness": 0.030619100395854058, "name": "PSO_DE_Optimizer", "description": "Improved exploitation by further adjusting the crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.01288702121455132, 0.007770977986750305, 0.012505901745456627, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6149691446642991, 0.023282420700338813, 0.057844575000934983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04797038306617141, 0.06376266719601875, 0.052775961271640526, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045942040986337584, 0.048571700955382324, 0.05255778259843713, 0.08273781076715414, 0.09757578076906903, 0.08480227929791984, 0.042430893302031425, 0.04783409115854975, 0.03768062432334596, 0.0754492878635522, 0.08305328488286334, 0.08106788080924932, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021272556735741466, 0.014478946749318156, 0.01567207402596449, 0.017594126946933852, 0.017039967182460036, 0.015142288038286433, 0.14093673144354302, 0.1350409194467702, 0.13566423780720238, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "e4c5063b-9006-430d-9595-d8fa2272e9a0", "fitness": 0.03837348595353454, "name": "PSO_DE_Optimizer", "description": "Enhanced local exploitation by increasing cognitive coefficient adjustment range.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.5 * (self.fitness_evaluations / self.budget))  # Altered\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.011999046930820545, 0.011885862192534069, 0.015839921338038465, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6062284463208665, 0.027736089961769905, 0.5959523314685178, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04640747952364943, 0.07012657928658306, 0.04663187391896961, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05069632343489483, 0.04466081764226881, 0.05198987202809291, 0.08401043046974477, 0.09773374156340608, 0.08464575024906185, 0.04128590293027257, 0.04686347722648687, 0.0404833714738132, 0.07707998974609931, 0.0817494590452933, 0.0910805089181056, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.024539427271976, 0.016534812663665632, 0.015210108591994786, 0.01759883353960756, 0.016660032640959055, 0.01617661875135068, 0.13613414583513783, 0.14062805536348988, 0.13606080876179827, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "386bb189-3451-4e5f-a8f9-61d9ddf60159", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced balance between exploration and exploitation by dynamically adjusting the crossover probability based on optimization progress.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "4b23f704-aebc-498d-8849-a3aff28423c2", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by adjusting the crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "dac5b07e-76e8-4f49-a070-9a310d22e67d", "fitness": 0.030421361260013786, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration and exploitation by adjusting the crossover probability adaptively.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        # Adjusting crossover probability adaptively\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Changed line: adapting crossover probability\n            trial_vector = np.where(np.random.rand(self.dim) < (self.crossover_prob - 0.1 * (self.fitness_evaluations / self.budget)), mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.010834670213666131, 0.008733573424030916, 0.016042028834235444, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6139976965419105, 0.019916262548301478, 0.04258860138797549, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.049164292684148014, 0.06645229504365524, 0.04666410953734634, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05155870847940569, 0.051999069832645795, 0.05062313501131799, 0.08871695374261024, 0.09937276875165302, 0.08593273784379685, 0.03908579318110661, 0.04689673604501343, 0.0363268559990948, 0.07010772746217242, 0.0844597296115458, 0.07970766189974687, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022067707663471325, 0.013813566063394789, 0.0186384073244813, 0.014830243486580907, 0.014531912676267855, 0.015182975766681595, 0.1370203300231152, 0.13391692245859022, 0.14289366761781208, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "4b909149-d67c-4100-a9d9-9c0e3189281a", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by adaptively adjusting the crossover probability over time.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adaptively adjusting the crossover probability\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "37c8d63f-727a-4ecb-9e5b-f5ffa016e0e9", "fitness": 0.03679465491739377, "name": "PSO_DE_Optimizer", "description": "Enhanced exploitation by increasing cognitive and social coefficients over time.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))  # Changed line\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0027056356807735327, 0.0008132338819613061, 0.009761861681326978, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6138205802790635, 0.03816824216790293, 0.5332046814375117, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04998568343786913, 0.06275252111094642, 0.04204143748188338, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05026984593776396, 0.0484804150589343, 0.050675987089718544, 0.08319383865415386, 0.09912703587664129, 0.08959515012401742, 0.04456066005771153, 0.0497329701343181, 0.03829806150020565, 0.06996874638191908, 0.07625208774181647, 0.0702492287578157, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02003424237820861, 0.011511596871324525, 0.014723103110651059, 0.015564991826636732, 0.012827815364046202, 0.01417328767048509, 0.13857602097557253, 0.13918555422694034, 0.14069976758901293, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "dfafee83-0ca3-4195-ae47-5880e2a2d9d0", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced global search by dynamically adjusting the crossover probability.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "4101d794-74df-4c5a-ad01-a571f7cd9b56", "fitness": 0.022572940053190577, "name": "PSO_DE_Optimizer", "description": "Enhanced mixture of PSO and DE by further modifying inertia weight decay for adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Altered\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00855122812035225, 0.003262433710283563, 0.019132994141296766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05345765031312977, 0.022531894046327938, 0.04343670755766871, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04574521859160918, 0.06570413534020947, 0.049251888777487984, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971138855931756, 0.050731169430505374, 0.049293630508647546, 0.08505044530304151, 0.09712485787259029, 0.08478867797716727, 0.04186060677387715, 0.04704008921673386, 0.04256766168794457, 0.07785427751766094, 0.08689304935120978, 0.07306882687588745, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022089295452667246, 0.013405457674441679, 0.014795628209294143, 0.016986555586595564, 0.013712018636587664, 0.014959154993485657, 0.1319145036423679, 0.15252339462452336, 0.12954597377159116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "f0c853de-f20b-4fb7-9875-3246357f0400", "fitness": 0.03868375971323422, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting the upper bound of the mutation factor and introducing adaptive inertia weight decay to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.7 * (self.fitness_evaluations / self.budget))  # Altered\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.005213259797620662, 0.008270828244068329, 0.017768884564474452, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.614449529501043, 0.025896065141748026, 0.6046066179230137, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.047916944292324515, 0.07309608139487078, 0.04345458517553413, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05459180497889227, 0.04675781332371398, 0.051496456434574234, 0.08356292806934762, 0.10453800116848178, 0.08587720583227365, 0.0470851244842071, 0.04702383886488981, 0.038569823339403175, 0.0731880852199508, 0.07718301470186262, 0.09184468207489516, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028780899341949717, 0.013533884469341895, 0.016620712357595546, 0.016711758323428305, 0.01553418101093329, 0.017101341676486692, 0.14135187904995927, 0.13629227229184837, 0.1386513267389129, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "0bb50398-c2ec-4aef-ad0d-cff8725fbc27", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced dynamic crossover probability based on fitness evaluations to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "ab348ea6-9939-4072-ba1c-bb04ac0a823d", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Enhanced convergence by adjusting the crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Changed\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "711e7231-627f-4ee6-99ae-8e34ae4005e5", "fitness": 0.02986613732168776, "name": "PSO_DE_Optimizer", "description": "Enhanced velocity update by introducing adaptive inertia weight scaling for improved convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * ((self.fitness_evaluations / self.budget) ** 2))  # Altered\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0036872462769358405, 0.0029596599941507096, 0.01231659233974447, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144570738868017, 0.02640725104354591, 0.044231259071926154, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04426144424088685, 0.05665884861071946, 0.043370784789855676, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05160612930866948, 0.049645065803707866, 0.04972159311295299, 0.08408543739716112, 0.10093083159778748, 0.09092090045097745, 0.04334626380287254, 0.047486937580670796, 0.03381008540246688, 0.0717530055409733, 0.07718389629264355, 0.06901879597745253, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.015216779319447316, 0.011114057636123054, 0.015100248855177911, 0.01773313549904798, 0.011912096481424106, 0.014279580204730968, 0.13971598430593535, 0.14217042658285883, 0.1469996061886525, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "d68195eb-adb0-45bc-8742-acd22d7300dc", "fitness": 0.03278595565268863, "name": "PSO_DE_Optimizer", "description": "Introduce adaptive crossover probability based on fitness evaluations to improve exploration and exploitation balance.  ", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9  # Original: self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.2 * (self.fitness_evaluations / self.budget))  # Changed crossover probability\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.010160584856593768, 0.008424121292596287, 0.013777696899223257, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6157121324660721, 0.01955165470270137, 0.20892301422310045, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04838869376086641, 0.06843837058943714, 0.04911641515983611, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.052690589003203114, 0.04827902816668128, 0.05390088025870743, 0.08692346847384613, 0.10309522060023801, 0.08922911878241313, 0.038974721163903436, 0.047044989143841476, 0.03798244864249389, 0.07128728074493984, 0.08344003105226239, 0.08168232684387677, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02106266043400451, 0.013943743755935656, 0.01638176896189658, 0.01735823058281072, 0.014606000682682141, 0.016395211940237298, 0.13536861245299225, 0.13652201472673509, 0.13366690706423479, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "932f07b8-c095-4341-80fc-0dc5404709d2", "fitness": 0.022952686293754094, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting both the upper and lower bounds of the mutation factor.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor for better exploration\n            self.mutation_factor = 0.7 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00846560001051433, 0.006087715188419995, 0.012317425596214182, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051133016757985206, 0.058050538009936536, 0.04716021073229926, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04673340241542445, 0.0655966538831545, 0.04348256557522012, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04489905339922862, 0.04311943411143271, 0.04970747649883456, 0.08416172159809099, 0.09806628902722525, 0.0891777303232365, 0.04303960710453614, 0.04339215154171261, 0.04903191014393804, 0.07202672046298153, 0.08356840965491286, 0.08034579558204391, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02822708148500508, 0.014803965230875238, 0.016581443986362854, 0.018376633522831365, 0.016548259457173975, 0.015058637399409047, 0.13313714277475064, 0.14105294948642144, 0.1309830026249048, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "3da07113-5565-478c-b170-1b5c2b894ba7", "fitness": 0.022572940053190577, "name": "PSO_DE_Optimizer", "description": "Fine-tune the inertia weight's decay by altering its formula for better convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Altered\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00855122812035225, 0.003262433710283563, 0.019132994141296766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05345765031312977, 0.022531894046327938, 0.04343670755766871, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04574521859160918, 0.06570413534020947, 0.049251888777487984, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971138855931756, 0.050731169430505374, 0.049293630508647546, 0.08505044530304151, 0.09712485787259029, 0.08478867797716727, 0.04186060677387715, 0.04704008921673386, 0.04256766168794457, 0.07785427751766094, 0.08689304935120978, 0.07306882687588745, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022089295452667246, 0.013405457674441679, 0.014795628209294143, 0.016986555586595564, 0.013712018636587664, 0.014959154993485657, 0.1319145036423679, 0.15252339462452336, 0.12954597377159116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "ee19b2ff-832f-4611-9baa-bf97b520cdfe", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Further enhance exploration by applying a decay strategy to the crossover probability over time.  ", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "60f9c5d9-2a9a-40ea-ad25-cbd5c98f1505", "fitness": 0.022572940053190577, "name": "PSO_DE_Optimizer", "description": "Refine inertia weight dynamics for improved convergence stability.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Changed from 0.6 to 0.5\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00855122812035225, 0.003262433710283563, 0.019132994141296766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05345765031312977, 0.022531894046327938, 0.04343670755766871, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04574521859160918, 0.06570413534020947, 0.049251888777487984, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971138855931756, 0.050731169430505374, 0.049293630508647546, 0.08505044530304151, 0.09712485787259029, 0.08478867797716727, 0.04186060677387715, 0.04704008921673386, 0.04256766168794457, 0.07785427751766094, 0.08689304935120978, 0.07306882687588745, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022089295452667246, 0.013405457674441679, 0.014795628209294143, 0.016986555586595564, 0.013712018636587664, 0.014959154993485657, 0.1319145036423679, 0.15252339462452336, 0.12954597377159116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "ebbc459b-11c2-4965-894b-920ab7d11854", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhanced strategy by dynamically adjusting the crossover probability for better exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "94a9322c-f026-4607-be02-e80d4ed75e58", "fitness": 0.030619100395854058, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9  # Initial crossover probability\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.01288702121455132, 0.007770977986750305, 0.012505901745456627, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6149691446642991, 0.023282420700338813, 0.057844575000934983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04797038306617141, 0.06376266719601875, 0.052775961271640526, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045942040986337584, 0.048571700955382324, 0.05255778259843713, 0.08273781076715414, 0.09757578076906903, 0.08480227929791984, 0.042430893302031425, 0.04783409115854975, 0.03768062432334596, 0.0754492878635522, 0.08305328488286334, 0.08106788080924932, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021272556735741466, 0.014478946749318156, 0.01567207402596449, 0.017594126946933852, 0.017039967182460036, 0.015142288038286433, 0.14093673144354302, 0.1350409194467702, 0.13566423780720238, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "9e322703-ac34-4a04-a863-50ecd09cef99", "fitness": 0.03861650314749329, "name": "PSO_DE_Optimizer", "description": "Adaptive mutation factor with a non-linear growth for enhanced exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Adaptive mutation factor with a non-linear growth for enhanced exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)**2  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.005863883931312763, 0.006530449496490287, 0.012008538615625564, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144427901804593, 0.05811631596861966, 0.6020826959033787, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04543955148726775, 0.06639977488547455, 0.04175838535682963, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04516954591838385, 0.05285130724199483, 0.049627515453077975, 0.08351834964436022, 0.09983528380099183, 0.09326443738433465, 0.04325077497452301, 0.04334300779450739, 0.0398414275739315, 0.07021439477147517, 0.0844597296115458, 0.08082395468577208, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.020894747953882464, 0.014379558475311138, 0.017812277568112433, 0.020151697339195862, 0.015936844054000088, 0.016460729908679306, 0.1440161152320717, 0.14249542870623078, 0.1311378431364587, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "985d12d7-0e4d-4eb9-986b-cadeaad90a81", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability based on fitness evaluations for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adaptive crossover probability to balance exploration and exploitation\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "bf763c1b-8a32-4a01-a68f-5bbb722c31ee", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced a dynamic crossover probability to adapt exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        # Dynamic crossover probability\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adjust crossover probability dynamically\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "50b085c6-d0a5-4fa1-adff-60f4bd47db4c", "fitness": 0.030619100395854058, "name": "PSO_DE_Optimizer", "description": "Introduced a dynamic adjustment to the crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.01288702121455132, 0.007770977986750305, 0.012505901745456627, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6149691446642991, 0.023282420700338813, 0.057844575000934983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04797038306617141, 0.06376266719601875, 0.052775961271640526, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045942040986337584, 0.048571700955382324, 0.05255778259843713, 0.08273781076715414, 0.09757578076906903, 0.08480227929791984, 0.042430893302031425, 0.04783409115854975, 0.03768062432334596, 0.0754492878635522, 0.08305328488286334, 0.08106788080924932, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021272556735741466, 0.014478946749318156, 0.01567207402596449, 0.017594126946933852, 0.017039967182460036, 0.015142288038286433, 0.14093673144354302, 0.1350409194467702, 0.13566423780720238, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "9c13943a-0c5e-482d-9f97-dcfd9c770469", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration and exploitation balance by dynamically adjusting the crossover probability.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Adjusted\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "fedccb54-98ff-47c7-b663-42e331f08c67", "fitness": 0.030933646196370783, "name": "PSO_DE_Optimizer", "description": "Improved balance between exploration and exploitation by optimizing the cognitive coefficient decay rate.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (0.5 * (self.fitness_evaluations / self.budget))  # Altered\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0038607915457283815, 0.003808602632625835, 0.016653218981013462, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6143080087206062, 0.05812299704786439, 0.04308007447962925, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04547817955923361, 0.06529221464056911, 0.04346354984141232, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0492751443901599, 0.05423988396282453, 0.05362539252241949, 0.0886691191066189, 0.0966943046079567, 0.09110957904226302, 0.03873267693730287, 0.04686347722648687, 0.04221056024731473, 0.06964454703563405, 0.0824820668779569, 0.08250141343413198, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021422146099998818, 0.015880555720317435, 0.015816144737236915, 0.016708874919855066, 0.01492698345378618, 0.01681846952688848, 0.13705715127929696, 0.1394582718311016, 0.14075725616524415, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "364885ed-7062-4bad-8930-676dda6a32dd", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Improved exploration by adapting the crossover probability dynamically.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Dynamically adapt crossover probability for improved exploration\n            self.crossover_prob = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "3de8a6eb-9fe2-4341-8354-92e23cd15f3e", "fitness": 0.022572940053190577, "name": "PSO_DE_Optimizer", "description": "Fine-tune the inertia weight decay to enhance convergence speed in the PSO component.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Adjusted decay\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00855122812035225, 0.003262433710283563, 0.019132994141296766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05345765031312977, 0.022531894046327938, 0.04343670755766871, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04574521859160918, 0.06570413534020947, 0.049251888777487984, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971138855931756, 0.050731169430505374, 0.049293630508647546, 0.08505044530304151, 0.09712485787259029, 0.08478867797716727, 0.04186060677387715, 0.04704008921673386, 0.04256766168794457, 0.07785427751766094, 0.08689304935120978, 0.07306882687588745, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022089295452667246, 0.013405457674441679, 0.014795628209294143, 0.016986555586595564, 0.013712018636587664, 0.014959154993485657, 0.1319145036423679, 0.15252339462452336, 0.12954597377159116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "09809bba-8855-4c0d-970d-9ed48c36b045", "fitness": 0.022572940053190577, "name": "PSO_DE_Optimizer", "description": "Improved exploitation by adjusting the inertia weight decay rate for better convergence around the global best.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.5 * (self.fitness_evaluations / self.budget))  # Adjusted\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00855122812035225, 0.003262433710283563, 0.019132994141296766, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05345765031312977, 0.022531894046327938, 0.04343670755766871, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04574521859160918, 0.06570413534020947, 0.049251888777487984, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04971138855931756, 0.050731169430505374, 0.049293630508647546, 0.08505044530304151, 0.09712485787259029, 0.08478867797716727, 0.04186060677387715, 0.04704008921673386, 0.04256766168794457, 0.07785427751766094, 0.08689304935120978, 0.07306882687588745, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.022089295452667246, 0.013405457674441679, 0.014795628209294143, 0.016986555586595564, 0.013712018636587664, 0.014959154993485657, 0.1319145036423679, 0.15252339462452336, 0.12954597377159116, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "dfa2283e-8cce-4faf-95c5-36d10e11f930", "fitness": 0.029185257414115026, "name": "PSO_DE_Optimizer", "description": "Improved exploration by enhancing the mutation strategy with adaptive scaling.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.5 * (np.sin(np.pi * self.fitness_evaluations / self.budget))  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0033259457019836347, 0.011609974586762384, 0.023466452641845215, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5218057829208439, 0.015126154984302809, 0.03067337565277839, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.046349824337553636, 0.07097032866751662, 0.04664204562504559, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05572303513298027, 0.04565880275782641, 0.05026121272785278, 0.08188727852292566, 0.10066015056445676, 0.08852964490818072, 0.04072071775641428, 0.042335861419908416, 0.043815076664688535, 0.07153736894416696, 0.08435511209248547, 0.07934858868804762, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.029282259676737477, 0.01609231474597017, 0.016484738905190643, 0.017313672463157626, 0.012428000892040214, 0.01576579807602152, 0.14422244141887508, 0.13613740200530655, 0.14054830076919855, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "7f436415-1f83-4a1b-8175-d71a2311f8d1", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Improved convergence by dynamically adjusting the crossover probability for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Adjust crossover probability for better convergence\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "29f5c860-f1db-4834-9280-59c11ce54add", "fitness": 0.022952686293754094, "name": "PSO_DE_Optimizer", "description": "Fine-tuned the mutation factor's range for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.7 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00846560001051433, 0.006087715188419995, 0.012317425596214182, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051133016757985206, 0.058050538009936536, 0.04716021073229926, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04673340241542445, 0.0655966538831545, 0.04348256557522012, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04489905339922862, 0.04311943411143271, 0.04970747649883456, 0.08416172159809099, 0.09806628902722525, 0.0891777303232365, 0.04303960710453614, 0.04339215154171261, 0.04903191014393804, 0.07202672046298153, 0.08356840965491286, 0.08034579558204391, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02822708148500508, 0.014803965230875238, 0.016581443986362854, 0.018376633522831365, 0.016548259457173975, 0.015058637399409047, 0.13313714277475064, 0.14105294948642144, 0.1309830026249048, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "d835dab3-1956-4868-8163-940a5f037928", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Enhance exploitation by dynamically adjusting the crossover probability.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "77046d8d-5615-48c8-8c1d-dd3c9abcd880", "fitness": 0.03081816523249262, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by introducing a decay factor to balance mutation over iterations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            decay_factor = 1 - (self.fitness_evaluations / self.budget)  # Altered\n            self.mutation_factor = (0.8 + 0.3 * (self.fitness_evaluations / self.budget)) * decay_factor  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004432629303817159, 0.008324902577665716, 0.013261196353457017, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05112609838105364, 0.05806368330134892, 0.6002618209548014, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.048601725080194336, 0.06852992626343368, 0.04172580666524939, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05056814753727412, 0.05173519191101128, 0.05014387047044777, 0.09325463280976576, 0.10072087772502036, 0.08917146450628421, 0.04258580885736807, 0.03906794369441524, 0.03717705763369894, 0.07183142974325063, 0.0852074270515305, 0.08230643114519309, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021033343099775226, 0.017179140454218977, 0.019170467018909787, 0.016523858473722508, 0.012746577590737274, 0.015460097232388503, 0.13455689974812157, 0.13778320120259935, 0.13809537038749597, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "8f58cd1c-a04f-4408-9c51-4f5780c38848", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced a dynamic crossover probability in DE to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "6825cf74-48a4-41d7-9a42-841d36bf6e2c", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability based on fitness evaluations for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Introduced adaptive crossover probability\n            self.crossover_prob = 0.9 - 0.4 * (self.fitness_evaluations / self.budget)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "65bf17f1-5f7b-4205-951f-c8b8b0dafebb", "fitness": 0.022952686293754094, "name": "PSO_DE_Optimizer", "description": "Fine-tuning the mutation factor's lower bound to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.7 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.00846560001051433, 0.006087715188419995, 0.012317425596214182, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051133016757985206, 0.058050538009936536, 0.04716021073229926, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04673340241542445, 0.0655966538831545, 0.04348256557522012, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04489905339922862, 0.04311943411143271, 0.04970747649883456, 0.08416172159809099, 0.09806628902722525, 0.0891777303232365, 0.04303960710453614, 0.04339215154171261, 0.04903191014393804, 0.07202672046298153, 0.08356840965491286, 0.08034579558204391, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02822708148500508, 0.014803965230875238, 0.016581443986362854, 0.018376633522831365, 0.016548259457173975, 0.015058637399409047, 0.13313714277475064, 0.14105294948642144, 0.1309830026249048, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "281de383-5e54-4d37-895e-a317bbc7ed74", "fitness": 0.02893121057481127, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            # Adaptive crossover probability\n            self.crossover_prob = 0.9 - (0.4 * (self.fitness_evaluations / self.budget))  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0061402055338580785, 0.003967237599108331, 0.021779136744438543, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051465201748223, 0.025795679304003727, 0.4864886802437375, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05083796329899892, 0.06664975498971926, 0.04767334976874138, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04487792023231463, 0.044314320743214286, 0.04991890399333854, 0.09049446965873398, 0.09875318973300751, 0.08728088557185298, 0.04171293131595322, 0.047957713532501334, 0.03700167555270972, 0.0754492878635522, 0.0830495569263141, 0.08105403114037057, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021976635890836538, 0.014764189867690236, 0.016206064597628744, 0.017877711023367326, 0.013451942616504287, 0.016380104612435553, 0.13914353041746474, 0.14152574718333388, 0.14079827011724033, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "e0fce0ca-420d-4497-83c5-debd7c8e22c8", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "2448fe70-def6-4c50-910c-d71eb82f9a4f", "fitness": 0.030369228418469413, "name": "PSO_DE_Optimizer", "description": "Slightly adjusted the crossover probability to balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.85  # Slightly adjusted from 0.9 to 0.85\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.07.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.008208888023164662, 0.008419717936601012, 0.019101457556116697, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.5603331936494216, 0.024459690167895398, 0.06281957405545813, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05059394811042439, 0.06814294637078899, 0.05022352456176027, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05217417916198075, 0.048787232142963544, 0.04969901268570265, 0.08845330242677885, 0.09860193588417054, 0.08957451392294724, 0.04462860309403782, 0.04254156370497619, 0.03902699901448181, 0.07585741536901269, 0.0830495569263141, 0.08020562312899648, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.029198218588129654, 0.013173849208818034, 0.01816211070492979, 0.016962451855896954, 0.013040066439506615, 0.015584011455819002, 0.1393828359469126, 0.14082528974373276, 0.13709186472684065, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "af6ba83d-217d-4786-af3d-cfc55cedf84c", "fitness": 0.03278595565268863, "name": "PSO_DE_Optimizer", "description": "Further refined by dynamically adjusting the crossover probability for diversity.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.2 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.010160584856593768, 0.008424121292596287, 0.013777696899223257, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6157121324660721, 0.01955165470270137, 0.20892301422310045, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04838869376086641, 0.06843837058943714, 0.04911641515983611, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.052690589003203114, 0.04827902816668128, 0.05390088025870743, 0.08692346847384613, 0.10309522060023801, 0.08922911878241313, 0.038974721163903436, 0.047044989143841476, 0.03798244864249389, 0.07128728074493984, 0.08344003105226239, 0.08168232684387677, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02106266043400451, 0.013943743755935656, 0.01638176896189658, 0.01735823058281072, 0.014606000682682141, 0.016395211940237298, 0.13536861245299225, 0.13652201472673509, 0.13366690706423479, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "1a9976a5-0a08-4052-b2ca-297711796486", "fitness": 0.036840270919804484, "name": "PSO_DE_Optimizer", "description": "Enhanced mutation factor calculation with adaptive scaling for improved exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.2 * np.sin((np.pi * self.fitness_evaluations) / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.09.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0043517503857223305, 0.006375353641370651, 0.012044359584801545, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.614498325511497, 0.025741945662402954, 0.4808047055138688, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.051156836698855845, 0.0640809413226221, 0.049497081827943545, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.05338219101135033, 0.05202219259111329, 0.050324117222612985, 0.08374720110349287, 0.1025208288567786, 0.0887580608541021, 0.04282328648175793, 0.04139006521779953, 0.04166033633173494, 0.0698570254128309, 0.0844597296115458, 0.0796817898605332, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.02859691236110573, 0.01712411237639, 0.016304149508713173, 0.01750541711761655, 0.014952097697650824, 0.01563438408360407, 0.1484262162558313, 0.1393131454442782, 0.13720407711077742, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "b562cb94-284c-47b5-a6c3-091edafe048d", "fitness": 0.030838141628416898, "name": "PSO_DE_Optimizer", "description": "Introduced a new decay function for the mutation factor to enhance local exploitation while maintaining diversity over iterations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.8 + 0.2 * np.exp(-5 * (self.fitness_evaluations / self.budget))  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.008232802089110258, 0.01160766020317916, 0.02336250567719278, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6138134018735477, 0.02500784747681517, 0.04379961520706377, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04815774557692021, 0.07099066245703334, 0.05137266848108102, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04637205102652764, 0.05272359457978659, 0.049627386281169694, 0.0883254114625438, 0.09710311874208954, 0.09254501195835518, 0.042662664269983774, 0.042890950767860425, 0.03934856026239353, 0.07052076199870616, 0.0844597296115458, 0.08106794337367673, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028260917432838983, 0.01361901099658569, 0.015990904111615745, 0.015940924094688835, 0.014749942846494113, 0.015309359010283852, 0.13796020940059261, 0.139953415467457, 0.13630855094365923, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "3746f670-e357-4760-951a-68d2b0a4c003", "fitness": 0.03853547271670697, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration through dynamic mutation control in Differential Evolution.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.35 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.10.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.007338153396372227, 0.011534083001716544, 0.013667345585944068, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144311110018292, 0.021883403067879392, 0.6031713617341644, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04908163748811212, 0.06395679679321054, 0.04801535988438954, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.049459752709150706, 0.0511803566652157, 0.059051454867495634, 0.08415173413699295, 0.10398419428455186, 0.09457305550848971, 0.039656307126950674, 0.04592504959833166, 0.03912408196186179, 0.0699765674059053, 0.08476405002782272, 0.0796817898605332, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.028717992608143006, 0.015980362251787894, 0.016736790869518736, 0.016759600861655954, 0.014983792973774168, 0.015196859725189027, 0.13254391843560187, 0.1355855141194905, 0.1451806880856028, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "61268ed0-13a0-4e83-8f76-d9fccb25d310", "fitness": 0.030587963015560334, "name": "PSO_DE_Optimizer", "description": "Enhanced exploration by dynamically adjusting the crossover probability based on fitness evaluations.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            # Dynamically adjust crossover probability\n            self.crossover_prob = 0.9 - 0.5 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.004671017341549399, 0.00711567477451891, 0.02186843371364311, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6155116770651659, 0.02129617504493042, 0.046489652372654344, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04969121190190062, 0.06448782757953408, 0.040886971759891866, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04382469233257702, 0.05400733940304847, 0.05221628002598799, 0.08914376679444003, 0.10114893403762615, 0.08479175439836462, 0.04281209477446257, 0.04688635956201681, 0.03664880314972829, 0.07507527067149666, 0.0830495569263141, 0.08108220984868453, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.0282846202144883, 0.013362098596759742, 0.01620363400517022, 0.01643870004433645, 0.012702334749200683, 0.016060551005166013, 0.13399675484891282, 0.14739147558760224, 0.1369265950249533, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "4156936e-e629-4d1e-b32e-52882c638d81", "fitness": 0.03117033582495596, "name": "PSO_DE_Optimizer", "description": "Enhance exploration by further adjusting the mutation factor for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            # Further adjusted mutation factor's upper bound for better exploration\n            self.mutation_factor = 0.85 + 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.0091033759429614, 0.004887942404721235, 0.02221502655888896, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6144788833855632, 0.024297589496979466, 0.07388451959878872, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04799088640778637, 0.06520936457521187, 0.046946801341649635, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04670118770099729, 0.054451879622422705, 0.055392984297400694, 0.09128141867221351, 0.10092860402598391, 0.08552876368354412, 0.04280087548870615, 0.03958171733554394, 0.04414881898511813, 0.07129682329060494, 0.0844597296115458, 0.08103455107095314, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.029446687493789092, 0.015887045426759894, 0.016320478129104532, 0.017148515658205632, 0.011970368573768098, 0.01543521756497468, 0.13319455388472923, 0.1401283948808233, 0.13985030472187143, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "dd203cf0-dcae-4921-9765-28da318aea49", "fitness": 0.030619100395854058, "name": "PSO_DE_Optimizer", "description": "Introduced adaptive crossover probability to enhance solution diversity and convergence speed.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - (0.3 * (self.fitness_evaluations / self.budget))  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.01288702121455132, 0.007770977986750305, 0.012505901745456627, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6149691446642991, 0.023282420700338813, 0.057844575000934983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04797038306617141, 0.06376266719601875, 0.052775961271640526, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045942040986337584, 0.048571700955382324, 0.05255778259843713, 0.08273781076715414, 0.09757578076906903, 0.08480227929791984, 0.042430893302031425, 0.04783409115854975, 0.03768062432334596, 0.0754492878635522, 0.08305328488286334, 0.08106788080924932, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021272556735741466, 0.014478946749318156, 0.01567207402596449, 0.017594126946933852, 0.017039967182460036, 0.015142288038286433, 0.14093673144354302, 0.1350409194467702, 0.13566423780720238, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "dcb356ff-53ba-4cb1-a09d-d6c0bb4edd67", "fitness": 0.030619100395854058, "name": "PSO_DE_Optimizer", "description": "Refined mutation strategy by adjusting the crossover probability dynamically for enhanced exploration.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 2.0 - (1.0 * (self.fitness_evaluations / self.budget))\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            self.crossover_prob = 0.9 - 0.3 * (self.fitness_evaluations / self.budget)  # Altered\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.08.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.01288702121455132, 0.007770977986750305, 0.012505901745456627, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.6149691446642991, 0.023282420700338813, 0.057844575000934983, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04797038306617141, 0.06376266719601875, 0.052775961271640526, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045942040986337584, 0.048571700955382324, 0.05255778259843713, 0.08273781076715414, 0.09757578076906903, 0.08480227929791984, 0.042430893302031425, 0.04783409115854975, 0.03768062432334596, 0.0754492878635522, 0.08305328488286334, 0.08106788080924932, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.021272556735741466, 0.014478946749318156, 0.01567207402596449, 0.017594126946933852, 0.017039967182460036, 0.015142288038286433, 0.14093673144354302, 0.1350409194467702, 0.13566423780720238, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
{"id": "511aaee4-c84e-4bff-a508-54008cbefdab", "fitness": 0.02430772572687799, "name": "PSO_DE_Optimizer", "description": "Emphasizing local search by dynamically adjusting the cognitive coefficient's lower bound for improved convergence.", "code": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.fitness_evaluations = 0\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n\n    def initialize_population(self):\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        return position, velocity\n\n    def evaluate_fitness(self, func, position):\n        fitness = np.array([func(p) for p in position])\n        self.fitness_evaluations += len(position)\n        return fitness\n\n    def update_velocity(self, velocity, position, personal_best, global_best):\n        r1 = np.random.rand(self.num_particles, self.dim)\n        r2 = np.random.rand(self.num_particles, self.dim)\n        self.inertia_weight = 0.9 - (0.6 * (self.fitness_evaluations / self.budget))\n        self.cognitive_coef = 1.0 + (1.0 * (self.fitness_evaluations / self.budget))  # Altered\n        self.social_coef = 2.0 + (1.0 * (self.fitness_evaluations / self.budget))\n        cognitive_velocity = self.cognitive_coef * r1 * (personal_best - position)\n        social_velocity = self.social_coef * r2 * (global_best - position)\n        new_velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n        return new_velocity\n\n    def differential_evolution(self, position, fitness, func):\n        for i in range(self.num_particles):\n            if self.fitness_evaluations >= self.budget:\n                break\n            candidates = [n for n in range(self.num_particles) if n != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            self.mutation_factor = 0.8 + 0.3 * (self.fitness_evaluations / self.budget)\n            mutant_vector = position[a] + self.mutation_factor * (position[b] - position[c])\n            mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n            trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, position[i])\n            trial_fitness = func(trial_vector)\n            self.fitness_evaluations += 1\n            if trial_fitness < fitness[i]:\n                position[i] = trial_vector\n                fitness[i] = trial_fitness\n        return position, fitness\n\n    def update_global_best(self, fitness, personal_best_fitness, personal_best):\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        return global_best\n\n    def __call__(self, func):\n        position, velocity = self.initialize_population()\n        fitness = self.evaluate_fitness(func, position)\n        personal_best = position.copy()\n        personal_best_fitness = fitness.copy()\n        global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n        while self.fitness_evaluations < self.budget:\n            velocity = self.update_velocity(velocity, position, personal_best, global_best)\n            position = position + velocity\n            position = np.clip(position, self.lower_bound, self.upper_bound)\n            fitness = self.evaluate_fitness(func, position)\n\n            update_indices = fitness < personal_best_fitness\n            personal_best[update_indices] = position[update_indices]\n            personal_best_fitness[update_indices] = fitness[update_indices]\n\n            global_best = self.update_global_best(fitness, personal_best_fitness, personal_best)\n\n            position, fitness = self.differential_evolution(position, fitness, func)\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["5ed844e2-9f8c-4f28-9c08-3851ca7aee78"], "operator": null, "metadata": {"aucs": [0.008044587415822146, 0.009963870464454239, 0.014085685442791429, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.16532784398251155, 0.024656456004351957, 0.04632160429706622, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.045134678851690424, 0.06594454897334245, 0.04596252133605527, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.04966035643408084, 0.05375777033605689, 0.04973373898547817, 0.08604127391875582, 0.10439287433165234, 0.08816014991845567, 0.046989994858463224, 0.04686347722648687, 0.04187301869793514, 0.08055018614483422, 0.07944986865148995, 0.0822301879495414, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187, 0.016931960852339167, 0.014998507597758559, 0.01620268908317224, 0.01653639868696999, 0.012454679801182866, 0.013476494920793614, 0.1383492639330799, 0.13574177828609502, 0.13205891538728975, 0.00043478260869567187, 0.00043478260869567187, 0.00043478260869567187]}}
