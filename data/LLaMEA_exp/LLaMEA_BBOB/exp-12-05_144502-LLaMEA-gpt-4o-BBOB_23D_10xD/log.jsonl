{"id": "5e7634ff-8498-488a-a31e-14007dcd630a", "fitness": 0.022682108542817617, "name": "HQIPSO", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization (HQIPSO) combines quantum-inspired movement with classical PSO for enhanced exploration and exploitation in high-dimensional spaces.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.9  # Quantum-inspired parameter\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004811191135968285, 0.008280591493104117, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.11782993512102757, 0.017422559053165254, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04853744831815543, 0.050149851338724294, 0.033213622199882, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049045878083531225, 0.043881582406360975, 0.04781797224610118, 0.0791799210898102, 0.08753475145393774, 0.08833131277774509, 0.022029720697211097, 0.024576870112594684, 0.027760240141961545, 0.06741006444719888, 0.07039267343260991, 0.07557098172519883, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016540427655395207, 0.019089176435393318, 0.019681239881457757, 0.01614777777659504, 0.01446420099752499, 0.0144432407994316, 0.12800810916096983, 0.12795706489843317, 0.12169906237729344, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "392f1cbe-a02a-4cec-8693-bd7db58849ce", "fitness": 0.02260566362580551, "name": "HQIPSO", "description": "Slightly adjusted the cognitive coefficient in HQIPSO to fine-tune exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.6  # Cognitive coefficient adjustment\n        c2 = 1.5  # Social coefficient\n        beta = 0.9  # Quantum-inspired parameter\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5e7634ff-8498-488a-a31e-14007dcd630a"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.013638542914328755, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.08790514824913165, 0.04083244506700989, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04655610679137778, 0.05027901523004419, 0.03479381906586043, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049111860239971716, 0.03799878641547905, 0.042696365111914214, 0.08404828993790814, 0.08615102134209662, 0.0886893851936944, 0.024378237203409592, 0.02661139734396567, 0.024914848602290873, 0.07243157522698696, 0.065598387701162, 0.07498552906239919, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016837001444079736, 0.019159479553869208, 0.019424567311129626, 0.014952153905313903, 0.014619325045048592, 0.014169727259725096, 0.12299430322527993, 0.13151100658603743, 0.12666728211543965, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5", "fitness": 0.0251006912643198, "name": "HQIPSO", "description": "Minor refinement of HQIPSO by adjusting quantum-inspired parameter for improved convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["5e7634ff-8498-488a-a31e-14007dcd630a"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.006967436448947151, 0.017654025375425264, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048565182723522504, 0.22024666137792126, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05072355509924864, 0.05005471887542001, 0.03235122468926932, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04894337491497658, 0.039192540728007375, 0.0441871001834897, 0.08846648891224218, 0.0837749940219934, 0.0819611739272541, 0.02875443802537858, 0.024155067689459297, 0.032202885288023286, 0.06615842880430811, 0.062395762134888066, 0.08825241122647742, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01746287448627326, 0.024581038639846398, 0.020757975514643645, 0.017407979810150853, 0.015724435841197426, 0.013706114877366393, 0.13035833954825404, 0.13276813025211265, 0.1281710637888428, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "9c45d951-867e-493e-b0fa-2a62e32fce84", "fitness": 0.0210401400124306, "name": "HQIPSO", "description": "Improve convergence by tuning the inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                w = 0.9 - (0.5 * self.evaluations / self.budget)  # Dynamically adjust inertia weight\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004377971023516336, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.030052525243946637, 0.017323654231587993, 0.006791585204450112, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04154569810000974, 0.04886196777741514, 0.03724300347628373, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.046243395810303234, 0.04814235801150457, 0.04045378914043618, 0.08127308587479676, 0.08272026186914505, 0.09210117946440388, 0.01620424533269782, 0.01898234689537881, 0.02398558848426391, 0.07945673318621127, 0.06519770256494983, 0.05943794346575226, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016196971671922245, 0.015194715621592136, 0.017951386539202363, 0.013100246194081677, 0.01438406388205804, 0.014781967296587872, 0.13867935377054486, 0.12660563080865883, 0.12629636212721607, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "5f5878e8-4746-4d4c-8fc5-3f397c069e6b", "fitness": 0.023239348601258994, "name": "HQIPSO", "description": "Minor refinement of HQIPSO by tweaking the cognitive coefficient for better personal exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.6  # Cognitive coefficient (adjusted)\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004459441497971617, 0.01144935368319766, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04650646717212292, 0.10901635757020667, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04774923097629924, 0.05031491536887667, 0.03518001462790754, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049111860239971716, 0.03864131275346283, 0.038949871040790285, 0.08733511005908912, 0.08613025809817731, 0.08296620035722713, 0.024019264737594415, 0.023016026339519602, 0.030809854332692455, 0.06794225787514041, 0.06277265099381801, 0.08213320919618095, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01747116618551625, 0.023628255250871977, 0.020217300790746795, 0.015697702734883023, 0.01572059169627915, 0.014685036285372433, 0.12717536530304474, 0.13170661159317087, 0.1371230647044298, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c9273567-bdf6-46c2-9e08-3ed78ab9a9a5", "fitness": 0.0210401400124306, "name": "HQIPSO", "description": "Further refine HQIPSO by introducing adaptive inertia weight for enhanced exploratory-exploitative balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w_max = 0.9  # Max inertia weight\n        w_min = 0.4  # Min inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                # Adaptive inertia weight\n                w = w_max - ((w_max - w_min) * (self.evaluations / self.budget))\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004377971023516336, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.030052525243946637, 0.017323654231587993, 0.006791585204450112, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04154569810000974, 0.04886196777741514, 0.03724300347628373, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.046243395810303234, 0.04814235801150457, 0.04045378914043618, 0.08127308587479676, 0.08272026186914505, 0.09210117946440388, 0.01620424533269782, 0.01898234689537881, 0.02398558848426391, 0.07945673318621127, 0.06519770256494983, 0.05943794346575226, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016196971671922245, 0.015194715621592136, 0.017951386539202363, 0.013100246194081677, 0.01438406388205804, 0.014781967296587872, 0.13867935377054486, 0.12660563080865883, 0.12629636212721607, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "3bb7f05e-4a37-482b-974f-7c5bdeb20d1c", "fitness": 0.021069677512232102, "name": "HQIPSO", "description": "Adjusted inertia weight for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.6  # Inertia weight (adjusted)\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.006106367609848284, 0.009229902383353306, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.020427174880177645, 0.01909290681672282, 0.020054755113910194, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.038406458975056235, 0.047101722200365126, 0.03408413562076518, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04938880605238394, 0.03894347180123314, 0.04129830310694427, 0.0828075865504061, 0.08903727063208877, 0.07904135919355593, 0.01930548921247377, 0.023012960854347675, 0.03070799007858349, 0.0765987869580661, 0.06726541954978071, 0.07849463649725708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.017271883490656892, 0.01634899130891143, 0.01751923417872059, 0.014237085381648362, 0.015871814058843414, 0.012590982287134178, 0.12113154141718707, 0.12647660398991678, 0.11820661894124351, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "f4031c15-63a1-4fd0-ab2a-f43edb202ab8", "fitness": 0.020171564318093766, "name": "HQIPSO", "description": "Improved HQIPSO by dynamically updating the inertia weight to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.9  # Inertia weight (changed from 0.5 to 0.9 for dynamic adaptation)\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02422638768618779, 0.004347826086956497, 0.01788347337783769, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.027615787299821726, 0.041607138310172376, 0.0319051719187563, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04355425894114151, 0.04710975321029731, 0.044637413474714394, 0.07840822231798317, 0.08603481137282876, 0.08146357113274516, 0.02333840966405265, 0.017376349914160594, 0.023174916917885313, 0.07069614390971823, 0.06347975488004876, 0.05523439285330145, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016018765753387454, 0.014705630652988688, 0.016842482428040095, 0.012369905722695584, 0.013310029795064793, 0.011687949968461231, 0.12461607460754254, 0.12865862950248763, 0.1363972052904311, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "7116a96c-df96-453b-a9c2-4b5d932a534c", "fitness": 0.02102842043292001, "name": "HQIPSO", "description": "Introduce a dynamic adjustment for the inertia weight `w` to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.005731291589959442, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.029481221805752522, 0.016941267872147114, 0.017695277979645097, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.039413706930414016, 0.04631497358455461, 0.033502536732440746, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05372451436211889, 0.04931154657921888, 0.040765352558944534, 0.07955897359079989, 0.08567628481485556, 0.08791233064314541, 0.01965033048327569, 0.01834082602802456, 0.018812884257423446, 0.07584946617328192, 0.08148131645032408, 0.05602842789323814, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01565279831931654, 0.014407032058651348, 0.01656353201843974, 0.012408332164123625, 0.014344244263328365, 0.014209263923546933, 0.12088884778380271, 0.12926273748105854, 0.12881260500232283, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "42027b66-51b2-4975-87ce-c455093459b0", "fitness": 0.021269659540235644, "name": "HQIPSO", "description": "Minor refinement of HQIPSO by adjusting the inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.7  # Inertia weight (adjusted)\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.005505920991658919, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.032592335011486506, 0.02122395180614911, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.0340121735695571, 0.0474189970800285, 0.04049486985895878, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048154971778293754, 0.04636606425466694, 0.04485875715231091, 0.07943547758597458, 0.08278965244482372, 0.08023694518813795, 0.02094200369030874, 0.019422307386474325, 0.03193585395167908, 0.08045667797470168, 0.06755818895592014, 0.07042780663886328, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016706474432443885, 0.020086393225547616, 0.01709912538998415, 0.013969187013135986, 0.01322009132917723, 0.012607487254945426, 0.14051086104399058, 0.12387590897888923, 0.1238548289958159, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "65018c80-ab45-4225-a029-caa28574161e", "fitness": 0.02102842043292001, "name": "HQIPSO", "description": "Refine HQIPSO by modifying inertia weight dynamically for better exploration and exploitation balance. ", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            w = 0.9 - (0.9 - 0.4) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.005731291589959442, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.029481221805752522, 0.016941267872147114, 0.017695277979645097, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.039413706930414016, 0.04631497358455461, 0.033502536732440746, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05372451436211889, 0.04931154657921888, 0.040765352558944534, 0.07955897359079989, 0.08567628481485556, 0.08791233064314541, 0.01965033048327569, 0.01834082602802456, 0.018812884257423446, 0.07584946617328192, 0.08148131645032408, 0.05602842789323814, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01565279831931654, 0.014407032058651348, 0.01656353201843974, 0.012408332164123625, 0.014344244263328365, 0.014209263923546933, 0.12088884778380271, 0.12926273748105854, 0.12881260500232283, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "aae5f38e-9831-4634-b1fc-c5133d21c56c", "fitness": 0.021069677512232102, "name": "HQIPSO", "description": "Enhanced HQIPSO by tuning the inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.6  # Inertia weight (adjusted for improved balance)\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.006106367609848284, 0.009229902383353306, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.020427174880177645, 0.01909290681672282, 0.020054755113910194, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.038406458975056235, 0.047101722200365126, 0.03408413562076518, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04938880605238394, 0.03894347180123314, 0.04129830310694427, 0.0828075865504061, 0.08903727063208877, 0.07904135919355593, 0.01930548921247377, 0.023012960854347675, 0.03070799007858349, 0.0765987869580661, 0.06726541954978071, 0.07849463649725708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.017271883490656892, 0.01634899130891143, 0.01751923417872059, 0.014237085381648362, 0.015871814058843414, 0.012590982287134178, 0.12113154141718707, 0.12647660398991678, 0.11820661894124351, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "e6d9e646-7c9e-413c-84df-4864aae6d912", "fitness": 0.021969614155554713, "name": "HQIPSO", "description": "Improve global exploration by introducing velocity scaling to enhance convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += 1.2 * self.velocities[i]  # Velocity scaling factor introduced\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.13288461303626053, 0.008389750198234736, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04437724569215684, 0.04224111754048332, 0.02788225872590644, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047840183062650365, 0.04009089724093384, 0.045395091575034185, 0.08452475247693725, 0.08128073131370361, 0.07903167092179764, 0.01894750033744097, 0.022038694590220453, 0.026551506062132857, 0.07192962410426396, 0.06562988775246437, 0.06789517447894655, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01680665925820468, 0.017210121155326163, 0.015237315629971326, 0.013504394307020218, 0.015272183333493894, 0.013681634778236917, 0.12903180771919154, 0.13240997227855322, 0.12172743163037458, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "7e6206ca-4b99-40b4-af8d-ed3e91d33bd6", "fitness": 0.023824962242923728, "name": "HQIPSO", "description": "Enhanced diversity by adjusting velocity initialization range.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Adjusted velocity range\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        beta = 0.8  # Quantum-inspired parameter (adjusted)\n\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.005437022871226382, 0.010616604300113575, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05192323895911266, 0.15340000335371362, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04681815326422123, 0.05070727094487393, 0.0382503433753526, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04950188389990884, 0.04424071070277624, 0.04502089499269524, 0.08009624082096978, 0.08691833342781041, 0.08616279198410748, 0.02202070434671133, 0.022362756094054026, 0.029598416510531855, 0.06797629010042738, 0.06473315484806241, 0.08000478758448781, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.017995841413898983, 0.020637556555126668, 0.01889449651694608, 0.015354228336911246, 0.015076510503521656, 0.015541279282329956, 0.12654717119997005, 0.12700966864761898, 0.13124657882694213, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff", "fitness": 0.026252475854490143, "name": "HQIPSO", "description": "Introduce adaptive beta for quantum-inspired parameter to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["f4e8239f-d36d-42bc-a25b-4fab0ac5e5c5"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.005546239616018522, 0.005502771242997251, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.35512300039300715, 0.01708127646224855, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048600811525381094, 0.05083787634873893, 0.02934502662494487, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05055288081268128, 0.04264498555633878, 0.043985070707709295, 0.0823696791195353, 0.08550892072444694, 0.08660735466731673, 0.03770167844247685, 0.02400947240454754, 0.02914282562910686, 0.06799805593155861, 0.06627752977869006, 0.07349970358636793, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016054953489557544, 0.017728164850865702, 0.016110212056748785, 0.013018992959084041, 0.015086561057743975, 0.014202437905803444, 0.14876235333158605, 0.12101173860573489, 0.13456333986596747, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "9d54f26e-63e7-44c9-abf8-9f131db839b7", "fitness": 0.020745183981693744, "name": "HQIPSO", "description": "Introduce adaptive inertia weight to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Initial inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n\n            # Adaptive inertia weight\n            w = 0.9 - 0.5 * (self.evaluations / self.budget)\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004563297970193836, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03172015595494837, 0.01897592636365708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03692384974411289, 0.04606115305813985, 0.0336889698551357, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04697307026627662, 0.04100891685134811, 0.04228273034470742, 0.0836899595557965, 0.08833302682291311, 0.08465574953411592, 0.020685148328375313, 0.02453531887682525, 0.024558540990920252, 0.07788416565000833, 0.07584221843500749, 0.05745585957565025, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015884960132580228, 0.014991823475609456, 0.018033992487903827, 0.01249285610545292, 0.014494875549478592, 0.012720026427918252, 0.12595696531047795, 0.12115069801079947, 0.1224368170905542, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c8891174-fd0c-4df8-a6b9-c6cf78f947f9", "fitness": 0.020745183981693744, "name": "HQIPSO", "description": "Enhance convergence by modifying the inertia weight to dynamically adapt based on evaluations.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w_initial = 0.9  # Initial inertia weight\n        w_final = 0.4    # Final inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = w_initial - ((w_initial - w_final) * (self.evaluations / self.budget))  # Adaptive inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004563297970193836, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03172015595494837, 0.01897592636365708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03692384974411289, 0.04606115305813985, 0.0336889698551357, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04697307026627662, 0.04100891685134811, 0.04228273034470742, 0.0836899595557965, 0.08833302682291311, 0.08465574953411592, 0.020685148328375313, 0.02453531887682525, 0.024558540990920252, 0.07788416565000833, 0.07584221843500749, 0.05745585957565025, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015884960132580228, 0.014991823475609456, 0.018033992487903827, 0.01249285610545292, 0.014494875549478592, 0.012720026427918252, 0.12595696531047795, 0.12115069801079947, 0.1224368170905542, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "0b78d337-8259-4509-9c49-6a6b61883e16", "fitness": 0.026252475854490143, "name": "HQIPSO", "description": "Enhance exploration by introducing a dynamic social coefficient to adaptively balance local and global searches.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5 + 0.5 * np.sin(2 * np.pi * self.evaluations / self.budget)  # Dynamic social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.005546239616018522, 0.005502771242997251, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.35512300039300715, 0.01708127646224855, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048600811525381094, 0.05083787634873893, 0.02934502662494487, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05055288081268128, 0.04264498555633878, 0.043985070707709295, 0.0823696791195353, 0.08550892072444694, 0.08660735466731673, 0.03770167844247685, 0.02400947240454754, 0.02914282562910686, 0.06799805593155861, 0.06627752977869006, 0.07349970358636793, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016054953489557544, 0.017728164850865702, 0.016110212056748785, 0.013018992959084041, 0.015086561057743975, 0.014202437905803444, 0.14876235333158605, 0.12101173860573489, 0.13456333986596747, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "a6cc1574-f239-4435-8a0c-4e6fc2d5f976", "fitness": 0.02407215428711895, "name": "HQIPSO", "description": "Enhance convergence by introducing velocity clamping to prevent erratic movements.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += np.clip(self.velocities[i], -1.0, 1.0)  # Clamping velocities\n\n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.018711663235856824, 0.024713658101973013, 0.013934766963328515, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.051246459836723046, 0.05644277845995782, 0.045341497527992436, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049426364984536786, 0.0392821545813411, 0.045221669286352295, 0.09280979670320444, 0.0998669690397892, 0.09221680873560612, 0.03602680314833673, 0.037754273095152, 0.041802290671743014, 0.09868412704131668, 0.08894573711631559, 0.09647246916732322, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016991925672140695, 0.020303537320470744, 0.017493238897790198, 0.019561530295180596, 0.017739624555844324, 0.01847773836109945, 0.1278027988545668, 0.1283531126523887, 0.14191914045319165, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "b0ac1c6f-a257-4b8e-b796-660a21ea6221", "fitness": 0.025324145725228748, "name": "HQIPSO", "description": "Enhance the cognitive coefficient dynamically based on the evaluation progress to improve early exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamically enhanced cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.00624786348128803, 0.004450477772752981, 0.008949002542701257, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.29808787773860956, 0.041502361543559574, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03917222187159908, 0.047503730179320525, 0.03415639652418878, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04636853701703636, 0.04196917613125939, 0.04308638829342426, 0.08727802550978081, 0.08593967287382775, 0.08745939256954849, 0.026645746994380493, 0.024883729024469003, 0.02698860845172113, 0.07301266786345761, 0.061001013567640205, 0.06658905298761508, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014993446190403992, 0.015853677991306436, 0.015971586081849787, 0.012476247117819361, 0.015439238879258133, 0.012547414842074667, 0.131409276238042, 0.13183580033243825, 0.13456333986596747, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "d9bd22b3-fee7-46c2-b2b4-3a790b6f6ddf", "fitness": 0.02228753117939179, "name": "HQIPSO", "description": "Enhance global exploration by integrating stochastic perturbation in position updates.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i] + np.random.normal(0, 0.1, self.dim)  # Stochastic perturbation\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.009778388413229866, 0.004840400445569215, 0.007144724006257541, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05477299408308012, 0.01317390028157217, 0.011290143644726358, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04400103487532969, 0.046379172309630734, 0.03142755304643552, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05038060608532313, 0.04004490337405919, 0.050265079246180844, 0.08804544640799628, 0.09398112851811369, 0.08375160293547323, 0.025889386130118264, 0.036826067125402706, 0.025992700493067455, 0.07626180612636502, 0.06885903187717657, 0.06865957027394753, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.019046839533774063, 0.014707547439086421, 0.017619389609954017, 0.012673331655825182, 0.018701566176212436, 0.014781621944448098, 0.13749560842423103, 0.13610452865140388, 0.1191974761300455, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "4da2be71-0d5e-402c-b968-aec685cb607b", "fitness": 0.020116260416565, "name": "HQIPSO", "description": "Introduce stochastic acceleration and scaled inertia to balance exploration and exploitation in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.7 + 0.3 * np.random.rand()  # Scaled inertia weight\n        c1 = 1.5 + 0.5 * np.random.rand()  # Stochastic cognitive coefficient\n        c2 = 1.5 + 0.5 * np.random.rand()  # Stochastic social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.029159872913701257, 0.035890931789662184, 0.010211018189829946, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02912653643085017, 0.04879800051047922, 0.022104932824268064, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.044645323924289326, 0.039751335466347015, 0.038473103507583706, 0.07816676214676177, 0.07953030363086666, 0.07867639577881314, 0.0226538398204168, 0.01812321925184246, 0.021518053497129208, 0.06717017551751059, 0.0698769656559105, 0.061090756767001486, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015047538865481935, 0.017390031489662117, 0.014534808288813927, 0.012002588197517428, 0.012570293318588943, 0.012860420322976185, 0.13252572452758238, 0.12471231067331556, 0.11610733277243568, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c5d72058-bec7-4ded-9f67-9c66e5ca73b6", "fitness": 0.020525052886355668, "name": "HQIPSO", "description": "Introduce adaptive fine-tuning to inertia weight for maintaining exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.5 + 0.4 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.031463810965469685, 0.019288347929662164, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.037105471582956295, 0.04291837227031814, 0.03055669629918545, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04732995582092259, 0.03964173063870535, 0.043376239804313266, 0.08299560858455235, 0.0871472326160847, 0.0850339086188181, 0.021270276879552408, 0.024112021216574298, 0.02985929967695078, 0.07204460245202537, 0.06086868609029861, 0.055956256180587194, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01746785543313467, 0.014688580848380539, 0.01770013693650252, 0.012532951250428526, 0.014243865006887346, 0.012428885873307816, 0.1300804610467673, 0.12208243691191012, 0.1256101168833138, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "d4826a89-b9bc-4001-83a1-4f3c9e7b843e", "fitness": 0.020745183981693744, "name": "HQIPSO", "description": "Introduce adaptive inertia weight to balance exploration and exploitation in the search process.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w_initial = 0.9  # Initial inertia weight\n        w_final = 0.4  # Final inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = w_final + (w_initial - w_final) * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004563297970193836, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03172015595494837, 0.01897592636365708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03692384974411289, 0.04606115305813985, 0.0336889698551357, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04697307026627662, 0.04100891685134811, 0.04228273034470742, 0.0836899595557965, 0.08833302682291311, 0.08465574953411592, 0.020685148328375313, 0.02453531887682525, 0.024558540990920252, 0.07788416565000833, 0.07584221843500749, 0.05745585957565025, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015884960132580228, 0.014991823475609456, 0.018033992487903827, 0.01249285610545292, 0.014494875549478592, 0.012720026427918252, 0.12595696531047795, 0.12115069801079947, 0.1224368170905542, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "f243f26d-91e6-47d9-ba4f-27f8e09b03ed", "fitness": 0.020307000281761425, "name": "HQIPSO", "description": "Adjusted the inertia weight for better exploration and exploitation balance.  ", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.5 + 0.4 * (1 - self.evaluations / self.budget)  # Adjusted inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.035995584067145536, 0.01970988725509515, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.029347393264591792, 0.041607138310172376, 0.03327208772185386, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.0460265942475232, 0.03708317210390577, 0.043389212512783715, 0.0794005084879218, 0.08115182024327217, 0.08189346524765762, 0.018579597506113044, 0.026343566801108942, 0.02667074981131834, 0.07879252594253727, 0.06347975488004876, 0.05544189765065022, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01578708589712774, 0.01542721979658046, 0.017760167374961666, 0.012532726396776939, 0.01303291286098529, 0.011625878964705239, 0.12702433700536042, 0.12725187595157783, 0.12347685998504865, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "6de2e982-ff38-403b-906c-7db253a0d694", "fitness": 0.026685570140150924, "name": "HQIPSO", "description": "Increase the inertia weight `w` to 0.6 to potentially improve exploratory capabilities.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b6a745ac-8953-4c16-a2a6-a8d1c0bf37ff"], "operator": null, "metadata": {"aucs": [0.0047798870757600476, 0.004347826086956497, 0.0072423137858134146, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4160855195384161, 0.018156931166547263, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047082174279208466, 0.04761039424361657, 0.036565332134124384, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04938880605238394, 0.04312310554609944, 0.04863004046723507, 0.08199562879785682, 0.08992234566100732, 0.08541812062407483, 0.02841210956500939, 0.024414276249994704, 0.023882822954085392, 0.06722106739555234, 0.06403018195759524, 0.07279046818859214, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016297631369691423, 0.015382314030549682, 0.01634069587067022, 0.012663715049646251, 0.013956087262964045, 0.014548937543888862, 0.11858234980942861, 0.1306627400982332, 0.13487070554673586, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "b2b7902b-1304-452a-958c-ba7e4a2fa8a4", "fitness": 0.021648633496765154, "name": "HQIPSO", "description": "Introduce dynamic adjustment of cognitive coefficient `c1` to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        w = 0.6  # Inertia weight\n        c1 = 1.5 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamic cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["6de2e982-ff38-403b-906c-7db253a0d694"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.005763874619229337, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053172798735164784, 0.04885739466649275, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04548512616750455, 0.044308926867292264, 0.035759244891605535, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048243476777288685, 0.04372291025602393, 0.04681022392309098, 0.07864041584496062, 0.0813858896308769, 0.08500383442224457, 0.021151570125262142, 0.021722175274058064, 0.025801998712713603, 0.07396955170633368, 0.06637605720838591, 0.0657169926472978, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015554321313948072, 0.015823253209595323, 0.015108938556287366, 0.01328078926354792, 0.015111105423112225, 0.012965844385950276, 0.12171559198822601, 0.12675145392189158, 0.13484567731566388, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "7f04f429-de82-473d-9618-f8cb26237b47", "fitness": 0.026973134626469483, "name": "HQIPSO", "description": "Replace the static inertia weight with an adaptive one to enhance performance across different stages of optimization.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["6de2e982-ff38-403b-906c-7db253a0d694"], "operator": null, "metadata": {"aucs": [0.004593212933118096, 0.004905641668295657, 0.006054220203799421, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42365624189706663, 0.018164937873846543, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.044887429578544524, 0.04816451320388704, 0.03681644889642299, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049087571849760314, 0.045591198005575984, 0.05090666615796369, 0.08307378965252987, 0.0843909846268811, 0.08500383442224457, 0.02985216347936248, 0.02859316510074772, 0.02542623117927667, 0.06792957634846253, 0.0656152939247, 0.07619972267728115, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016557585801005748, 0.01611604233038233, 0.017931514196298015, 0.01260877816247219, 0.015559483633763138, 0.01377613608695949, 0.1333625193023199, 0.12765701013286201, 0.12262725804084362, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "1e33ee72-12ae-4e1e-8e20-363eb4808cd8", "fitness": 0.026549975331685936, "name": "HQIPSO", "description": "Introduce a dynamic adjustment to the cognitive coefficient for improved adaptability in the optimization process.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 1.5 + 0.5 * (self.evaluations / self.budget)  # Dynamic cognitive coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["7f04f429-de82-473d-9618-f8cb26237b47"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.005037427203256284, 0.00491066856917044, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4234215562460314, 0.018180444004207263, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04396197358077958, 0.0511912996413072, 0.033138287790418275, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05085139907315517, 0.0427614620584893, 0.049397301352105405, 0.07845755958138412, 0.08152543133296397, 0.08740992851623497, 0.02893867946755646, 0.024372293244087184, 0.02755632152626064, 0.06902762354559466, 0.05956366558865411, 0.07202731553280772, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01594202316341098, 0.015523895445431757, 0.01737921094682393, 0.01295622476063707, 0.013730747236866847, 0.013973224107118654, 0.12077589908860176, 0.1318361124777634, 0.12644590097418318, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "af39efe1-ca6b-49ca-ba40-569e2c11f0b8", "fitness": 0.02365147798834349, "name": "HQIPSO", "description": "Introduce a decay factor into the cognitive coefficient to balance exploration and exploitation over time.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1_decay = c1 * (1 - self.evaluations / self.budget)  # Introduce decay for c1\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1_decay * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["7f04f429-de82-473d-9618-f8cb26237b47"], "operator": null, "metadata": {"aucs": [0.007404481664683327, 0.004347826086956497, 0.007121729702163182, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.1865380159330241, 0.01737636979567092, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03715048315710001, 0.054108637141188964, 0.04046254251808923, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049886813125261775, 0.042067962728619346, 0.04179667397286446, 0.07727131504542861, 0.09632353813115291, 0.08923401425525668, 0.025582388863741645, 0.027602478043540546, 0.025649823207574696, 0.07812061779913915, 0.07189226834263163, 0.07230123571078584, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015990770366867912, 0.015503950418755075, 0.016511799543698302, 0.012715578620928647, 0.01477372151791434, 0.013875024736052621, 0.12500923394562602, 0.12678303007348657, 0.12254756897339902, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "3323c23e-88f9-4e81-b96e-9ff883a07077", "fitness": 0.026780986680781025, "name": "HQIPSO", "description": "Introduce a dynamic social coefficient to balance exploration and exploitation better as the search progresses.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        # c2 = 1.5  # Social coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 1.5 + 0.5 * (self.evaluations / self.budget)  # Dynamic social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["7f04f429-de82-473d-9618-f8cb26237b47"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.005873022452445142, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.43097957162414624, 0.018481182790631934, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04050197821793189, 0.046941961984545366, 0.04314165775816148, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049087571849760314, 0.045364098990965496, 0.050095515384542155, 0.07831363632149169, 0.0827738692472818, 0.08730270799374251, 0.02336510028253902, 0.03033120871902517, 0.023295288509386114, 0.06914563482104996, 0.06515331946465963, 0.07599585311520463, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01605433997909289, 0.018339540857637227, 0.016049733100057084, 0.012591905211811527, 0.01323161856201116, 0.012088865259579418, 0.1297283294841879, 0.1248204156104652, 0.12353093951083849, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1", "fitness": 0.027303207645784016, "name": "HQIPSO", "description": "Introduce adaptive social coefficient to improve the convergence speed.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["7f04f429-de82-473d-9618-f8cb26237b47"], "operator": null, "metadata": {"aucs": [0.004448957118238339, 0.009704089614389177, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42264995500045965, 0.023303806463192522, 0.03459739599780265, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.043137985020741065, 0.047264973462596505, 0.03011369101878536, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05286944093305668, 0.04941375476869714, 0.05217597672128582, 0.08218547946889787, 0.08274786440865967, 0.08277745714194007, 0.02862097503572114, 0.02361187557757305, 0.02260041669159396, 0.07791850599121941, 0.06966295389585975, 0.06334329996728083, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015720334074239783, 0.017522915598449096, 0.018527743835420996, 0.0136816638676166, 0.01491293846192987, 0.013899656797727533, 0.12691109982562376, 0.1262442102559005, 0.12830501174242104, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "0772fab7-df3d-4254-bb73-d6121b81b712", "fitness": 0.021779258385512548, "name": "HQIPSO", "description": "Introduce a dynamic cognitive coefficient to adapt exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 0.5 + 2.0 * (1 - self.evaluations / self.budget)  # Dynamic cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.006393492491635455, 0.008425675108902797, 0.007597838411067204, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05045505341907308, 0.010954941545559538, 0.033193054880028994, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04285281056191059, 0.0505479970654682, 0.030382347003608423, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045372892153013655, 0.05154490437968018, 0.05208692168660456, 0.08755571433916798, 0.08219448725158163, 0.080924075138474, 0.026008802093924643, 0.021718280081991836, 0.029431370504259813, 0.07308714900751068, 0.0697181426935205, 0.0650170229157574, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015924195484899872, 0.016607857747528487, 0.019567099692850642, 0.015365769562827647, 0.01334028861942993, 0.013785131088117408, 0.11920346876280719, 0.11922072148234708, 0.1270204029311811, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "752595a4-4991-4e82-996f-a8ab70492252", "fitness": 0.021779258385512548, "name": "HQIPSO", "description": "Introduce adaptive cognitive coefficient to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 0.5 + 2.0 * (1 - self.evaluations / self.budget)  # Adaptive cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.006393492491635455, 0.008425675108902797, 0.007597838411067204, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05045505341907308, 0.010954941545559538, 0.033193054880028994, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04285281056191059, 0.0505479970654682, 0.030382347003608423, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045372892153013655, 0.05154490437968018, 0.05208692168660456, 0.08755571433916798, 0.08219448725158163, 0.080924075138474, 0.026008802093924643, 0.021718280081991836, 0.029431370504259813, 0.07308714900751068, 0.0697181426935205, 0.0650170229157574, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015924195484899872, 0.016607857747528487, 0.019567099692850642, 0.015365769562827647, 0.01334028861942993, 0.013785131088117408, 0.11920346876280719, 0.11922072148234708, 0.1270204029311811, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "e0ef2942-a715-4798-8e63-dc660fe19695", "fitness": 0.02158175520959125, "name": "HQIPSO", "description": "Introduce an adaptive cognitive coefficient to enhance the exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.005437086237035538, 0.004347826086956497, 0.004670947300452921, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02092286562113166, 0.020783043479353447, 0.03207067780449091, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03961442287958361, 0.049400561176150215, 0.03105581343231012, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049306323831643684, 0.045467665464290596, 0.05208692168660456, 0.07929627179976995, 0.08287656121541076, 0.0850470228281619, 0.02626474320281391, 0.02488117852780536, 0.028597122311528334, 0.07362649052346293, 0.06569404920136745, 0.06727433012524497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014825956706823185, 0.016541665670120942, 0.017867426935387343, 0.012125585298417563, 0.014858768232672404, 0.012562479707898144, 0.12192246836936138, 0.13219383940416451, 0.13965756437798227, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "3aed3899-f545-4956-86e1-11bfc5db3398", "fitness": 0.02647390802764207, "name": "HQIPSO", "description": "Fine-tune the adaptive social coefficient's range to enhance convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.7 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.009532707819967068, 0.004347826086956497, 0.006879461145258947, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.35495342812665975, 0.017234892622900344, 0.046370756936245594, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04498543877870198, 0.049455603613396626, 0.030346693721325924, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049087571849760314, 0.047472370668049435, 0.044838961929385523, 0.0828302215397666, 0.08697136475706291, 0.08010481128460656, 0.02526346996639839, 0.022540313158180614, 0.025971223432459056, 0.08059980627439434, 0.06883348209805873, 0.0637730203802076, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01497260750853302, 0.0179483019608061, 0.018299382980460632, 0.012418343949918809, 0.016005517891336085, 0.014187821008596058, 0.12671670432470772, 0.1331164329978508, 0.12745414352610407, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "bebb19dc-4ae3-42cf-89e3-e8f7f7a53190", "fitness": 0.026974032867412765, "name": "HQIPSO", "description": "Introduce an adaptive cognitive coefficient for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 1.5 + 0.5 * (1 - self.evaluations / self.budget)  # Adaptive cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.00518941986902377, 0.004974754255942515, 0.004435775374679318, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4209060721986716, 0.009860493864925601, 0.034502264307556985, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04494407976874282, 0.05149024053999518, 0.036467809868972245, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048477801812095156, 0.04768988246344763, 0.05208692168660456, 0.07799329709763347, 0.08182315949635, 0.08665167256243911, 0.02726702978865858, 0.02581398530664325, 0.02633517793857798, 0.07382177948222135, 0.06627909121446562, 0.05903877751108333, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01507344431405433, 0.015118424409025666, 0.01883525062868019, 0.015609889367667162, 0.013098689504267624, 0.014415140734862386, 0.12623455543250672, 0.12833031523621852, 0.12675647476553353, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "df201de2-d247-485f-8dd5-8b51509141f2", "fitness": 0.027303207645784016, "name": "HQIPSO", "description": "Incorporate an adaptive quantum-inspired coefficient to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.004448957118238339, 0.009704089614389177, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42264995500045965, 0.023303806463192522, 0.03459739599780265, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.043137985020741065, 0.047264973462596505, 0.03011369101878536, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05286944093305668, 0.04941375476869714, 0.05217597672128582, 0.08218547946889787, 0.08274786440865967, 0.08277745714194007, 0.02862097503572114, 0.02361187557757305, 0.02260041669159396, 0.07791850599121941, 0.06966295389585975, 0.06334329996728083, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015720334074239783, 0.017522915598449096, 0.018527743835420996, 0.0136816638676166, 0.01491293846192987, 0.013899656797727533, 0.12691109982562376, 0.1262442102559005, 0.12830501174242104, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "ab9a48d3-9330-499e-b9c6-4740637f1e39", "fitness": 0.020373937567594324, "name": "HQIPSO", "description": "Refine HQIPSO by replacing quantum-inspired movement with a Gaussian perturbation for more diverse exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # w = 0.6  # Inertia weight\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Gaussian perturbation instead of quantum-inspired movement\n                gaussian_perturbation = beta * np.random.normal(0, 1, self.dim) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + gaussian_perturbation\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004468086869805266, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03815669159118695, 0.010422931593571327, 0.012001786968002914, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03767748614082911, 0.04216682872574817, 0.026465414287840217, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04745695706748421, 0.04377460330686067, 0.03875674109774885, 0.08264850016264569, 0.08261824395350825, 0.07909204762216537, 0.024042224620503427, 0.020961759345881625, 0.02984914530328564, 0.06787332889440811, 0.06409418546911227, 0.05671801579327662, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014987496977071912, 0.014834100795628857, 0.015621127138217838, 0.013719687888396948, 0.012984699176477599, 0.011874257468423743, 0.12505751611604654, 0.12833728686513624, 0.128958005801441, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "dddd78a0-3ac6-4a8f-bb3d-fe3ca3ca4ecf", "fitness": 0.02081527011662614, "name": "HQIPSO", "description": "Improve exploration by introducing a dynamic cognitive coefficient and random reinitialization.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # Dynamic cognitive coefficient based on evaluations\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 0.5 + 1.5 * (self.evaluations / self.budget)  # Dynamic cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                # Random reinitialization for diversity\n                if self.evaluations % (self.budget // 10) == 0:\n                    self.positions[i] = np.random.uniform(-5.0, 5.0, self.dim)\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.0047876410392557744, 0.004386252476323738, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.017490990604889234, 0.005601499440315627, 0.005504010788382252, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03589519976351119, 0.04739201089680978, 0.04208030507601612, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049898580543508486, 0.04206479450843248, 0.05208692168660456, 0.08361903466511034, 0.08939352524815813, 0.08557127840806511, 0.02799166538139386, 0.023619821423092824, 0.025527950317775994, 0.07020494063145266, 0.06874507773059324, 0.06243575904881016, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015610919572199289, 0.015362903708716735, 0.015858125318171434, 0.01305712340155507, 0.01485653375402507, 0.014277175656771113, 0.1262850129464116, 0.12062165084941445, 0.13151622177218647, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "a46de4d4-954e-4914-90b6-767519d06211", "fitness": 0.027438353698982065, "name": "HQIPSO", "description": "Introduce a damping factor to reduce velocity over time, improving convergence accuracy.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99  # Damping factor for velocity reduction\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["8abc1aba-c45d-4b5b-8a7e-51a80b3be8b1"], "operator": null, "metadata": {"aucs": [0.004545940779564939, 0.010572307130125025, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42261755485701813, 0.016266200672105158, 0.030852250492033884, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04392299698982616, 0.047423410338083394, 0.03045062194067283, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05591411466339735, 0.04897293899911448, 0.05142625544470614, 0.08228635771606185, 0.08196977994025345, 0.08612797731762711, 0.028070066910585778, 0.020823618665171795, 0.02327096469806067, 0.0801942154407772, 0.07318329837391724, 0.06275584459426842, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01577033791909732, 0.017512258888922827, 0.018515343297008657, 0.013673770662837148, 0.014940288809516034, 0.014835171892296217, 0.12574756393419195, 0.13042913643673715, 0.13553435678360093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "a5d7f375-4f2c-4524-8383-4e75a4983589", "fitness": 0.021454757237574756, "name": "HQIPSO", "description": "Refine velocity update by incorporating a decaying inertia weight to improve convergence precision.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.5 + 0.2 * (1 - self.evaluations / self.budget)  # Adjusted adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99  # Damping factor for velocity reduction\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["a46de4d4-954e-4914-90b6-767519d06211"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.006116875257659915, 0.007346117738051938, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.020003353388685974, 0.025371154889257896, 0.016149520104549397, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.044760959913632825, 0.04847510869560079, 0.028658468107740975, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048257842129899586, 0.04794700022817133, 0.051103410756410006, 0.08128173198482058, 0.0809013147881229, 0.08015710192664216, 0.02857446701329125, 0.02070448390000268, 0.03872459664017136, 0.08027752252588505, 0.06493530510685774, 0.0641826219169741, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015349332384320347, 0.01631801159408075, 0.018357901159854917, 0.013876415200467673, 0.013958297901254468, 0.014781646642272106, 0.13157247602181343, 0.1278219918804815, 0.12182096956927946, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "e3c12a20-2afe-4d01-9be7-e39fe5cb2fb5", "fitness": 0.022209904743726763, "name": "HQIPSO", "description": "Introduce a decaying damping factor to adaptively control the velocity over time, ensuring the algorithm's convergence without premature stagnation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.5 + 0.5 * (self.evaluations / self.budget))  # Decaying damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["a46de4d4-954e-4914-90b6-767519d06211"], "operator": null, "metadata": {"aucs": [0.008405465207958152, 0.006985300585361176, 0.01640144642605157, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03607254301464491, 0.007082571534061888, 0.028517708267433606, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.043076511033822595, 0.05483992751437816, 0.03039946756206302, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.052998884314010675, 0.04654730900003645, 0.04979078886308219, 0.08207589837986118, 0.08665855838763892, 0.08713125828517598, 0.02438791713713373, 0.025926876169904856, 0.02386615213259702, 0.07781391645782554, 0.07854479457550512, 0.058115025306693435, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015877363141561185, 0.027177654374259452, 0.018777040246392707, 0.013043816434898936, 0.01615101626360671, 0.013706032538366997, 0.13181942033319727, 0.12335442091427862, 0.13095936149435217, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "1fb00a55-679c-4556-9659-58fa2b71145c", "fitness": 0.027324625303717633, "name": "HQIPSO", "description": "Integrate a sinusoidal adjustment to the damping factor for smoother convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 + 0.01 * np.sin(np.pi * self.evaluations / self.budget)  # Sinusoidal damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["a46de4d4-954e-4914-90b6-767519d06211"], "operator": null, "metadata": {"aucs": [0.004472669683225017, 0.010337461928814684, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4226699357513548, 0.01627651212335568, 0.035047193171589885, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04286955961358574, 0.04724688739160665, 0.030150504443109516, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.056010247095272914, 0.04907878025545642, 0.051380947980193326, 0.08251142547244394, 0.08085001340272857, 0.08243229574409616, 0.028368464133984972, 0.021583946427635503, 0.026019669408229196, 0.08062214789315492, 0.07191786646522913, 0.06538463581815934, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015738510737600686, 0.01747361088809274, 0.018517111487146853, 0.013683591820165097, 0.014908596394051399, 0.013820926877040063, 0.12259864154944877, 0.1295261623396211, 0.12891818383214704, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "136d0586-5dc3-4d97-b2dc-c95358d1d3f5", "fitness": 0.027107379001987415, "name": "HQIPSO", "description": "Introduce noise reduction by dynamically adjusting beta using a noise threshold, enhancing convergence on noisy landscapes.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            noise_threshold = 0.01  # Introduce a noise threshold\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget) * (1 - noise_threshold)  # Adjust beta with noise\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99  # Damping factor for velocity reduction\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["a46de4d4-954e-4914-90b6-767519d06211"], "operator": null, "metadata": {"aucs": [0.004534758494271318, 0.010602945292563448, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42258344545859994, 0.016234896741108118, 0.030880688667510814, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04315452203016046, 0.04744755651780763, 0.03052990210371065, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.054867457781740514, 0.0484753679836224, 0.0520279639326392, 0.08054508209884881, 0.08203744544211744, 0.0862737471709697, 0.02796146870489602, 0.018183643394126037, 0.02254010203374668, 0.08052336643768387, 0.07100836459201543, 0.06525750617766013, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015768658215511766, 0.017519709630266167, 0.018349492145079305, 0.013680876857990687, 0.014947130460639002, 0.014355797877841803, 0.12822701434070283, 0.12086150669947959, 0.12539434912065484, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "4c0ae74f-e9bb-4a42-ade7-9373eda89c2d", "fitness": 0.02770682585530071, "name": "HQIPSO", "description": "Enhance velocity stability by tweaking damping factor adaptively as evaluations progress.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["a46de4d4-954e-4914-90b6-767519d06211"], "operator": null, "metadata": {"aucs": [0.006983454831461344, 0.013338124473125212, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42192515519990303, 0.015016322597417808, 0.029261683301503583, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.055652852721706836, 0.04862758295226166, 0.029169731015093125, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04817969193118432, 0.04158419239331046, 0.051723792874482255, 0.08181534802123391, 0.08315666429871449, 0.08412125069551124, 0.023691746457034535, 0.021762167036670887, 0.031242282386731546, 0.07725020778435987, 0.07261076296642299, 0.06597512738433231, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016257119174210577, 0.017458375436244067, 0.01843652738935675, 0.014938146496091376, 0.014771431284626546, 0.014089089781883612, 0.13451610043783258, 0.1312221104776633, 0.14315789804215162, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "456ee65e-d9dd-4fc1-9172-e0e22e06f5ec", "fitness": 0.026942138176086126, "name": "HQIPSO", "description": "Adjust quantum-inspired movement to harmonize with adaptive parameters for smoother convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = (beta ** 2) * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.007032241407139095, 0.009777924393544302, 0.01185839417229173, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.35138175699814156, 0.006933572978215952, 0.02888967725065561, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05348438673987399, 0.053479802235478324, 0.030682303519654508, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05304063007362014, 0.0408171723891847, 0.051723792874482255, 0.08779113393519389, 0.08406525608832316, 0.08851642721691977, 0.02777713630723655, 0.0223351907213426, 0.029388207586354187, 0.07730042079524302, 0.07120310233875082, 0.06624571780303345, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01641920474490155, 0.017428440034810477, 0.018696566892516975, 0.015027895226761845, 0.016103558583214883, 0.01418890528916572, 0.13740032983677486, 0.12507820655105084, 0.14315789804215162, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "4703b844-e964-406c-a227-15acfb9505e5", "fitness": 0.02269710471512089, "name": "HQIPSO", "description": "Introduce adaptive quantum factor based on evaluations for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement with adaptive factor\n                adaptive_quantum_factor = 0.5 + 0.5 * (self.evaluations / self.budget)\n                quantum_move = adaptive_quantum_factor * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.01203021533543469, 0.017128974842742117, 0.00919062658275116, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.031761852589154094, 0.00472186986928691, 0.008007447592829453, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04661239121126026, 0.04985050868767871, 0.047768064075065175, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05254205595812844, 0.047149084069859626, 0.04392428444604146, 0.0948901593293241, 0.08690191736306829, 0.0943117955273578, 0.03540390543784133, 0.025488977187657635, 0.026033594344628375, 0.07383894223028298, 0.0760305390272833, 0.08754993038207703, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.018148201577285916, 0.01814313062702866, 0.019041340618141445, 0.014916257529219656, 0.017423195245334755, 0.015731637597089065, 0.12355990848056331, 0.13139138186552812, 0.12209065420658716, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c2704b9a-eed4-4ea5-a406-fe6e0d0681f9", "fitness": 0.021965428028707996, "name": "HQIPSO", "description": "Improve exploration by integrating a small adaptive perturbation factor to update velocities.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move + 0.05 * np.random.randn(self.dim)\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.010552204723957792, 0.009118147269782884, 0.005346634338814549, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.034575088907657925, 0.008362835016347603, 0.0501899151332329, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.030264045859186295, 0.0478886088722531, 0.033114676729003256, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04967111179909567, 0.050186278961271924, 0.04982887933174973, 0.08090523373570402, 0.08791873836556852, 0.08099601930010747, 0.027243508053854004, 0.020794989420571897, 0.03214006061982422, 0.0745719942596117, 0.07146455700307497, 0.06980832237098089, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01637281223336673, 0.016162411122090936, 0.017871108143916348, 0.012780030769384831, 0.01491809114715481, 0.01516965658578917, 0.12034807024876981, 0.12546291891768102, 0.13487517317499798, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "d638c069-6bdc-48a8-be60-87067cc0e3aa", "fitness": 0.02128735586126028, "name": "HQIPSO", "description": "Add a chaotic factor to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                \n                # Introduce chaotic behavior\n                chaotic_factor = np.random.rand() * np.tanh(self.evaluations / self.budget)\n                self.velocities[i] += chaotic_factor * (np.random.rand(self.dim) - 0.5)\n                \n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.006079894944166053, 0.0061781070283810635, 0.0044994768573921595, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016630609179931866, 0.013903800105050101, 0.013621975227340877, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.040009417047195295, 0.047922494176319, 0.04078405139589847, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05018976792195495, 0.04708807026721651, 0.04885655222289864, 0.08287543251226503, 0.0903586774591073, 0.0842943565004658, 0.024735680150902994, 0.02444766325128922, 0.025857736581137103, 0.07082096430768903, 0.06202474770444033, 0.06338540901834977, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016165507436872506, 0.01733274092003012, 0.016748574354378265, 0.012684510414804673, 0.015133301834029056, 0.012904163305492933, 0.12957289953252504, 0.13288300573854228, 0.13209133896250091, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "f3570741-202b-418d-85bc-6dda1eb84b1b", "fitness": 0.02113895973345971, "name": "HQIPSO", "description": "Refine velocity update by amplifying quantum influence via cosine function for enhanced exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.cos(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.004416670080707341, 0.005586607185425696, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.011870808752280304, 0.03695735474669193, 0.017650422702819246, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04009225195027266, 0.045207637892813346, 0.04295089247678796, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048716466938695246, 0.04308349172303594, 0.03920762683487433, 0.08244701713486968, 0.08312411191909908, 0.08741771616806349, 0.021568166758894836, 0.02711476751646713, 0.023656352647952517, 0.0719007537814248, 0.0689481315082352, 0.06334390058808415, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016493007404338456, 0.015186347671601652, 0.016085987294850224, 0.013364614303016054, 0.014411868243281556, 0.014576331851568591, 0.12543672977300346, 0.12810776629322862, 0.12612477692758617, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "d10c2bf9-cc24-4042-8d61-f2a0aee25dcb", "fitness": 0.0216037222461906, "name": "HQIPSO", "description": "Refine velocity adjustment by introducing a mutation factor in velocity updates.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i] + np.random.normal(0, 0.1, self.dim)  # Add mutation factor\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.007211876633372305, 0.005068594491364875, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03411536017476613, 0.00775919110175094, 0.03884254969317469, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03228431324562486, 0.047969615806467414, 0.028872922230180564, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.044824578499322976, 0.0440686924651581, 0.05193011429918892, 0.08022325093701699, 0.09061618165212848, 0.08171553128060449, 0.01976422722206006, 0.024389711411990866, 0.028095551791572748, 0.07777940225004054, 0.07165467452784524, 0.0656889863753054, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016221492638330393, 0.016231149044207305, 0.017904501272553164, 0.013284713638281431, 0.015983310702566644, 0.015491638352628456, 0.13496230854101543, 0.12529030033725086, 0.1302667393708239, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "cc08a116-9adf-4d2c-a1a0-d43197b154de", "fitness": 0.02770682585530071, "name": "HQIPSO", "description": "Introduce local search enhancement by hybridizing with the Nelder-Mead simplex method post-iterations.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        # Perform Nelder-Mead refinement\n        result = minimize(func, self.global_best_position, method='Nelder-Mead', options={'maxiter': self.budget - self.evaluations})\n        if result.success and result.fun < self.global_best_score:\n            self.global_best_position = result.x\n            self.global_best_score = result.fun\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.006983454831461344, 0.013338124473125212, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42192515519990303, 0.015016322597417808, 0.029261683301503583, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.055652852721706836, 0.04862758295226166, 0.029169731015093125, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04817969193118432, 0.04158419239331046, 0.051723792874482255, 0.08181534802123391, 0.08315666429871449, 0.08412125069551124, 0.023691746457034535, 0.021762167036670887, 0.031242282386731546, 0.07725020778435987, 0.07261076296642299, 0.06597512738433231, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016257119174210577, 0.017458375436244067, 0.01843652738935675, 0.014938146496091376, 0.014771431284626546, 0.014089089781883612, 0.13451610043783258, 0.1312221104776633, 0.14315789804215162, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "7f280579-868a-47cd-bc8b-310c30622115", "fitness": 0.018576698484726803, "name": "HQIPSO", "description": "Refine velocity updates by incorporating nonlinear attraction towards global best position.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])**2  # Nonlinear attraction\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02112242050214652, 0.04163386230492905, 0.01854366125182838, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05146073595795608, 0.03989305219725714, 0.04678020641421232, 0.07601427185752141, 0.07441512169738007, 0.07807794306736626, 0.01250506533094664, 0.014291319053265417, 0.020727124878621606, 0.06202455401217344, 0.058468231421645145, 0.05518365532326741, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.013973837367501907, 0.014109576786069722, 0.01395985340832262, 0.012427760751229089, 0.011991722478398303, 0.011287695800776043, 0.13037502132267575, 0.129722807336081, 0.11983713820484665, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c09cf494-3655-456c-ba00-55230240399e", "fitness": 0.024922779704516243, "name": "HQIPSO", "description": "Enhance velocity stability by tweaking damping factor adaptively as evaluations progress with a refined social coefficient.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 1.0 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.004373970704354524, 0.004485536799244905, 0.005262237520136659, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.07986099821677373, 0.1774765662645098, 0.04139996965412551, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04088370795445717, 0.045981062455210164, 0.030749184237250704, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048716466938695246, 0.05554726400117638, 0.04567594359194671, 0.08800851584275249, 0.08910572572741093, 0.08379632248904179, 0.027528117164480004, 0.021544259461226734, 0.030236225360999902, 0.0758326308272077, 0.06791215731646805, 0.06708738277664339, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01595338755806963, 0.017559573676961815, 0.015629124031112718, 0.012391390302084915, 0.014972461196813391, 0.012451258796533637, 0.12909920484048754, 0.13350944596770498, 0.12880135139911542, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "fb92d1e0-fee2-4b80-a099-f890396030d4", "fitness": 0.027088482382518052, "name": "HQIPSO", "description": "Refine HQIPSO by tuning the adaptive inertia weight for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.3 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.005048079986760712, 0.004477989991423348, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4227281152116593, 0.023830088679650308, 0.03448569333908258, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04326680276912609, 0.0474062180188648, 0.02821453731928103, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045682225065336035, 0.047698781867739015, 0.052596033992204805, 0.08245174342843531, 0.07978072452408036, 0.08233633766802229, 0.02853185892478738, 0.02480939078538913, 0.022908610622948022, 0.07840805588757493, 0.0663057863378207, 0.06822719598359372, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015057093742733785, 0.017293158086528537, 0.018664666573236954, 0.014308381573254647, 0.014453806677603653, 0.0142491898876137, 0.11894637192315316, 0.1335848544852991, 0.12766241644896703, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "13cc2900-699f-4298-9dfb-4820df316787", "fitness": 0.026482636300523527, "name": "HQIPSO", "description": "Introduce a sinusoidal variation in the inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * np.sin((self.evaluations / self.budget) * np.pi)  # Sinusoidal inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.0044215650857434285, 0.0077225124412985124, 0.008763079893437609, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.36238973065736557, 0.012579291140851101, 0.028820840093771505, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04827067110112826, 0.0516026067284745, 0.029104590878109904, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05258549822428005, 0.048422747017516365, 0.05128413191079417, 0.07818613478887804, 0.08663662660517402, 0.07997115358586904, 0.027566586129316284, 0.027247662014310392, 0.025336620354578288, 0.0711356606516268, 0.07730572766092314, 0.05981935487074941, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015104298844749842, 0.017203764224804408, 0.017893010941002707, 0.013872939315178079, 0.013042789723875847, 0.014082048820433846, 0.12834519056422278, 0.1287568174172815, 0.13666746629977566, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "eaf4e65e-960e-470c-b359-3a7a3fb9646e", "fitness": 0.02493754487590064, "name": "HQIPSO", "description": "Enhance adaptive social influence by modifying social coefficient c2 for improved convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.5 * (self.evaluations / self.budget)  # Adaptive social coefficient (changed)\n            damping_factor = 0.99 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.007141657483926589, 0.012824756809293736, 0.009214399974407761, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.22799807341620082, 0.00969722579246568, 0.030371879920606637, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05394217301549009, 0.04974050726618362, 0.026782449213217818, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04881953052871735, 0.04194787500370867, 0.051723792874482255, 0.0795944400787425, 0.08268657808123625, 0.08323039415681854, 0.024771360204883797, 0.022822884189828696, 0.0312832639598003, 0.07738517786540755, 0.07145265709138504, 0.0628697700295554, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014457134258709647, 0.017771133746109058, 0.018371401447437985, 0.014025810695648233, 0.01514799431848568, 0.013886893602471972, 0.1413939901365242, 0.12838143220877563, 0.14315789804215162, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "58150e87-b5a3-44f7-a377-0a076eb9929c", "fitness": 0.02775970650757186, "name": "HQIPSO", "description": "Fine-tune the damping factor initialization to enhance exploration by altering the quantum move influence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["4c0ae74f-e9bb-4a42-ade7-9373eda89c2d"], "operator": null, "metadata": {"aucs": [0.005913800295372362, 0.009565343106690327, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42165878831588977, 0.01450478621318907, 0.028947361273120253, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05769159953044323, 0.05017859627487631, 0.03002931218757887, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05021208378273889, 0.04844521660032142, 0.05236126663246354, 0.08173870307592757, 0.08420389131058859, 0.08823953554995978, 0.02416912439843477, 0.020696674483760447, 0.02982858019587109, 0.07759126944155659, 0.07242784568222516, 0.0641370055725139, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01656332438915642, 0.017286013894948216, 0.01865133700685495, 0.01484237513746045, 0.015180965968367488, 0.013992745008043372, 0.12364081458499032, 0.1489399162928028, 0.1241366205900093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "11d1b6dc-2333-4485-ba07-7238efc17873", "fitness": 0.02208408387659367, "name": "HQIPSO", "description": "Adjust the quantum-inspired movement by modifying the sine function frequency to enhance exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(3 * np.pi * r1) * (self.global_best_position - self.positions[i])  # Adjust frequency\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.006249306644484975, 0.00685804113557098, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03089827613969187, 0.026760872916442358, 0.010445445675325682, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05304627211378421, 0.05355150658705676, 0.057027294803166595, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04905886056280706, 0.04652633334348777, 0.03950699707929417, 0.0796001736355808, 0.08134026523586635, 0.09029361887653375, 0.02358181617614108, 0.020665695813893548, 0.027520201149355716, 0.07573100259677046, 0.06429041028731164, 0.06458423188504958, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01757203343185354, 0.016968352280822496, 0.016735535453441308, 0.01509630632788439, 0.013836647776693689, 0.014734380065826835, 0.13230962366533516, 0.13012080828846517, 0.13818720742767687, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "9b60c550-c7d5-4fae-be88-1455ffd444cf", "fitness": 0.02163840329294189, "name": "HQIPSO", "description": "Introduce a small stochastic perturbation to the quantum-inspired movement for improved exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement with stochastic perturbation\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i]) * (1 + 0.1 * np.random.randn())\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.0045915246626879735, 0.007510072122177691, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.022905978358997214, 0.007446594035538268, 0.009419224272167903, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.032106262032840505, 0.053020994385639675, 0.06946601361721294, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04989014073782416, 0.05046750352019802, 0.04974471272761638, 0.0874294542308397, 0.08262323732878529, 0.09120496447464976, 0.0337301560541734, 0.015493558395211049, 0.031160144242070587, 0.06878299025640788, 0.06273157965565535, 0.07232459708248484, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016861718320311248, 0.018536644960758464, 0.017302347343427615, 0.016385491112514416, 0.014810426445407643, 0.01269649748120083, 0.1233210355384442, 0.12228709833032203, 0.1267575536271216, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "0e5e53a1-a28f-454c-b22b-4beac5e98f3f", "fitness": 0.023622722785278025, "name": "HQIPSO", "description": "Introduce multi-swarm adaptive neighborhood exploration to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.num_swarms = 3  # Multi-swarm setup\n        self.swarm_size = self.pop_size // self.num_swarms\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement with swarm influence\n                swarm_id = i // self.swarm_size\n                local_best_position = self.personal_best_positions[swarm_id * self.swarm_size:(swarm_id + 1) * self.swarm_size].mean(axis=0)\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (local_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.005459959934935088, 0.015057510385001915, 0.012330336289490318, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.013419733951196777, 0.008563624832001682, 0.009270948300078463, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.06237312636952819, 0.057131428052555, 0.055983050853944505, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.043566118550259825, 0.0435026872148746, 0.044437157652357784, 0.0974380358080591, 0.09088835883550472, 0.09371944185103354, 0.03626397940746229, 0.03610487432419085, 0.038256838105032664, 0.09612489052200757, 0.08695196010467388, 0.08733592192119821, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016648677113706434, 0.01725773143063669, 0.019677284036755394, 0.017697385379324082, 0.01558200777272889, 0.016985156158860648, 0.12298201696027533, 0.12479501577860252, 0.13242208699156788, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "f1373c7e-22df-4fb4-b9e5-34bac77a3d7b", "fitness": 0.02256133120247429, "name": "HQIPSO", "description": "Introduce a small random perturbation to positions to enhance exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i] + np.random.normal(0, 0.01, self.dim)  # Added perturbation\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.01077675404245415, 0.00947710753697395, 0.004929241087271219, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.030308130110761722, 0.011855350357951266, 0.0928593302908145, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.029305089535333395, 0.048004734957412865, 0.03230658427832245, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05001482893689946, 0.03984281030608705, 0.047732310148374646, 0.09184010426431366, 0.09151063665671755, 0.08596839112491617, 0.02314197655394523, 0.022134329501165673, 0.02725092952571284, 0.0808646220494762, 0.07057651831237866, 0.06892530778712502, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016248626902291008, 0.014691119038499623, 0.01708337160804474, 0.012773223284559876, 0.015210072720789891, 0.015548601714812538, 0.12263352447783504, 0.13349572437430102, 0.12449779944043482, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "dc3b8b4a-c297-4686-9bd1-1ed6ce8c2c3a", "fitness": 0.02775970650757186, "name": "HQIPSO", "description": "Enhance position update mechanism by incorporating an attraction-repulsion dynamic to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.005913800295372362, 0.009565343106690327, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42165878831588977, 0.01450478621318907, 0.028947361273120253, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05769159953044323, 0.05017859627487631, 0.03002931218757887, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05021208378273889, 0.04844521660032142, 0.05236126663246354, 0.08173870307592757, 0.08420389131058859, 0.08823953554995978, 0.02416912439843477, 0.020696674483760447, 0.02982858019587109, 0.07759126944155659, 0.07242784568222516, 0.0641370055725139, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01656332438915642, 0.017286013894948216, 0.01865133700685495, 0.01484237513746045, 0.015180965968367488, 0.013992745008043372, 0.12364081458499032, 0.1489399162928028, 0.1241366205900093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "e444915c-645d-4676-b6f9-b0e164653a2b", "fitness": 0.026885500377565937, "name": "HQIPSO", "description": "Introduce a dynamic cognitive coefficient to further enhance exploration by adjusting the personal best influence based on progress.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 1.5 - 0.5 * (self.evaluations / self.budget)  # Adaptive cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.006116498529668779, 0.014094267374659686, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.36584118009004163, 0.01426001980651459, 0.028731458129983345, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05243556562107787, 0.049978213536229, 0.030327560712671175, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049814770216607296, 0.042402080412319965, 0.05309761676766722, 0.09027323520457542, 0.08475111283587156, 0.08100507937579704, 0.0227403227966001, 0.027959391702902847, 0.029665451073808802, 0.07998171624641259, 0.072751924984504, 0.07000231964003578, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016497498998558457, 0.018688635218532035, 0.018024952214169887, 0.014249635394370741, 0.01516104166251786, 0.014343045397744003, 0.12545063629950537, 0.13356424298571856, 0.1265900322165524, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "ef7e3493-36c4-4bc2-bb09-181ff4bcf2fc", "fitness": 0.022391946337502067, "name": "HQIPSO", "description": "Enhance global exploration by introducing a small random perturbation to the global best position.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i] + np.random.normal(0, 0.001, self.dim)  # Small random perturbation\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.012167484606177559, 0.008023045213461644, 0.0050237654136428, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.042691729288928615, 0.00970500005845365, 0.007237599392859284, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053557863181250664, 0.0522464202282199, 0.03783701184992039, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.059121434299256204, 0.04327458023022401, 0.04785904965896104, 0.0900442096834243, 0.08331126588623206, 0.08634997736883687, 0.028059548206651796, 0.025545604624556573, 0.025053385332029277, 0.06941105602516118, 0.07301933157323892, 0.07162414651084381, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02488759044104305, 0.01802117003669601, 0.017433502930861877, 0.013362301179953184, 0.017175169723192663, 0.014637420292287207, 0.1359064105761305, 0.13181007286470414, 0.12521429397077688, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "55afba91-3cb7-4a0f-9e50-407634b0888c", "fitness": 0.021706169164906603, "name": "HQIPSO", "description": "Enhance HQIPSO by introducing an adaptive quantum move and improved inertia weight based on search progress.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.1 * np.sin(2 * np.pi * self.evaluations / self.budget)  # Adaptive quantum beta\n            w = 0.5 + 0.3 * np.cos(np.pi * self.evaluations / self.budget)  # Improved adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.008613866448040741, 0.0044450292620347165, 0.005028403829582473, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.038504692762263204, 0.016776718577125815, 0.029682041603123155, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04627399503218799, 0.04415000504708089, 0.04040670454967821, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05020907277143316, 0.034757709445031315, 0.03690970397080984, 0.08474580041780455, 0.08508447287018628, 0.08706955000548655, 0.025488553787881285, 0.028207590272158134, 0.02613842444752912, 0.07081222682290034, 0.07019058478522333, 0.07237309248829982, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014956747376080881, 0.017356024906905132, 0.021179312333867162, 0.012983000558859037, 0.014861350044636956, 0.015781812299773157, 0.12570869645380867, 0.1265801064821196, 0.12496019456919105, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "b788cadf-99ed-4d02-83b6-b5f7db62ec31", "fitness": 0.021781766692841285, "name": "HQIPSO", "description": "Adjust the inertia weight to enhance convergence by making the update more responsive to evaluations.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Adjusted adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.004407244271770527, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02908318738842075, 0.029471053381479262, 0.022024895512280596, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04511863618081713, 0.04430481409595621, 0.02595793451862838, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04569706448482391, 0.0523169822679751, 0.05248731301788401, 0.08387392979495045, 0.082580796411307, 0.08277716219716802, 0.028937173081905465, 0.021380755081795932, 0.029995129083323913, 0.08144237167793211, 0.06387713236445647, 0.0660670522834117, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014965048439630757, 0.016023021671517146, 0.017989609484895586, 0.013915862056541828, 0.01476601179905268, 0.01469055642575201, 0.12674196636356283, 0.1303216366336155, 0.13576851408763146, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "a950e9ef-b1b6-48c1-8c8f-da8b06c2f9ff", "fitness": 0.024920067475758423, "name": "HQIPSO", "description": "Adjust the damping factor scaling to enhance global search effectiveness.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.8 + 0.2 * (self.evaluations / self.budget))  # Adjusted adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.005836319844282345, 0.007847577970192088, 0.008850357170890333, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.2643491774198409, 0.013877681660890762, 0.028041828855803752, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05712170307099107, 0.04740868341952831, 0.02975062090055236, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049083102627386466, 0.050427440355145126, 0.04989957998434835, 0.07566163441228468, 0.08750468743889794, 0.08007227972607922, 0.02340112078824086, 0.021851780132226217, 0.02563932176889372, 0.08548883841153965, 0.06748110027586685, 0.05671604209614489, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01643573702777046, 0.018250401031066676, 0.018035956397281172, 0.014822729849043648, 0.013448364293997761, 0.014668872872109162, 0.1260083584100823, 0.1312664432922357, 0.12238842109882075, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "33e0d7d8-a5f4-4919-9870-1023fe810aba", "fitness": 0.027511783212630973, "name": "HQIPSO", "description": "Introduce a minor adjustment to the adaptive beta scaling for enhanced exploitation in the search space.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.85 + 0.15 * (1 - self.evaluations / self.budget)  # Slightly adjusted adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.009108444127706172, 0.009608867001922539, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4219460011694619, 0.01457045746742569, 0.028725886712706927, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05415817750665286, 0.049736279826831487, 0.029537069062488097, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049443382057091645, 0.04259643738804375, 0.05236126663246354, 0.08271592702046138, 0.08610830813030335, 0.08491925028238945, 0.028004199836397126, 0.027507327879498056, 0.028866301859771237, 0.07489826148777967, 0.06834095013316432, 0.0614766085652404, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016523687644721008, 0.017258217736856762, 0.018602712242497876, 0.0147292230300613, 0.015248238691395799, 0.013665841137228796, 0.14126015482658816, 0.12881579311107116, 0.1231585970020801, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "b480b0db-54bf-4c79-960f-7506b855d32d", "fitness": 0.027908616458532605, "name": "HQIPSO", "description": "Enhance global best position update strategy by introducing a threshold to prevent premature convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["58150e87-b5a3-44f7-a377-0a076eb9929c"], "operator": null, "metadata": {"aucs": [0.005913800295372362, 0.009565343106690327, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42165878831588977, 0.01450478621318907, 0.028947361273120253, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.057678641355676796, 0.05017859627487631, 0.03002931218757887, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053695201339281406, 0.04844521660032142, 0.05236126663246354, 0.08173870307592757, 0.08420389131058859, 0.08823953554995978, 0.02416912439843477, 0.020696674483760447, 0.03096211044137631, 0.07759126944155659, 0.07854567252411704, 0.0641370055725139, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01656332438915642, 0.017286013894948216, 0.01865133700685495, 0.01484237513746045, 0.015180965968367488, 0.013992745008043372, 0.12364081458499032, 0.1489399162928028, 0.1241366205900093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "5d10cdd6-e22d-4aff-9b70-57582f5329c5", "fitness": 0.02536970970538367, "name": "HQIPSO", "description": "Introduce a non-linear decay in the adaptive inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * np.exp(-3 * (self.evaluations / self.budget))  # Non-linear adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.04.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004768565360908972, 0.00956219245796286, 0.009880396177020523, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.27263733441703564, 0.013668774708466613, 0.0279100491401556, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05596142544164484, 0.04952187997063118, 0.03166546207556953, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05048117969797872, 0.04621277208230601, 0.05430154979673507, 0.08006755732864057, 0.08202631574538655, 0.08878841165346063, 0.02190904828606921, 0.02511352826609292, 0.02956150315347883, 0.07829406418147433, 0.07059410154810608, 0.06978348514200305, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01680283664664095, 0.01807332633797576, 0.018730036643405112, 0.012047615690736091, 0.015392541270918714, 0.014192256700515271, 0.12337028988900212, 0.1297184417058077, 0.12297346161932188, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "37789bce-2a60-44b1-b1f7-2dccf05d5ddb", "fitness": 0.02199483381602063, "name": "HQIPSO", "description": "Introduce a small mutation in global best update to enhance exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best with small mutation\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i] + np.random.uniform(-0.01, 0.01, self.dim)  # Mutation\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.016451072628266172, 0.0059367548645512525, 0.005816082424000557, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.023319486746983364, 0.02258970677315364, 0.013171767572085713, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03288603415727753, 0.05219752428964752, 0.04602871862951374, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05026257693337832, 0.04104562647820442, 0.04022876672425446, 0.08746055869042413, 0.08296262633066998, 0.08811132486082851, 0.023555087009405562, 0.020990626564646342, 0.03203953726682929, 0.07704932492973504, 0.06988860448573586, 0.06957316207423347, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015440645366798456, 0.0162389564455796, 0.020448376538501623, 0.018909464248082042, 0.014664652102972187, 0.016208559571843195, 0.12799364066918673, 0.1374927196305854, 0.1320573540939386, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "1ce95ae2-d69d-4be6-bcc4-120cdbb888c1", "fitness": 0.027908616458532605, "name": "HQIPSO", "description": "Introduce a dynamic threshold for global best update to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n            dynamic_threshold = 0.1 + 0.1 * (self.evaluations / self.budget)  # Dynamic global best update threshold\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > dynamic_threshold:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.005913800295372362, 0.009565343106690327, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42165878831588977, 0.01450478621318907, 0.028947361273120253, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.057678641355676796, 0.05017859627487631, 0.03002931218757887, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053695201339281406, 0.04844521660032142, 0.05236126663246354, 0.08173870307592757, 0.08420389131058859, 0.08823953554995978, 0.02416912439843477, 0.020696674483760447, 0.03096211044137631, 0.07759126944155659, 0.07854567252411704, 0.0641370055725139, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01656332438915642, 0.017286013894948216, 0.01865133700685495, 0.01484237513746045, 0.015180965968367488, 0.013992745008043372, 0.12364081458499032, 0.1489399162928028, 0.1241366205900093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "0b8db8ae-9842-4dd4-884f-faa77a26c251", "fitness": 0.023347853436437773, "name": "HQIPSO", "description": "Introduce mutation in velocity update for enhanced exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i] + 0.001 * np.random.randn(self.dim)  # Mutation in velocity update\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.010767587026063952, 0.009506839363486619, 0.004870771478115543, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.028853569308719074, 0.011969669065586719, 0.1688084075092947, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02888593032009501, 0.04815246397584649, 0.03223960646798174, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.046628429362746915, 0.03958525256315781, 0.04852337983538957, 0.09163550192483383, 0.0894300436885146, 0.08532192355123291, 0.021223547944074772, 0.021875728561839614, 0.02461258718385917, 0.07418030642370421, 0.07146422229504124, 0.06988162861794434, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016276255598314027, 0.015779649529112594, 0.01782393938715965, 0.012794304600248885, 0.015204397859544416, 0.015472343304963165, 0.1254800825020097, 0.12377631429012159, 0.12741206823234386, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "00688719-e4f5-49f0-a7f1-15687f497e00", "fitness": 0.027359283354011655, "name": "HQIPSO", "description": "Refine the momentum and adaptive parameters of HQIPSO to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.9 + 0.1 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.5 + 0.3 * (1 - self.evaluations / self.budget)  # Modified inertia weight\n            c2 = 0.6 + 1.5 * (self.evaluations / self.budget)  # Adjusted social coefficient\n            damping_factor = 0.96 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Slightly altered damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004664739057084644, 0.004358197895694693, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.44234525545627423, 0.03222009921221425, 0.027679277097824473, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04266464686503724, 0.043832395327686124, 0.030201987647576423, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04951484198459555, 0.04294571992110574, 0.05245276926743159, 0.07921656629053675, 0.08221179864065353, 0.08191617287454245, 0.021181807857400536, 0.021054058244892482, 0.03757778046398519, 0.0809603801264357, 0.07077637148469784, 0.06648080421152014, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015041231278409395, 0.016786490337587834, 0.01835592268980224, 0.013142878492031218, 0.014376639737306296, 0.014127349087484697, 0.12039902689072979, 0.128464095595634, 0.12796257571353487, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "e477184e-8d47-4d8e-b934-cb84e4371b92", "fitness": 0.025416867984904765, "name": "HQIPSO", "description": "Improve the adaptive update of the social coefficient for better convergence by adding a sigmoid function transformation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (np.tanh(5 * (self.evaluations / self.budget - 0.5)) + 1)  # Sigmoid transformed adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.007497523843667753, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.29966316678750105, 0.01548698978309715, 0.03864269573698442, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04724383124815368, 0.048294739025319, 0.03563976079725828, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047402724139059105, 0.050173949516521765, 0.05434702673368452, 0.07929539833069987, 0.08238493741708608, 0.08731092191928136, 0.02449074216664715, 0.022379170250666047, 0.020858128099580875, 0.07785775683674201, 0.06628011615834406, 0.0606233652084458, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015141747420839069, 0.014566986255652337, 0.017892594061409417, 0.012990042064941698, 0.013996010211423382, 0.015302034122902541, 0.12973257731256194, 0.13258039737694105, 0.12063481426164613, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "073a6d70-8ca9-402f-a799-a29a2cb13418", "fitness": 0.021864358107221444, "name": "HQIPSO", "description": "Introduce a dynamic adaptation of the cognitive coefficient `c1` to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            c1 = 1.5 * (0.5 + 0.5 * (self.evaluations / self.budget))  # Dynamic cognitive coefficient\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.006676672901422376, 0.005792427889570906, 0.009614029939087554, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.017172516507407587, 0.013962810271859527, 0.032027861389771095, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.033667524784448455, 0.04908198782611506, 0.03545993694905436, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04590490225048638, 0.04499870178218934, 0.05236126663246354, 0.08747087792839892, 0.08137832018719349, 0.08738318051926142, 0.02943240675065173, 0.031941669134771145, 0.023370723524119286, 0.07716461143513997, 0.07063966335364458, 0.07048800949859946, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015287456133374344, 0.017225692729586073, 0.018213655166163356, 0.013380584668013507, 0.01817584506802572, 0.016542911845427777, 0.1335220672716121, 0.1285505861796825, 0.12473618755022964, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "a322181d-469d-40ac-91eb-51f1abb75e59", "fitness": 0.022517984227647916, "name": "HQIPSO", "description": "Enhanced with dynamic velocity limitation to improve exploration and convergence balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n\n            max_velocity = 0.1 * (5.0 - (-5.0)) * (1 - self.evaluations / self.budget)  # Dynamic max velocity\n            self.velocities = np.clip(self.velocities, -max_velocity, max_velocity)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.010919510209064232, 0.014218152218798297, 0.008859353468882003, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.006309585724378786, 0.008420786734392727, 0.011873244741005595, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05598199765046452, 0.05869482024625683, 0.04069045896976342, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04645022454326042, 0.04384120189707319, 0.05357255992557508, 0.08791449827330045, 0.08799286463162392, 0.0921161069596973, 0.02928117652793627, 0.026024126407170223, 0.03597335240424926, 0.07533187608149605, 0.08290328204968611, 0.07064493081660606, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016188461903255846, 0.03603993671845018, 0.01734346574034107, 0.01222288622187695, 0.016840167811284834, 0.01615293916891325, 0.1251952518806183, 0.12372446618343658, 0.12696448262961935, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "c6b492c9-3868-4fcf-8fc7-56c41bcb9718", "fitness": 0.026649279625602144, "name": "HQIPSO", "description": "Introduce dynamic population size adjustment based on the evaluation budget.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget) * (1 - 0.5 * (budget / (budget + 100)))))  # Adjusted dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.05.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.021442675587589055, 0.006949155548984121, 0.004501875256656018, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01993282112878836, 0.03922839500897124, 0.3609946900871144, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04679201507717434, 0.020620150042412133, 0.0409785362521351, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047959109185848336, 0.043313120904444835, 0.04029567663407585, 0.09074601322216491, 0.08057500340510315, 0.08254717616294804, 0.02402888198361397, 0.023954831421187817, 0.022572660691356217, 0.07362858638907888, 0.07118417638813213, 0.0679796554692047, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015675452713563187, 0.035027482057158665, 0.019316006102075955, 0.015369103421755015, 0.015948357192683393, 0.015234904401164151, 0.12602120204958212, 0.12884659052400493, 0.1344751330822107, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "5f448ff1-ec9e-48a3-b73c-4154c575b83a", "fitness": 0.01939617922074714, "name": "HQIPSO", "description": "Incorporate a stochastic boundary escape mechanism and better adaptive coefficient management to prevent stagnation and premature convergence.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.4  # Cognitive coefficient (changed from 1.5)\n        \n        while self.evaluations < self.budget:\n            beta = 0.85 + 0.15 * (1 - self.evaluations / self.budget)  # Adaptive beta (adjusted)\n            w = 0.3 + 0.3 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight (adjusted)\n            c2 = 0.6 + 1.9 * (self.evaluations / self.budget)  # Adaptive social coefficient (adjusted)\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                if np.any(self.positions[i] < -5.0) or np.any(self.positions[i] > 5.0):  # New line to introduce boundary escape\n                    self.positions[i] = np.random.uniform(-5.0, 5.0, self.dim)  # New line to reset out-of-bounds positions\n                else:\n                    self.positions[i] += self.velocities[i]\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03508362025675127, 0.042110874314044366, 0.023207684204788692, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045727988288431276, 0.03748123611532728, 0.041798300695018886, 0.08588719624795182, 0.07935209400743193, 0.0804807177450998, 0.022405944681408774, 0.01927159485451202, 0.019383859499511602, 0.06357315288722365, 0.0613599449886415, 0.07483444491932889, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014033628373804063, 0.014081538060341514, 0.01437854483927814, 0.012187724523453625, 0.012280535902549738, 0.011513130819856388, 0.12163745671929815, 0.13723913846901303, 0.11851890030681578, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "668aee83-2fa7-4ed2-a14f-606f71b81f21", "fitness": 0.02715611037423392, "name": "HQIPSO", "description": "Increase the adaptive inertia weight upper bound to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.5 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004676047753413237, 0.006055385021295767, 0.004405892178238502, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42287307675235875, 0.023182559334867237, 0.03506410805503435, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04628687275487198, 0.047055461767048556, 0.028385676228558143, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05238104855566583, 0.048217096016163974, 0.05191627367059071, 0.08227901983256047, 0.0820261189184992, 0.08287838192379082, 0.026435961522769724, 0.02473238976721015, 0.024648087453519874, 0.07909769778824294, 0.07011026799633935, 0.06635272794163338, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01582474050805094, 0.01710241314742078, 0.018669350748950042, 0.013775423684439403, 0.01441120466903345, 0.01428054970431536, 0.1255198751086326, 0.12072105077610851, 0.12326649171304538, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "61a4bb70-5675-4ec6-9569-eed15eaf4469", "fitness": 0.022157382117008035, "name": "HQIPSO", "description": "Integrate chaotic maps to enhance exploration by modifying the velocity update equation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i] * (np.sin(0.5 * np.pi * r2))  # Integrating chaotic map\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.007443154285603493, 0.01282740873389887, 0.008639985720789278, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01734857149873592, 0.004456561963129935, 0.014170185526301116, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.06953205747104374, 0.047393729926434314, 0.03340752148156212, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04946091977215239, 0.04299491002769251, 0.04102646841790614, 0.08767050035010371, 0.08635239476914236, 0.09224090966381038, 0.0297690738848172, 0.030428983708609914, 0.030255671779344406, 0.08122649981265351, 0.07210673835657633, 0.06458929314965844, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01670100386033191, 0.019393150893612376, 0.02359228740806929, 0.014879233838475892, 0.01536397745770246, 0.015000567681901722, 0.12238519881693655, 0.1285971091171203, 0.1334687473982893, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "46db0c47-2afd-4fc4-b55f-1a93e0c540de", "fitness": 0.027539168311272462, "name": "HQIPSO", "description": "Enhance the damping factor to further stabilize velocity updates and prevent erratic movements.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.95 + 0.05 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.007359064269587656, 0.013339183029707713, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42191920012356543, 0.014892699682998445, 0.029218493319116412, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.055347005012633566, 0.049411032520449205, 0.028931628113593066, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048255581869916964, 0.0405593218706527, 0.05097102144498189, 0.08255597802821868, 0.08247712111720484, 0.0802467900018361, 0.02470514266658419, 0.023430522831641598, 0.03337540085606616, 0.07634522716126269, 0.07277143422120536, 0.06425329943016944, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01636771464362352, 0.017494374554755665, 0.018326195443654325, 0.014928670628362783, 0.014797089865656643, 0.014111175257220387, 0.13132584907777856, 0.1317132501469499, 0.13643412948309397, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "aa214c98-6a3f-4a2d-a8eb-80bd7940d16f", "fitness": 0.026843961559124156, "name": "HQIPSO", "description": "Implement a differential inertia weight adjustment to improve convergence speed in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.5 * (1 - self.evaluations / self.budget) + 0.3  # Differential inertia weight adjustment\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004532020012618432, 0.007779495149476623, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42216742051878875, 0.01833717197642104, 0.009138280913482566, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.042012580971518276, 0.04711712117408218, 0.029972964673397606, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047237140927275156, 0.04753748369484678, 0.051756663488418564, 0.07956015387433413, 0.08527362261529181, 0.08144782086768332, 0.02211564053248305, 0.020003665597385645, 0.03157569509341618, 0.0844823951457101, 0.06792730151141013, 0.06915606783269612, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015572793041514155, 0.0172674848303489, 0.018726856277245463, 0.013746704308543856, 0.014474504992079584, 0.014452116785563796, 0.12384060102441707, 0.12968705648658208, 0.1289098862007787, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "4c18ae3b-e6d3-486c-88ca-7a23870a8d6d", "fitness": 0.02162277357718793, "name": "HQIPSO", "description": "Improves update strategy by increasing adaptability of inertia weight for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.9 - 0.5 * (self.evaluations / self.budget)  # More adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004407244271770527, 0.004347826086956497, 0.008755807853640607, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02908318738842075, 0.016100729860446417, 0.022024895512280596, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04511863618081713, 0.04430481409595621, 0.02595793451862838, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045694896284781406, 0.0523169822679751, 0.05248731301788401, 0.08387392979495045, 0.082580796411307, 0.08277716219716802, 0.028937173081905465, 0.019757040330664166, 0.029995129083323913, 0.08144237167793211, 0.06387713236445647, 0.06592452638008306, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014965048439630757, 0.016023021671517146, 0.017989609484895586, 0.013915862056541828, 0.01476601179905268, 0.0139738027075621, 0.12674196636356283, 0.1303216366336155, 0.13576851408763146, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "2ba1258c-5029-4353-8760-bdbab6b75b8c", "fitness": 0.02162277357718793, "name": "HQIPSO", "description": "Introduce a dynamic inertia weight initialization to improve exploration in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight initialization changed\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004407244271770527, 0.004347826086956497, 0.008755807853640607, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02908318738842075, 0.016100729860446417, 0.022024895512280596, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04511863618081713, 0.04430481409595621, 0.02595793451862838, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.045694896284781406, 0.0523169822679751, 0.05248731301788401, 0.08387392979495045, 0.082580796411307, 0.08277716219716802, 0.028937173081905465, 0.019757040330664166, 0.029995129083323913, 0.08144237167793211, 0.06387713236445647, 0.06592452638008306, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014965048439630757, 0.016023021671517146, 0.017989609484895586, 0.013915862056541828, 0.01476601179905268, 0.0139738027075621, 0.12674196636356283, 0.1303216366336155, 0.13576851408763146, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "2b156329-ef06-4260-bec2-15d25f1ad76c", "fitness": -Infinity, "name": "HQIPSO", "description": "Introduce a dynamic population size update strategy based on convergence progress to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n\n            # Dynamic update of population size based on evaluations\n            self.pop_size = max(5, int(self.pop_size * (1 + 0.01 * (self.global_best_score / np.mean(self.personal_best_scores)))))\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "An exception occurred: IndexError('index 15 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 15 is out of bounds for axis 0 with size 15')", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {}}
{"id": "b6fc3762-4026-4c24-9bb2-24f0becf13f4", "fitness": 0.021162487503437702, "name": "HQIPSO", "description": "Introduce a mutation step in the position update to enhance exploration capabilities and avoid local minima.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Mutation step\n                mutation_prob = 0.1  # Probability of mutation\n                if np.random.rand() < mutation_prob:\n                    mutation_strength = 0.1  # Strength of mutation\n                    self.positions[i] += np.random.normal(0, mutation_strength, self.dim)\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.009816445517507155, 0.004347826086956497, 0.005879965799528097, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.0190088124940041, 0.012297947366422313, 0.014506130951196572, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03546837331413977, 0.055647227297412005, 0.03185314341168277, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047706717288705014, 0.0497714838962543, 0.05211855585717862, 0.08806420027904427, 0.08140557987841379, 0.08358119143144604, 0.02462710721916328, 0.026439954288194678, 0.028090254211112886, 0.07558210776077978, 0.07410615884782512, 0.060945810591647276, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016904574556931617, 0.015804596836210494, 0.016136903279234893, 0.01804147548277535, 0.014693162592897546, 0.012964365006972733, 0.12149121714627864, 0.12028739305576341, 0.12350172284966277, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "17b64402-61a8-43d4-bcc0-e2cbcf0d0a48", "fitness": 0.023846405204922913, "name": "HQIPSO", "description": "Introduce adaptive quantum amplitude to refine exploration and exploitation balance in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_amplitude = 0.1 + 0.9 * (self.evaluations / self.budget)\n                quantum_move = beta * quantum_amplitude * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.018365579085166894, 0.015921554252880665, 0.01080811889798683, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.007811592066391038, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.06639375477963716, 0.05633451586378779, 0.04614074228832743, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.050128290917256124, 0.04002407552976761, 0.041085712782369166, 0.09612037330808021, 0.09892287317387294, 0.0914712797108812, 0.04176792794752149, 0.03099793468867207, 0.03276651509772632, 0.09864710005327149, 0.09356532105337467, 0.08537847081728489, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.022770851418044247, 0.01735639484262408, 0.0185735429680004, 0.01757246840373694, 0.01782369451723398, 0.025232149089342792, 0.1220771556939173, 0.12803969400125326, 0.133539143679955, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "ce39936c-d343-47c5-a024-1a7fd3cf52e9", "fitness": 0.021852129283589417, "name": "HQIPSO", "description": "Slightly adjust the quantum-inspired movement by altering the sine function for improved exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.cos(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004451840605721569, 0.005819435433634501, 0.006291414482408886, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01160655600152849, 0.035917464311075564, 0.024844101813447872, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03980202773972075, 0.0455965395135105, 0.04389172033149791, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05063225845059527, 0.043944935973135535, 0.04071205048554072, 0.08368715921732384, 0.08362876433356492, 0.0827324076724214, 0.0273233650162501, 0.033838653317270984, 0.02512531997303724, 0.07122223758705226, 0.06858633208730347, 0.06699397480876523, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016579912347433612, 0.015350028040521102, 0.01579250100458962, 0.012562709943138683, 0.015208548276787415, 0.015503296765525865, 0.13652778237874508, 0.1409007034786237, 0.12567057137609317, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "81ef4cb1-a69f-441c-a9af-75f113ac5fd4", "fitness": 0.02446441490415779, "name": "HQIPSO", "description": "Adjust quantum-inspired movement intensity to enhance exploration in later stages.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])  * (self.evaluations / self.budget)\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.01843772095947227, 0.015161238571718472, 0.009960669475984063, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.005514913843169267, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.0046217147242682, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.06406208577494499, 0.06433041630940939, 0.04795346023594815, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.049252798125588915, 0.057813532188809025, 0.0418331443535922, 0.09046360275577503, 0.09319574930732266, 0.0991172087922495, 0.043617319237369445, 0.03662074037437779, 0.03303227035562828, 0.10450074418559796, 0.10044616262174955, 0.10158807349142562, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.02562288071205565, 0.01776721991049457, 0.018835912014345646, 0.018197771676744523, 0.018692919975707878, 0.024550888294851303, 0.12522223157206924, 0.12087381855556789, 0.12319414296399411, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "7d7cb272-6bee-4b2f-a365-5f88e2ddf33e", "fitness": 0.022532315817262734, "name": "HQIPSO", "description": "Introduce velocity clamping to prevent overly large velocity updates and enhance stability.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.velocities[i] = np.clip(self.velocities[i], -1.0, 1.0)  # Enforcing velocity clamping\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.019890183311428555, 0.007539040850014778, 0.013312884727079144, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.0471744328102075, 0.052634309425846904, 0.03894582773192301, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.048092092505865214, 0.03715548798033963, 0.05212150591107367, 0.08990089282941105, 0.08809449075929132, 0.0903673357016882, 0.032939959482793824, 0.03233375463166144, 0.03346962320234026, 0.08353553034340455, 0.08081824486534017, 0.09302676707440838, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016014298152308704, 0.016465099099989167, 0.01806351705384235, 0.015601928511874696, 0.015875130843063245, 0.01254416030693939, 0.12650331811805438, 0.12957492974603957, 0.13467981895364523, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "8183873f-f637-4210-92b3-54a7c619eac5", "fitness": 0.027908616458532605, "name": "HQIPSO", "description": "Introduce a dynamic adjustment to the cognitive coefficient to enhance exploration and exploitation balance in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.005913800295372362, 0.009565343106690327, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42165878831588977, 0.01450478621318907, 0.028947361273120253, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.057678641355676796, 0.05017859627487631, 0.03002931218757887, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053695201339281406, 0.04844521660032142, 0.05236126663246354, 0.08173870307592757, 0.08420389131058859, 0.08823953554995978, 0.02416912439843477, 0.020696674483760447, 0.03096211044137631, 0.07759126944155659, 0.07854567252411704, 0.0641370055725139, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.01656332438915642, 0.017286013894948216, 0.01865133700685495, 0.01484237513746045, 0.015180965968367488, 0.013992745008043372, 0.12364081458499032, 0.1489399162928028, 0.1241366205900093, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "93d2582d-f6c1-4db8-b222-33185916c3dd", "fitness": 0.021170100047727996, "name": "HQIPSO", "description": "Introduce a non-linear dynamic adjustment for the cognitive coefficient to enhance exploration.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        # c1 = 1.5  # Original linear cognitive coefficient\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n            c1 = 1.5 * (np.cos(np.pi * self.evaluations / self.budget) + 1)  # Non-linear dynamic cognitive coefficient\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.007093543017105741, 0.0067712011972522745, 0.00447625720643563, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.03608295794919725, 0.011001598178918326, 0.031055556470701795, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.035415766621250344, 0.05101588464660134, 0.030445661488167297, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04777902970259684, 0.04112004925061352, 0.05236126663246354, 0.08960981028208503, 0.08057058010202212, 0.07977679843389729, 0.03321321626269702, 0.026568464293535876, 0.02623412451421403, 0.07055263980315996, 0.06694646218783584, 0.05528704262349182, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014444112134016862, 0.01493366565901244, 0.01762920571224369, 0.0144197451122422, 0.012710130009980558, 0.013129243895646292, 0.12403444228180205, 0.12393819053823063, 0.12302186157682526, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "1f019be0-411a-4cde-9eaa-9de3777f07d3", "fitness": 0.01959730469485703, "name": "HQIPSO", "description": "Introduce velocity normalization to enhance convergence stability and prevent overshooting in HQIPSO.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.velocities[i] = self.velocities[i] / np.linalg.norm(self.velocities[i])  # Normalize velocity\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004605301815538643, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.028804234715535837, 0.043022479212314835, 0.02172239326414649, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.047463947804480267, 0.038932009621562624, 0.03366506147377846, 0.08185981603809855, 0.08116553895821044, 0.07970413727289294, 0.022510902301237423, 0.02420829031534566, 0.022736795203201488, 0.07314001014791283, 0.07048187469795064, 0.07512547877412634, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.014035637710993254, 0.015766176094702322, 0.015798043496814906, 0.013426413817966276, 0.014376177489773823, 0.011734915290186887, 0.12769492772376012, 0.1232567614540454, 0.12142078724817451, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "47ea230f-9df5-4352-b4d4-4021d6040725", "fitness": 0.02193715213220042, "name": "HQIPSO", "description": "Introduce dynamic cognitive coefficient to enhance exploration capability.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c1 = 1.5 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamic cognitive coefficient\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.008308095783876368, 0.004655996738528456, 0.005333067427938265, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.034431871732436115, 0.014444981207149654, 0.03514429455731738, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04741692389723329, 0.05010356228697466, 0.037244935175611005, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.04887984232006637, 0.0544697259487914, 0.05236126663246354, 0.08748478190372899, 0.08422558995281526, 0.08575442429933222, 0.02279219356958906, 0.027125407314387395, 0.030354613703862277, 0.07166797604922304, 0.0670770022759648, 0.05725046882758256, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015120423981575537, 0.017639155447025545, 0.020034330043920412, 0.012392502214779832, 0.013272708106569664, 0.014751402156277793, 0.12906493563377275, 0.12383922762057953, 0.12422455105688424, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "2821f6e7-242a-471d-b29b-db01161d32ea", "fitness": 0.027858865046368513, "name": "HQIPSO", "description": "HQIPSO with adaptive personal learning rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                adaptive_c1 = c1 * (1 + 0.1 * (self.evaluations / self.budget))  # Adaptive personal learning rate\n                cognitive_velocity = adaptive_c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.006640419643980766, 0.009166866023981535, 0.010776519211756708, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.4215790961295407, 0.01473082087003219, 0.028928278995595802, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.054202194570245, 0.04937830702941848, 0.029903941011276025, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05340668087593925, 0.045499035319387926, 0.052812904637642655, 0.08332971640458298, 0.08386050804499146, 0.08219461498714775, 0.024355851828710362, 0.025565308140940934, 0.029778417001184332, 0.07599645632955587, 0.0712001517510088, 0.06656615039926417, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.016067870090511582, 0.015212812849161206, 0.018870765332279826, 0.012248409892103629, 0.015150226852408966, 0.01389639370996032, 0.12557602870594353, 0.155518170158651, 0.13081667088915627, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "8fd8dfc9-aa94-4738-b3f1-829996b060a7", "fitness": 0.023150183934119394, "name": "HQIPSO", "description": "Introduce a conditional strategy to apply quantum-inspired movement only when the global best score isn't improved for consecutive iterations.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.stagnation_counter = 0  # Initialize stagnation counter\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n        \n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                    self.stagnation_counter = 0  # Reset counter if improvement\n                else:\n                    self.stagnation_counter += 1  # Increment counter if no improvement\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement conditionally applied\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i]) if self.stagnation_counter > 5 else 0\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.019344698090215773, 0.015369750290685436, 0.010315276096846127, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.019815217936924534, 0.0060429741685738, 0.022437652995896507, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.05968896614706021, 0.05672129727702957, 0.02592418264608698, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.053695201339281406, 0.048648505489634175, 0.04302036861515057, 0.08173870307592757, 0.09520267340075339, 0.09650015233220044, 0.026260484674090256, 0.02288442851260275, 0.03790557836693187, 0.07759126944155659, 0.09617419115085535, 0.06950395645612806, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015677382018076336, 0.017286013894948216, 0.019080146217438254, 0.014356878318204314, 0.015180965968367488, 0.014509948668481432, 0.12790661196405084, 0.1489399162928028, 0.12648115575762242, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
{"id": "6fdd8e61-0a75-4ece-8888-961c0b62fa77", "fitness": 0.027265995678598713, "name": "HQIPSO", "description": "HQIPSO with adaptive inertia weight range to improve exploitation and exploration balance.", "code": "import numpy as np\n\nclass HQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5, int(np.sqrt(budget)))  # Dynamic population size\n        self.positions = np.random.uniform(-5.0, 5.0, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.pop_size, np.inf)\n        self.global_best_position = np.zeros(dim)\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def __call__(self, func):\n        c1 = 1.5  # Cognitive coefficient\n\n        while self.evaluations < self.budget:\n            beta = 0.8 + 0.2 * (1 - self.evaluations / self.budget)  # Adaptive beta\n            w = 0.3 + 0.4 * (1 - self.evaluations / self.budget)  # Adaptive inertia weight\n            c2 = 0.5 + 2.0 * (self.evaluations / self.budget)  # Adaptive social coefficient\n            damping_factor = 0.95 * (0.9 + 0.1 * (self.evaluations / self.budget))  # Adaptive damping factor\n\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < self.global_best_score and np.linalg.norm(self.positions[i] - self.global_best_position) > 0.1:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # Quantum-inspired movement\n                quantum_move = beta * np.sin(2 * np.pi * r1) * (self.global_best_position - self.positions[i])\n\n                # Standard PSO updates\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] *= damping_factor  # Apply damping factor to velocity\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_move\n                self.positions[i] += self.velocities[i]\n                \n                # Ensure positions are within bounds\n                self.positions[i] = np.clip(self.positions[i], -5.0, 5.0)\n        \n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm HQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.06.", "error": "", "parent_ids": ["b480b0db-54bf-4c79-960f-7506b855d32d"], "operator": null, "metadata": {"aucs": [0.004460741467895102, 0.010893116681143566, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.42238922235638665, 0.02452429095781461, 0.030258746158974614, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.044775995055322926, 0.04924451663323781, 0.02711051886275273, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.052705628987955055, 0.04559533421603168, 0.05206168894727181, 0.08052216392457556, 0.084153396469834, 0.0871529391437762, 0.026721886856031385, 0.02180475986906416, 0.02544788646652274, 0.07965279583058926, 0.07032899320754471, 0.06691013725830441, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497, 0.015962365893194663, 0.018053907637755162, 0.01860109076852512, 0.014375766077092234, 0.015067656417147357, 0.014306453787094386, 0.12548118140006626, 0.12252787965374667, 0.1251041061343272, 0.004347826086956497, 0.004347826086956497, 0.004347826086956497]}}
