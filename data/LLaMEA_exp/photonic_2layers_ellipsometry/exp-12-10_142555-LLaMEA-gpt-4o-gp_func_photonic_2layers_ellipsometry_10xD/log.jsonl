{"id": "e7841218-c52b-44c5-a445-b001f3e44f73", "fitness": 0.11910360175797985, "name": "DMDE", "description": "A dynamic mutation-based Differential Evolution (DMDE) algorithm that adapts mutation strategies based on performance feedback to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 0, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "8b2f1867-d92c-4aa7-b968-4d0bcf1b5f0b", "fitness": 0.11910360175797985, "name": "ADMDE", "description": "Adaptive Dual Mutation Differential Evolution (ADMDE) integrates dynamic adaptation of both mutation factor and crossover probability to balance exploration and exploitation effectively over time.", "code": "import numpy as np\n\nclass ADMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        return (candidate, candidate_fitness) if candidate_fitness < target_fitness else (target, target_fitness)\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Adaptive strategy for F and CR\n        self.F = 0.5 + 0.5 * (iteration / max_iterations)  # Linearly increase F\n        self.CR = 0.9 - 0.3 * (iteration / max_iterations)  # Linearly decrease CR\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        \n        max_iterations = self.budget // self.pop_size\n\n        for iteration in range(max_iterations):\n            self.adapt_parameters(iteration, max_iterations)\n            \n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 1, "feedback": "The algorithm ADMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "3fff25fd-f149-4e09-8d64-19687a775d01", "fitness": 0.11910360175797985, "name": "SADE", "description": "A self-adaptive Differential Evolution (SADE) approach that dynamically adjusts control parameters (F and CR) using historical success rates to enhance convergence speed and accuracy.  ", "code": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.F = 0.5  # initial mutation factor\n        self.CR = 0.9  # initial crossover probability\n        self.current_evaluations = 0\n        self.successful_F = []\n        self.successful_CR = []\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F = self._adapt_parameter(self.successful_F, 0.1, 0.9)\n        return a + F * (b - c)\n\n    def crossover(self, target, donor):\n        CR = self._adapt_parameter(self.successful_CR, 0.1, 0.9)\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, candidate_fitness, target_fitness):\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness, True\n        return target, target_fitness, False\n\n    def _adapt_parameter(self, successful_params, lower_bound, upper_bound):\n        if successful_params:\n            return np.mean(successful_params)\n        else:\n            return np.random.uniform(lower_bound, upper_bound)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                trial_fitness = func(trial_vector)\n                population[i], fitness[i], success = self.select(trial_vector, population[i], trial_fitness, fitness[i])\n                self.current_evaluations += 1\n                if success:\n                    self.successful_F.append(self.F)\n                    self.successful_CR.append(self.CR)\n\n                if self.current_evaluations >= self.budget:\n                    break\n\n            # Reset successful parameters after some iterations to avoid bias\n            if len(self.successful_F) > self.pop_size:\n                self.successful_F = []\n            if len(self.successful_CR) > self.pop_size:\n                self.successful_CR = []\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 2, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "e3b57857-3f8f-4437-9fb2-8f3caa2f7338", "fitness": 0.11910360175797985, "name": "DMDE", "description": "A hybrid adaptive mutation and crossover strategy in Differential Evolution to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.adaptive_CR = 0.9  # Adaptive Crossover Probability\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.adaptive_CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def adaptive_strategy(self, iteration):\n        self.adaptive_CR = 0.9 - 0.5 * (iteration / (self.budget / self.pop_size))\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        iteration = 0\n        while self.current_evaluations < self.budget:\n            self.adaptive_strategy(iteration)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            iteration += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "0ea1d779-c1eb-42c2-992b-94e2d83deec8", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An adaptive mutation-based Differential Evolution algorithm, enhancing mutation factor dynamically based on diversity metrics to improve convergence efficiency.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        div_factor = np.std(population, axis=0).mean()  # Compute diversity\n        adaptive_F = self.F * (1 + 0.5 * (div_factor / self.dim))\n        return a + adaptive_F * (b - c)  # Use adaptive mutation factor\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 4, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "aac6024f-9256-43cf-b3b6-737def97c5e3", "fitness": 0.11910360175797985, "name": "EDMDE", "description": "Enhanced Dynamic Mutation-based Differential Evolution (EDMDE) incorporating adaptive parameter control and elitism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size\n        self.current_evaluations = 0\n        self.CR = 0.9  # Initial crossover probability\n        self.F = 0.5  # Initial mutation factor\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, best_idx):\n        best = population[best_idx]\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F = np.random.uniform(0.4, 0.9)  # Adaptively varying F\n        return a + F * (b - c) + F * (best - a)  # Incorporate elitism with best solution\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            best_idx = np.argmin(fitness)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, best_idx)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            # Adaptive control of CR based on performance\n            if np.random.rand() < 0.1:\n                self.CR = np.random.uniform(0.7, 1.0)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm EDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "ec65835c-578d-4285-a124-5af3ce7993f1", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An adaptive Differential Evolution algorithm with dynamic crossover and mutation strategies based on population diversity.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  \n        self.CR = 0.9  \n        self.F = 0.5  \n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def adaptive_factors(self, population):\n        diversity = np.std(population, axis=0)\n        self.CR = 0.9 * (1 - np.mean(diversity) / np.max(diversity))\n        self.F = 0.5 + 0.5 * (np.mean(diversity) / np.max(diversity))\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  \n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adaptive_factors(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "469838b3-7f74-496f-9ce2-b0840708a494", "fitness": 0.11901181452453012, "name": "HSDE", "description": "A hybrid swarm-enhanced Differential Evolution (HSDE) that integrates adaptive velocity updates from Particle Swarm Optimization to improve convergence and diversity.", "code": "import numpy as np\n\nclass HSDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n        # Initialize PSO-related parameters\n        self.velocity = np.random.rand(self.pop_size, self.dim)\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social coefficient\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, idx, population, personal_best, global_best):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive = self.c1 * r1 * (personal_best[idx] - population[idx])\n        social = self.c2 * r2 * (global_best - population[idx])\n        self.velocity[idx] = self.w * self.velocity[idx] + cognitive + social\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        personal_best = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                self.update_velocity(i, population, personal_best, global_best)\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                if fitness[i] < personal_best_fitness[global_best_idx]:\n                    global_best_idx = i\n                    global_best = population[i]\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm HSDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11901 with standard deviation 0.04913.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16158315115097266, 0.1616228920032612, 0.16115582776231197, 0.14550233606188578, 0.1455190924045786, 0.1452581728071749, 0.05015734654899939, 0.050157631417625304, 0.05014988056396119]}}
{"id": "f9f531fb-cba3-4920-bcfa-57fc50b4e06b", "fitness": 0.11910360175797985, "name": "DMDEPlus", "description": "A dual-mutation strategy Differential Evolution (DMDE+) that dynamically adjusts mutation tactics and employs a secondary population to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DMDEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F_base = 0.5\n        self.current_evaluations = 0\n        self.elite_size = max(1, self.pop_size // 10)  # Maintain an elite pool\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, elite_population, strategy=\"base\"):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        if strategy == \"base\":\n            a, b, c = population[indices]\n        elif strategy == \"elite\":\n            elite_indices = np.random.choice(len(elite_population), 2, replace=False)\n            a, b = elite_population[elite_indices]\n            c = population[indices[0]]\n        factor = self.F_base if strategy == \"base\" else self.F_base * 1.2\n        return a + factor * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_elite_population(self, population, fitness):\n        elite_indices = np.argsort(fitness)[:self.elite_size]\n        return population[elite_indices]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        elite_population = self.update_elite_population(population, fitness)\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                strategy = \"base\" if i % 2 == 0 else \"elite\"\n                donor_vector = self.mutate(i, population, elite_population, strategy)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            elite_population = self.update_elite_population(population, fitness)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm DMDEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "dbb6bdd4-5e66-4d5e-9a78-6f802dcf9e78", "fitness": 0.11910360175797985, "name": "ImprovedDMDE", "description": "Introducing adaptive parameter control and a diversity maintenance strategy to the existing DMDE algorithm for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, F):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, success_rate):\n        if success_rate > 0.2:\n            self.F = min(self.F * 1.1, 1.0)\n            self.CR = max(self.CR * 0.9, 0.1)\n        else:\n            self.F = max(self.F * 0.9, 0.1)\n            self.CR = min(self.CR * 1.1, 1.0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            successful_trials = 0\n            for i in range(self.pop_size):\n                F_adapted = self.F * (1 + np.random.uniform(-0.1, 0.1))\n                CR_adapted = self.CR * (1 + np.random.uniform(-0.1, 0.1))\n                \n                donor_vector = self.mutate(i, population, F_adapted)\n                trial_vector = self.crossover(population[i], donor_vector, CR_adapted)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                candidate, candidate_fitness = self.select(trial_vector, population[i], func)\n                \n                if candidate_fitness < fitness[i]:\n                    successful_trials += 1\n                \n                population[i] = candidate\n                fitness[i] = candidate_fitness\n                self.current_evaluations += 1\n                \n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.adapt_parameters(successful_trials / self.pop_size)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 9, "feedback": "The algorithm ImprovedDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "71c80019-3962-4d16-9c58-c296d4f5b0ac", "fitness": 0.11910360175797985, "name": "M_DMDE", "description": "A Memetic Dynamic Mutation Differential Evolution (M-DMDE) algorithm that integrates local search techniques and adaptive mutation strategies to boost convergence speed and solution quality.", "code": "import numpy as np\n\nclass M_DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, fitness):\n        # Adapting mutation factor based on fitness variability\n        if np.std(fitness) > 0.1:\n            self.F = 0.5 + np.random.rand() * 0.5\n        else:\n            self.F = 0.5\n        \n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def local_search(self, candidate, func, bounds):\n        # Simple perturbation-based local search\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        local_candidate = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n        local_fitness = func(local_candidate)\n        candidate_fitness = func(candidate)\n        return (local_candidate, local_fitness) if local_fitness < candidate_fitness else (candidate, candidate_fitness)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, fitness)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                \n                # Apply local search occasionally\n                if np.random.rand() < 0.2:\n                    population[i], fitness[i] = self.local_search(population[i], func, bounds)\n                    self.current_evaluations += 1\n                \n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 10, "feedback": "The algorithm M_DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "3e74a7c2-c3a8-4af7-b8b8-0ce7dc68a30b", "fitness": 0.11910360175797985, "name": "ADE", "description": "An Adaptive Differential Evolution (ADE) algorithm that dynamically adjusts mutation and crossover parameters based on historical performance to balance exploration and exploitation in black-box optimization tasks.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.success_history = []\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.success_history.append((True, candidate_fitness))\n            return candidate, candidate_fitness\n        else:\n            self.success_history.append((False, target_fitness))\n            return target, target_fitness\n\n    def adapt_parameters(self):\n        if len(self.success_history) > 10:\n            recent_successes = sum(success for success, _ in self.success_history[-10:])\n            if recent_successes > 5:\n                self.CR = min(1.0, self.CR + 0.1)\n                self.F = min(1.0, self.F + 0.1)\n            else:\n                self.CR = max(0.1, self.CR - 0.1)\n                self.F = max(0.1, self.F - 0.1)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.adapt_parameters()\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "9522ecab-2b69-4fff-87fc-1d4a3e9ee196", "fitness": 0.11910360175797985, "name": "EnhancedDMDE", "description": "An enhanced DMDE algorithm incorporating adaptive mutation and crossover rates based on population diversity to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR_base = 0.9\n        self.F_base = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n    \n    def calculate_diversity(self, population):\n        return np.std(population, axis=0).mean()\n    \n    def mutate(self, idx, population, diversity):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F = self.F_base * (1 + diversity)\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, diversity):\n        CR = self.CR_base * (1 - diversity)\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, diversity)\n                trial_vector = self.crossover(population[i], donor_vector, diversity)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a6213311-8fa4-4e97-a211-8136d9d7c10c", "fitness": 0.11910360175797985, "name": "APSDE", "description": "Adaptive Population Size Differential Evolution (APSDE) dynamically adjusts the population size based on convergence rates to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass APSDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.pop_size = self.initial_pop_size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adjust_population_size(self, fitness, stagnation_threshold=50):\n        if len(set(fitness[-stagnation_threshold:])) == 1:  # Check for stagnation\n            self.pop_size = max(self.initial_pop_size // 2, 4)  # Reduce population\n        else:\n            self.pop_size = min(self.initial_pop_size, self.pop_size + 1)  # Increase population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            previous_fitness = fitness.copy()\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            if self.current_evaluations < self.budget:\n                self.adjust_population_size(fitness)\n\n            best_idx = np.argmin(fitness)\n            population = population[np.argsort(fitness)]\n            fitness = np.sort(fitness)\n            population = population[:self.pop_size]\n            fitness = fitness[:self.pop_size]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 13, "feedback": "The algorithm APSDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "8a7b967d-ee69-4902-bb28-c92682f01c44", "fitness": 0.11910360175797985, "name": "ADFEDS", "description": "Adaptive Differential Evolution with Fitness-based Dynamic Strategy (ADFEDS) enhances DMDE by incorporating fitness-based adaptation for mutation and crossover rates to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass ADFEDS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.mutation_change_threshold = 0.1\n        self.crossover_change_threshold = 0.05\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, fitness):\n        sorted_indices = np.argsort(fitness)\n        a, b, c = population[sorted_indices[:3]]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor, fitness):\n        sorted_indices = np.argsort(fitness)\n        best_idx = sorted_indices[0]\n        if fitness[best_idx] < np.mean(fitness):\n            self.CR += self.crossover_change_threshold\n        else:\n            self.CR -= self.crossover_change_threshold\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        \n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, fitness)\n                trial_vector = self.crossover(population[i], donor_vector, fitness)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 14, "feedback": "The algorithm ADFEDS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "23b71e4b-7a20-43c0-abad-39765d45936f", "fitness": 0.11910360175797985, "name": "DMDE", "description": "Enhanced DMDE algorithm introducing adaptive crossover rates based on diversity to improve convergence through balanced exploration and exploitation.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def adaptive_crossover_rate(self, population):\n        diversity = np.std(population, axis=0).mean() / (population.max() - population.min() + 1e-9)\n        return 0.5 + 0.4 * (1 - diversity)\n    \n    def crossover(self, target, donor, cr):\n        crossover_mask = np.random.rand(self.dim) < cr\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                cr = self.adaptive_crossover_rate(population)\n                trial_vector = self.crossover(population[i], donor_vector, cr)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 15, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "7cbd5bb9-2d75-41bb-88a8-f50bde125778", "fitness": 0.11910360175797985, "name": "DMDE", "description": "A dynamic mutation-based Differential Evolution (DMDE) algorithm with adaptive mutation factor and crossover rate based on population diversity to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.initial_CR = 0.9  # initial crossover probability\n        self.initial_F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def adaptive_parameters(self, fitness):\n        diversity = np.std(fitness)\n        CR = self.initial_CR * (1 + diversity / (1 + diversity))\n        F = self.initial_F * (1 - diversity / (1 + diversity))\n        return CR, F\n\n    def mutate(self, idx, population, F):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            CR, F = self.adaptive_parameters(fitness)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, F)\n                trial_vector = self.crossover(population[i], donor_vector, CR)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 16, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "1b8a2206-3401-4f7b-86c1-e5667a19ae7f", "fitness": 0.11910360175797985, "name": "AdaptiveDMDE", "description": "An adaptive Differential Evolution that dynamically adjusts both mutation strategies and population size based on convergence speed and diversity to enhance flexibility in exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_pop_size = 10 * dim\n        self.CR = 0.9\n        self.F_init = 0.5\n        self.F = self.F_init\n        self.current_evaluations = 0\n        self.pop_size = self.init_pop_size\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def dynamic_mutation_factor(self, diversity):\n        return self.F_init * np.exp(-diversity)\n\n    def calculate_diversity(self, population):\n        center = np.mean(population, axis=0)\n        return np.mean(np.linalg.norm(population - center, axis=1))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        return (candidate, candidate_fitness) if candidate_fitness < target_fitness else (target, target_fitness)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.F = self.dynamic_mutation_factor(diversity)\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n\n                if self.current_evaluations >= self.budget:\n                    break\n\n            # Dynamically adjust the population size based on convergence\n            best_idx = np.argmin(fitness)\n            if self.current_evaluations % (self.init_pop_size * 2) == 0:\n                improvement_rate = np.abs(fitness[best_idx] - np.median(fitness)) / np.mean(fitness)\n                if improvement_rate < 0.01:  # If convergence is slow\n                    self.pop_size = max(4, self.pop_size // 2)\n                    population = population[:self.pop_size]\n                    fitness = fitness[:self.pop_size]\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "47acc80c-a693-4d1a-a6a3-17b037dbbc4d", "fitness": 0.11910360175797985, "name": "AMR_DE", "description": "Introducing Adaptive Mutation Rates (AMR-DE) into the DMDE framework, which dynamically adjusts mutation factors and crossover probabilities based on historical success rates to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AMR_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.mutation_adapt_rate = 0.1\n        self.crossover_adapt_rate = 0.1\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness, True\n        return target, target_fitness, False\n\n    def adapt_parameters(self, success_rate):\n        self.F = np.clip(self.F + self.mutation_adapt_rate * (success_rate - 0.5), 0.1, 0.9)\n        self.CR = np.clip(self.CR + self.crossover_adapt_rate * (success_rate - 0.5), 0.1, 0.9)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i], success = self.select(trial_vector, population[i], func)\n                if success:\n                    successful_mutations += 1\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            success_rate = successful_mutations / self.pop_size\n            self.adapt_parameters(success_rate)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm AMR_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "75e4d723-1d4b-4ff6-a5b1-27d81b2aa39a", "fitness": 0.11910360175797985, "name": "EDE", "description": "An enhanced Differential Evolution (EDE) algorithm with adaptive crossover rate and mutation factor to improve convergence speed and robustness.", "code": "import numpy as np\n\nclass EDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n        self.adaptation_threshold = int(0.1 * budget)\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_adapted = self.F * np.random.uniform(0.5, 1.5)  # Adaptive mutation factor\n        return a + F_adapted * (b - c)\n\n    def crossover(self, target, donor):\n        CR_adapted = np.clip(self.CR * np.random.uniform(0.5, 1.5), 0, 1)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < CR_adapted\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            if self.current_evaluations % self.adaptation_threshold == 0:\n                self.CR = np.clip(np.mean(fitness) / np.min(fitness), 0.1, 0.9)  # Update CR dynamically\n                self.F = np.clip(self.CR, 0.4, 0.9)  # Update F based on CR\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 19, "feedback": "The algorithm EDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "25f7531e-fe26-4de5-806e-c0891ba20b36", "fitness": 0.11910360175797985, "name": "CoDE", "description": "A Coevolutionary Differential Evolution (CoDE) algorithm that incorporates coevolutionary strategies to leverage subpopulation interactions for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass CoDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(20, 7 * dim)  # Larger population for diverse exploration\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, bounds):\n        # Select three random distinct indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        donor = a + self.F * (b - c)\n        \n        # Coevolutionary strategy: create a hybrid donor by blending with a random individual\n        rand_indiv_idx = np.random.choice(self.pop_size)\n        rand_indiv = population[rand_indiv_idx]\n        hybrid_donor = np.random.uniform(0.4, 0.6) * donor + np.random.uniform(0.4, 0.6) * rand_indiv\n        return np.clip(hybrid_donor, bounds.lb, bounds.ub)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Ensure at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, bounds)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm CoDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "2f8bc143-78db-44b3-b6cc-48bdea983009", "fitness": 0.11910360175797985, "name": "IDMDE", "description": "Improved Dynamic Mutation-based Differential Evolution (IDMDE) with adaptive mutation factor and crossover probability to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass IDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.F_min = 0.4\n        self.F_max = 0.9\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, success_rate):\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * success_rate\n        self.F = self.F_min + (self.F_max - self.F_min) * success_rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        successful_mutations = 0\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                previous_fitness = fitness[i]\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < previous_fitness:\n                    successful_mutations += 1\n                \n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            success_rate = successful_mutations / self.pop_size\n            self.adapt_parameters(success_rate)\n            successful_mutations = 0\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 21, "feedback": "The algorithm IDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "5bc95f55-a367-406a-be04-b56775c41fe8", "fitness": 0.11910360175797985, "name": "ADE", "description": "An Adaptive Differential Evolution (ADE) algorithm that dynamically adjusts mutation and crossover probabilities based on population diversity to enhance convergence efficiency.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.history = []\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self):\n        if len(self.history) >= 2:\n            diversity = np.std(self.history[-2:], axis=0).mean()\n            self.F = 0.4 + 0.1 * diversity\n            self.CR = 0.8 + 0.1 * diversity\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.history.append(np.copy(population))\n            self.adapt_parameters()\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 22, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "37d2fc1a-2077-48c6-8483-8daab27a42b9", "fitness": 0.11910360175797985, "name": "ASDE", "description": "An Adaptively Scaled Differential Evolution (ASDE) algorithm that enhances convergence speed by dynamically adjusting mutation factors based on population diversity.", "code": "import numpy as np\n\nclass ASDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.min_F = 0.3\n        self.max_F = 0.7\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def adapt_mutation_factor(self, population):\n        diversity = np.std(population, axis=0).mean()\n        self.F = self.min_F + ((self.max_F - self.min_F) * (1 - diversity))\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_mutation_factor(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 23, "feedback": "The algorithm ASDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "205b62cd-4c1a-4c09-9b2c-2e2a10e94250", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An adaptive DMDE algorithm that dynamically adjusts crossover probability and mutation factor based on success rates to improve convergence speed and precision.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n        self.success_rate = 0.2  # Initial success rate for adaptation\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask): \n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.success_rate = min(1.0, self.success_rate + 0.01)\n            return candidate, candidate_fitness\n        self.success_rate = max(0.0, self.success_rate - 0.01)\n        return target, target_fitness\n\n    def adapt_parameters(self):\n        if self.success_rate > 0.5:\n            self.CR = np.clip(self.CR + 0.01, 0.1, 1.0)\n            self.F = np.clip(self.F + 0.01, 0.1, 1.0)\n        else:\n            self.CR = np.clip(self.CR - 0.01, 0.1, 1.0)\n            self.F = np.clip(self.F - 0.01, 0.1, 1.0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n\n                self.adapt_parameters()\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 24, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "4d78d6c4-f2e7-42d5-9375-a298575e464e", "fitness": 0.11910360175797985, "name": "ADE", "description": "An Adaptive Differential Evolution (ADE) algorithm with dynamically changing crossover and mutation factors based on population diversity to improve convergence.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        diversity = np.std(population, axis=0).mean()\n        F_dynamic = self.F + 0.2 * (1 - diversity)\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        diversity = np.std(target)\n        CR_dynamic = self.CR * diversity\n        crossover_mask = np.random.rand(self.dim) < CR_dynamic\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 25, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "c92d0bdc-281a-4493-9a0e-c9d972031244", "fitness": 0.11910360175797985, "name": "ADE", "description": "An adaptive Differential Evolution (ADE) algorithm that dynamically adjusts crossover and mutation parameters based on the population's convergence rate to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR_initial = 0.9  # initial crossover probability\n        self.CR_min = 0.1  # minimum crossover probability\n        self.CR_max = 1.0  # maximum crossover probability\n        self.F_initial = 0.5  # initial mutation factor\n        self.F_min = 0.3  # minimum mutation factor\n        self.F_max = 0.8  # maximum mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, F):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, fitness):\n        diversity = np.std(fitness) / np.mean(fitness)\n        CR = self.CR_max - (self.CR_max - self.CR_min) * diversity\n        F = self.F_min + (self.F_max - self.F_min) * diversity\n        return CR, F\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                CR, F = self.adapt_parameters(fitness)\n                donor_vector = self.mutate(i, population, F)\n                trial_vector = self.crossover(population[i], donor_vector, CR)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 26, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "9786f501-d78f-477a-80fc-a7737eac89d0", "fitness": 0.11910360175797985, "name": "ADE_DPM", "description": "Adaptive Differential Evolution with Dynamic Population Management (ADE-DPM) incorporates adaptive mutation strategies and dynamically adjusts population size based on convergence trends to balance exploration and exploitation efficiently.", "code": "import numpy as np\n\nclass ADE_DPM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # initial population size\n        self.CR = 0.9  # crossover probability\n        self.F_min = 0.4  # minimum mutation factor\n        self.F_max = 0.9  # maximum mutation factor\n        self.current_evaluations = 0\n        self.population = None\n        self.fitness = None\n        self.bounds = None\n\n    def generate_population(self):\n        lb, ub = self.bounds.lb, self.bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[indices]\n        # Adaptive mutation factor\n        F = np.random.uniform(self.F_min, self.F_max)\n        return a + F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, candidate_fitness, target_fitness):\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_population_size(self):\n        # Dynamically adjust population size based on convergence\n        improvement_rate = np.std(self.fitness) / max(np.mean(self.fitness), 1e-9)\n        if improvement_rate < 0.01:  # If convergence is too slow\n            self.pop_size = min(self.pop_size + 1, 20 * self.dim)  # Increase population\n        elif improvement_rate > 0.1:  # If convergence is too fast\n            self.pop_size = max(self.pop_size - 1, 5 * self.dim)  # Decrease population\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population = self.generate_population()\n        self.fitness = np.array([func(ind) for ind in self.population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.update_population_size()\n            new_population = np.zeros((self.pop_size, self.dim))\n            new_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i)\n                trial_vector = self.crossover(self.population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, self.bounds.lb, self.bounds.ub)\n\n                candidate_fitness = func(trial_vector)\n                self.current_evaluations += 1\n\n                new_population[i], new_fitness[i] = self.select(\n                    trial_vector, self.population[i], candidate_fitness, self.fitness[i]\n                )\n\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]", "configspace": "", "generation": 27, "feedback": "The algorithm ADE_DPM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "2afb9f87-b911-4587-ac64-98a538299487", "fitness": 0.11910360175797985, "name": "ADE", "description": "An adaptive Differential Evolution (ADE) algorithm that dynamically tunes crossover and mutation parameters based on population diversity to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, diversity_factor):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * diversity_factor * (b - c)\n\n    def crossover(self, target, donor, diversity_factor):\n        adaptive_CR = self.CR * diversity_factor\n        crossover_mask = np.random.rand(self.dim) < adaptive_CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            diversity_factor = np.std(population) / (np.mean(population) + 1e-6)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, diversity_factor)\n                trial_vector = self.crossover(population[i], donor_vector, diversity_factor)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 28, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "2077b5c8-8bbc-4429-b0f3-e8eb25223a8f", "fitness": 0.11910360175797985, "name": "ADE", "description": "An adaptive Differential Evolution (ADE) algorithm enhances DMDE by dynamically adjusting the mutation factor and crossover rate based on population diversity to improve convergence and robustness.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_parameters(self, population):\n        # Update F and CR based on population diversity\n        diversity = np.std(population, axis=0).mean()\n        self.F = 0.1 + 0.9 * (diversity / self.dim)\n        self.CR = 0.1 + 0.8 * (1 - diversity / self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.update_parameters(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 29, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "d9f0c8a3-5393-40a6-8320-239015db8d1f", "fitness": 0.11910360175797985, "name": "DMDE", "description": "DMDE with adaptive crossover to dynamically adjust exploration and exploitation balance based on population diversity.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adjust_cr(self, fitness):\n        diversity = np.std(fitness)\n        self.CR = min(1.0, 0.7 + 0.3 * (diversity / np.mean(fitness)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adjust_cr(fitness)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 30, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "930d5fba-10ac-47fc-83a5-befe10d66d5a", "fitness": 0.11910360175797985, "name": "ADDE", "description": "An adaptive Differential Evolution algorithm (ADDE) utilizing adaptive mutation factor and crossover probability based on the diversity of the population for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass ADDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def adapt_parameters(self, population):\n        diversity = np.mean(np.std(population, axis=0))\n        self.F = 0.5 + 0.3 * (1 - diversity)\n        self.CR = 0.9 - 0.3 * diversity\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 31, "feedback": "The algorithm ADDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "db23cb08-0b29-43b6-b112-9a40e0d0879f", "fitness": 0.11910360175797985, "name": "DMDE_Adaptive", "description": "Introduces adaptive mutation and crossover probabilities in DMDE to improve convergence by dynamically adjusting strategies based on population diversity.", "code": "import numpy as np\n\nclass DMDE_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def calculate_diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def mutate(self, idx, population, diversity):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        adaptive_F = self.F + 0.1 * (1.0 - diversity)\n        return a + adaptive_F * (b - c)\n\n    def adaptive_crossover(self, diversity):\n        return self.CR * diversity\n\n    def crossover(self, target, donor, diversity):\n        crossover_rate = self.adaptive_crossover(diversity)\n        crossover_mask = np.random.rand(self.dim) < crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, diversity)\n                trial_vector = self.crossover(population[i], donor_vector, diversity)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 32, "feedback": "The algorithm DMDE_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "f8688c62-d3f8-47db-a236-491a19ba4fd6", "fitness": 0.11910360175797985, "name": "DMDE", "description": "A dynamic mutation-based Differential Evolution (DMDE) with adaptive crossover and mutation probabilities based on population diversity to enhance convergence speed.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        diversity_factor = np.std(population)\n        F = self.F + 0.1 * diversity_factor  # Adaptive mutation factor\n        return a + F * (b - c)\n\n    def crossover(self, target, donor):\n        diversity_factor = np.std(target - donor)\n        CR = self.CR - 0.1 * diversity_factor  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 33, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "7f749a08-6855-4987-9e9c-c26cf90a8cdc", "fitness": 0.11910360175797985, "name": "ADEDL", "description": "The Adaptive Differential Evolution with Dynamic Learning (ADEDL) algorithm improves upon DMDE by incorporating dynamic learning rates for mutation and crossover probabilities, enhancing both exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass ADEDL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.initial_CR = 0.9\n        self.initial_F = 0.5\n        self.current_evaluations = 0\n        self.CR = np.full(self.pop_size, self.initial_CR)\n        self.F = np.full(self.pop_size, self.initial_F)\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor, idx):\n        crossover_mask = np.random.rand(self.dim) < self.CR[idx]\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func, idx):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.update_parameters(success=True, idx=idx)\n            return candidate, candidate_fitness\n        self.update_parameters(success=False, idx=idx)\n        return target, target_fitness\n\n    def update_parameters(self, success, idx):\n        learning_rate = 0.1\n        if success:\n            self.CR[idx] = min(1.0, self.CR[idx] + learning_rate * (1.0 - self.CR[idx]))\n            self.F[idx] = min(1.0, self.F[idx] + learning_rate * (1.0 - self.F[idx]))\n        else:\n            self.CR[idx] = max(0.1, self.CR[idx] - learning_rate * (self.CR[idx] - 0.1))\n            self.F[idx] = max(0.1, self.F[idx] - learning_rate * (self.F[idx] - 0.1))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector, i)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func, i)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 34, "feedback": "The algorithm ADEDL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "e6bb8e97-14c2-4d30-b57f-f98b53af04ce", "fitness": 0.11910360175797985, "name": "DMDE", "description": "Introduce adaptive crossover and mutation rates based on population diversity to enhance search efficiency and solution quality.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor, diversity_factor):\n        adaptive_cr = self.CR * diversity_factor\n        crossover_mask = np.random.rand(self.dim) < adaptive_cr\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                diversity_factor = self.diversity(population)\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector, diversity_factor)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 35, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "53196e19-81c0-4601-ba57-faec2d1519c9", "fitness": 0.11910360175797985, "name": "DMCDE", "description": "A dynamic mutation and crossover-based Differential Evolution (DMCDE) algorithm that dynamically adjusts mutation and crossover rates based on convergence speed to enhance exploration and exploitation adaptively.", "code": "import numpy as np\n\nclass DMCDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n        self.best_fitness_history = []\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adjust_parameters(self):\n        if len(self.best_fitness_history) < 2:\n            return\n        improvement = self.best_fitness_history[-2] - self.best_fitness_history[-1]\n        if improvement < 0.01:  # if not improving much, enhance exploration\n            self.F = min(1.0, self.F + 0.1)\n            self.CR = max(0.1, self.CR - 0.1)\n        else:  # if improving, enhance exploitation\n            self.F = max(0.1, self.F - 0.1)\n            self.CR = min(1.0, self.CR + 0.1)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        best_idx = np.argmin(fitness)\n        self.best_fitness_history.append(fitness[best_idx])\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n                \n            best_idx = np.argmin(fitness)\n            self.best_fitness_history.append(fitness[best_idx])\n            self.adjust_parameters()\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 36, "feedback": "The algorithm DMCDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "aeea48ec-8478-416a-927c-b7cd75ac957a", "fitness": 0.11910360175797985, "name": "MSA_DE", "description": "A Multi-Strategy Adaptation DE (MSA-DE) algorithm that dynamically adjusts mutation and crossover strategies based on success history to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass MSA_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.success_rate = []\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def adaptive_mutation_factor(self):\n        if not self.success_rate:\n            return self.F\n        success_ratio = np.mean(self.success_rate[-min(10, len(self.success_rate)):])\n        adaptive_F = self.F + 0.1 * (success_ratio - 0.5)\n        return np.clip(adaptive_F, 0.1, 1.0)\n\n    def mutate(self, idx, population, adaptive_F):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + adaptive_F * (b - c)\n\n    def crossover(self, target, donor):\n        new_CR = np.random.normal(self.CR, 0.1)\n        new_CR = np.clip(new_CR, 0, 1)\n        crossover_mask = np.random.rand(self.dim) < new_CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.success_rate.append(1)\n            return candidate, candidate_fitness\n        self.success_rate.append(0)\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                adaptive_F = self.adaptive_mutation_factor()\n                donor_vector = self.mutate(i, population, adaptive_F)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 37, "feedback": "The algorithm MSA_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "9ee7eaf5-261a-4cc7-a617-fabf6b975228", "fitness": 0.11910360175797985, "name": "AMDE", "description": "An adaptive mutation-based Differential Evolution (AMDE) algorithm that employs adaptive control of mutation and crossover parameters based on success rates to improve convergence speed.", "code": "import numpy as np\n\nclass AMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.success_rate = 0  # Added success rate tracker\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        # Added adaptation based on success rate\n        adaptive_F = self.F * (1 + np.tanh(self.success_rate * 5))\n        return a + adaptive_F * (b - c)\n\n    def crossover(self, target, donor):\n        # Adapt crossover rate based on success\n        adaptive_CR = self.CR * (1 + 0.5 * (self.success_rate - 0.5))\n        crossover_mask = np.random.rand(self.dim) < adaptive_CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.success_rate = (self.success_rate * 0.9) + 0.1  # Update success rate\n            return candidate, candidate_fitness\n        self.success_rate *= 0.9  # Decay success rate\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 38, "feedback": "The algorithm AMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "68ebe0a9-bcbc-4238-9c04-fc0fd8cb9463", "fitness": 0.11910360175797985, "name": "SAMC_DE", "description": "A self-adaptive mutation and crossover DE algorithm (SAMC-DE) that dynamically adjusts parameters F and CR based on population diversity and performance to improve convergence and robustness.", "code": "import numpy as np\n\nclass SAMC_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n        self.diversity_threshold = 0.1  # Added for diversity-based adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def calculate_diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def adapt_parameters(self, population):\n        diversity = self.calculate_diversity(population)\n        if diversity < self.diversity_threshold:\n            self.F = np.clip(self.F * 1.2, 0.4, 1.0)\n            self.CR = np.clip(self.CR * 0.8, 0.1, 0.9)\n        else:\n            self.F = np.clip(self.F * 0.8, 0.4, 1.0)\n            self.CR = np.clip(self.CR * 1.2, 0.1, 0.9)\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters(population)  # Added for parameter adaptation\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm SAMC_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a021351e-5598-47a7-9ade-0b734c2b35e0", "fitness": 0.11910360175797985, "name": "EDMDE", "description": "An enhanced dynamic mutation-based Differential Evolution (EDMDE) with adaptive mutation and crossover rates based on historical success to improve search efficiency.", "code": "import numpy as np\n\nclass EDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.success_rate = 0\n        self.success_count = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.success_count += 1\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adjust_mutation_factor(self):\n        self.success_rate = self.success_count / self.pop_size\n        if self.success_rate > 0.2:\n            self.F = min(1.0, self.F + 0.1)\n        else:\n            self.F = max(0.4, self.F - 0.1)\n        self.success_count = 0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            self.adjust_mutation_factor()\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 40, "feedback": "The algorithm EDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "e2750417-0021-4dd3-8834-90f1c8a55204", "fitness": 0.11910360175797985, "name": "ADE", "description": "An Adaptive Differential Evolution (ADE) algorithm that dynamically adjusts mutation factor and crossover probability based on population diversity to enhance convergence efficiency.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F = self.dynamic_scaling(population)\n        return a + F * (b - c)\n\n    def crossover(self, target, donor):\n        CR = self.dynamic_crossover(target, donor)\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def dynamic_scaling(self, population):\n        diversity = np.mean(np.std(population, axis=0))\n        return np.clip(0.1 + diversity, 0.2, 0.9)\n\n    def dynamic_crossover(self, target, donor):\n        differences = np.linalg.norm(target - donor)\n        return np.clip(1 - differences/self.dim, 0.1, 0.9)\n    \n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 41, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "2ce5f672-d7e1-4392-a1c5-31d377c9c8aa", "fitness": 0.11910360175797985, "name": "DMDE", "description": "A Differential Evolution algorithm with adaptive control parameters and diversity preservation to enhance convergence and robustness.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self):\n        self.CR = 0.8 + 0.2 * np.random.rand()\n        self.F = 0.4 + 0.6 * np.random.rand()\n\n    def preserve_diversity(self, population):\n        mean_vector = np.mean(population, axis=0)\n        for i in range(self.pop_size):\n            if np.linalg.norm(population[i] - mean_vector) < 0.1:\n                population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.preserve_diversity(population)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 42, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "115329c4-ea15-4b2e-bb93-8dae7064fa86", "fitness": 0.11910360175797985, "name": "FCDMDE", "description": "A Feedback-Controlled Dynamic Mutation Differential Evolution (FCDMDE) that leverages adaptive mutation scaling based on convergence speed to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass FCDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n        self.convergence_rate = 0.1  # Initial convergence rate\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def adjust_mutation_factor(self, previous_best_fitness, current_best_fitness):\n        if current_best_fitness < previous_best_fitness:\n            self.F *= 1.05  # Increase mutation factor if improvement is observed\n        else:\n            self.F *= 0.95  # Decrease mutation factor if no improvement\n\n        # Keep F within reasonable bounds\n        self.F = np.clip(self.F, 0.1, 1.0)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        best_fitness = np.min(fitness)\n        previous_best_fitness = best_fitness\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            current_best_fitness = np.min(fitness)\n            self.adjust_mutation_factor(previous_best_fitness, current_best_fitness)\n            previous_best_fitness = current_best_fitness\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 43, "feedback": "The algorithm FCDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "5884340d-5747-456d-9d73-23505fc249ce", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An adaptive parameter control strategy for DMDE, dynamically adjusting mutation factor (F) and crossover probability (CR) based on population diversity to maintain a balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n    \n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n    \n    def adaptive_parameters(self, fitness):\n        diversity = np.std(fitness)\n        self.F = 0.4 + (0.5 - 0.4) * (diversity / (1 + diversity))\n        self.CR = 0.7 + (0.9 - 0.7) * (1 - diversity / (1 + diversity))\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adaptive_parameters(fitness)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 44, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "2a0c9747-c679-406b-9d18-17e9638939ce", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An enhanced DMDE with adaptive crossover and mutation strategies that dynamically adjust based on population diversity to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = np.random.rand() * (1.2 - 0.4) + 0.4  # adaptive mutation factor\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor, diversity_factor):\n        CR_dynamic = self.CR * diversity_factor  # adaptive crossover scale\n        crossover_mask = np.random.rand(self.dim) < CR_dynamic\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def diversity(self, population):\n        return np.std(population) / (np.mean(population) + 1e-9)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            diversity_factor = self.diversity(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector, diversity_factor)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 45, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a3cc4133-6eab-47c2-8d3c-ddcc796e8322", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An adaptive Differential Evolution algorithm that dynamically adjusts mutation and crossover rates based on population diversity and convergence trends to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_adj = np.random.uniform(0.4, 0.9)  # Adaptive mutation factor\n        return a + F_adj * (b - c)\n\n    def crossover(self, target, donor):\n        CR_adj = np.random.uniform(0.7, 1.0)  # Adaptive crossover probability\n        crossover_mask = np.random.rand(self.dim) < CR_adj\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n    \n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 46, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "51c4e4d4-b0a9-41e9-80bd-add65cc6ae77", "fitness": 0.11910360175797985, "name": "ADE", "description": "An adaptive Differential Evolution (ADE) that dynamically adjusts mutation factors and crossover rates based on population diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.min_CR = 0.1  # minimum crossover probability\n        self.max_CR = 0.9  # maximum crossover probability\n        self.min_F = 0.4  # minimum mutation factor\n        self.max_F = 0.9  # maximum mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def diversity_measure(self, population):\n        # Standard deviation of the population to measure diversity\n        return np.mean(np.std(population, axis=0))\n\n    def mutate(self, idx, population, F):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            # Adjust mutation factor and crossover rate based on diversity\n            diversity = self.diversity_measure(population)\n            F = self.min_F + (self.max_F - self.min_F) * (1 - diversity)\n            CR = self.min_CR + (self.max_CR - self.min_CR) * diversity\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, F)\n                trial_vector = self.crossover(population[i], donor_vector, CR)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 47, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "6bc25fd7-0c4a-4ab2-958a-ffe7af0d1f67", "fitness": 0.11910360175797985, "name": "DSA_DE", "description": "A dynamic self-adaptive Differential Evolution (DSA-DE) algorithm that dynamically adjusts the mutation factor and crossover probability based on historical population performance to enhance convergence and diversity.", "code": "import numpy as np\n\nclass DSA_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, F):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + F * (b - c)\n\n    def crossover(self, target, donor, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, historical_success):\n        CR = np.clip(0.9 - 0.5 * np.mean(historical_success[-5:]), 0.1, 0.9)\n        F = np.clip(0.5 + 0.3 * np.std(historical_success[-5:]), 0.1, 0.9)\n        return CR, F\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        historical_success = []\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                CR, F = self.adapt_parameters(historical_success)\n                donor_vector = self.mutate(i, population, F)\n                trial_vector = self.crossover(population[i], donor_vector, CR)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                new_ind, new_fitness = self.select(trial_vector, population[i], func)\n                historical_success.append(new_fitness < fitness[i])\n                population[i], fitness[i] = new_ind, new_fitness\n                self.current_evaluations += 1\n                \n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 48, "feedback": "The algorithm DSA_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "1f1a8327-9fba-4563-9640-49b2d65ceca0", "fitness": 0.11910360175797985, "name": "ADE", "description": "A novel adaptive Differential Evolution (ADE) algorithm with dynamic adaptation of mutation and crossover rates based on population diversity to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, population):\n        diversity = np.std(population, axis=0).mean()\n        self.F = 0.5 * (1 - diversity)\n        self.CR = 0.9 * diversity\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters(population)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 49, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "10ba4671-c5da-40c4-b8e8-49f94a665887", "fitness": 0.11910360175797985, "name": "IDMDE", "description": "Improved Dynamic Mutation-based Differential Evolution (IDMDE) by incorporating adaptive population resizing and dynamic crossover probability adjustment based on convergence feedback to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass IDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # initial population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n        self.population_size = self.initial_pop_size\n        self.min_pop_size = 5\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.population_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adapt_parameters(self, improvement):\n        if improvement < 1e-6 and self.population_size > self.min_pop_size:\n            self.population_size = max(self.min_pop_size, int(self.population_size * 0.9))\n        elif improvement > 1e-3:\n            self.CR = min(1.0, self.CR + 0.05)\n        else:\n            self.CR = max(0.1, self.CR - 0.05)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n        best_fitness = np.min(fitness)\n\n        while self.current_evaluations < self.budget:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.population_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                selected, fit = self.select(trial_vector, population[i], func)\n                new_population.append(selected)\n                new_fitness.append(fit)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            improvement = best_fitness - np.min(new_fitness)\n            self.adapt_parameters(improvement)\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n            best_fitness = np.min(fitness)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 50, "feedback": "The algorithm IDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "6590687b-fd70-4fdc-8a9e-c82b9225fa4a", "fitness": 0.11910360175797985, "name": "CDMDE", "description": "A Coevolutionary Dynamic Mutation Differential Evolution (CDMDE) algorithm that leverages coevolutionary dynamics and adaptive mutation strategies to enhance convergence speed and robustness in black-box optimization.", "code": "import numpy as np\n\nclass CDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.min_F, self.max_F = 0.1, 0.9  # range for mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def adaptive_mutation_factor(self, fitness):\n        rank = np.argsort(fitness)\n        scaled_rank = rank / (self.pop_size - 1)\n        self.F = self.min_F + scaled_rank * (self.max_F - self.min_F)\n\n    def mutate(self, idx, population, fitness):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adaptive_mutation_factor(fitness)\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, fitness)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 51, "feedback": "The algorithm CDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "71268916-e5af-4857-b56d-31001ab16cc3", "fitness": 0.11910360175797985, "name": "EDMDE", "description": "Enhanced Dynamic Mutation-Based Differential Evolution (EDMDE) incorporates adaptive parameters and probabilistic selection to improve convergence and robustness.", "code": "import numpy as np\n\nclass EDMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = 0.5  # mutation factor\n        self.current_evaluations = 0\n\n    def adapt_parameters(self):\n        self.F = 0.5 + np.random.rand() * 0.3  # Adapt F randomly within a range\n        self.CR = 0.8 + np.random.rand() * 0.2  # Adapt CR randomly within a range\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        prob = 1 / (1 + np.exp(-(candidate_fitness - target_fitness)))\n        if np.random.rand() < prob:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 52, "feedback": "The algorithm EDMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "85590a50-0740-4679-b5fd-22fedfc0fbcc", "fitness": 0.11910360175797985, "name": "DMDE", "description": "An Adaptive Mutation and Crossover Strategy in DMDE to Improve Balancing Between Exploration and Exploitation for Better Convergence.", "code": "import numpy as np\n\nclass DMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n    \n    def adaptive_mutation_factor(self, generation):\n        \"\"\" Adaptive mutation factor based on the current generation. \"\"\"\n        return 0.5 + (0.5 - 0.2) * (1 - generation / self.budget)\n\n    def mutate(self, idx, population, generation):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F = self.adaptive_mutation_factor(generation)\n        return a + F * (b - c)\n    \n    def adaptive_crossover_probability(self, fitness, i):\n        \"\"\" Adaptive crossover probability based on the fitness of each individual. \"\"\"\n        return self.CR + 0.1 * (fitness[i] / np.max(fitness))\n\n    def crossover(self, target, donor, fitness, i):\n        CR = self.adaptive_crossover_probability(fitness, i)\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, self.current_evaluations)\n                trial_vector = self.crossover(population[i], donor_vector, fitness, i)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 53, "feedback": "The algorithm DMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "129e6868-b5c9-4307-9670-ef937cb1e2e6", "fitness": 0.11910360175797985, "name": "ACDE", "description": "An adaptive control parameter Differential Evolution (AC-DE) algorithm that dynamically adjusts the mutation factor and crossover probability based on convergence speed to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ACDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.F = 0.5  # initial mutation factor\n        self.current_evaluations = 0\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def adjust_parameters(self, success_rate):\n        # Adaptive adjustment of CR and F based on success rate\n        self.CR = np.clip(self.CR + 0.1 * (0.5 - success_rate), 0.1, 1.0)\n        self.F = np.clip(self.F + 0.1 * (0.5 - success_rate), 0.1, 1.0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        while self.current_evaluations < self.budget:\n            successes = 0\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                new_individual, new_fitness = self.select(trial_vector, population[i], func)\n                if new_fitness < fitness[i]:\n                    successes += 1\n                population[i], fitness[i] = new_individual, new_fitness\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            success_rate = successes / self.pop_size\n            self.adjust_parameters(success_rate)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 54, "feedback": "The algorithm ACDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a207cffe-3b7b-4cdf-9798-a771368f83a0", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "DMDE-PSO: An enhanced Differential Evolution algorithm integrating Particle Swarm Optimization principles for adaptive parameter tuning and improved convergence.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 55, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["e7841218-c52b-44c5-a445-b001f3e44f73"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "dd10cb26-9692-4392-b01a-ca0b43b3561d", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "Introducing adaptive mutation factor scaling and stochastic crossover rate for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size) * 0.8 + 0.4  # dynamic mutation factor with adaptive scaling\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = np.random.rand() * 0.5 + 0.5  # stochastic crossover rate\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 56, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "43bf0d06-fa2c-47c5-9cce-4b0590a149cc", "fitness": 0.11910360175797985, "name": "DMDE_PSO_Adapt", "description": "DMDE-PSO+Adapt: Enhanced DMDE-PSO with adaptive inertia weight and mutation factor based on convergence speed for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO_Adapt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.initial_F = 0.5  # initial mutation factor\n        self.F = np.full(self.pop_size, self.initial_F)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.global_best_fitness = np.inf\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w_max = 0.9\n        w_min = 0.4\n        w = w_max - ((w_max - w_min) * (self.current_evaluations / self.budget))  # adaptive inertia\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def adapt_mutation_factor(self, idx, improvement):\n        if improvement:\n            self.F[idx] *= 0.9  # decrease F for convergence\n        else:\n            self.F[idx] *= 1.1  # increase F for exploration\n        self.F[idx] = np.clip(self.F[idx], 0.1, 1.0)  # ensure F is between 0.1 and 1.0\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n        self.global_best_fitness = fitness[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                new_individual, new_fitness = self.select(trial_vector, population[i], func)\n                improvement = new_fitness < fitness[i]\n                self.adapt_mutation_factor(i, improvement)\n\n                population[i] = new_individual\n                fitness[i] = new_fitness\n\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.global_best_fitness:\n                    self.global_best = population[i]\n                    self.global_best_fitness = fitness[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 57, "feedback": "The algorithm DMDE_PSO_Adapt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a575e268-e9c3-4d0e-9b43-bcb3a00dc447", "fitness": 0.11911054130590143, "name": "HybridDE_PSO_Adaptive", "description": "Hybrid DE-PSO with Adaptive Learning: Integrates adaptive learning strategies in Differential Evolution and Particle Swarm Optimization for enhanced convergence and better handling of diverse problem landscapes.", "code": "import numpy as np\n\nclass HybridDE_PSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.learning_rate = 0.1  # learning rate for adaptive updates\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 2.0  # personal attraction coefficient\n        c2 = 2.0  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def adaptive_update(self):\n        improvement = max(0, np.min(self.personal_best_fitness) - np.min(self.global_best_fitness))\n        self.F = np.clip(self.F + self.learning_rate * improvement, 0.4, 1.0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n            \n            self.adaptive_update()\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 58, "feedback": "The algorithm HybridDE_PSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "06a6a3ad-b1be-4b0d-a53d-56ef530aaff2", "fitness": 0.11911054130590143, "name": "DE_PSO_TSA", "description": "DE-PSO-TSA: Hybridizing Differential Evolution and Particle Swarm Optimization with a Time-varying Scaling Factor for enhanced exploration-exploitation trade-off and convergence speed.", "code": "import numpy as np\n\nclass DE_PSO_TSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5 + np.random.rand() * 0.5  # dynamic inertia weight\n        c1 = 1.5\n        c2 = 1.5\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n    \n    def time_varying_scaling_factor(self):\n        # Time-varying scaling factor: decreases F over time to enhance exploitation\n        max_iter = self.budget // self.pop_size\n        current_iter = self.current_evaluations // self.pop_size\n        return 0.9 - (0.8 * (current_iter / max_iter))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            self.F = self.time_varying_scaling_factor()\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 59, "feedback": "The algorithm DE_PSO_TSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "b4b793c0-e7d6-43b2-9df5-0dee5c377f3f", "fitness": 0.11911054130590143, "name": "Enhanced_DMDE_PSO", "description": "Enhanced DMDE-PSO with adaptive inertia weight and mutation factors for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.inertia_weight = 0.9  # start with high inertia weight\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w_max = 0.9\n        w_min = 0.4\n        # Adaptive inertia weight decreasing over iterations\n        self.inertia_weight = w_max - ((w_max - w_min) * self.current_evaluations / self.budget)\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                self.inertia_weight * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def adapt_mutation_factor(self, fitness):\n        # Adapt mutation factor based on fitness diversity\n        mean_fitness = np.mean(fitness)\n        fitness_std = np.std(fitness)\n        for i in range(self.pop_size):\n            if fitness[i] < mean_fitness:\n                self.F[i] = 0.5 * (1 - fitness_std / fitness[i])\n            else:\n                self.F[i] = 0.5 * (1 + fitness_std / fitness[i])\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            self.adapt_mutation_factor(fitness)\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 60, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "8c6459de-1012-45ae-9a67-92b6d9e2f4cd", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "Enhanced DMDE-PSO with dynamic crossover probability and adaptive mutation factor for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # initial crossover probability\n        self.min_CR = 0.1  # minimum crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_adaptive = self.F[idx] * (1 - (self.current_evaluations / self.budget))\n        return a + F_adaptive * (b - c)\n\n    def crossover(self, target, donor):\n        CR_dynamic = max(self.min_CR, self.CR * (1 - (self.current_evaluations / self.budget)))\n        crossover_mask = np.random.rand(self.dim) < CR_dynamic\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 61, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "b6ea0640-20b3-4a1e-b8df-b88ffb3b325d", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "Enhanced DMDE_PSO: Refining the mutation factor and introducing a convergence boosting mechanism for improved performance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size) * 0.8 + 0.4  # refined mutation factor range\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        # Select three random indices different from idx\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity * 0.9  # convergence boosting factor\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 62, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "53d669ef-8ec7-48f8-9f95-037f1eaf36ed", "fitness": 0.11911054130590143, "name": "DMDE_PSO_v2", "description": "DMDE_PSO_v2: Refined DMDE-PSO incorporating adaptive inertia weight and randomized crossover probability to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.8 + 0.2 * np.random.rand()  # adaptive CR\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        c1 = 1.5\n        c2 = 1.5\n        for i in range(self.pop_size):\n            w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # adaptive inertia weight\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 63, "feedback": "The algorithm DMDE_PSO_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "f9bbafd6-b595-4acb-a6a2-02749b762da2", "fitness": 0.11910360175797985, "name": "DMDE_PSO", "description": "DMDE-PSO+: A refined version of DMDE-PSO with adaptive mutation and improved inertia weight strategy to boost convergence efficiency.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        # Adaptive mutation factor based on fitness\n        F = np.random.uniform(0.5, 1.0) * (1 - self.personal_best_fitness[idx] / self.personal_best_fitness.min()) \n        return a + F * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        # Adjust inertia weight dynamically\n        w = 0.9 - (0.5 * (self.current_evaluations / self.budget))  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        # Initialize personal and global bests\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 64, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16128730009404113, 0.16205778698968432, 0.16153822867261436, 0.1453346523526775, 0.14576277918028357, 0.14547781810577232, 0.05015225367432963, 0.050164944433402914, 0.050156652319013006]}}
{"id": "a3f07930-9410-4758-8038-c55bde4e2597", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "Modified DMDE-PSO: Enhanced adaptive mutation and selective pressure balancing for improved convergence and exploration.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.8  # Adjusted crossover probability\n        self.F = np.random.rand(self.pop_size) * 0.5 + 0.5  # More dynamic range for mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_mut = self.F[idx] if np.random.rand() < 0.5 else self.F.mean()  # Adaptive mutation factor\n        return a + F_mut * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.4  # Adjusted inertia weight for better balance\n        c1 = 2.0  # Increased personal attraction coefficient\n        c2 = 1.5\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 65, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "95417257-439d-44e8-9751-084ac56c21ad", "fitness": 0.11911054130590143, "name": "Enhanced_DMDE_PSO", "description": "Enhanced DMDE-PSO with Adaptive Strategy: Introduces adaptive mutation factor scaling and elitism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size) * 0.5 + 0.5  # adaptive mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.elitism_factor = 0.1  # percentage of top individuals retained\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5\n        c1 = 1.5\n        c2 = 1.5\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            # Update velocity and apply PSO movement\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n            # Elitism: Retain top individuals\n            elites = int(self.elitism_factor * self.pop_size)\n            elite_indices = np.argsort(fitness)[:elites]\n            for idx in elite_indices:\n                population[idx] = self.personal_best[idx]\n\n            # Adaptive mutation factor update\n            self.F = 0.5 + 0.5 * (1 - (self.current_evaluations / self.budget))\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 66, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "4f501358-47fb-4401-9119-53c942344eed", "fitness": 0.11911054130590143, "name": "DMDE_PSO", "description": "Enhanced DMDE-PSO with adaptive crossover probability and dynamic population size for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.adaptive_CR = self.CR  # Adaptive Crossover Probability\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.adaptive_CR  # Adaptive CR\n        if not np.any(crossover_mask):  \n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            self.adaptive_CR = min(1, self.adaptive_CR + 0.05)  # Increase CR if improvement\n            return candidate, candidate_fitness\n        self.adaptive_CR = max(0.1, self.adaptive_CR - 0.05)  # Decrease CR if no improvement\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  \n        c1 = 1.5  \n        c2 = 1.5  \n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 67, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "456535c9-56e6-4b1f-b86b-f355987648dc", "fitness": 0.11911054130590143, "name": "ADSO", "description": "Adaptive Dual-Swarm Optimization (ADSO): Enhancing convergence by integrating dynamic intra-swarm communication and adaptive mutation factors to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ADSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def adaptive_mutation(self, idx, population, fitness):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_adaptive = 1 / (1 + np.exp(-0.1 * (fitness[idx] - self.personal_best_fitness[idx])))\n        return a + F_adaptive * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5\n        c1 = 1.5\n        c2 = 1.5\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.adaptive_mutation(i, population, fitness)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 68, "feedback": "The algorithm ADSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "3b7b7989-ba2b-4054-8434-aac4e992b913", "fitness": 0.11911054130590143, "name": "DMDE_PSO_Plus", "description": "DMDE-PSO+: A refined Differential Evolution and Particle Swarm Optimization hybrid leveraging adaptive inertia weight and dynamic parameter adaptation for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass DMDE_PSO_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.w_min = 0.4  # minimum inertia weight\n        self.w_max = 0.9  # maximum inertia weight\n        self.w = self.w_max  # initial inertia weight\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        return a + self.F[idx] * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                self.w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def adapt_parameters(self):\n        self.F = 0.5 + np.random.rand(self.pop_size) * 0.5  # adjust mutation factor\n        self.w = self.w_max - (self.w_max - self.w_min) * (self.current_evaluations / self.budget)  # adaptive inertia weight\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 69, "feedback": "The algorithm DMDE_PSO_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "80c95ca1-c43f-413e-a136-5edb19e6c773", "fitness": 0.11911054130590143, "name": "ADAPT_DE_PSO", "description": "ADAPT-DE-PSO: An adaptive DE-PSO hybrid that dynamically adjusts mutation and velocity factors based on convergence speed and diversity.", "code": "import numpy as np\n\nclass ADAPT_DE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.diversity_threshold = 1e-5\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = self.F[idx] + np.random.uniform(-0.1, 0.1)  # Adaptive mutation factor\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity_and_position(self, population):\n        w = 0.5\n        c1 = 1.5\n        c2 = 1.5\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n            if np.linalg.norm(self.velocity[i]) < self.diversity_threshold:\n                self.velocity[i] += np.random.normal(0, 0.1, self.dim)  # Introduce random perturbation\n            population[i] += self.velocity[i]\n        return np.clip(population, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            population = self.update_velocity_and_position(population)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 70, "feedback": "The algorithm ADAPT_DE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11911 with standard deviation 0.04920.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16150686151759464, 0.16165364691411965, 0.1617656987551268, 0.14545424895223746, 0.14553666670008225, 0.14560350756154816, 0.05015569399659081, 0.050158177610825305, 0.050160369744988054]}}
{"id": "1375bf09-9183-41e1-bf20-cb233d193005", "fitness": 0.11917225248679136, "name": "DMDE_PSO", "description": "Enhanced DMDE-PSO by introducing adaptive learning rate and dynamic population size adjustment for improved convergence robustness.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.random.rand()  # adaptive F\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 71, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["a207cffe-3b7b-4cdf-9798-a771368f83a0"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16161110051575844, 0.14557053904285522, 0.14570489000048759, 0.14551723130965954, 0.05015920468280244, 0.05016324925440474, 0.050157788734265574]}}
{"id": "d2deef07-7f37-4843-8751-f915ec18dd62", "fitness": 0.11910199826158167, "name": "Improved_DMDE_PSO", "description": "Improved DMDE-PSO by integrating simulated annealing-inspired temperature-controlled mutation factor for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass Improved_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.initial_temp = 1.0  # initial temperature\n        self.final_temp = 0.1  # final temperature\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population, temp):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.random.rand() * (temp / self.initial_temp)  # temperature-controlled F\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5\n        c1 = 1.5\n        c2 = 1.5\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.current_evaluations / self.budget))\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population, temp)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 72, "feedback": "The algorithm Improved_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {"aucs": [0.16129650579057664, 0.16205778698968432, 0.16151989535715217, 0.14533969164557825, 0.14576277918028357, 0.14546764978053905, 0.05015239844335839, 0.050164944433402914, 0.0501563327336596]}}
{"id": "14241559-3014-4b56-892f-2fd872cbe4ff", "fitness": 0.11917225248679136, "name": "DMDE_PSO", "description": "Improved DMDE_PSO by refining the adaptive mutation factor and enhancing global best update mechanism for better convergence.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.3 + 0.7 * np.random.rand()  # refined adaptive F\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i].copy()  # ensure global best is updated accurately\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 73, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16161110051575844, 0.14557053904285522, 0.14570489000048759, 0.14551723130965954, 0.05015920468280244, 0.05016324925440474, 0.050157788734265574]}}
{"id": "4f96db0d-1ea9-4e01-9478-84bb9ffab728", "fitness": 0.11917225248679136, "name": "DMDE_PSO", "description": "Improved convergence via adaptive inertia weight and enhanced diversity preservation.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.random.rand()  # adaptive F\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w_max, w_min = 0.9, 0.4  # adaptive inertia weights\n        w = w_max - (w_max - w_min) * (self.current_evaluations / self.budget)\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n        \n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 74, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16161110051575844, 0.14557053904285522, 0.14570489000048759, 0.14551723130965954, 0.05015920468280244, 0.05016324925440474, 0.050157788734265574]}}
{"id": "0bf04432-786d-47db-99b5-4feaf49582bd", "fitness": -Infinity, "name": "DMDE_PSO", "description": "Enhance DMDE-PSO with time-varying crossover probability and gradient-based mutation factor adjustment to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        gradient = np.gradient([func(ind) for ind in [a, b, c]])  # gradient-based mutation\n        F_dynamic = 0.5 + 0.5 * np.random.rand() * np.abs(np.mean(gradient))  # adaptive F\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        current_ratio = self.current_evaluations / self.budget\n        self.CR = 0.9 * (1 - current_ratio) + 0.1 * current_ratio  # time-varying CR\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.5  # inertia weight\n        c1 = 1.5  # personal attraction coefficient\n        c2 = 1.5  # global attraction coefficient\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 75, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {}}
{"id": "ac9fb536-5d7e-4e10-a01f-c9b3825e3f9b", "fitness": -Infinity, "name": "Enhanced_DMDE_PSO", "description": "Enhanced DMDE-PSO with adaptive inertia weight and tournament selection for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.random.rand()\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def tournament_selection(self, candidates, func):\n        selected = np.random.choice(candidates, 2, replace=False)\n        fitness1, fitness2 = func(selected[0]), func(selected[1])\n        if fitness1 < fitness2:\n            return selected[0], fitness1\n        else:\n            return selected[1], fitness2\n\n    def update_velocity(self, population, iteration, max_iterations):\n        w_max, w_min = 0.9, 0.4\n        w = w_max - ((w_max - w_min) * iteration / max_iterations)\n        c1 = 1.5\n        c2 = 1.5\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        iterations = 0\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.tournament_selection([trial_vector, population[i]], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population, iterations, self.budget // self.pop_size)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n            iterations += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 76, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {}}
{"id": "c2e0fe4c-2c76-4b05-9b1d-89c999de16a7", "fitness": 0.1191745687747987, "name": "DMDE_PSO", "description": "Improve convergence with adaptive learning rates, inertia weight decay, and fitness-based mutation strategy.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # fitness-based mutation\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 77, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["1375bf09-9183-41e1-bf20-cb233d193005"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16162436514950562, 0.14557053904285522, 0.14570489000048759, 0.1455245969672203, 0.05015920468280244, 0.05016324925440474, 0.05015800503502388]}}
{"id": "0dcaae1b-6ea3-48e1-8361-1048aa2cee9b", "fitness": 0.11917225248679136, "name": "DMDE_PSO", "description": "Introduce a dynamic crossover probability to adaptively enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # fitness-based mutation\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.5 + 0.5 * np.random.rand()  # Introduce dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 78, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16161110051575844, 0.14557053904285522, 0.14570489000048759, 0.14551723130965954, 0.05015920468280244, 0.05016324925440474, 0.050157788734265574]}}
{"id": "437a413c-4509-4367-afad-3fab254a470c", "fitness": 0.11917368250153605, "name": "DMDE_PSO", "description": "Enhance convergence by refining dynamic mutation and adaptive learning rates.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.4 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # refined dynamic mutation\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.3 * (self.current_evaluations / self.budget)  # adjusted adaptive learning rate\n        c2 = 1.5 - 0.3 * (self.current_evaluations / self.budget)  # adjusted adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 79, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.1616192825473568, 0.14557053904285522, 0.14570489000048759, 0.1455217859895649, 0.05015920468280244, 0.05016324925440474, 0.050157922155463885]}}
{"id": "5d027840-3e85-42f9-89ef-dad50aa724a3", "fitness": 0.1191745687747987, "name": "Improved_DMDE_PSO", "description": "Integrate adaptive population resizing and opposition-based learning to enhance diversity and exploration in the search space.", "code": "import numpy as np\n\nclass Improved_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = max(10, 5 * dim)  # dynamic initial population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.initial_pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.initial_pop_size, self.dim))  # velocity for PSO component\n        self.adaptive_pop_size = self.initial_pop_size\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.adaptive_pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.adaptive_pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.adaptive_pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # fitness-based mutation\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.adaptive_pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def adaptive_resizing(self, population, fitness):\n        # Dynamically resize population based on convergence\n        if self.current_evaluations > self.budget / 2:\n            self.adaptive_pop_size = max(5, int(self.adaptive_pop_size * 0.9))\n            best_indices = np.argsort(fitness)[:self.adaptive_pop_size]\n            return population[best_indices], fitness[best_indices]\n        return population, fitness\n\n    def opposition_based_learning(self, population, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        opposition_population = lb + ub - population\n        fitness = np.array([func(ind) for ind in opposition_population])\n        self.current_evaluations += opposition_population.shape[0]\n        return opposition_population, fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.adaptive_pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            if self.current_evaluations > self.budget / 2:\n                opp_population, opp_fitness = self.opposition_based_learning(population, bounds)\n                combined_population = np.vstack((population, opp_population))\n                combined_fitness = np.hstack((fitness, opp_fitness))\n                best_indices = np.argsort(combined_fitness)[:self.adaptive_pop_size]\n                population, fitness = combined_population[best_indices], combined_fitness[best_indices]\n\n            for i in range(self.adaptive_pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n            population, fitness = self.adaptive_resizing(population, fitness)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 80, "feedback": "The algorithm Improved_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16162436514950562, 0.14557053904285522, 0.14570489000048759, 0.1455245969672203, 0.05015920468280244, 0.05016324925440474, 0.05015800503502388]}}
{"id": "cb782ac0-642f-41f6-b5f4-ccbd45af1c0f", "fitness": 0.1191745687747987, "name": "DMDE_PSO", "description": "Introduce a small random perturbation in the velocity update to enhance exploration.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # fitness-based mutation\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + 0.01 * np.random.randn(self.dim)  # Added small random perturbation\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 81, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16162436514950562, 0.14557053904285522, 0.14570489000048759, 0.1455245969672203, 0.05015920468280244, 0.05016324925440474, 0.05015800503502388]}}
{"id": "3fc5ef74-d5ba-4a0b-8b2d-d4bd0899f257", "fitness": 0.1191745687747987, "name": "Enhanced_DMDE_PSO", "description": "Enhance convergence by incorporating adaptive swarm intelligence with dynamic communication topology and self-adaptive mutation and crossover strategies.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        return (candidate, candidate_fitness) if candidate_fitness < target_fitness else (target, target_fitness)\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_best = np.random.choice(self.personal_best)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (local_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 82, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16162436514950562, 0.14557053904285522, 0.14570489000048759, 0.1455245969672203, 0.05015920468280244, 0.05016324925440474, 0.05015800503502388]}}
{"id": "4ae87111-a436-459d-9490-3b86c41f7316", "fitness": 0.11917203539024707, "name": "Enhanced_DMDE_PSO", "description": "Enhance DMDE_PSO by integrating a chaotic map for parameter tuning and a self-adaptive mechanism for mutation rate control.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.chaotic_map = self.init_chaotic_map()  # Chaotic sequence for parameter tuning\n\n    def init_chaotic_map(self, length=1000):\n        # Generate a sequence using a logistic map\n        x = 0.7  # Initial condition\n        chaotic_sequence = np.zeros(length)\n        for i in range(length):\n            x = 4 * x * (1 - x)  # Logistic map equation\n            chaotic_sequence[i] = x\n        return chaotic_sequence\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))\n        \n        # Self-adaptive mutation factor\n        F_dynamic *= self.chaotic_map[self.current_evaluations % len(self.chaotic_map)]\n        \n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 83, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195121195660922, 0.16161110051575844, 0.14557053904285522, 0.14570427894600457, 0.14551723130965954, 0.05015920468280244, 0.05016323594089922, 0.050157788734265574]}}
{"id": "a40fe7d0-2c23-46e4-976b-fb420adff8d3", "fitness": -Infinity, "name": "DMDE_PSO", "description": "Enhance global exploration by increasing crossover probability dynamically based on evaluations.", "code": "class DMDE_PSO:\n    def __init__(self, budget, dim):\n        # ... [rest of the code remains unchanged]\n        self.CR = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        # ... [rest of the code remains unchanged]\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                self.CR = 0.9 - 0.4 * (self.current_evaluations / self.budget)  # dynamic crossover probability\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                # ... [rest of the loop remains unchanged]", "configspace": "", "generation": 84, "feedback": "An exception occurred: AttributeError(\"'DMDE_PSO' object has no attribute 'current_evaluations'\").", "error": "AttributeError(\"'DMDE_PSO' object has no attribute 'current_evaluations'\")", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {}}
{"id": "aefe9ab0-f3a8-4270-b67b-2ec15c835e6e", "fitness": 0.11911687240634869, "name": "RefinedDMDE_PSO", "description": "Enhance convergence by integrating greedy selection with adaptive mutation scaling and velocity reset to discourage premature convergence.", "code": "import numpy as np\n\nclass RefinedDMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population, stagnation_counter):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n\n        for i in range(self.pop_size):\n            if stagnation_counter > 10:  # Reset velocity in case of stagnation\n                self.velocity[i] = np.zeros(self.dim)\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        stagnation_counter = 0\n\n        while self.current_evaluations < self.budget:\n            prev_best_fitness = fitness[best_idx]\n\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            if prev_best_fitness <= fitness[best_idx]:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            self.update_velocity(population, stagnation_counter)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 85, "feedback": "The algorithm RefinedDMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11912 with standard deviation 0.04920.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16136364790664037, 0.16205778698968432, 0.16153843031978143, 0.14537637180998642, 0.14576277918028357, 0.14547779759714852, 0.05015346464990178, 0.050164944433402914, 0.05015662877030902]}}
{"id": "cbf04692-220e-4b19-9219-bb08a3ecd983", "fitness": 0.11917225248679136, "name": "DMDE_PSO", "description": "Enhance global exploration with dynamic neighborhood mutation and adaptive velocity clamping.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        neighborhood = np.random.choice(self.pop_size, 2, replace=False)  # dynamic neighborhood mutation\n        d, e = population[neighborhood]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))  # fitness-based mutation\n        return a + F_dynamic * (b - c + d - e)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        offspring = np.where(crossover_mask, donor, target)\n        return offspring\n   \n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            velocity_clamp = 0.1 + 0.9 * np.exp(-3 * self.current_evaluations / self.budget)  # adaptive velocity clamping\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n            self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 86, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16161110051575844, 0.14557053904285522, 0.14570489000048759, 0.14551723130965954, 0.05015920468280244, 0.05016324925440474, 0.050157788734265574]}}
{"id": "76d86fa6-8380-4036-b126-708585ce7808", "fitness": 0.1191745687747987, "name": "Enhanced_DMDE_PSO", "description": "Enhance convergence and exploration with adaptive inertia and mutation, swarm-based local search, and fitness-biased global diversity.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf * np.ones(self.pop_size)\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        \n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n    \n    def mutate(self, idx, population):\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))\n        return a + F_dynamic * (b - c)\n    \n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n    \n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n    \n    def update_velocity(self, population):\n        w_max, w_min = 0.9, 0.4\n        w = w_max - (w_max - w_min) * (self.current_evaluations / self.budget)\n        c1 = 2.0\n        c2 = 2.0\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i] \n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 87, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11917 with standard deviation 0.04924.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.16171372738336953, 0.16195254145751914, 0.16162436514950562, 0.14557053904285522, 0.14570489000048759, 0.1455245969672203, 0.05015920468280244, 0.05016324925440474, 0.05015800503502388]}}
{"id": "1bb81729-fe9f-4ce0-9d5e-d3072d4a1aff", "fitness": -Infinity, "name": "ChaoticDMDE_PSO", "description": "Introduce enhanced exploration with chaotic map initialization and diversity preservation through crowding distance for improved convergence.", "code": "import numpy as np\n\nclass ChaoticDMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.8  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def chaotic_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        chaotic_seq = np.random.rand(self.pop_size, self.dim)\n        for _ in range(100):  # iterate logistic map\n            chaotic_seq = self.logistic_map(chaotic_seq)\n        return lb + (ub - lb) * chaotic_seq\n\n    def crowding_distance(self, population, fitness):\n        distances = np.zeros(self.pop_size)\n        sorted_idx = np.argsort(fitness)\n        for i in range(1, self.pop_size - 1):\n            distances[sorted_idx[i]] += (fitness[sorted_idx[i + 1]] - fitness[sorted_idx[i - 1]])\n        distances[sorted_idx[0]] = distances[sorted_idx[-1]] = np.inf\n        return distances\n\n    def select(self, candidate, target, candidate_fitness, target_fitness, crowd_distances, idx):\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        if candidate_fitness == target_fitness:\n            if crowd_distances[idx] > crowd_distances[np.where((target == self.personal_best).all(axis=1))[0][0]]:\n                return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.chaotic_initialization(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            crowd_distances = self.crowding_distance(population, fitness)\n            for i in range(self.pop_size):\n                if self.current_evaluations >= self.budget:\n                    break\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                trial_fitness = func(trial_vector)\n                population[i], fitness[i] = self.select(trial_vector, population[i], trial_fitness, fitness[i], crowd_distances, i)\n                \n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 88, "feedback": "An exception occurred: AttributeError(\"'ChaoticDMDE_PSO' object has no attribute 'mutate'\").", "error": "AttributeError(\"'ChaoticDMDE_PSO' object has no attribute 'mutate'\")", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {}}
{"id": "13cf4b21-16d5-462a-aefe-8f2c7cbcd020", "fitness": 0.11919034351405651, "name": "DMDE_PSO", "description": "Enhance global convergence by introducing a dynamic neighborhood search and adaptive exploration-exploitation balance strategy.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        F_dynamic = 0.5 + 0.5 * np.tanh(self.personal_best_fitness[idx] / np.max(self.personal_best_fitness))\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 89, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11919 with standard deviation 0.04926.", "error": "", "parent_ids": ["c2e0fe4c-2c76-4b05-9b1d-89c999de16a7"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16193531312051324, 0.161559827678731, 0.14566698433069303, 0.1456966528481256, 0.14548963542341709, 0.050162162906499774, 0.050163050642567875, 0.0501570543820844]}}
{"id": "d2765f74-9134-4ac9-9afa-db77866b7170", "fitness": 0.11922099302240136, "name": "DMDE_PSO", "description": "Improve exploration by introducing dynamic adjustment to crossover probability and introducing an adaptive mutation strategy based on current fitness variance.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)  # dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 90, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11922 with standard deviation 0.04928.", "error": "", "parent_ids": ["13cf4b21-16d5-462a-aefe-8f2c7cbcd020"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16197382861551346, 0.16169758153176428, 0.14566698433069303, 0.14571774041806562, 0.14556535619375488, 0.050162162906499774, 0.050163665134393964, 0.05015920777705074]}}
{"id": "15c22d33-bc5c-4bb4-a513-cfabea9eaf02", "fitness": 0.11919033915693403, "name": "DMDE_PSO", "description": "Enhance exploration by introducing sinusoidal variation in mutation factor and enforcing a minimum crossover rate.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.sin(fitness_variance)  # modified\n        return a + F_dynamic * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = max(0.4, 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi))  # modified\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 91, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11919 with standard deviation 0.04926.", "error": "", "parent_ids": ["d2765f74-9134-4ac9-9afa-db77866b7170"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16193531312051324, 0.161559827678731, 0.14566698433069303, 0.1456966528481256, 0.14548963542341709, 0.050162162906499774, 0.050163050642567875, 0.05015701516798199]}}
{"id": "1dcef1e1-9183-4bfe-88b5-654392a10162", "fitness": 0.11923990492756704, "name": "DMDE_PSO", "description": "Enhance exploration by modulating the mutation factor and improving the velocity update based on population diversity.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim  # New line for diversity factor\n        return a + F_dynamic * diversity_factor * (b - c)  # Modified line with diversity factor\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)  # dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 92, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["d2765f74-9134-4ac9-9afa-db77866b7170"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "e50abf80-16cd-4e04-8cc0-d7ed6e686aa7", "fitness": 0.11910471500907599, "name": "Enhanced_DMDE_PSO", "description": "Integrate self-adaptive strategies for dynamic parameter tuning and introduce an exploitative phase based on clustering to balance exploration and exploitation effectively.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.selection_pressure = 0.5  # New parameter for self-adaptive selection pressure\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim\n        return a + F_dynamic * diversity_factor * (b - c)\n\n    def crossover(self, target, donor):\n        CR_dynamic = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)\n        crossover_mask = np.random.rand(self.dim) < CR_dynamic\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n            )\n\n    def exploit(self, population, bounds):\n        num_clusters = max(2, self.pop_size // 10)\n        kmeans = KMeans(n_clusters=num_clusters)\n        kmeans.fit(population)\n        centers = kmeans.cluster_centers_\n\n        for center in centers:\n            perturbation = 0.1 * (bounds.ub - bounds.lb) * np.random.normal(size=self.dim)\n            candidate = np.clip(center + perturbation, bounds.lb, bounds.ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < np.min(self.personal_best_fitness):\n                self.global_best = candidate\n                self.global_best_fitness = candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n            # Trigger exploit phase periodically\n            if self.current_evaluations % (self.budget // 10) == 0:\n                self.exploit(population, bounds)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 93, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11910 with standard deviation 0.04919.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.16132783681264118, 0.16208511559306338, 0.1614769788742374, 0.1453568302856013, 0.145777702245093, 0.1454440532699255, 0.050152897659454077, 0.05016537766865381, 0.0501556426730142]}}
{"id": "87d06177-afc0-4499-9999-af86e0d64ffb", "fitness": 0.11923990492756704, "name": "EnhancedDMDE_PSO", "description": "Integrate dynamic neighborhood search and temporal diversity control to enhance convergence speed and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedDMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.local_weights = np.random.rand(self.pop_size, self.dim)\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim\n        return a + F_dynamic * diversity_factor * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n        \n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            # Introduce dynamic neighborhood influence\n            neighbors_indices = np.random.choice(self.pop_size, 2, replace=False)\n            neighborhood_best = min(neighbors_indices, key=lambda idx: self.personal_best_fitness[idx])\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.personal_best[neighborhood_best] - population[i])\n                + local_adjustment\n            )\n\n    def perform_local_search(self, population, bounds):\n        # Perform a local search periodically to enhance exploitation\n        if self.current_evaluations % (self.pop_size * 5) == 0:\n            for i in range(self.pop_size):\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = population[i] + perturbation\n                candidate = np.clip(candidate, bounds.lb, bounds.ub)\n                candidate_fitness = func(candidate)\n                if candidate_fitness < self.personal_best_fitness[i]:\n                    self.personal_best[i] = candidate\n                    self.personal_best_fitness[i] = candidate_fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n            self.perform_local_search(population, bounds)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "1f41a138-04b7-4b5d-8c68-fdf029508d4d", "fitness": 0.11923990492756704, "name": "DMDE_PSO", "description": "Refined particle velocity update by enhancing inertia weight adaptation and mutation factor stability.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)  # Line adjusted to maintain stability\n        diversity_factor = np.std(population, axis=0).mean() / self.dim\n        return a + F_dynamic * diversity_factor * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.7 - 0.3 * (self.current_evaluations / self.budget)  # Line adjusted for better adaptation\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 95, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "52ae889c-788f-4b26-adb9-81f0365fc22c", "fitness": 0.11923990492756704, "name": "DMDE_PSO", "description": "Introduce adaptive population size and dynamic boundary adjustments to enhance convergence and diversity.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim  # New line for diversity factor\n        return a + F_dynamic * diversity_factor * (b - c)  # Modified line with diversity factor\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)  # dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb * 0.9, bounds.ub * 1.1)  # Adjusted dynamic boundaries\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            self.pop_size = int(max(10, self.pop_size * 0.98))  # Adaptive population size\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 96, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "72346eeb-5880-451c-8761-9f6cec250375", "fitness": 0.11923990492756704, "name": "Enhanced_DMDE_PSO", "description": "Enhance convergence by introducing adaptive inertia and mutation factors based on population diversity and individual performance improvements.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.local_weights = np.random.rand(self.pop_size, self.dim)\n        self.improvement_tracker = np.zeros(self.pop_size)\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim\n        return a + F_dynamic * diversity_factor * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w_initial = 0.9\n        w_final = 0.4\n        w = w_initial - (w_initial - w_final) * (self.current_evaluations / self.budget)\n        c1 = 2.05\n        c2 = 2.05\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                improvement = self.personal_best_fitness[i] - fitness[i] \n\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n                    self.improvement_tracker[i] = improvement\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "1ece1298-c58d-4cf3-9169-c235d2bf5ca2", "fitness": 0.11923990492756704, "name": "DMDE_PSO", "description": "Improve convergence by dynamically adjusting the local weights and incorporating mutation scaling based on fitness improvement ratio.", "code": "import numpy as np\n\nclass DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)  # dynamic population size\n        self.CR = 0.9  # crossover probability\n        self.F = np.random.rand(self.pop_size)  # dynamic mutation factor\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))  # velocity for PSO component\n        self.local_weights = np.random.rand(self.pop_size, self.dim)  # local search adjustments\n\n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        while idx in selected_indices:\n            selected_indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = population[selected_indices]\n        fitness_variance = np.var(self.personal_best_fitness)\n        improvement_ratio = (np.min(self.personal_best_fitness) - np.max(self.personal_best_fitness)) / (np.max(self.personal_best_fitness) + 1e-10)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance + improvement_ratio)  # Modified line for mutation scaling\n        diversity_factor = np.std(population, axis=0).mean() / self.dim  # New line for diversity factor\n        return a + F_dynamic * diversity_factor * (b - c)  # Modified line with diversity factor\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)  # dynamic crossover probability\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):  # Guarantee at least one crossover\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # inertia weight decay\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)  # adaptive learning rate\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 98, "feedback": "The algorithm DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11924 with standard deviation 0.04929.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1618824102938765, 0.16206241730523518, 0.1617178980966012, 0.14566698433069303, 0.14576617246795198, 0.14557649280088503, 0.050162162906499774, 0.050165073902594615, 0.050159532243766014]}}
{"id": "ad72b26b-4bd7-4b49-b622-c48b853f9aae", "fitness": 0.11924620858275614, "name": "Enhanced_DMDE_PSO", "description": "Introduce an adaptive neighborhood strategy combined with a non-linear inertia weight decay to balance exploration and exploitation.", "code": "import numpy as np\n\nclass Enhanced_DMDE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 5 * dim)\n        self.CR = 0.9\n        self.F = np.random.rand(self.pop_size)\n        self.current_evaluations = 0\n        self.personal_best = None\n        self.personal_best_fitness = np.inf\n        self.velocity = np.zeros((self.pop_size, self.dim))\n        self.local_weights = np.random.rand(self.pop_size, self.dim)\n        self.neighborhood_size = min(5, self.pop_size // 2)\n    \n    def generate_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, population):\n        neighborhood_indices = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n        while idx in neighborhood_indices:\n            neighborhood_indices = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n        a, b, c = population[neighborhood_indices][:3]\n        fitness_variance = np.var(self.personal_best_fitness)\n        F_dynamic = 0.5 + 0.5 * np.tanh(fitness_variance)\n        diversity_factor = np.std(population, axis=0).mean() / self.dim\n        return a + F_dynamic * diversity_factor * (b - c)\n\n    def crossover(self, target, donor):\n        self.CR = 0.6 + 0.4 * np.sin(self.current_evaluations / self.budget * np.pi)\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, donor, target)\n\n    def select(self, candidate, target, func):\n        candidate_fitness = func(candidate)\n        target_fitness = func(target)\n        if candidate_fitness < target_fitness:\n            return candidate, candidate_fitness\n        return target, target_fitness\n\n    def update_velocity(self, population):\n        w = 0.9 - 0.5 * ((self.current_evaluations / self.budget) ** 2)\n        c1 = 1.5 + 0.5 * (self.current_evaluations / self.budget)\n        c2 = 1.5 - 0.5 * (self.current_evaluations / self.budget)\n        self.local_weights = 0.5 + 0.3 * np.tanh((self.personal_best_fitness - np.min(self.personal_best_fitness)) / np.max(self.personal_best_fitness))\n\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(2)\n            local_adjustment = self.local_weights[i] * np.random.normal(0, 1, self.dim)\n            self.velocity[i] = (\n                w * self.velocity[i]\n                + c1 * r1 * (self.personal_best[i] - population[i])\n                + c2 * r2 * (self.global_best - population[i])\n                + local_adjustment\n            )\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self.generate_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.pop_size\n\n        self.personal_best = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        self.global_best = population[best_idx]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.pop_size):\n                donor_vector = self.mutate(i, population)\n                trial_vector = self.crossover(population[i], donor_vector)\n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n\n                population[i], fitness[i] = self.select(trial_vector, population[i], func)\n                if fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best[i] = population[i]\n                    self.personal_best_fitness[i] = fitness[i]\n\n                if fitness[i] < self.personal_best_fitness[best_idx]:\n                    self.global_best = population[i]\n                    best_idx = i\n\n                self.current_evaluations += 1\n                if self.current_evaluations >= self.budget:\n                    break\n\n            self.update_velocity(population)\n            population += self.velocity\n            population = np.clip(population, bounds.lb, bounds.ub)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 99, "feedback": "The algorithm Enhanced_DMDE_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11925 with standard deviation 0.04930.", "error": "", "parent_ids": ["1dcef1e1-9183-4bfe-88b5-654392a10162"], "operator": null, "metadata": {"aucs": [0.1619187153388545, 0.16206241730523518, 0.1617178980966012, 0.14568683498452317, 0.14576617246795198, 0.14557649280088503, 0.05016274010439348, 0.050165073902594615, 0.050159532243766014]}}
