{"id": "c412177a-fec8-4269-882d-6d9a1c444e30", "fitness": 0.08956095422255607, "name": "ADE_FBA", "description": "Adaptive Differential Evolution with Fitness-Based Adaptation (ADE-FBA) that dynamically tunes mutation and crossover rates based on population diversity and fitness improvements.", "code": "import numpy as np\n\nclass ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 0, "feedback": "The algorithm ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "81bfb0e4-3c03-44b4-ba6d-fb1cb865bc2c", "fitness": 0.08956095422255607, "name": "EDE_PCAPC", "description": "Enhanced Adaptive Differential Evolution using Population Clustering and Adaptive Parameter Control (EDE-PCAPC) which incorporates population clustering for maintaining diversity and employs adaptive parameter control for mutation and crossover rates based on convergence speed.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EDE_PCAPC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Cluster the population to maintain diversity\n            num_clusters = max(2, self.population_size // 10)\n            kmeans = KMeans(n_clusters=num_clusters).fit(pop)\n            labels = kmeans.labels_\n\n            for i in range(self.population_size):\n                cluster_indices = np.where(labels == labels[i])[0]\n                indices = list(set(cluster_indices) - {i})\n                \n                if len(indices) < 3: continue  # Skip if not enough individuals in cluster\n\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive parameter control based on convergence speed\n                if eval_count % (self.population_size * 2) == 0:\n                    convergence_speed = (np.max(fitness) - np.min(fitness)) / np.mean(fitness)\n                    self.mutation_factor = 0.3 + 0.4 * convergence_speed\n                    self.crossover_rate = 0.4 + 0.5 * (1 - convergence_speed)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 1, "feedback": "The algorithm EDE_PCAPC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "5d859a2b-07af-4e92-8bb4-78bb0269ff1f", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) incorporating a Gaussian mutation strategy and adaptive population resizing for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.shrink_factor = 0.9\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                # Gaussian mutation to improve exploration\n                gaussian_mutant = np.clip(mutant + 0.01 * np.random.randn(self.dim), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, gaussian_mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n                if eval_count >= self.budget:\n                    break\n\n            pop, fitness = np.array(new_pop), np.array(new_fitness)\n            \n            # Population resizing for improved exploitation\n            if eval_count % (self.initial_population_size * 5) == 0:\n                self.population_size = max(int(self.population_size * self.shrink_factor), 4)\n\n            # Dynamic adaptation of mutation factor and crossover rate\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.std(pop, axis=0).mean() / (ub - lb).mean()\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 2, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "b64d0059-bfc1-40da-86ae-894853a321c7", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) with Adaptive Memory-Based Mutation and Dynamic Population Sizing to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.memory = np.zeros((self.initial_population_size, dim))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        self.memory[:self.population_size] = pop\n        \n        while eval_count < self.budget:\n            if eval_count % (self.population_size * 5) == 0 and eval_count > self.population_size:\n                # Dynamic population resizing\n                self.population_size = min(self.initial_population_size, int(self.population_size * 1.1))\n                pop = np.vstack((pop, np.random.uniform(lb, ub, (self.population_size - pop.shape[0], self.dim))))\n                fitness = np.append(fitness, [func(ind) for ind in pop[self.memory.shape[0]:]])\n                eval_count += self.population_size - self.memory.shape[0]\n                self.memory = np.vstack((self.memory, pop[self.memory.shape[0]:]))\n            \n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = self.memory[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "8b4ab274-936f-40c9-a0f0-e79111b3fb80", "fitness": 0.08956095422255607, "name": "E_ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (E-ADE-FBA) incorporating a novel diversity-driven mutation strategy and adaptive population resizing for improved optimization.", "code": "import numpy as np\n\nclass E_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.min_pop_size = 4 * dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Implementing diversity-driven mutation\n                best = pop[np.argmin(fitness)]\n                mutant = np.clip(a + self.mutation_factor * (b - c) + 0.1 * (best - pop[i]), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation and population resizing\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1 and self.population_size > self.min_pop_size:\n                        self.population_size = max(self.min_pop_size, self.population_size // 2)\n                        pop = pop[:self.population_size]\n                        fitness = fitness[:self.population_size]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 4, "feedback": "The algorithm E_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "9b5f279a-2f4b-42cf-8f77-1c4469948c11", "fitness": 0.08956095422255607, "name": "ADE_FBA_SDM", "description": "Adaptive Differential Evolution with Fitness-Based Adaptation and Stochastic Differential Mutation (ADE-FBA-SDM) uses stochastic differential mutation and adaptive parameter tuning based on diversity and fitness trends to enhance exploration and convergence.", "code": "import numpy as np\n\nclass ADE_FBA_SDM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.sdm_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            fitness_trend = np.mean(fitness)\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Stochastic Differential Mutation\n                sdm_noise = self.sdm_factor * np.random.normal(size=self.dim)\n                mutant = np.clip(a + self.mutation_factor * (b - c) + sdm_noise, lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation based on diversity and fitness trend\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    fitness_improvement = max(0, fitness_trend - np.mean(fitness))\n                    self.mutation_factor = 0.3 + 0.7 * diversity * (1 + fitness_improvement)\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm ADE_FBA_SDM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "7d3cc672-f4ea-48f6-97b3-0638b35b0568", "fitness": 0.08956095422255607, "name": "ADE_FBA_Enhanced", "description": "Enhanced ADE-FBA with adaptive learning rate and population clustering to improve exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass ADE_FBA_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            num_clusters = max(2, self.population_size // 10)\n            km = KMeans(n_clusters=num_clusters, n_init=1)\n            km.fit(pop)\n            clusters = km.labels_\n\n            for i in range(self.population_size):\n                cluster_indices = np.where(clusters == clusters[i])[0]\n                indices = list(filter(lambda x: x != i, cluster_indices))\n\n                if len(indices) < 3:\n                    indices = list(range(0, i)) + list(range(i+1, self.population_size))\n\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation with enhanced learning rate\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    self.mutation_factor *= 1.1\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm ADE_FBA_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "79943b67-edc8-4382-a0ac-b4136250b264", "fitness": 0.08956095422255607, "name": "D_ADE_FDB", "description": "Dynamic Adaptive Differential Evolution with Fitness and Diversity Balancing (D-ADE-FDB) that enhances search capability by balancing fitness improvement and population diversity using a novel self-adaptive mechanism for mutation and crossover rates.", "code": "import numpy as np\n\nclass D_ADE_FDB:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    fitness_improvement = np.mean(fitness) - np.mean([func(ind) for ind in pop])\n                    \n                    self.mutation_factor = 0.3 + 0.7 * (diversity + fitness_improvement) / 2\n                    self.crossover_rate = 0.1 + 0.8 * (1 - (diversity + fitness_improvement) / 2)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm D_ADE_FDB got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "cdc1728f-e117-4629-9ece-54d7195770dd", "fitness": 0.08956095422255607, "name": "eADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (eADE-FBA) introducing elitism and dynamic population size for improved convergence.", "code": "import numpy as np\n\nclass eADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Elitism\n                if trial_fitness < fitness[best_idx]:\n                    best_idx = i\n                    best_individual = trial\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Dynamic population resizing\n                if eval_count % (self.population_size * 4) == 0:\n                    self.population_size = max(4 * self.dim, eval_count // 100)\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_individual, fitness[best_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm eADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "01097cf9-59f2-4751-becc-51712785b629", "fitness": 0.08956095422255607, "name": "E_ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (E-ADE-FBA), introducing adaptive population size and improved dynamic parameter tuning based on fitness improvement rate to boost convergence.", "code": "import numpy as np\n\nclass E_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation based on fitness improvement rate\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                improvement_rate = np.mean(fitness) - np.min(fitness)\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                if improvement_rate < 1e-3:\n                    self.population_size = min(int(self.population_size * 1.1), self.initial_population_size * 2)\n\n            if eval_count >= self.budget:\n                break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 9, "feedback": "The algorithm E_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "c5caab14-3b77-4e4f-8310-1d5a1b2677d0", "fitness": 0.08956095422255607, "name": "ADE_FBA_Enhanced", "description": "Enhanced ADE-FBA with Success-based Parameter Adaptation and Linear Population Reduction for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass ADE_FBA_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population_size = self.initial_population_size\n        self.success_count = 0  # Track successful trials\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_count += 1  # Increment on success\n\n                # Dynamic adaptation based on success rate\n                if eval_count % (self.population_size * 2) == 0:\n                    success_rate = self.success_count / (self.population_size * 2)\n                    self.mutation_factor = 0.4 + 0.6 * success_rate\n                    self.crossover_rate = 0.2 + 0.7 * (1 - success_rate)\n                    self.success_count = 0  # Reset success count\n\n                # Linear population size reduction\n                if eval_count % (self.initial_population_size * 10) == 0 and self.population_size > 4:\n                    self.population_size = max(4, self.population_size - 1)\n                    pop = pop[:self.population_size]\n                    fitness = fitness[:self.population_size]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 10, "feedback": "The algorithm ADE_FBA_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "7865f9c0-f4e7-4f39-bbce-127cb4017d83", "fitness": 0.08956095422255607, "name": "EADE_DC", "description": "Enhanced Adaptive Differential Evolution with Diversity-Controlled Mutation and Crossover (EADE-DC) adjusts mutation and crossover rates based on both population diversity and convergence speed to improve search efficiency.", "code": "import numpy as np\n\nclass EADE_DC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        prev_best_fitness = np.min(fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation based on diversity and convergence speed\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                convergence_speed = abs(prev_best_fitness - np.min(fitness)) / prev_best_fitness\n                self.mutation_factor = 0.3 + 0.7 * (diversity + convergence_speed) / 2\n                self.crossover_rate = 0.1 + 0.8 * (1 - (diversity + convergence_speed) / 2)\n                prev_best_fitness = np.min(fitness)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm EADE_DC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "c9153b2c-5ab5-4155-bbe8-83bbd18f03b7", "fitness": 0.08956095422255607, "name": "EADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (EADE-FBA) incorporates self-adaptive mutation and crossover strategies based on population diversity, further enhanced with a re-evaluation mechanism for stagnant solutions to improve search exploitation.", "code": "import numpy as np\n\nclass EADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_threshold = 0.1 * dim\n        self.re_evaluation_interval = self.population_size * 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        last_improvement = np.zeros(self.population_size)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    last_improvement[i] = eval_count\n\n                if eval_count % self.re_evaluation_interval == 0:\n                    stagnant = eval_count - last_improvement > self.stagnation_threshold\n                    re_eval_indices = np.where(stagnant)[0]\n                    for idx in re_eval_indices:\n                        re_eval_fitness = func(pop[idx])\n                        eval_count += 1\n                        if re_eval_fitness < fitness[idx]:\n                            fitness[idx] = re_eval_fitness\n                            last_improvement[idx] = eval_count\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm EADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "368b62b9-22a3-450e-b462-397faea1b693", "fitness": 0.08956095422255607, "name": "EADE_APS", "description": "Enhanced Adaptive Differential Evolution with Adaptive Population Size (EADE-APS) that dynamically adjusts population size, mutation, and crossover rates using fitness and diversity metrics.", "code": "import numpy as np\n\nclass EADE_APS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.min_population_size = 5\n        self.max_population_size = 15 * dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_population_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                indices = list(range(0, i)) + list(range(i+1, pop_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count % (pop_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                \n                # Adapt population size\n                if diversity > 0.1:\n                    pop_size = min(self.max_population_size, pop_size + 1)\n                elif diversity < 0.05:\n                    pop_size = max(self.min_population_size, pop_size - 1)\n                \n                # Reinitialize population if size changed\n                if pop_size != len(pop):\n                    pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                    fitness = np.array([func(ind) for ind in pop])\n                    eval_count += pop_size\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 13, "feedback": "The algorithm EADE_APS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "a9c38353-3915-408c-aad4-4374c3f256a9", "fitness": 0.08956095422255607, "name": "EADE_FDBA", "description": "Enhanced Adaptive Differential Evolution with Fitness and Diversity-Based Adaptation (EADE-FDBA) that incorporates an adaptive population resizing mechanism to focus computational resources more efficiently over time.", "code": "import numpy as np\n\nclass EADE_FDBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Adaptive population resizing\n                fitness_std = np.std(fitness)\n                if fitness_std < 1e-5:\n                    self.population_size = max(4, self.population_size // 2)\n                    pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in pop])\n                    eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 14, "feedback": "The algorithm EADE_FDBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "a445e1ad-87be-4a05-a21e-7bacc4dc8356", "fitness": 0.08956095422255607, "name": "EADE_AMC", "description": "Enhanced Adaptive Differential Evolution with Adaptive Mutation and Crossover (EADE-AMC) that dynamically adjusts mutation and crossover rates based on the current fitness ranking within the population.", "code": "import numpy as np\n\nclass EADE_AMC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation based on fitness ranking\n                if eval_count % (self.population_size * 2) == 0:\n                    sorted_indices = np.argsort(fitness)\n                    rank = np.argsort(sorted_indices)\n                    norm_rank = rank / (self.population_size - 1)\n                    self.mutation_factor = 0.2 + 0.8 * np.mean(norm_rank)\n                    self.crossover_rate = 0.8 * (1 - np.mean(norm_rank))\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 15, "feedback": "The algorithm EADE_AMC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "916079b7-9f19-404b-9a48-37467043aefa", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) introducing stochastic perturbation and elite retention to improve diversity and convergence speed.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.elite_fraction = 0.05  # New elite retention parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            elite_count = int(self.elite_fraction * self.population_size)  # Calculate elite count\n            elite_indices = fitness.argsort()[:elite_count]  # Identify elite individuals\n            new_pop = np.copy(pop)  # Initialize new population with current pop\n\n            for i in range(self.population_size):\n                if i in elite_indices:  # Preserve elite individuals\n                    continue\n                \n                indices = list(range(0, i)) + list(range(i + 1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                perturbation = np.random.normal(scale=0.1, size=self.dim)  # New stochastic perturbation\n                mutant = np.clip(a + self.mutation_factor * (b - c) + perturbation, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            pop = new_pop  # Update population\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 16, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "67e6112e-8b13-4e82-ba08-78b4f1a7ebe7", "fitness": 0.08956095422255607, "name": "EAD_VFBA", "description": "Enhanced Adaptive Differential Evolution with Vectorized Fitness-Based Adaptation (EAD-VFBA) utilizing vectorized operations and memory of previous mutations for better diversity and convergence.", "code": "import numpy as np\n\nclass EAD_VFBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.previous_mutations = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            for i in range(self.population_size):\n                idxs = indices[indices != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                mutant = 0.5 * mutant + 0.5 * self.previous_mutations[i]  # Use previous mutations\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.previous_mutations[i] = mutant  # Store successful mutation\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean(np.linalg.norm(pop[:, None] - pop, axis=2)) / self.dim\n                    self.mutation_factor = 0.4 + 0.6 * diversity  # Adjust factors\n                    self.crossover_rate = 0.2 + 0.7 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm EAD_VFBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "50a14ca8-657f-4794-ad66-2dc7219c977c", "fitness": 0.08956095422255607, "name": "E_ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (E-ADE-FBA) incorporating a novel diversity-aware mutation strategy and adaptive restart for improved exploration and convergence.", "code": "import numpy as np\n\nclass E_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.restart_threshold = 0.2  # Threshold for adaptive restart\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                # Diversity-aware mutation strategy\n                diversity = np.std(pop, axis=0) / (ub - lb)\n                self.mutation_factor = 0.3 + 0.4 * np.mean(diversity)\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Adaptive restart mechanism\n            if eval_count % (self.population_size * 2) == 0:\n                mean_fitness = np.mean(fitness)\n                worst_fitness = np.max(fitness)\n                if (worst_fitness - mean_fitness) / (np.abs(mean_fitness) + 1e-12) < self.restart_threshold:\n                    pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in pop])\n                    eval_count += self.population_size\n\n                # Dynamic adaptation of crossover rate\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm E_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "30425ea0-9580-4d86-95d1-257b018aa081", "fitness": 0.08956095422255607, "name": "E_ADE", "description": "Enhanced Adaptive Differential Evolution (E-ADE) that incorporates dynamic scaling of mutation and crossover parameters based on fitness variance and incorporates a probabilistic local search for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass E_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.local_search_prob = 0.1  # Probability of performing local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        def local_search(ind):\n            perturbation = np.random.normal(scale=(ub - lb) / 100, size=self.dim)\n            candidate = np.clip(ind + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            return (candidate, candidate_fitness) if candidate_fitness < func(ind) else (ind, func(ind))\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if np.random.rand() < self.local_search_prob:\n                    pop[i], fitness[i] = local_search(pop[i])\n                    eval_count += 1\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    fitness_variance = np.var(fitness)\n                    self.mutation_factor = 0.4 + 0.6 * np.tanh(fitness_variance)\n                    self.crossover_rate = 0.2 + 0.6 * (1 - np.tanh(fitness_variance))\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 19, "feedback": "The algorithm E_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d91e9552-92c8-4ba2-8f83-4a02859b520a", "fitness": 0.08956095422255607, "name": "IADE_DPR", "description": "Improved Adaptive Differential Evolution with Dynamic Population Resizing (IADE-DPR) that incorporates adaptive population resizing based on fitness diversity and convergence rate to enhance exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass IADE_DPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n            \n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.std(fitness) / np.mean(fitness)\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if diversity < 0.1 and self.population_size > 4 * self.dim:\n                    # Reduce the population if diversity is too low\n                    reduction_factor = 0.9\n                    self.population_size = int(self.population_size * reduction_factor)\n                    pop = pop[:self.population_size]\n                    fitness = fitness[:self.population_size]\n                elif diversity > 0.2 and self.population_size < self.initial_population_size:\n                    # Increase the population if diversity is high\n                    increase_factor = 1.1\n                    extra_pop_size = int(self.population_size * (increase_factor - 1))\n                    extra_pop = np.random.uniform(lb, ub, (extra_pop_size, self.dim))\n                    extra_fitness = np.array([func(ind) for ind in extra_pop])\n                    eval_count += extra_pop_size\n                    pop = np.vstack((pop, extra_pop))\n                    fitness = np.concatenate((fitness, extra_fitness))\n                    self.population_size = pop.shape[0]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm IADE_DPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "6bf08f8e-55aa-4e32-a33b-b640db41699a", "fitness": 0.08956095422255607, "name": "EADE_AA", "description": "Enhanced Adaptive Differential Evolution with Adaptive Archive (EADE-AA) incorporates an elite archive to enhance diversity and convergence by balancing exploration and exploitation through adaptive parameter control.", "code": "import numpy as np\n\nclass EADE_AA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.archive = []\n        self.archive_size = self.population_size // 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                if self.archive:\n                    d = self.archive[np.random.randint(len(self.archive))]\n                    a = np.random.choice([a, d])\n\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    self.archive.append(pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(np.random.randint(len(self.archive)))\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 21, "feedback": "The algorithm EADE_AA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "76f81a32-721e-4ec6-a8ed-053c5230f7de", "fitness": 0.08956095422255607, "name": "ADE_SAMC", "description": "Adaptive Differential Evolution with Self-Adaptive Mutation and Crossover (ADE-SAMC) introduces self-adjusting strategies for mutation and crossover rates based on historical performance, enhancing convergence efficiency and robustness.", "code": "import numpy as np\n\nclass ADE_SAMC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        success_mutation = []\n        success_crossover = []\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    success_mutation.append(self.mutation_factor)\n                    success_crossover.append(self.crossover_rate)\n\n                if eval_count >= self.budget:\n                    break\n\n            # Self-adaptation of mutation and crossover rates\n            if eval_count % (self.population_size * 2) == 0 and success_mutation:\n                self.mutation_factor = np.mean(success_mutation)\n                self.crossover_rate = np.mean(success_crossover)\n                success_mutation.clear()\n                success_crossover.clear()\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 22, "feedback": "The algorithm ADE_SAMC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "f4a577e2-1a10-4d42-b172-0b87193192f3", "fitness": 0.08956095422255607, "name": "IADE_DPS", "description": "Improved Adaptive Differential Evolution with Dynamic Population Size (IADE-DPS) that adjusts population size adaptively based on convergence speed and fitness improvements.", "code": "import numpy as np\n\nclass IADE_DPS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.initial_population_size\n\n        while eval_count < self.budget:\n            population_size = min(self.initial_population_size, self.budget - eval_count)\n            for i in range(population_size):\n                indices = list(range(0, i)) + list(range(i+1, population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 23, "feedback": "The algorithm IADE_DPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "02a48d56-ecca-4121-9d38-3b686c2cd417", "fitness": 0.08956095422255607, "name": "ADE_CMRD", "description": "Enhanced Adaptive Differential Evolution with Covariance-Based Mutation and Diversity-Driven Restart (ADE-CMDR) to exploit covariance information for improved mutation and reset population when diversity is low.", "code": "import numpy as np\n\nclass ADE_CMRD:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            cov_matrix = np.cov(pop, rowvar=False)  # Compute covariance matrix\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * np.dot(np.random.normal(0, 1, self.dim), cov_matrix), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Restart if diversity is too low\n                if diversity < 0.1:\n                    pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in pop])\n                    eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 24, "feedback": "The algorithm ADE_CMRD got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "3bdcd4a1-1b35-4e81-8657-f1a5a69d4b79", "fitness": 0.08956095422255607, "name": "ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation that incorporates adaptive population size adjustment for improved convergence.", "code": "import numpy as np\n\nclass ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.adaptive_population_size = int(self.population_size / 2)  # Initial adaptive size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.adaptive_population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    self.adaptive_population_size = max(4, int(self.population_size * (1 - diversity)))  # Update adaptive size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 25, "feedback": "The algorithm ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "fc193f91-5613-48ff-8556-6bca8f2b4b16", "fitness": 0.08956095422255607, "name": "EADE_DPS", "description": "Enhanced Adaptive Differential Evolution with Diversity-Preserving Strategy (EADE-DPS) that incorporates a diversity-preserving mechanism and self-adaptive mutation to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE_DPS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    fitness[i] = trial_fitness\n                else:\n                    new_pop.append(pop[i])\n                \n                if eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_pop)\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.std(pop, axis=0).mean()\n                self.mutation_factor = 0.3 + 0.7 * (1 - diversity)\n                self.crossover_rate = 0.5 + 0.5 * diversity\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 26, "feedback": "The algorithm EADE_DPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "bb65b5a2-a2c2-4268-8aeb-eadd0f259943", "fitness": 0.08956095422255607, "name": "E_ADE", "description": "Enhanced Adaptive Differential Evolution (E-ADE) incorporates a dynamic self-adaptive mechanism for mutation and crossover rates, leveraging historical performance trends to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass E_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.historical_fitness = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        self.historical_fitness.append(np.mean(fitness))\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation based on historical trends\n                if eval_count % (self.population_size * 2) == 0:\n                    current_mean_fitness = np.mean(fitness)\n                    prev_mean_fitness = self.historical_fitness[-1]\n                    improvement = prev_mean_fitness - current_mean_fitness\n                    self.historical_fitness.append(current_mean_fitness)\n\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = np.clip(self.mutation_factor + 0.1 * improvement / prev_mean_fitness, 0.3, 0.9)\n                    self.crossover_rate = np.clip(self.crossover_rate - 0.1 * improvement / prev_mean_fitness, 0.1, 0.9)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 27, "feedback": "The algorithm E_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "456e456c-c702-4d3b-923d-a31465670934", "fitness": 0.08956095422255607, "name": "QI_ADE", "description": "Quantum-Inspired Adaptive Differential Evolution (QI-ADE) incorporates quantum-inspired operations and adaptive strategies to enhance exploration and exploitation balancing in a dynamic environment.", "code": "import numpy as np\n\nclass QI_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                # Quantum-inspired mechanism\n                q_gate = np.random.rand(self.dim) < (1 / (1 + np.exp(-crossover)))\n                trial = np.where(q_gate, np.random.uniform(lb, ub, self.dim), trial)\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.2 + 0.8 * np.sqrt(diversity)\n                    self.crossover_rate = 0.15 + 0.75 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 28, "feedback": "The algorithm QI_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "7d856984-fafc-492e-af86-5d033aff505b", "fitness": 0.08956095422255607, "name": "ADE_FBMDA", "description": "Adaptive Differential Evolution with Fitness-Based and Memory-Driven Adaptation (ADE-FBMDA) that utilizes stored successful mutations to enhance exploration and model successful parameter adaptations.", "code": "import numpy as np\nfrom collections import deque\n\nclass ADE_FBMDA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.memory_factor = 0.5\n        self.successful_mutations = deque(maxlen=5 * dim)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                base_mutant = a + self.mutation_factor * (b - c)\n\n                # Utilize successful mutations\n                if self.successful_mutations:\n                    memory_mutant = np.mean(self.successful_mutations, axis=0)\n                    mutant = np.clip((1 - self.memory_factor) * base_mutant + self.memory_factor * memory_mutant, lb, ub)\n                else:\n                    mutant = np.clip(base_mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.successful_mutations.append(mutant)\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 29, "feedback": "The algorithm ADE_FBMDA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "440fbc3f-9edc-4207-9686-ab7be14c66d7", "fitness": 0.08956095422255607, "name": "ADE_CDC", "description": "Enhanced Adaptive Differential Evolution with Crowd-based Diversity Control (ADE-CDC) that introduces crowding distance to maintain diversity and dynamically adjusts parameters for robust exploration and exploitation.", "code": "import numpy as np\n\nclass ADE_CDC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        def crowding_distance(pop):\n            distances = np.zeros(self.population_size)\n            for i in range(self.dim):\n                sorted_indices = np.argsort(pop[:, i])\n                sorted_pop = pop[sorted_indices]\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, self.population_size - 1):\n                    distances[sorted_indices[j]] += (sorted_pop[j + 1, i] - sorted_pop[j - 1, i])\n            return distances\n\n        while eval_count < self.budget:\n            distances = crowding_distance(pop)\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i] or (trial_fitness == fitness[i] and distances[i] > np.median(distances)):\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 30, "feedback": "The algorithm ADE_CDC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "8a1eb136-0f4a-4f16-b732-ede658be58de", "fitness": 0.08956095422255607, "name": "ADE_FBA_Enhanced", "description": "Enhanced ADE-FBA with self-adaptive strategy parameters and stochastic ranking to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass ADE_FBA_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor_min = 0.3\n        self.mutation_factor_max = 0.9\n        self.crossover_rate_min = 0.5\n        self.crossover_rate_max = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        rank = np.argsort(fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + np.random.uniform(self.mutation_factor_min, self.mutation_factor_max) * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < np.random.uniform(self.crossover_rate_min, self.crossover_rate_max)\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                rank = np.argsort(fitness)\n                \n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 31, "feedback": "The algorithm ADE_FBA_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "5ca4d485-8c33-4328-a30b-0a0290065bad", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) with Fitness and Diversity-Based Adaptation, which dynamically adjusts mutation and crossover rates for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        # Record best solution\n        best_idx = np.argmin(fitness)\n        best_solution = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Dynamic adaptation based on diversity and fitness improvement\n                if eval_count % self.population_size == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    improvement = (best_fitness - np.min(fitness)) / abs(best_fitness)\n                    self.mutation_factor = 0.3 + 0.7 * (diversity + 0.5 * improvement)\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity + 0.5 * improvement)\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_solution, best_fitness", "configspace": "", "generation": 32, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "5e8b7e36-3e5d-48f4-be28-6e243517863f", "fitness": 0.08956095422255607, "name": "ADE_PS", "description": "A novel Adaptive Differential Evolution with Progressive Selection (ADE-PS) that incorporates a progressive selection mechanism to dynamically adjust the population size and enhance diversity for superior convergence.", "code": "import numpy as np\n\nclass ADE_PS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.current_population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.initial_population_size\n\n        while eval_count < self.budget:\n            for i in range(self.current_population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.current_population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.current_population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    # Progressive selection mechanism\n                    if diversity < 0.1:\n                        self.current_population_size = max(5 * self.dim, self.current_population_size // 2)\n                        selected_indices = np.argsort(fitness)[:self.current_population_size]\n                        pop = pop[selected_indices]\n                        fitness = fitness[selected_indices]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 33, "feedback": "The algorithm ADE_PS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "4d5ccabf-7bb1-487d-94a1-8107d66bd61e", "fitness": 0.08956095422255607, "name": "ADE_FBA_Improved", "description": "Improved Adaptive Differential Evolution incorporating adaptive population size and diversity-enhanced mutation strategies to enhance convergence and exploration capabilities.", "code": "import numpy as np\n\nclass ADE_FBA_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.min_population_size = 4 * dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c) + 0.1 * (pop.mean(axis=0) - a), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = max(self.min_population_size, int(self.population_size * 0.9))\n                        pop = pop[:self.population_size]\n                        fitness = fitness[:self.population_size]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 34, "feedback": "The algorithm ADE_FBA_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d761bbb0-3b26-40a2-a22c-4d80420a7a9b", "fitness": 0.08956095422255607, "name": "ADE_FBA_LS", "description": "Improved Adaptive Differential Evolution using Fitness-Based Adaptation (ADE-FBA) with Local Search Intensification for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ADE_FBA_LS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.local_search_intensity = 5  # New parameter for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Local Search Intensification\n                if eval_count % (self.population_size * 5) == 0:\n                    for _ in range(self.local_search_intensity):\n                        neighbor = np.clip(pop[i] + np.random.normal(0, 0.1, self.dim), lb, ub)\n                        neighbor_fitness = func(neighbor)\n                        eval_count += 1\n                        if neighbor_fitness < fitness[i]:\n                            pop[i] = neighbor\n                            fitness[i] = neighbor_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 35, "feedback": "The algorithm ADE_FBA_LS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "6943c1f7-8a6a-4a0f-9f3c-7bfdc1ed73dc", "fitness": 0.08956095422255607, "name": "ADE_FBA", "description": "Enhanced Dynamic Differential Evolution with Memory-Based Adaptation (EDDE-MBA) that uses memory of successful mutations to adapt mutation and crossover rates dynamically.", "code": "import numpy as np\n\nclass ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.successful_mutations = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.successful_mutations.append(self.mutation_factor)\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.4 + 0.6 * diversity\n                    self.crossover_rate = 0.2 + 0.7 * (1 - diversity)\n\n                    # Use memory of successful mutations\n                    if self.successful_mutations:\n                        self.mutation_factor = np.mean(self.successful_mutations[-5:])\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 36, "feedback": "The algorithm ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "01a39383-bdde-475c-acef-0a9f8df5fd94", "fitness": 0.08956095422255607, "name": "ADE_DMMCS", "description": "Adaptive Differential Evolution with Dynamic Multi-Mutation and Crossover Strategies (ADE-DMMCS) that integrates multiple mutation and crossover strategies for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ADE_DMMCS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.strategy_switch_frequency = 0.2 * self.budget \n\n    def mutate(self, pop, i):\n        indices = list(range(0, i)) + list(range(i+1, self.population_size))\n        a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n        return np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n\n    def crossover(self, mutant, target):\n        crossover = np.random.rand(self.dim) < self.crossover_rate\n        return np.where(crossover, mutant, target)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        mutation_strategy = self.mutate\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                mutant = mutation_strategy(pop, i)\n                trial = self.crossover(mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count % self.strategy_switch_frequency < self.population_size:\n                    self.mutation_factor = np.random.rand()\n                    self.crossover_rate = np.random.rand()\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 37, "feedback": "The algorithm ADE_DMMCS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "ea053d42-d3f2-4284-b2a5-69ae1d6310de", "fitness": 0.08956095422255607, "name": "EADE_DGS", "description": "Enhanced Adaptive Differential Evolution with Diversity-Guided Strategies (EADE-DGS) that leverages population diversity to dynamically adjust mutation and crossover operators, and introduces a dynamic population resizing mechanism.", "code": "import numpy as np\n\nclass EADE_DGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(min(self.population_size, self.budget - eval_count)):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation\n            diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n            self.mutation_factor = 0.3 + 0.7 * diversity\n            self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n            if diversity < 0.1 and self.population_size > 5 * self.dim:\n                self.population_size = max(5 * self.dim, self.population_size // 2)\n\n            if eval_count >= self.budget:\n                break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 38, "feedback": "The algorithm EADE_DGS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "77404282-5959-4d71-8e16-7c7b37c43423", "fitness": 0.08956095422255607, "name": "EADE_DPS", "description": "Enhanced Adaptive Differential Evolution with Dynamic Population Sizing (EADE-DPS) that adapts mutation and crossover rates based on fitness diversity and dynamically adjusts population size for efficient convergence.", "code": "import numpy as np\n\nclass EADE_DPS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_population_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                indices = list(range(0, i)) + list(range(i+1, pop_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation of factors and population resizing\n            if eval_count % (pop_size * 2) == 0:\n                diversity = np.std(fitness) / (np.mean(fitness) + 1e-9)\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Adjust population size based on convergence\n                if diversity < 0.1:\n                    pop_size = max(int(pop_size * 0.9), self.dim)\n                else:\n                    pop_size = min(int(pop_size * 1.1), self.initial_population_size)\n\n                pop = pop[:pop_size]\n                fitness = fitness[:pop_size]\n\n            if eval_count >= self.budget:\n                break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm EADE_DPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d69d1f25-c8e7-4349-b1b2-80945ab45b9c", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) with Dynamic Diversity Control, which adaptively adjusts mutation and crossover rates as well as population size based on real-time diversity and convergence trends to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_population_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            \n            for i in range(pop_size):\n                indices = list(range(0, i)) + list(range(i + 1, pop_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n                if eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            best_idx = np.argmin(fitness)\n            \n            # Dynamic adaptation\n            diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n            self.mutation_factor = 0.3 + 0.7 * diversity\n            self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n            if eval_count % (self.initial_population_size * 2) == 0:\n                if diversity < 0.1:\n                    pop_size = min(self.initial_population_size * 2, self.budget - eval_count + pop_size)\n                    pop = np.vstack((pop, np.random.uniform(lb, ub, (pop_size - len(pop), self.dim))))\n                    fitness = np.hstack((fitness, [func(ind) for ind in pop[len(fitness):]]))\n                    eval_count += pop_size - len(pop)\n                else:\n                    pop_size = max(self.initial_population_size // 2, 4)\n                    indices = np.argsort(fitness)[:pop_size]\n                    pop = pop[indices]\n                    fitness = fitness[indices]\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 40, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "4c09fd11-0302-464d-a309-982c3f5f158c", "fitness": 0.08956095422255607, "name": "EDE", "description": "Enhanced Differential Evolution (EDE) introduces adaptive mutation and crossover strategies with periodic random reinitialization of subpopulations to maintain diversity and improve convergence.", "code": "import numpy as np\n\nclass EDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.reinit_interval = self.population_size * 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Periodic reinitialization of part of the population\n                if eval_count % self.reinit_interval == 0:\n                    num_reinit = self.population_size // 5\n                    reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                    pop[reinit_indices] = np.random.uniform(lb, ub, (num_reinit, self.dim))\n                    fitness[reinit_indices] = [func(ind) for ind in pop[reinit_indices]]\n                    eval_count += num_reinit\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 41, "feedback": "The algorithm EDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "36145d36-1177-4ad9-8d3b-462bdd91e5eb", "fitness": 0.08956095422255607, "name": "EADE_FDBA", "description": "Enhanced Adaptive Differential Evolution with Fitness and Diversity-Based Adaptation (EADE-FDBA) introduces a multi-objective approach combining fitness improvement and diversity preservation to dynamically adjust mutation and crossover rates for improved convergence.", "code": "import numpy as np\n\nclass EADE_FDBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        def calculate_diversity(population):\n            pairwise_distances = np.array([np.linalg.norm(p1 - p2) for i, p1 in enumerate(population) for p2 in population[i+1:]])\n            return np.mean(pairwise_distances) / self.dim\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Multi-objective dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = calculate_diversity(pop)\n                    fitness_improvement = np.mean([np.abs(fitness[i] - func(pop[i])) for i in range(self.population_size)])\n                    self.mutation_factor = 0.3 + 0.7 * diversity / (1.0 + fitness_improvement)\n                    self.crossover_rate = 0.1 + 0.8 * (1.0 - diversity / (1.0 + fitness_improvement))\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 42, "feedback": "The algorithm EADE_FDBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "dfe4c57b-3427-4c5b-8020-b3427369ff2d", "fitness": 0.08956095422255607, "name": "EADE_DDC", "description": "Enhanced Adaptive Differential Evolution with Dynamic Diversity Control (EADE-DDC) using adaptive scaling and mutation strategies based on population diversity.", "code": "import numpy as np\n\nclass EADE_DDC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.scaling_factor = 0.5  # New scaling factor\n        self.diversity_threshold = 0.1  # New threshold for diversity control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c) * self.scaling_factor, lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.4 + 0.6 * diversity\n                self.crossover_rate = 0.2 + 0.7 * (1 - diversity)\n                self.scaling_factor = 0.3 * (diversity / self.diversity_threshold)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 43, "feedback": "The algorithm EADE_DDC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d3987eff-b064-4268-85c5-ea0ba1575e6d", "fitness": 0.08956095422255607, "name": "Improved_ADE_FBA", "description": "Improved Adaptive Differential Evolution with Fitness-Based Adaptation (ADE-FBA) integrating success-history based parameter adaptation and a greedy selection mechanism for enhanced convergence.", "code": "import numpy as np\n\nclass Improved_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_history.append((self.mutation_factor, self.crossover_rate))\n                \n                # Success-history based adaptation\n                if eval_count % (self.population_size * 2) == 0 and self.success_history:\n                    avg_mutation, avg_crossover = np.mean(self.success_history, axis=0)\n                    self.mutation_factor = max(0.1, min(0.9, avg_mutation))\n                    self.crossover_rate = max(0.1, min(0.9, avg_crossover))\n                    self.success_history = []\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 44, "feedback": "The algorithm Improved_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "95a4819a-e7ed-4e7b-835c-82bde9a15ccf", "fitness": 0.08956095422255607, "name": "EDE_DL", "description": "Enhanced Differential Evolution with Dynamic Learning (EDE-DL) integrates adaptive parameters and a learning mechanism to improve convergence speed and solution quality using historical data and diversity insights.", "code": "import numpy as np\n\nclass EDE_DL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.historical_data = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        self.historical_data = list(zip(pop, fitness))\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n                if eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n\n            # Update historical data\n            self.historical_data.extend(zip(pop, fitness))\n            self.historical_data = sorted(self.historical_data, key=lambda x: x[1])[:self.population_size]\n\n            # Dynamic adaptation using historical data\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.std([ind for ind, _ in self.historical_data]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 45, "feedback": "The algorithm EDE_DL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "c5ef6304-4f3e-4ace-86ea-1a30c78d6c79", "fitness": 0.08956095422255607, "name": "IADE_FBA", "description": "Improved Adaptive Differential Evolution with Fitness-Based Adaptation (IADE-FBA) that incorporates a dynamic strategy pool and self-adaptive parameter control to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass IADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.strategy_pool = [('rand/1', 0.5, 0.9), ('best/1', 0.7, 0.7)]\n        self.adaptation_period = 50\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        strategy_scores = np.zeros(len(self.strategy_pool))\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                strategy_idx = np.argmax(np.random.multinomial(1, strategy_scores + 1e-9))\n                strategy, F, CR = self.strategy_pool[strategy_idx]\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                if strategy == 'rand/1':\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n                elif strategy == 'best/1':\n                    best_idx = np.argmin(fitness)\n                    mutant = np.clip(pop[best_idx] + F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    strategy_scores[strategy_idx] += 1\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count % self.adaptation_period == 0:\n                strategy_scores = strategy_scores / np.sum(strategy_scores)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 46, "feedback": "The algorithm IADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "19a0df52-65ca-4c78-8dce-ea617e1f14c5", "fitness": 0.08956095422255607, "name": "ADE_FBA_PC", "description": "Adaptive Differential Evolution with Fitness-Based Adaptation and Population Clustering (ADE-FBA-PC) that incorporates dynamic mutation and crossover rates with a clustering mechanism to maintain diversity and focus exploration on promising regions.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass ADE_FBA_PC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.num_clusters = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Clustering to maintain diversity\n            if eval_count % (self.population_size * 5) == 0:\n                kmeans = KMeans(n_clusters=min(self.num_clusters, self.population_size))\n                labels = kmeans.fit_predict(pop)\n            else:\n                labels = np.zeros(self.population_size)  # no clustering\n\n            for i in range(self.population_size):\n                cluster_indices = np.where(labels == labels[i])[0]\n                if len(cluster_indices) <= 3:\n                    cluster_indices = np.arange(self.population_size)\n\n                indices = list(set(range(self.population_size)) - {i})\n                a, b, c = pop[np.random.choice(cluster_indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 47, "feedback": "The algorithm ADE_FBA_PC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d6978397-febc-4349-a521-e533be73a38e", "fitness": 0.08956095422255607, "name": "E_ADE_APR", "description": "Enhanced Adaptive Differential Evolution with Adaptive Population Resizing (E-ADE-APR) that refines mutation and crossover strategies alongside population resizing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass E_ADE_APR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n            # Dynamic adaptation and population resizing\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                if diversity < 0.2:\n                    self.population_size = max(5, self.population_size // 2)\n                    pop = pop[:self.population_size]\n                    fitness = fitness[:self.population_size]\n                elif diversity > 0.8:\n                    extra_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    pop = np.vstack((pop, extra_pop))\n                    fitness = np.hstack((fitness, np.array([func(ind) for ind in extra_pop])))\n                    self.population_size = pop.shape[0]\n                    eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 48, "feedback": "The algorithm E_ADE_APR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "f3408b76-6e2b-430d-963c-e3f647081c24", "fitness": 0.08956095422255607, "name": "EADE_FBA_DM", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation and Differential Mutation (EADE-FBA-DM) that adaptively adjusts both control parameters and employs a differential mutation strategy to improve convergence speed and robustness.", "code": "import numpy as np\n\nclass EADE_FBA_DM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_mutation_factor = 0.7\n        self.initial_crossover_rate = 0.7\n        self.mutation_factor = self.initial_mutation_factor\n        self.crossover_rate = self.initial_crossover_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                \n                # Dynamic adaptation and differential mutation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.std(pop, axis=0).mean() / self.dim\n                    self.mutation_factor = 0.5 + 0.5 * diversity\n                    self.crossover_rate = 0.2 + 0.6 * (1 - diversity)\n                    if diversity < 0.1:  # Introduce differential mutation when diversity is low\n                        a, b, c = pop[np.random.choice(self.population_size, 3, replace=False)]\n                        pop[i] = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                        fitness[i] = func(pop[i])\n                        eval_count += 1\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 49, "feedback": "The algorithm EADE_FBA_DM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "8fcf54be-448c-4d23-a79c-b97c80c37288", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) applies dynamic adaptation of mutation and crossover rates based on convergence speed and incorporates an elitist strategy to retain the best solutions.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_solution = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                # Dynamic adaptation based on convergence speed\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    convergence_speed = np.std(fitness) / np.mean(fitness)\n                    self.mutation_factor = 0.3 + 0.7 * diversity * (1 - convergence_speed)\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity) * convergence_speed\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_solution, best_fitness", "configspace": "", "generation": 50, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "d93c2d97-bcca-42b4-9dbf-60a93af4ba82", "fitness": 0.08956095422255607, "name": "ADE_FBA_RPC", "description": "Adaptive Differential Evolution with Fitness-Based Adaptation and Rank-based Parameter Control (ADE-FBA-RPC), enhancing performance by adapting mutation and crossover rates using rank-based diversity measures.", "code": "import numpy as np\n\nclass ADE_FBA_RPC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation with rank-based diversity\n                if eval_count % (self.population_size * 2) == 0:\n                    sorted_indices = np.argsort(fitness)\n                    rank_diversity = np.mean([np.linalg.norm(pop[i] - pop[j]) \n                                             for i in sorted_indices[:self.population_size//2] \n                                             for j in sorted_indices[self.population_size//2:]])\n                    rank_diversity /= self.dim\n                    self.mutation_factor = 0.3 + 0.7 * rank_diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - rank_diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 51, "feedback": "The algorithm ADE_FBA_RPC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "3d88d2f9-820b-4d04-9381-fb9042e044db", "fitness": 0.08956095422255607, "name": "EADE_DA", "description": "Enhanced Adaptive Differential Evolution with Dynamic Adjustments (EADE-DA) that employs adaptive population size and feedback-driven control of mutation and crossover rates to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EADE_DA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.initial_population_size) == 0:\n                    diversity = np.std(fitness)\n                    self.mutation_factor = 0.3 + 0.4 * (1 - diversity)\n                    self.crossover_rate = 0.2 + 0.6 * diversity\n                    if diversity < 0.1 and self.population_size > 4:\n                        self.population_size -= 1\n                    elif diversity > 0.6:\n                        self.population_size = min(self.initial_population_size, self.population_size + 1)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 52, "feedback": "The algorithm EADE_DA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "429c0b65-0fe3-4852-a301-a9ac14efccb9", "fitness": 0.08956095422255607, "name": "EADE_SR", "description": "Enhanced Adaptive Differential Evolution with Strategic Restart (EADE-SR) that incorporates strategic restarting to escape local optima and improve convergence.", "code": "import numpy as np\n\nclass EADE_SR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.restart_threshold = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        def initialize_population():\n            return np.random.uniform(lb, ub, (self.population_size, self.dim))\n        \n        pop = initialize_population()\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        best_fitness = float('inf')\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                # Strategic Restart\n                if eval_count % (self.population_size * 5) == 0:\n                    current_best = np.min(fitness)\n                    if current_best < best_fitness - self.restart_threshold * best_fitness:\n                        best_fitness = current_best\n                    else:\n                        pop = initialize_population()\n                        fitness = np.array([func(ind) for ind in pop])\n                        eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 53, "feedback": "The algorithm EADE_SR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "bb8d7ce5-a334-4bc2-9562-b657f3b7619a", "fitness": 0.08956095422255607, "name": "EDE_AMS", "description": "Enhanced Differential Evolution with Adaptive Multi-Strategy (EDE-AMS) that combines multiple mutation strategies and adaptively tunes parameters to improve exploration and exploitation.", "code": "import numpy as np\n\nclass EDE_AMS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.strategy_probs = [0.5, 0.5]  # Initial probabilities for strategies\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c, d = pop[np.random.choice(indices, 4, replace=False)]\n                \n                if np.random.rand() < self.strategy_probs[0]:\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                else:\n                    mutant = np.clip(a + self.mutation_factor * (b - c + d - a), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    self.strategy_probs = [0.5 + 0.5 * (1 - diversity), 0.5 - 0.5 * (1 - diversity)]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 54, "feedback": "The algorithm EDE_AMS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "daea28a8-401a-43e1-a9cc-3e62d723886d", "fitness": 0.08956095422255607, "name": "E_ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation (E-ADE-FBA) introducing an elite preservation mechanism and adaptive scaling of crossover rate based on recent success rates.", "code": "import numpy as np\n\nclass E_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.elite_fraction = 0.1  # Introducing elite fraction for preservation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            num_elites = max(1, int(self.elite_fraction * self.population_size))\n            elites = pop[np.argsort(fitness)[:num_elites]]  # Preserving elites\n\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    recent_success_rate = np.mean([1 if trial_fitness < fitness[i] else 0 for i in range(self.population_size)])\n                    self.crossover_rate = 0.1 + 0.8 * recent_success_rate  # Adaptive scaling based on success\n\n                if eval_count >= self.budget:\n                    break\n\n            pop[:num_elites] = elites  # Re-inserting preserved elites\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 55, "feedback": "The algorithm E_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "065559e4-d016-42dc-849e-690b4ab9b5fe", "fitness": 0.08956095422255607, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) incorporates a novel scaling factor and adaptive crossover mechanism based on population performance dynamics.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.4 * diversity\n                    self.crossover_rate = 0.4 + 0.5 * (1 - diversity)\n                    if np.std(fitness) < 0.1:  # New condition for stagnation\n                        self.mutation_factor *= 1.2  # Boost mutation factor\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 56, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "6ba40f6f-2a53-4046-996f-17469881bb83", "fitness": 0.08956095422255607, "name": "E_ADE_FBA", "description": "Enhanced Adaptive Differential Evolution with Fitness-Based Adaptation and Dynamic Strategy Selection (E-ADE-FBA) that incorporates multiple mutation strategies and adapts strategy selection based on performance feedback.", "code": "import numpy as np\n\nclass E_ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.strategy_weights = np.array([0.5, 0.5])  # Start with equal weights for two strategies\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n\n                # Choose strategy-based mutation\n                strategy_prob = np.random.rand()\n                if strategy_prob < self.strategy_weights[0]:\n                    # DE/rand/1 strategy\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                else:\n                    # DE/best/1 strategy\n                    best = pop[np.argmin(fitness)]\n                    mutant = np.clip(best + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    # Increase the weight of the successful strategy\n                    if strategy_prob < self.strategy_weights[0]:\n                        self.strategy_weights[0] += 0.1\n                    else:\n                        self.strategy_weights[1] += 0.1\n\n                # Normalize strategy weights\n                self.strategy_weights /= np.sum(self.strategy_weights)\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 57, "feedback": "The algorithm E_ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "05b6f69a-c7b9-40e5-9b5e-c1b2f90751f8", "fitness": 0.08956095422255607, "name": "IADE_DA", "description": "Improved Adaptive Differential Evolution with Dual Adaptation (IADE-DA) that incorporates both mutation and crossover rate adjustment based on diversity and fitness trends, enhancing convergence and exploration capabilities.", "code": "import numpy as np\n\nclass IADE_DA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        previous_mean_fitness = np.mean(fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dual adaptation mechanism\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    current_mean_fitness = np.mean(fitness)\n                    fitness_trend = (previous_mean_fitness - current_mean_fitness) / previous_mean_fitness\n\n                    self.mutation_factor = np.clip(0.3 + 0.7 * diversity * fitness_trend, 0.1, 1.0)\n                    self.crossover_rate = np.clip(0.1 + 0.8 * (1 - diversity) * fitness_trend, 0.1, 1.0)\n\n                    previous_mean_fitness = current_mean_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 58, "feedback": "The algorithm IADE_DA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "15343e67-756b-4ed3-9c70-0b42951d9a78", "fitness": 0.08956095422255607, "name": "ADE_FBA", "description": "Improved Adaptive Differential Evolution with Fitness-Based Adaptation using adaptive population sizes and mutation factor based on fitness variance.", "code": "import numpy as np\n\nclass ADE_FBA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.initial_population_size\n\n        while eval_count < self.budget:\n            for i in range(len(pop)):\n                indices = list(range(0, i)) + list(range(i+1, len(pop)))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count % (len(pop) * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    fitness_var = np.var(fitness)\n                    if fitness_var < 0.1:\n                        pop = pop[:len(pop)//2]\n                        fitness = fitness[:len(pop)//2]\n                    \n                if eval_count >= self.budget:\n                    break\n                \n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 59, "feedback": "The algorithm ADE_FBA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "6a0c14d0-9361-4ead-bc13-e75dd8f3f30e", "fitness": 0.08956095422255607, "name": "EDE_GIM", "description": "Enhanced Adaptive Differential Evolution with Gradient-Informed Mutation (EDE-GIM) that integrates gradient estimation for improved exploration and convergence by adjusting strategy parameters based on fitness landscape analysis.", "code": "import numpy as np\n\nclass EDE_GIM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        # Gradient estimation variables\n        delta = 1e-5\n        gradient_factor = 0.01\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Select three distinct individuals for mutation\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n\n                # Gradient-informed mutation\n                gradient = self.estimate_gradient(func, pop[i], delta)\n                enhanced_mutant = mutant + gradient_factor * gradient\n                enhanced_mutant = np.clip(enhanced_mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, enhanced_mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Dynamic adaptation\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    gradient_factor = 0.01 + 0.1 * (1 - diversity)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]\n\n    def estimate_gradient(self, func, x, delta):\n        grad = np.zeros(self.dim)\n        for j in range(self.dim):\n            x_forward = np.copy(x)\n            x_forward[j] += delta\n            grad[j] = (func(x_forward) - func(x)) / delta\n        return grad", "configspace": "", "generation": 60, "feedback": "The algorithm EDE_GIM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08956 with standard deviation 0.02499.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12377221833358887, 0.12303928189936342, 0.06325422940732106, 0.06338925468852208, 0.06330041451836388, 0.08208282054445415, 0.08234334562559942, 0.08217156820548921]}}
{"id": "eb4028ca-8546-4a48-96f9-603fb85feb37", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) improves search efficiency by incorporating adaptive mutation based on success history and dynamic population size adjustment.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 61, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["c412177a-fec8-4269-882d-6d9a1c444e30"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "94e24a17-c29b-46a4-985c-c4e574b08f4f", "fitness": 0.0895921035690345, "name": "EADE_SAC", "description": "Enhanced Adaptive Differential Evolution with Success-Based Adaptive Crossover leverages adaptive crossover rates based on success history to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE_SAC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                if self.success_crossover_rates:\n                    crossover_rate = np.mean(self.success_crossover_rates)\n                else:\n                    crossover_rate = self.crossover_rate\n\n                crossover = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(crossover_rate)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 62, "feedback": "The algorithm EADE_SAC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "60d613ee-612f-4060-9bc8-39304812aa04", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) with adaptive selection pressure through dynamic scaling factor adjustment based on convergence speed.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity  # Adaptive scaling factor adjustment\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 63, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "86a0bf6d-084f-4091-ae67-c8c4b8afbd6f", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) with improved diversity check by introducing a minimum threshold for mutation factor to maintain search exploration.  ", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = max(0.1, self.mutation_factor) if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 64, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "85d9f12e-9724-43ac-809b-78d67625b545", "fitness": 0.0895921035690345, "name": "IADE", "description": "Improved Adaptive Differential Evolution (IADE) enhances EADE by introducing adaptive control of both mutation and crossover rates based on historical performance and by using a diversity-preserving mechanism to maintain population variety.", "code": "import numpy as np\n\nclass IADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                Cr = self.crossover_rate if not self.success_crossover_rates else np.mean(self.success_crossover_rates)\n                crossover = np.random.rand(self.dim) < Cr\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(Cr)\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                \n                if diversity < 0.1:\n                    self.population_size = min(2 * self.population_size, 10 * dim)\n                    new_individuals = np.random.uniform(lb, ub, (self.population_size - len(pop), self.dim))\n                    pop = np.vstack((pop, new_individuals))\n                    fitness = np.append(fitness, [func(ind) for ind in new_individuals])\n                    eval_count += len(new_individuals)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 65, "feedback": "The algorithm IADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "d77e5fa7-ef3d-4efd-a8e3-f206b35c374d", "fitness": 0.08959114561340727, "name": "EADE", "description": "Modified EADE by adapting mutation factor based on diversity and success history.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Modified line: incorporate diversity into mutation factor\n                F = self.mutation_factor if not self.success_mutation_factors else (np.mean(self.success_mutation_factors) + np.std(self.success_mutation_factors)) / 2\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 66, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377221833358887, 0.12322170040682856, 0.0632564300029198, 0.06338925468852208, 0.06332252122636928, 0.08208709539987658, 0.08234334562559942, 0.08221404078238415]}}
{"id": "ecc9ae67-e78a-484d-8868-dc8836c77eb4", "fitness": 0.0895921035690345, "name": "EADE_ACM", "description": "Enhanced Adaptive Differential Evolution with Adaptive Crossover and Memory (EADE-ACM) utilizes adaptive crossover rates and memory-based mutation factor adjustments to enhance convergence and maintain diversity.", "code": "import numpy as np\n\nclass EADE_ACM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                CR = self.crossover_rate if not self.success_crossover_rates else np.mean(self.success_crossover_rates)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(CR)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 67, "feedback": "The algorithm EADE_ACM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "3f1cf25b-09ef-4ecf-bc81-367af33f0db0", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution with diversity-controlled mutation and crossover rates for improved optimization performance.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.5 + 0.5 * diversity  # Adjusted mutation factor range\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 68, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "a669d668-d7cb-4cfc-be56-6749c6eb2c4d", "fitness": 0.0895921035690345, "name": "APEDE", "description": "Adaptive Population Enhanced Differential Evolution (AP-EDE) enhances EADE by integrating adaptive population resampling based on fitness variance and mutation factor adjustment to maintain diversity and improve convergence.", "code": "import numpy as np\n\nclass APEDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, 10 * dim // 2)\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.min_diversity = 0.1\n        self.resample_threshold = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if diversity < self.min_diversity:\n                    new_population = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in new_population])\n                    eval_count += self.initial_population_size\n                    self.population_size = self.initial_population_size\n                    pop = new_population\n\n                if np.std(fitness) < self.resample_threshold:\n                    pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(ind) for ind in pop])\n                    eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 69, "feedback": "The algorithm APEDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "ad4b63ab-a96c-4507-9f0f-5834f5674c2f", "fitness": 0.0895921035690345, "name": "EADE_DTA", "description": "Enhanced Adaptive Differential Evolution with Dynamic Threshold Adjustment (EADE-DTA) introduces dynamic threshold scaling for mutation and crossover, adapting based on population convergence and successful trial history to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EADE_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n        self.success_crossover_rates = []  # Track successful crossover rates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                CR = self.crossover_rate if not self.success_crossover_rates else np.mean(self.success_crossover_rates)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n                    self.success_crossover_rates.append(CR)  # Store successful crossover rate\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    threshold = np.percentile(fitness, 30)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * self.dim)\n                    pop = np.array([ind for ind, fit in zip(pop, fitness) if fit < threshold])\n                    fitness = fitness[fitness < threshold]\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 70, "feedback": "The algorithm EADE_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "932b5c7a-5425-42b6-8389-2c6a276bb80b", "fitness": 0.0895921035690345, "name": "EADE", "description": "Optimized mutation factor update by averaging historical trials for enhanced convergence.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors[-10:])  # Changed line: average of last 10 successes\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 71, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "cb695bc8-4e31-43da-a154-eee96dc50cae", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution with dynamic crossover and diversity-based mutation strategies.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use mean of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 72, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "fd82d4af-d93b-4293-95c4-c87328ee56ae", "fitness": 0.0895921035690345, "name": "EADE", "description": "Enhanced Adaptive Differential Evolution (EADE) improves search efficiency by incorporating adaptive mutation based on success history and dynamic population size adjustment, with a refined mutation factor selection.", "code": "import numpy as np\n\nclass EADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  # Dynamic population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []  # Track successful mutation factors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.mutation_factor if not self.success_mutation_factors else np.median(self.success_mutation_factors)\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Use median of successful mutations\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)  # Store successful mutation factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:  # Dynamic population size adjustment\n                        self.population_size = min(2 * self.population_size, 10 * dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 73, "feedback": "The algorithm EADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377858938507891, 0.12322170040682856, 0.0632564300029198, 0.06339001919033682, 0.06332252122636928, 0.08208709539987658, 0.08234483167293971, 0.08221404078238415]}}
{"id": "a090cf73-7103-48f0-95cb-d9e2a661c1f2", "fitness": 0.0896017306508275, "name": "ASMDE", "description": "Advanced Stochastic Mutation Differential Evolution (ASMDE) enhances search by introducing stochastic mutation factors and adaptive crossover rates based on population diversity to improve convergence efficiency.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) + np.random.normal(0, 0.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1: \n                        self.population_size = min(2 * self.population_size, 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 74, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["eb4028ca-8546-4a48-96f9-603fb85feb37"], "operator": null, "metadata": {"aucs": [0.12278230966234993, 0.12377221833358887, 0.12322350050594744, 0.06326467298313254, 0.06338925468852208, 0.06332273787425036, 0.08210307608444523, 0.08234334562559942, 0.08221446009961153]}}
{"id": "568f6646-ef88-40c6-a97a-5e80f276e1e0", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "ASMDE with Adaptive Population Resizing and Dynamic Mutation Factor Adjustment improves exploration by dynamically resizing the population based on diversity and using adaptive mutation factors for enhanced convergence.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 75, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["a090cf73-7103-48f0-95cb-d9e2a661c1f2"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "f2b0ef33-e8bb-4e60-a875-e49ecaab3ec3", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Improved ASMDE with Adaptive Crossover Rate Adjustment to maintain exploration-exploitation balance.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.9 * (1 - diversity)  # Adjusted crossover rate\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 76, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "2caf271c-4f19-44de-a207-1e326a17b971", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "ASMDE with Enhanced Mutation Strategy improves exploration by dynamically adjusting the mutation factor range for better convergence.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.8, 1.2) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 77, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "b17aab4e-c013-4fac-809a-c80131eef759", "fitness": 0.08959698257401788, "name": "EASMDE", "description": "Enhanced ASMDE with Self-adaptive Mutation and Crossover (EASMDE), incorporating feedback loops for mutation and crossover rates based on recent successes to improve convergence and diversity management.", "code": "import numpy as np\n\nclass EASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                F = (np.mean(self.success_mutation_factors) if self.success_mutation_factors \n                     else self.base_mutation_factor) * np.random.uniform(0.9, 1.1)\n                C = (np.mean(self.success_crossover_rates) if self.success_crossover_rates \n                     else self.crossover_rate) * np.random.uniform(0.9, 1.1)\n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < C\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(C)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 78, "feedback": "The algorithm EASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12270724320541926, 0.12377221833358887, 0.12326699266533847, 0.06325564931174266, 0.06338925468852208, 0.06332796544044805, 0.08208557266056471, 0.08234334562559942, 0.08222460123493747]}}
{"id": "2cb6a19a-5dde-4005-a3fc-93800b2ca09c", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Enhanced Adaptive Mutation Factor with Consideration of Population Fitness Diversity for Improved Convergence", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    fitness_diversity = np.std(fitness) / np.mean(fitness)\n                    self.base_mutation_factor = 0.3 + 0.7 * fitness_diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - fitness_diversity)\n\n                    if fitness_diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 79, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "4a387dd2-f13c-4692-9e4d-b9a8ff1c4967", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Enhanced Adaptive Mutation Factor by introducing a dynamic scaling factor based on past successes to improve convergence.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F * 1.05)  # Line changed: Increased scaling factor\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 80, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "e61ee895-af07-4755-afd8-407133ea7b38", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Dynamic Learning Rate and Adaptive Crossover enhances convergence by dynamically adjusting learning rates based on fitness improvement trends and adapting crossover rates based on population diversity.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        prev_best_fitness = np.min(fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    current_best_fitness = np.min(fitness)\n                    if current_best_fitness < prev_best_fitness:\n                        self.learning_rate *= 1.1\n                    else:\n                        self.learning_rate *= 0.9\n                    self.base_mutation_factor *= (1 + self.learning_rate * (current_best_fitness - prev_best_fitness) / current_best_fitness)\n                    prev_best_fitness = current_best_fitness\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "63980b95-c0cb-46b1-8d59-3b5987c067ce", "fitness": 0.08959910106935931, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Dynamic Strategy Adaptation integrates a learning mechanism to adjust crossover and mutation strategies based on historical performance, optimizing exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                CR = self.crossover_rate if not self.success_crossover_rates else np.mean(self.success_crossover_rates) * np.random.uniform(0.9, 1.1)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(CR)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12276662075975842, 0.12377221833358887, 0.12322170040682856, 0.06326279310548377, 0.06338925468852208, 0.06332252122636928, 0.08209941469569926, 0.08234334562559942, 0.08221404078238415]}}
{"id": "b0ee8b10-071e-4f88-a404-9a7bf22ed985", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Enhanced ASMDE with Adaptive Selection Pressure and Dynamic Restart Mechanism, introducing selection pressure control for improved convergence and a restart mechanism for better exploration.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.restart_threshold = 0.1  # 1 new line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < self.restart_threshold:  # 1 changed line\n                        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))  # 1 new line\n                        fitness = np.array([func(ind) for ind in pop])  # 1 new line\n                        eval_count += self.population_size  # 1 new line\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 83, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "1930160c-4fd0-463e-ab53-4c7e1d25f9bb", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Diversity-Driven Mutation and Crossover Adjustment adapts mutation and crossover rates based on population diversity, dynamically refines parameters, and optimizes exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < self.diversity_threshold:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n                        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                        fitness = np.array([func(ind) for ind in pop])\n                        eval_count += self.population_size\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "07b65871-1358-4078-97a7-488a331f216d", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Introduce adaptive scaling of mutation factor based on convergence rate for improved diversity management in ASMDE.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    # Change here: Adapt population size based on convergence\n                    if diversity < 0.1:\n                        self.population_size = int(self.population_size * (0.5 + np.random.uniform(0.1, 0.2)))\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 85, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "582e53ba-31ba-4298-8a43-06af4ab11f9a", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Self-Adaptive Learning Rate and Time-Varying Population Size dynamically adjusts learning rates and adapts population size based on convergence speed and diversity for improved efficiency and robustness.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.eval_limit_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.median(self.success_mutation_factors) * np.random.uniform(0.8, 1.2)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    # Time-varying population size based on convergence speed\n                    convergence_speed = np.std(fitness) / np.mean(fitness)\n                    if diversity < 0.1 or convergence_speed < 0.01:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n                    else:\n                        self.population_size = min(self.population_size * 2, 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "982770f3-c876-4a57-ace2-4a6892c06ae6", "fitness": -Infinity, "name": "ImprovedASMDE", "description": "Improved ASMDE using Adaptive Population Resizing with Dynamic Scaling Factor and Diversity-Based Crossover for Enhanced Convergence and Robustness.", "code": "import numpy as np\n\nclass ImprovedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.scaling_factor_decay = 0.995  # New parameter for scaling factor decay\n        self.diversity_threshold = 0.05    # New parameter for diversity threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                F *= self.scaling_factor_decay  # Apply decay to mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                trial = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate * (1 - diversity):\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.base_mutation_factor = 0.3 + 0.7 * diversity\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if diversity < self.diversity_threshold:\n                    self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 87, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'diversity' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'diversity' referenced before assignment\")", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {}}
{"id": "da002c14-f493-4447-8609-1c7ae5c27d8a", "fitness": 0.08959231841428192, "name": "AQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution (AQIDE) enhances global exploration and convergence speed by incorporating quantum-inspired superposition states and entanglement-based mutation strategies.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.entanglement_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        def quantum_superposition():\n            return np.random.rand(self.dim) * (ub - lb) + lb\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(quantum_superposition() + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 88, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278215414408178, 0.12377221833358887, 0.12316144056335754, 0.06326464616016292, 0.06338925468852208, 0.06331509771318322, 0.08210302597700658, 0.08234334562559942, 0.08219968252303489]}}
{"id": "8894e7cb-f151-4918-b71b-43edd8bcf92f", "fitness": 0.08959910106935931, "name": "ASMDER", "description": "ASMDER adapts dynamically not only the population size and mutation factor but also the crossover rate using successful trials' feedback to enhance convergence and maintain diversity.", "code": "import numpy as np\n\nclass ASMDER:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.base_crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_crossover_rates = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                CR = (self.base_crossover_rate if not self.success_crossover_rates\n                      else np.mean(self.success_crossover_rates) * np.random.uniform(0.9, 1.1))\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_crossover_rates.append(CR)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.base_crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 89, "feedback": "The algorithm ASMDER got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12276662075975842, 0.12377221833358887, 0.12322170040682856, 0.06326279310548377, 0.06338925468852208, 0.06332252122636928, 0.08209941469569926, 0.08234334562559942, 0.08221404078238415]}}
{"id": "570c8dfe-42db-43a4-8f7c-a24d1ad4b111", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Adaptive Population Scaling and Targeted Parameter Adjustment focuses on scaling population based on convergence rate and adjusts mutation and crossover rates dynamically for better performance.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.convergence_threshold = 0.001\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        previous_best_fitness = np.min(fitness)\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n            current_best_fitness = np.min(fitness)\n            if np.abs(previous_best_fitness - current_best_fitness) < self.convergence_threshold:\n                self.population_size = min(max(self.population_size * 2, 4), 20 * self.dim)\n            else:\n                self.population_size = max(4, self.population_size // 2)\n\n            diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n            self.base_mutation_factor = 0.3 + 0.7 * diversity\n            self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n            previous_best_fitness = current_best_fitness\n\n            if eval_count >= self.budget:\n                break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "40a1bb4b-c45e-423a-b6f8-96651f933602", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Adaptive Learning Rate and Stochastic Population Resizing improves convergence by adjusting learning rates based on success history and uses stochastic elements in population resizing for better diversity management.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.success_ratio_threshold = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        learning_rate = 0.1\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    successful_mutations += 1\n\n                if eval_count >= self.budget:\n                    break\n\n            success_ratio = successful_mutations / self.population_size\n            if success_ratio < self.success_ratio_threshold:\n                learning_rate = min(1.0, learning_rate + 0.05)\n            else:\n                learning_rate = max(0.05, learning_rate - 0.05)\n\n            if eval_count % (self.population_size * 2) == 0:\n                diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                self.base_mutation_factor = learning_rate * (0.3 + 0.7 * diversity)\n                self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                if diversity < 0.1 and np.random.rand() < 0.5:\n                    self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "aafb2cc5-ec44-47fb-9bee-0caf3fa8492c", "fitness": 0.08960206758942249, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Adaptive Neighborhood Search and Improved Diversity Management refines convergence by incorporating local exploitation strategies and optimizing diversity-based mechanisms.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Exploitation via Local Search\n                if np.random.rand() < self.local_search_probability:\n                    local_best = self.local_search(pop[i], func, lb, ub)\n                    local_best_fitness = func(local_best)\n                    eval_count += 1\n                    if local_best_fitness < fitness[i]:\n                        pop[i] = local_best\n                        fitness[i] = local_best_fitness\n                        continue\n\n                # Exploration with Differential Evolution\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                # Adaptive Diversity Management\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n                    else:\n                        self.population_size = min(self.population_size + 2, 10 * self.dim)\n                        new_individuals = np.random.uniform(lb, ub, (2, self.dim))\n                        pop = np.vstack((pop, new_individuals))\n                        fitness = np.append(fitness, [func(ind) for ind in new_individuals])\n                        eval_count += 2\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]\n\n    def local_search(self, individual, func, lb, ub):\n        epsilon = 0.1 * (ub - lb)\n        perturbed = np.clip(individual + np.random.uniform(-epsilon, epsilon, self.dim), lb, ub)\n        return perturbed", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12269545478030253, 0.12378815166208279, 0.1232965646815064, 0.06325422940732106, 0.06339116490725849, 0.06333157164743053, 0.08208282054445415, 0.08234705916025042, 0.08223159151419601]}}
{"id": "d40d9f29-e8f7-4b5c-877f-d909868c4abd", "fitness": 0.08960320395470266, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Temporal Population Diversification introduces dynamic population diversification by rotating individuals based on past successes and failures, leading to a balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.failure_count = 0\n        self.success_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.success_count += 1\n                    self.failure_count = 0\n                else:\n                    self.failure_count += 1\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1 or self.failure_count > self.population_size:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n                        self.failure_count = 0\n\n                    if self.success_count > self.population_size:\n                        self.population_size = min(self.population_size * 2, self.budget - eval_count)\n                        self.success_count = 0\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "92ad1a18-f97e-446b-b4d4-4d88ffaf4b2c", "fitness": 0.08960320395470266, "name": "ASMDE", "description": "Enhanced ASMDE with refined diversity calculation for improved exploration and convergence.", "code": "import numpy as np\n\nclass ASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)  \n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1) \n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean(np.std(pop, axis=0)) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 94, "feedback": "The algorithm ASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322738125155475, 0.06326537969202906, 0.06338925468852208, 0.06332320501084432, 0.08210445092881391, 0.08234334562559942, 0.08221536282586506]}}
{"id": "d3570903-8ff9-44b1-bcfb-94e59f2561d7", "fitness": -Infinity, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Dynamic Archive-Based Mutation and Adaptive Diversity Control improves convergence by utilizing historical information and adjusting diversity-based parameters.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.archive = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if len(self.archive) > 0:\n                    archive_sample = np.random.choice(self.archive)\n                else:\n                    archive_sample = pop[np.random.choice(range(self.population_size))]\n                \n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b = pop[np.random.choice(indices, 2, replace=False)]\n                F = self.base_mutation_factor if not self.success_mutation_factors else np.mean(self.success_mutation_factors) * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - archive_sample), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    self.archive.append(pop[i].copy())\n                    if len(self.archive) > self.population_size:\n                        self.archive.pop(0)\n\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.4 + 0.6 * diversity\n                    self.crossover_rate = 0.2 + 0.7 * (1 - diversity)\n\n                    if diversity < 0.15:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 95, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {}}
{"id": "5765b4ec-cc6a-4a4e-8cf9-9b8970a05a8c", "fitness": 0.0896032547174171, "name": "EnhancedASMDE", "description": "Enhanced ASMDE with Adaptive Learning Rate Rescaling leverages adaptive learning rate rescaling based on success history and fitness landscape to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.learning_rate_scaler = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Adaptive mutation factor with learning rate scaling\n                F = self.base_mutation_factor * self.learning_rate_scaler\n                if self.success_mutation_factors:\n                    avg_success = np.mean(self.success_mutation_factors)\n                    F = avg_success * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    # Scale learning rate based on improvement\n                    self.learning_rate_scaler *= 1.05\n                else:\n                    # Decrease learning rate scaler if no improvement\n                    self.learning_rate_scaler *= 0.95\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["568f6646-ef88-40c6-a97a-5e80f276e1e0"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322771857749193, 0.06326537969202906, 0.06338925468852208, 0.06332324562953073, 0.08210445092881391, 0.08234334562559942, 0.08221544174567152]}}
{"id": "b3d7b853-3fce-407b-b935-4b9cd67f0fc6", "fitness": 0.0896032547174171, "name": "EnhancedASMDE", "description": "EnhancedASMDE with Adaptive Differential Mutation Factor to boost diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.learning_rate_scaler = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Adaptive mutation factor with learning rate scaling\n                F = self.base_mutation_factor * self.learning_rate_scaler\n                if self.success_mutation_factors:\n                    avg_success = np.mean(self.success_mutation_factors)\n                    F = avg_success * np.random.uniform(0.9, 1.1) + 0.1  # Modified line\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    # Scale learning rate based on improvement\n                    self.learning_rate_scaler *= 1.05\n                else:\n                    # Decrease learning rate scaler if no improvement\n                    self.learning_rate_scaler *= 0.95\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["5765b4ec-cc6a-4a4e-8cf9-9b8970a05a8c"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322771857749193, 0.06326537969202906, 0.06338925468852208, 0.06332324562953073, 0.08210445092881391, 0.08234334562559942, 0.08221544174567152]}}
{"id": "e4f64601-a707-45f4-b2d0-5e890222cdbf", "fitness": 0.0896032547174171, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Success History and Dynamic Population leverages adaptive strategies based on success history, dynamic population sizing, and fitness landscape analysis to enhance convergence speed and solution quality while maintaining diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.learning_rate_scaler = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                F = self.base_mutation_factor * self.learning_rate_scaler\n                if self.success_mutation_factors:\n                    avg_success = np.mean(self.success_mutation_factors)\n                    F = avg_success * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    self.success_mutation_factors.append(F)\n                    self.learning_rate_scaler *= 1.05\n                else:\n                    self.learning_rate_scaler *= 0.95\n\n                if eval_count % (self.population_size * 2) == 0:\n                    diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n                    self.base_mutation_factor = 0.3 + 0.7 * diversity\n                    self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n                    if diversity < 0.1:\n                        self.population_size = min(max(self.population_size // 2, 4), 10 * self.dim)\n                        # Regenerate population\n                        additional_pop = np.random.uniform(lb, ub, (self.population_size - len(pop), self.dim))\n                        pop = np.vstack((pop, additional_pop))\n                        fitness_additional = np.array([func(ind) for ind in additional_pop])\n                        fitness = np.hstack((fitness, fitness_additional))\n                        eval_count += len(additional_pop)\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08960 with standard deviation 0.02502.", "error": "", "parent_ids": ["5765b4ec-cc6a-4a4e-8cf9-9b8970a05a8c"], "operator": null, "metadata": {"aucs": [0.12278823723550647, 0.12377221833358887, 0.12322771857749193, 0.06326537969202906, 0.06338925468852208, 0.06332324562953073, 0.08210445092881391, 0.08234334562559942, 0.08221544174567152]}}
{"id": "7ede578b-c982-4e8f-b19b-2b61c906dfd7", "fitness": 0.08959205045086419, "name": "AdaptiveASMDE", "description": "The AdaptiveASMDE with Dynamic Population Size adjusts the population size adaptively based on diversity and improvement rates to enhance exploration and convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveASMDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, 10 * dim // 2)\n        self.base_mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.success_mutation_factors = []\n        self.learning_rate_scaler = 1.0\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.population_size):\n                indices = list(range(0, i)) + list(range(i+1, self.population_size))\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                \n                # Adaptive mutation factor with learning rate scaling\n                F = self.base_mutation_factor * self.learning_rate_scaler\n                if self.success_mutation_factors:\n                    avg_success = np.mean(self.success_mutation_factors)\n                    F = avg_success * np.random.uniform(0.9, 1.1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(trial_fitness)\n                    self.success_mutation_factors.append(F)\n                    # Scale learning rate based on improvement\n                    self.learning_rate_scaler *= 1.05\n                else:\n                    new_population.append(pop[i])\n                    new_fitness.append(fitness[i])\n                    # Decrease learning rate scaler if no improvement\n                    self.learning_rate_scaler *= 0.95\n\n                if eval_count >= self.budget:\n                    break\n\n            pop = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n            # Adjust population size based on diversity\n            diversity = np.mean([np.linalg.norm(p1 - p2) for p1 in pop for p2 in pop]) / self.dim\n            if diversity > 0.1:\n                self.population_size = min(self.initial_population_size, int(self.population_size * 1.1))\n            else:\n                self.population_size = max(4, int(self.population_size * 0.9))\n\n            # Re-initialize the population if necessary\n            if len(pop) < self.population_size:\n                additional_pop = np.random.uniform(lb, ub, (self.population_size - len(pop), self.dim))\n                pop = np.vstack((pop, additional_pop))\n                additional_fitness = np.array([func(ind) for ind in additional_pop])\n                fitness = np.concatenate((fitness, additional_fitness))\n                eval_count += len(additional_pop)\n\n            # Dynamic adjustment of mutation factor and crossover rate\n            self.base_mutation_factor = 0.3 + 0.7 * diversity\n            self.crossover_rate = 0.1 + 0.8 * (1 - diversity)\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx], fitness[best_idx]", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveASMDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08959 with standard deviation 0.02501.", "error": "", "parent_ids": ["5765b4ec-cc6a-4a4e-8cf9-9b8970a05a8c"], "operator": null, "metadata": {"aucs": [0.12271370405457671, 0.12377221833358887, 0.12322771857749193, 0.0632564300029198, 0.06338925468852208, 0.06332324562953073, 0.08208709539987658, 0.08234334562559942, 0.08221544174567152]}}
