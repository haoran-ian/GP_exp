{"id": "b5b25e6c-1c62-4cbd-9e65-dede3cc62ae8", "fitness": 0.2846013589721781, "name": "HPSO_ADE", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) combines particle swarm optimization and differential evolution for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        while self.budget > 0:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n        return global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28460 with standard deviation 0.30721.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.6085954553266544, 0.8264638504206596, 0.6793444331905015, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.16893705543878101, 0.12039580085319501, 0.14267563551981122]}}
{"id": "daa5e8fe-b54e-4687-a4e5-28bbd7f5e19a", "fitness": 0.27824156801209887, "name": "Enhanced_HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (Enhanced HPSO-ADE) integrates velocity adaptation and mutation strategy diversification for better convergence and solution quality.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 2.0  # Cognitive (personal) weight\n        self.c2 = 2.0  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            # Linearly decreasing inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (iteration / max_iterations)\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            # Adaptive mutation strategy\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                if np.random.rand() < self.cr:\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                else:\n                    mutant = np.clip(global_best_position + self.f * (b - c), lb, ub)\n                j_rand = np.random.randint(self.dim)\n                trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            population = trial_population\n            iteration += 1\n        \n        return global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm Enhanced_HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27824 with standard deviation 0.31387.", "error": "", "parent_ids": ["b5b25e6c-1c62-4cbd-9e65-dede3cc62ae8"], "operator": null, "metadata": {"aucs": [0.7665350629676625, 0.6822786816042951, 0.7000546100414315, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11298230881480731, 0.0857957331521001, 0.1415277155285939]}}
{"id": "946671df-bb5b-455c-ad42-1eecf9999af4", "fitness": 0.30109285241519756, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with Dynamic Inertia Weight and Adaptive Mutation for Improved Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30109 with standard deviation 0.30382.", "error": "", "parent_ids": ["b5b25e6c-1c62-4cbd-9e65-dede3cc62ae8"], "operator": null, "metadata": {"aucs": [0.6643065410567164, 0.8264638504206596, 0.6787906792190932, 0.10543707712021666, 0.0050000000000000044, 0.06038696849997638, 0.1336116470770219, 0.09431119281449984, 0.1415277155285939]}}
{"id": "26b8edef-4a34-4ccd-93f2-6c6c3d0daba7", "fitness": 0.24109096878317418, "name": "Enhanced_HPSO_ADE_Levy", "description": "Introduce a Stochastic Levy Flight-based Exploration Mechanism in HPSO-ADE to Enhance Diversification and Accelerate Convergence.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.alpha = 0.01  # Levy flight step size factor\n    \n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                \n                # Levy flight-based perturbation\n                if np.random.rand() < 0.1:  # 10% chance to use Levy flight\n                    levy_step = self.alpha * self.levy_flight()\n                    trial_population[i] = np.clip(trial_population[i] + levy_step, lb, ub)\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm Enhanced_HPSO_ADE_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24109 with standard deviation 0.28217.", "error": "", "parent_ids": ["946671df-bb5b-455c-ad42-1eecf9999af4"], "operator": null, "metadata": {"aucs": [0.6768414917855385, 0.7968291520953448, 0.3174146168506964, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.1344502380632907, 0.08775550472510363, 0.1415277155285939]}}
{"id": "a99e2a1e-02eb-4dfb-b230-1d5a8777f2a8", "fitness": 0.16348761379266152, "name": "HPSO_ADE_Plus", "description": "HPSO_ADE+ with Adaptive Learning Strategies: Enhanced HPSO-ADE using adaptive learning rates for cognitive and social components and chaotic mutation to improve convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_start = 2.5  # Initial cognitive weight\n        self.c2_start = 0.5  # Initial social weight\n        self.c1_end = 0.5  # Final cognitive weight\n        self.c2_end = 2.5  # Final social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            # Adaptive learning rates\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.c1_start + (self.c1_end - self.c1_start) * (iteration / max_iterations)\n            c2 = self.c2_start + (self.c2_end - self.c2_start) * (iteration / max_iterations)\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            # Chaotic mutation for exploration\n            chaotic_mutation = np.random.laplace(loc=0.0, scale=1.0, size=(self.population_size, self.dim))\n            trial_population += chaotic_mutation * (ub - lb) * 0.01\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HPSO_ADE_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16349 with standard deviation 0.19537.", "error": "", "parent_ids": ["946671df-bb5b-455c-ad42-1eecf9999af4"], "operator": null, "metadata": {"aucs": [0.2811780691891651, 0.6594395792145047, 0.17042929724858202, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11298230881480731, 0.09083155413830057, 0.1415277155285939]}}
{"id": "cae39148-1cff-4c89-b4c9-4daaf5f1fcdf", "fitness": 0.16652948458725872, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with Adaptive Velocity Clamping and Crossover for Better Convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            v_max = (ub - lb) * 0.1  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -v_max, v_max)\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16653 with standard deviation 0.19895.", "error": "", "parent_ids": ["946671df-bb5b-455c-ad42-1eecf9999af4"], "operator": null, "metadata": {"aucs": [0.14654649581289292, 0.7166994432220022, 0.09481561308163777, 0.10543707712021666, 0.0050000000000000044, 0.06038696849997638, 0.1340408552055089, 0.09431119281449984, 0.1415277155285939]}}
{"id": "ef81ae15-9812-4d88-897c-000c2c54abd0", "fitness": 0.296214971800087, "name": "HPSO_ADE", "description": "Hybrid PSO-DE with Adaptive Population Reduction for Enhanced Convergence Efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.min_population_size = 5  # Minimum population size for reduction\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Adaptive population size reduction\n            if iteration % 10 == 0 and self.population_size > self.min_population_size:\n                # Reduce population size by 10% but not below the minimum\n                reduction_factor = max(self.min_population_size, int(self.population_size * 0.9))\n                sorted_indices = np.argsort(personal_best_scores)\n                population = population[sorted_indices[:reduction_factor]]\n                velocities = velocities[sorted_indices[:reduction_factor]]\n                personal_best_positions = personal_best_positions[sorted_indices[:reduction_factor]]\n                personal_best_scores = personal_best_scores[sorted_indices[:reduction_factor]]\n                self.population_size = reduction_factor\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29621 with standard deviation 0.31418.", "error": "", "parent_ids": ["946671df-bb5b-455c-ad42-1eecf9999af4"], "operator": null, "metadata": {"aucs": [0.6684763549536048, 0.8264638504206596, 0.7029748883880321, 0.10543707712021666, 0.0050000000000000044, 0.0050000000000000044, 0.12153172691799852, 0.08952313287167701, 0.1415277155285939]}}
{"id": "f275becb-d319-4efb-af03-af5c57793fc0", "fitness": 0.3166765560531495, "name": "HPSO_ADE", "description": "Refined HPSO-ADE with Enhanced Mutation Strategy for Better Global Exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)  # Changed from 3 to 5\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)  # Changed mutation formula\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31668 with standard deviation 0.35911.", "error": "", "parent_ids": ["946671df-bb5b-455c-ad42-1eecf9999af4"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786953751285455, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09498183477792699, 0.14881391395422416]}}
{"id": "6b11e415-56ce-47b1-bd9d-b4cafe64e13a", "fitness": 0.2726883178074399, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Inertia and Dual Mutation Strategies for Robust Global Optimization.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            inertia_weight = self.w_min + (self.w_max - self.w_min) * (1 - iteration / max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (inertia_weight * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutation_strategy = np.random.rand()\n                    if mutation_strategy > 0.5:\n                        mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    else:\n                        mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27269 with standard deviation 0.32055.", "error": "", "parent_ids": ["f275becb-d319-4efb-af03-af5c57793fc0"], "operator": null, "metadata": {"aucs": [0.8679054225255108, 0.7678499158845494, 0.4583374681269381, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11337735335927912, 0.09019698484208771, 0.1415277155285939]}}
{"id": "b2e5e629-6714-49ba-b445-4a0e79687972", "fitness": 0.3166765560531495, "name": "APSO_DE", "description": "Introducing Adaptive Particle Swarm and Differential Evolution (APSO-DE) with Dynamic Parameter Tuning for Enhanced Convergence and Exploration.", "code": "import numpy as np\n\nclass APSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f0 = 0.8\n        self.cr = 0.9\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n        \n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            dynamic_w = self.w_max - (self.w_max - self.w_min) * (iteration / max_iterations)\n            dynamic_f = self.f0 * (1 - (iteration / max_iterations))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (dynamic_w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices]\n                    mutant = np.clip(a + dynamic_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm APSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31668 with standard deviation 0.35911.", "error": "", "parent_ids": ["f275becb-d319-4efb-af03-af5c57793fc0"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786953751285455, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09498183477792699, 0.14881391395422416]}}
{"id": "1842762b-faaa-477c-b32f-f0f17335558b", "fitness": 0.317185880332147, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Learning Strategy for Dynamic Parameter Optimization and Efficient Exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31719 with standard deviation 0.35880.", "error": "", "parent_ids": ["f275becb-d319-4efb-af03-af5c57793fc0"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786988417365221, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09956228668092837, 0.14881391395422416]}}
{"id": "499c43e9-f1f2-4b69-b2cc-b18420c82b1b", "fitness": 0.31232777871794404, "name": "HPSO_ADE_Improved", "description": "Improved HPSO-ADE with Time-Varying Inertia and Adaptive Mutation Strategy for Enhanced Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Updated max inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.w = self.w_max  # Initial inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_max - (self.w_max - self.w_min) * (iteration / max_iterations)  # Time-varying inertia \n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            adaptive_f = self.f * (1 - 0.5 * (iteration / max_iterations))  # Adaptive mutation factor\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm HPSO_ADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31233 with standard deviation 0.36169.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786264961749338, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11536807999277077, 0.09956228668092837, 0.1415277155285939]}}
{"id": "3a30df09-ed04-4b52-93b2-a22053253dd9", "fitness": 0.2348837760606394, "name": "HPSO_ADE_Improved", "description": "Improved HPSO-ADE with Dynamic Neighborhood Topology and Adaptive Mutation Control for Enhanced Convergence and Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.neighborhood_size = 5\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.dynamic_topology = True  # Enables dynamic neighborhood topology\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            if self.dynamic_topology:\n                distances = np.linalg.norm(population[:, None, :] - population[None, :, :], axis=2)\n                neighbors_idx = np.argsort(distances, axis=1)[:, 1:self.neighborhood_size+1]\n            \n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n\n            for i in range(self.population_size):\n                if self.dynamic_topology:\n                    local_best_idx = neighbors_idx[i, np.argmin(personal_best_scores[neighbors_idx[i]])]\n                    local_best_position = personal_best_positions[local_best_idx]\n                else:\n                    local_best_position = global_best_position\n\n                velocities[i] = (self.w * velocities[i] + \n                                 c1 * r1[i] * (personal_best_positions[i] - population[i]) +\n                                 c2 * r2[i] * (local_best_position - population[i]))\n\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations)) * np.random.rand()\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n\n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm HPSO_ADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23488 with standard deviation 0.29145.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9038702208854528, 0.5814491307555281, 0.12289465451862525, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.2438466417371452, 0.10307601255486531, 0.14381732409413805]}}
{"id": "6cb2679d-12d8-4b74-bd3a-dd974b51fad1", "fitness": 0.2800231125597932, "name": "HPSO_ADE_Enhanced", "description": "Introduce a dynamic crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * (iteration / max_iterations):  # Adjusted crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28002 with standard deviation 0.30402.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.7560762007569636, 0.7838494151693838, 0.5435568931659296, 0.0050000000000000044, 0.0050000000000000044, 0.019749083499634668, 0.12995060389418778, 0.12550372842790392, 0.15152208812413515]}}
{"id": "edccbe9b-a12e-4529-861a-ed26f25737a0", "fitness": 0.31155913476348446, "name": "HPSO_ADE_Enhanced", "description": "Modified HPSO-ADE with Adaptive Local Search and Dynamic Population Sizing for Enhanced Convergence and Exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.local_search_prob = 0.2  # Probability for local search\n        self.dynamic_pop_size = lambda t: max(5, self.population_size - t)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            current_pop_size = self.dynamic_pop_size(iteration)\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(current_pop_size, self.dim), np.random.rand(current_pop_size, self.dim)\n            velocities[:current_pop_size] = (self.w * velocities[:current_pop_size] +\n                                             c1 * r1 * (personal_best_positions[:current_pop_size] - population[:current_pop_size]) +\n                                             c2 * r2 * (global_best_position - population[:current_pop_size]))\n            trial_population = population[:current_pop_size] + velocities[:current_pop_size]\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(current_pop_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(current_pop_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                \n                if np.random.rand() < self.local_search_prob:\n                    trial_population[i] += np.random.normal(0, 0.1, self.dim)\n                    trial_population[i] = np.clip(trial_population[i], lb, ub)\n\n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= current_pop_size\n            \n            improvement = trial_scores < personal_best_scores[:current_pop_size]\n            personal_best_scores[:current_pop_size][improvement] = trial_scores[improvement]\n            personal_best_positions[:current_pop_size][improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n        \n        return global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31156 with standard deviation 0.36338.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8697799877991133, 0.6677151510051866, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11662265032439545, 0.08210749680742113, 0.1489015044097326]}}
{"id": "58a50254-9ec8-4345-acc8-94657fe7746a", "fitness": 0.27279349912982875, "name": "HPSO_ADE_Enhanced_Refined", "description": "Integrates adaptive mutation scaling and stochastic neighborhood adjustments for improved global search efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations)) * np.random.rand()  # Stochastic adjustment\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm HPSO_ADE_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27279 with standard deviation 0.29656.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9038702208854528, 0.5814491307555281, 0.46408216214132947, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.2438466417371452, 0.10307601255486531, 0.14381732409413805]}}
{"id": "33be8ffa-c8c0-43e0-a23e-27ebb07c0e3a", "fitness": 0.31232777871794404, "name": "HPSO_ADE_Enhanced", "description": "Introduce an adaptive differential weight strategy into the DE mutation process to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) * 0.5)  # Adjusted adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31233 with standard deviation 0.36169.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786264961749338, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11536807999277077, 0.09956228668092837, 0.1415277155285939]}}
{"id": "7b141a40-ac8e-4780-bcb9-ce9e4fd7c910", "fitness": 0.28044179129919805, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Dynamic Opposite Learning Strategy for Improved Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            opposite_population = lb + ub - trial_population\n            opposite_scores = np.array([func(ind) for ind in opposite_population])\n            self.budget -= self.population_size\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            all_scores = np.concatenate((trial_scores, opposite_scores))\n            all_positions = np.concatenate((trial_population, opposite_population))\n            \n            better_indices = np.argsort(all_scores)[:self.population_size]\n            trial_scores = all_scores[better_indices]\n            trial_population = all_positions[better_indices]\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28044 with standard deviation 0.32752.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.8142636993930369, 0.8686992177514443, 0.4581812183711912, 0.0050000000000000044, 0.006043482065624439, 0.0050000000000000044, 0.12128187032938142, 0.1039789182535108, 0.1415277155285939]}}
{"id": "f99fb4ac-9d41-4062-b029-85c126a01a3c", "fitness": 0.29678364835309307, "name": "HPSO_ADE_Enhanced", "description": "Enhanced PSO-ADE with dynamic crossover probability for improved exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * (1 - iteration / max_iterations):  # Dynamic crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29678 with standard deviation 0.34864.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.5415368247820305, 0.009117777668813054, 0.0050000000000000044, 0.0050000000000000044, 0.11302325233620325, 0.09498183477792699, 0.1415277155285939]}}
{"id": "ed416368-3d9e-4e3b-8b74-a016a6282974", "fitness": 0.2491036124127332, "name": "AdvancedPSO_DE", "description": "Advanced PSO-DE hybrid with adaptive inertia weight and dynamic scaling for enhanced global search capabilities.", "code": "import numpy as np\n\nclass AdvancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 2.0  # Cognitive (personal) weight\n        self.c2 = 2.0  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            # Adjusting inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (iteration / max_iterations))\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 5, replace=False)\n                a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                adaptive_f = self.f * (1 - (iteration / max_iterations))\n                mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                j_rand = np.random.randint(self.dim)\n                trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm AdvancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24910 with standard deviation 0.31879.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.8382313200372145, 0.8356888412965345, 0.13425478310406913, 0.0050000000000000044, 0.0050000000000000044, 0.02529752552864717, 0.141706160112271, 0.11522616610726855, 0.1415277155285939]}}
{"id": "00b41148-f1c3-4ba3-8331-6cc3ed9ed1e7", "fitness": 0.2539884035623497, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Mutation Strategy and Fitness-Based Dynamic Parameters for Improved Convergence and Exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    fitness_factor = 1 - (personal_best_scores[i] - global_best_score) / personal_best_scores[i]\n                    adaptive_f *= fitness_factor  # Adjust mutation magnitude based on fitness\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25399 with standard deviation 0.27989.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [0.6033673258554746, 0.7728788911822104, 0.5280073774830545, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.11302325233620325, 0.11209106967561122, 0.1415277155285939]}}
{"id": "118a7596-6fbe-449e-8635-1c4df18b3276", "fitness": -Infinity, "name": "HPSO_ADE_Enhanced", "description": "An improved HPSO-ADE using adaptive velocities and dynamic population size for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.adapt_velocities = lambda t, T: 1 - (t / T)  # New adaptive velocity factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.initial_population_size\n        \n        while self.budget > 0:\n            self.population_size = self.initial_population_size + int(10 * (iteration / max_iterations))  # Dynamically change population size\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.adapt_velocities(iteration, max_iterations) * self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 21, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,2) (20,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,2) (20,2) ')", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {}}
{"id": "93d9723b-8ca2-4e31-b25f-4966a96f7218", "fitness": 0.3278630556070903, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Parameter Tuning and Elite Strategy for Improved Convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32786 with standard deviation 0.37707.", "error": "", "parent_ids": ["1842762b-faaa-477c-b32f-f0f17335558b"], "operator": null, "metadata": {"aucs": [1.0, 0.8569600075587592, 0.6786988417365221, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09956228668092837, 0.14881391395422416]}}
{"id": "eec36b22-6a56-44a5-a942-5d20247d5445", "fitness": 0.2634264256079814, "name": "EnhancedPSO_ADE_OBL", "description": "Enhanced Particle Swarm Optimization with Adaptive Differential Evolution and Opposition-Based Learning for Improved Exploration and Convergence.", "code": "import numpy as np\n\nclass EnhancedPSO_ADE_OBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n\n    def opposition_based_learning(self, population, lb, ub):\n        opposite_population = lb + ub - population\n        opposite_population = np.clip(opposite_population, lb, ub)\n        return opposite_population\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            opposite_population = self.opposition_based_learning(population, lb, ub)\n            opposite_scores = np.array([func(ind) for ind in opposite_population])\n            self.budget -= self.population_size\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores, opposite_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedPSO_ADE_OBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26343 with standard deviation 0.30710.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.813839592970389, 0.770169685166344, 0.4180053567438291, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.12128187032938142, 0.09101360973329509, 0.1415277155285939]}}
{"id": "6e204176-47a7-4b1c-8d22-2e6fa748acde", "fitness": 0.3166722875617149, "name": "HPSO_ADE_Enhanced", "description": "Improved Adaptive Weight Strategy for Enhanced Convergence in Black Box Optimization.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * (np.sin(np.pi * iteration / max_iterations))  # New Adaptive Weight Strategy\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31667 with standard deviation 0.35911.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786569587056341, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09498183477792699, 0.14881391395422416]}}
{"id": "d7a35b78-eaf9-4409-a1db-ad825202ff65", "fitness": 0.3099107900439978, "name": "HPSO_ADE_Enhanced_V2", "description": "Introducing dynamic population resizing and neighborhood-based velocity adjustment to enhance the convergence of HPSO-ADE.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 10\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.initial_population_size\n        \n        while self.budget > 0 and population_size >= self.min_population_size:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(population_size):\n                if np.random.rand() < self.cr:\n                    neighbors = np.random.choice(range(population_size), 5, replace=False)\n                    a, b, c, d, e = population[neighbors[0]], population[neighbors[1]], population[neighbors[2]], population[neighbors[3]], population[neighbors[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            combined_scores = np.hstack((trial_scores, personal_best_scores))\n            elite_idx = np.argmin(combined_scores)\n            if elite_idx < population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            # Dynamic population resizing based on budget and convergence\n            if iteration % 10 == 0:\n                population_size = max(self.min_population_size, population_size - 1)\n                population = population[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n                trial_population = trial_population[:population_size]\n\n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm HPSO_ADE_Enhanced_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30991 with standard deviation 0.35835.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6509671765732735, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.125854953431916, 0.09498183477792699, 0.1415277155285939]}}
{"id": "fa2b7bbe-21d9-4042-98c2-f4120bb3c0be", "fitness": 0.3144471633160705, "name": "HPSO_ADE_EliteBoost", "description": "HPSO-ADE_EliteBoost integrates adaptive inertia, elite memory storage, and hybrid crossover to refine convergence accuracy and speed.", "code": "import numpy as np\n\nclass HPSO_ADE_EliteBoost:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.elite_storage_size = 5\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        elite_storage = [global_best_position]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n                elite_storage.append(global_best_position)\n                if len(elite_storage) > self.elite_storage_size:\n                    elite_storage.pop(0)\n            \n            if np.random.rand() < 0.5:\n                elite_idx = np.random.choice(len(elite_storage))\n                if elite_idx < len(elite_storage):\n                    global_best_position = np.copy(elite_storage[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm HPSO_ADE_EliteBoost got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31445 with standard deviation 0.35903.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.674416824490756, 0.0050000000000000044, 0.0050000000000000044, 0.030398093234996093, 0.1136022015317204, 0.09921420497429767, 0.1415277155285939]}}
{"id": "c03c0e49-824b-4c39-b7f9-2cec3935767b", "fitness": 0.29533603451469226, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Parameter Tuning and Elite Strategy for Improved Convergence, plus refined mutant vector selection for diversity.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e) * np.random.uniform(0.5, 1.5), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29534 with standard deviation 0.34916.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9038702208854528, 0.8918127585737302, 0.4674278899911458, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.15745241876270444, 0.08093330689060352, 0.1415277155285939]}}
{"id": "93947c9b-4b39-428c-b798-d59f14b802b7", "fitness": 0.24050069260207665, "name": "HPSO_ADE_Enhanced", "description": "Refined Enhanced HPSO-ADE with Adaptive Differential Weight for Improved Balance between Exploration and Exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations)) * 0.5  # Refined adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24050 with standard deviation 0.26185.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.5369456399999852, 0.7836506086668185, 0.4359793464512285, 0.0050000000000000044, 0.0050000000000000044, 0.04346828059424179, 0.11985174381016994, 0.09153384070099935, 0.1430767731952467]}}
{"id": "defe3ba0-85d6-4f1f-a4f9-776e341cee96", "fitness": 0.2660383020900359, "name": "HPSO_ADE_Enhanced_Quantum", "description": "Incorporating Quantum-inspired Behavior and Enhanced Diversity Management for Improved Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_Quantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9 \n        self.w_min = 0.4 \n        self.c1 = 1.5 \n        self.c2 = 1.5 \n        self.f = 0.8 \n        self.cr = 0.9 \n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.quantum_alpha = 0.1  # Quantum-inspired step size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) + \n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            quantum_jump = np.random.uniform(-self.quantum_alpha, self.quantum_alpha, (self.population_size, self.dim))\n            trial_population += quantum_jump\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm HPSO_ADE_Enhanced_Quantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26604 with standard deviation 0.30643.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.8138704206580589, 0.8114988672595644, 0.32271644536659005, 0.0050000000000000044, 0.00527640043033184, 0.03007154908733356, 0.1234297404559741, 0.11944352865035057, 0.16303776690211946]}}
{"id": "d6decf6e-9591-4616-9bbd-d6de71c24631", "fitness": 0.29525304137731356, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Adaptive Momentum and Dynamic Mutation Strategy for Accelerated Convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        prev_velocities = np.zeros_like(velocities)  # For momentum\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.momentum * prev_velocities +\n                          self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            prev_velocities = np.copy(velocities)\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (np.cos(np.pi * iteration / max_iterations) ** 2)  # Dynamic mutation strategy\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29525 with standard deviation 0.34172.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.47913394233386963, 0.008873776852807436, 0.008863266817192295, 0.0050000000000000044, 0.13513109219672548, 0.09498183477792699, 0.1644280293330307]}}
{"id": "8e960925-f9f4-4dd8-9b9b-1352cd9490be", "fitness": 0.31510530895088196, "name": "HPSO_ADE_Levy", "description": "Enhanced HPSO-ADE with Lvy Flight Strategy and Adaptive Mutation for Robust Exploration and Exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n    \n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * L\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), 1 / 3.0)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            adaptive_f = self.f * (1 - (iteration / max_iterations))\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            if np.random.rand() < 0.3:\n                L = 0.01 * np.random.rand()\n                levy_step = self.levy_flight(L)\n                global_best_position = np.clip(global_best_position + levy_step, lb, ub)\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm HPSO_ADE_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31511 with standard deviation 0.35872.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.674416824490756, 0.0050000000000000044, 0.0050000000000000044, 0.0310430150018689, 0.1136022015317204, 0.09738410765182115, 0.14863620179750148]}}
{"id": "5ec51c11-b482-4df7-aefe-648b382cebda", "fitness": 0.317185880332147, "name": "HPSO_ADE_Enhanced", "description": "Improved HPSO-ADE with enhanced elitism by recalculating global best position in each iteration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Recalculate the global best position each iteration\n            all_scores = np.hstack((trial_scores, personal_best_scores))\n            elite_idx = np.argmin(all_scores)\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            else:\n                global_best_position = np.copy(personal_best_positions[elite_idx - self.population_size])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31719 with standard deviation 0.35880.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6786988417365221, 0.0050000000000000044, 0.0050000000000000044, 0.016480153884970816, 0.14025229664840788, 0.09956228668092837, 0.14881391395422416]}}
{"id": "7f01f0d7-d3df-433c-8f91-c5bb05b98cb3", "fitness": 0.26135210521518026, "name": "HPSO_ADE_Enhanced", "description": "Incorporate stochastic rank-based selection and dynamic mutation to enhance diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  \n        self.w_min = 0.4  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.f = 0.8  \n        self.cr = 0.9  \n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  \n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  \n        self.mutation_rate = 0.1  # New: Mutation rate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Stochastic rank-based selection\n            ranked_idx = np.argsort(trial_scores)\n            selection_prob = (len(ranked_idx) - np.arange(len(ranked_idx))) / sum(len(ranked_idx) - np.arange(len(ranked_idx)))\n            selected_idx = np.random.choice(ranked_idx, 1, p=selection_prob)[0]\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[selected_idx])\n            \n            # Dynamic mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    trial_population[i] += np.random.normal(0, 0.1, self.dim)\n                    trial_population[i] = np.clip(trial_population[i], lb, ub)\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26135 with standard deviation 0.33655.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.15891590315628368, 0.0050000000000000044, 0.0050000000000000044, 0.01694873159456156, 0.16067568452971281, 0.09612699577429273, 0.14863620179750148]}}
{"id": "4216ed12-940d-457a-9894-75b42bd3efb6", "fitness": 0.27200650796027304, "name": "HPSO_ADE_Enhanced", "description": "Enhanced HPSO-ADE with Novel Diversity Preservation Mechanism and Adaptive Mutation for Robust Convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * np.random.rand() * (1 - (iteration / max_iterations))  # Adaptive mutation factor\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            # Diversity Preservation: Random restart for stagnant individuals\n            if iteration > 0 and iteration % (max_iterations // 4) == 0:\n                diversity_idx = np.random.choice(range(self.population_size), self.population_size // 5, replace=False)\n                trial_population[diversity_idx] = np.random.uniform(lb, ub, (len(diversity_idx), self.dim))\n                trial_scores[diversity_idx] = np.array([func(ind) for ind in trial_population[diversity_idx]])\n                self.budget -= len(diversity_idx)\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27201 with standard deviation 0.29364.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9038702208854528, 0.5776220542336067, 0.44608216214132934, 0.012866233896947965, 0.0050000000000000044, 0.0050000000000000044, 0.2438466417371452, 0.11224354321938179, 0.1415277155285939]}}
{"id": "298bbfd5-4499-4695-9958-47e8dd8823eb", "fitness": 0.27279349912982875, "name": "HPSO_ADE_Enhanced", "description": "Introduced a dynamic mutation scaling factor in the adaptive DE component for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations)) * np.random.rand()  # Added dynamic factor\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27279 with standard deviation 0.29656.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9038702208854528, 0.5814491307555281, 0.46408216214132947, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.2438466417371452, 0.10307601255486531, 0.14381732409413805]}}
{"id": "8c9a7127-896c-4d46-aff7-2e2f15ec8c79", "fitness": 0.3157315777703343, "name": "HPSO_DE_AdaptiveEnhanced", "description": "Hybrid PSO-DE Algorithm with Adaptive Momentum and Memory-Based Elite Strategy for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass HPSO_DE_AdaptiveEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        elite_position = np.copy(global_best_position)\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if global_best_score < func(elite_position):\n                elite_position = np.copy(global_best_position)\n            \n            iteration += 1\n            \n        return elite_position", "configspace": "", "generation": 36, "feedback": "The algorithm HPSO_DE_AdaptiveEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31573 with standard deviation 0.35810.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9039054225255108, 0.8569600075587592, 0.6696858252754387, 0.0050000000000000044, 0.0050000000000000044, 0.015074420756198914, 0.1395409056614444, 0.09795912851487787, 0.1484584896407788]}}
{"id": "ad51ff23-0992-45d3-98a6-a11db9ca377c", "fitness": 0.33418790600965637, "name": "HPSO_ADE_Enhanced", "description": "Enhanced PSO-ADE with Chaotic Initialization and Dynamic Parameter Control for Better Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33419 with standard deviation 0.39416.", "error": "", "parent_ids": ["93d9723b-8ca2-4e31-b25f-4966a96f7218"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.008815761372559905, 0.0050000000000000044, 0.0050000000000000044, 0.07878067329743021, 0.10878782240464402, 0.13711989707810435]}}
{"id": "71206063-f8c2-4769-9d15-c271c5da0946", "fitness": 0.33418790600965637, "name": "HPSO_ADE_Enhanced", "description": "Minor refinement with a focus on parameter adjustment for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33419 with standard deviation 0.39416.", "error": "", "parent_ids": ["ad51ff23-0992-45d3-98a6-a11db9ca377c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.008815761372559905, 0.0050000000000000044, 0.0050000000000000044, 0.07878067329743021, 0.10878782240464402, 0.13711989707810435]}}
{"id": "93a838b0-b406-4dc1-870d-da89e7734d58", "fitness": 0.3298289618271334, "name": "HPSO_ADE_Enhanced", "description": "Incorporate a weighted random inertia factor to dynamically balance exploration and exploitation during optimization.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            # Modify the inertia weight to include a weighted random factor\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations) * np.random.uniform(0.9, 1.1)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n            if elite_idx < self.population_size:\n                global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32983 with standard deviation 0.39730.", "error": "", "parent_ids": ["ad51ff23-0992-45d3-98a6-a11db9ca377c"], "operator": null, "metadata": {"aucs": [0.9093317662236302, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.02032776551959825, 0.0050000000000000044, 0.0714235407327718, 0.09888344413140171, 0.09916482214017563]}}
{"id": "ebad4e3f-b4ef-4dba-9ea0-462067fb5a5f", "fitness": 0.3395458056134031, "name": "HPSO_ADE_Enhanced", "description": "Introduce an elite retention strategy by ensuring the global best individual is always retained in the next generation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic initialization\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Elite Strategy: Retain the best individual from both populations\n            if np.random.rand() < 0.05:  # Change: Introduce probabilistic retention of global best\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33955 with standard deviation 0.38955.", "error": "", "parent_ids": ["ad51ff23-0992-45d3-98a6-a11db9ca377c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.07934063563289773, 0.10878782240464402, 0.09916482214017563]}}
{"id": "97e717a9-b939-4e9f-b369-c8db5b32de8c", "fitness": 0.3428713246684765, "name": "HPSO_ADE_Enhanced", "description": "Introduce a temperature-based annealing factor to gradually reduce mutation impact in crossover operations.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34287 with standard deviation 0.38743.", "error": "", "parent_ids": ["ebad4e3f-b4ef-4dba-9ea0-462067fb5a5f"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "b65e9cb9-9ff1-4d82-a0e8-002b55b3789d", "fitness": 0.3428713246684765, "name": "HPSO_ADE_Enhanced", "description": "Improve the global best update mechanism by allowing a probabilistic elite selection to adaptively enhance exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(trial_scores)  # Modified line for elite selection\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34287 with standard deviation 0.38743.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "119b2c53-7178-4634-8938-426d777231bf", "fitness": 0.3428713246684765, "name": "HPSO_ADE_Enhanced", "description": "Incorporate differential evolution's adaptive scaling factor into the particle swarm optimization phase for increased convergence speed.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34287 with standard deviation 0.38743.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "22c028e5-66a0-4196-8842-c30bccc8704f", "fitness": 0.33825263503836167, "name": "HPSO_ADE_Enhanced", "description": "Introduce adaptive mutation vectors based on global feedback, enhancing exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - global_best_score / max(personal_best_scores))  # New: Adaptive mutation based on global feedback\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 44, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33825 with standard deviation 0.39049.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.882925017798699, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.07483848857292374, 0.12143948263326365, 0.07935854699572842]}}
{"id": "14d28d75-85cf-4b76-ae6b-c824e3c92c6f", "fitness": 0.29269766986038476, "name": "HPSO_ADE_Enhanced_Levy", "description": "Enhance diversity and exploration by integrating a Lvy flight mechanism with the adaptive crossover strategy.", "code": "import numpy as np\nfrom scipy.special import gamma\n\nclass HPSO_ADE_Enhanced_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n        \n    def levy_flight(self, L, dimension):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, dimension)\n        v = np.random.normal(0, 1, dimension)\n        step = u / np.abs(v)**(1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                if np.random.rand() < 0.1:\n                    trial_population[i] += self.levy_flight(0.01, self.dim)  # Apply Lvy flight for exploration enhancement\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm HPSO_ADE_Enhanced_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29270 with standard deviation 0.30981.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.6914777403560495, 0.7402336337750229, 0.7303708301634606, 0.0050000000000000044, 0.0050000000000000044, 0.016947588159999194, 0.10062932612438902, 0.22485589436527686, 0.11976401579926499]}}
{"id": "749f47eb-e337-462f-834c-f2e054f56e85", "fitness": 0.33161224418388013, "name": "HPSO_ADE_Enhanced", "description": "Use an exponential decay factor in the temperature-based annealing for more rapid mutation reduction.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = np.exp(-iteration / (0.2 * max_iterations))  # Change: Exponential decay in temperature\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33161 with standard deviation 0.39552.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.09705766026056606, 0.10878782240464402, 0.09947771505554204]}}
{"id": "a5501879-ad34-4f34-aaee-8306dab51582", "fitness": 0.3501106139909493, "name": "HPSO_ADE_Enhanced", "description": "Adjust the adaptive differential weight to improve convergence speed.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35011 with standard deviation 0.38226.", "error": "", "parent_ids": ["97e717a9-b939-4e9f-b369-c8db5b32de8c"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "1fa7e61f-4e69-4052-8286-ee1e5c12b77c", "fitness": 0.3501106139909493, "name": "HPSO_ADE_Enhanced", "description": "Introduce a dynamic mutation scaling factor to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35011 with standard deviation 0.38226.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "a80e45ad-a64c-454f-8ccb-cb3e552799f0", "fitness": 0.3153756319272712, "name": "HPSO_ADE_Enhanced", "description": "Utilize chaotic map to enhance exploration while maintaining convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: np.sin(np.pi * x)  # Changed to sinusoidal map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31538 with standard deviation 0.35105.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.8776002188002057, 0.7916752098397046, 0.7521847833380715, 0.0050000000000000044, 0.09982206690622009, 0.0050781918005878834, 0.10952932045180763, 0.10276748391424118, 0.09472341229460202]}}
{"id": "547e3852-6428-45e5-8805-2e5201ac8c0c", "fitness": 0.33116579426592424, "name": "HPSO_ADE_Enhanced", "description": "Incorporate adaptive chaotic mapping into position update for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities + 0.05 * self.chaotic_map(population)  # Added: Adaptive chaotic mapping for position update\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33117 with standard deviation 0.39516.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.08804876273332807, 0.08162987806638267, 0.10132840972520119]}}
{"id": "cc25be81-5fb4-4efe-b04d-e5add44a9d44", "fitness": 0.3501106139909493, "name": "Enhanced_HPSO_ADE", "description": "Introduce adaptive chaotic mutation and dynamic population size adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.initial_population_size\n        \n        while self.budget > 0:\n            # Dynamic population size reduction\n            if iteration > 0 and iteration % 10 == 0 and self.population_size > 10:\n                self.population_size -= 1\n            \n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities[:self.population_size] + \n                          c1 * r1 * (personal_best_positions[:self.population_size] - population[:self.population_size]) +\n                          c2 * r2 * (global_best_position - population[:self.population_size]))\n            trial_population = population[:self.population_size] + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores[:self.population_size]\n            personal_best_scores[:self.population_size][improvement] = trial_scores[improvement]\n            personal_best_positions[:self.population_size][improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Adaptive chaotic mutation\n            if np.random.rand() < 0.1:\n                chaotic_factor = np.random.rand()\n                global_best_position = lb + self.chaotic_map(chaotic_factor) * (ub - lb)\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm Enhanced_HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35011 with standard deviation 0.38226.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "e7efcba5-d6f9-460b-82a4-69e9abc96e09", "fitness": 0.34693034813139517, "name": "HPSO_ADE_Enhanced_V2", "description": "Dynamic hybrid approach using adaptive differential evolution with chaotic sequences and temperature-based annealing to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (self.w_max - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = np.exp(-5 * (iteration / max_iterations))  # Revised temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm HPSO_ADE_Enhanced_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34693 with standard deviation 0.38433.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.08603726284850477, 0.0050000000000000044, 0.03448472617761367, 0.09312704894032409, 0.1306212062547667, 0.10891588902717853]}}
{"id": "7b64af8b-a1ef-4b62-a6c2-5a8e498edc50", "fitness": -Infinity, "name": "HPSO_ADE_Enhanced_V2", "description": "Incorporate adaptive sub-populations and a synergy-based learning rate to enhance diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.sub_population_size = 5  # New: Sub-population size for diversity\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.synergy_lr = lambda t, T: 0.1 * (1 - t / T)  # New: Synergy-based learning rate\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            lr = self.synergy_lr(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            # New: Sub-population synergy\n            sub_populations = np.array_split(trial_population, self.population_size // self.sub_population_size)\n            for sub_pop in sub_populations:\n                sub_scores = np.array([func(ind) for ind in sub_pop])\n                self.budget -= self.sub_population_size\n                sub_best_idx = np.argmin(sub_scores)\n                sub_best_position = sub_pop[sub_best_idx]\n                velocities = velocities - lr * (sub_best_position - sub_pop)  # Synergy adjustment\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 53, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,2) (5,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,2) (5,2) ')", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {}}
{"id": "b7a1d013-c6a5-49ad-bdc1-1a94c4038511", "fitness": 0.3469438973497234, "name": "Enhanced_HPSO_ADE", "description": "Enhance convergence by incorporating adaptive inertia weights and mutation strategies based on Gaussian and Cauchy distributions for more robust exploration and exploitation.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    distribution_choice = np.random.rand()\n                    if distribution_choice < 0.5:\n                        mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    else:\n                        gaussian_noise = np.random.normal(0, 1, self.dim)\n                        mutant = np.clip(a + adaptive_f * gaussian_noise, lb, ub)\n                    \n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm Enhanced_HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34694 with standard deviation 0.40434.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [1.0, 0.8764225266983533, 0.8605737148457021, 0.0050000000000000044, 0.014701739923993817, 0.0050000000000000044, 0.09359495710706378, 0.15948079319717223, 0.10772134437522551]}}
{"id": "5ada58d2-a041-4562-a39e-09822b4bd155", "fitness": -Infinity, "name": "HPSO_ADE_Enhanced_Refined", "description": "Implement a dynamic population resizing strategy with semi-stochastic mutation to improve diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  \n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2) \n                    stochastic_factor = np.random.uniform(0.5, 1.5)  # New: Semi-stochastic component for mutation\n                    mutant = np.clip(a + adaptive_f * stochastic_factor * (b - c + d - e), lb, ub)  # Modified mutation\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            if iteration % 10 == 0:  # New: Dynamic population resizing every 10 iterations\n                self.population_size = max(5, int(self.population_size * 0.9))  # Reduce population size by 10%\n                velocities = np.resize(velocities, (self.population_size, self.dim))\n                trial_population = np.resize(trial_population, (self.population_size, self.dim))\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 55, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (18,2) (20,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (18,2) (20,2) ')", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {}}
{"id": "88e4bb8e-2ed8-4cf4-8b9c-7813815aa9c9", "fitness": 0.3387596569707849, "name": "HPSO_ADE_Enhanced_V2", "description": "Introduce a dynamic exploration-exploitation balance through adaptive velocity and learning factors based on population diversity metrics to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            diversity = np.std(population, axis=0).mean()\n            self.w = (self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)) * (1 + 0.5 * diversity)\n            c1 = self.adaptive_c1(iteration, max_iterations) * (1 + diversity)\n            c2 = self.adaptive_c2(iteration, max_iterations) * (1 - diversity)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm HPSO_ADE_Enhanced_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33876 with standard deviation 0.41323.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [1.0, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.0612512093146198, 0.08162987806638267, 0.10132840972520119]}}
{"id": "40aa176c-3d26-4bc4-b1dd-b2a7400e0e95", "fitness": 0.3457448207777818, "name": "HPSO_ADE_Enhanced", "description": "Fine-tune the adaptive differential weight for dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 1.5)  # Fine-tune adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34574 with standard deviation 0.38500.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.030861464983747755, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "63b917b4-bb8a-4122-94fc-607fe7396285", "fitness": 0.2487828023537052, "name": "HPSO_ADE_Enhanced_v2", "description": "Introduce self-adaptive chaos-induced mutation and temperature-based inertia weight for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            temperature = 1 - (iteration / max_iterations)  # Temperature for annealing and inertia adaptation\n            self.w = self.w_min + (0.9 - self.w_min) * temperature  # Temperature-based inertia weight\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    mutant = self.chaotic_map(mutant)  # Apply chaos-induced mutation\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm HPSO_ADE_Enhanced_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24878 with standard deviation 0.28288.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.6484080608789393, 0.6487080006388961, 0.638131536619462, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.08795851883777639, 0.11990977959052418, 0.08092932461774904]}}
{"id": "d02b3079-bab5-4570-9070-38144c5af122", "fitness": 0.34068151257860335, "name": "HPSO_ADE_Enhanced", "description": "Fine-tune the differential weight adaptively using an exponential decay function for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * np.exp(-2 * (iteration / max_iterations))  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34068 with standard deviation 0.38880.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.08956199831970058, 0.10878782240464402, 0.09916482214017563]}}
{"id": "702b054e-d8bb-4abc-9854-b06f5f26858e", "fitness": 0.3359259260736109, "name": "Enhanced_HPSO_ADE", "description": "Integrate multi-strategy adaptation with chaos-enhanced initialization and dynamic crossover, enhancing diversity and exploitation balance.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2) \n                    mutant = np.clip(population[indices[0]] + adaptive_f * (population[indices[1]] - population[indices[2]] + \n                                                                            population[indices[3]] - population[indices[4]]), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            if iteration % 10 == 0:\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.1:\n                        trial_population[i] = lb + np.random.rand(self.dim) * (ub - lb)\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm Enhanced_HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33593 with standard deviation 0.39229.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03570478381254927, 0.09354120088306095, 0.10981239076348548, 0.11008795926923298]}}
{"id": "6b9eea36-185d-40b1-970c-540120dbf1d6", "fitness": 0.33529786230280606, "name": "HPSO_ADE_Enhanced", "description": "Introduced a small random factor to adaptive cognitive and social weights to enhance exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T) + np.random.uniform(-0.1, 0.1)  # Adaptive cognitive weight with randomness\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33530 with standard deviation 0.39369.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9093317662236302, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.09099200129943985, 0.11117196086778047, 0.10155761670354335]}}
{"id": "ba601f43-5b3a-4198-816f-c54d6b5e1047", "fitness": 0.3501106139909493, "name": "HPSO_ADE_T_C_Enhanced", "description": "Integrate chaotic initialization, adaptive inertia weight, and temperature-based crossover to accelerate convergence and enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_T_C_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n        \n        return global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm HPSO_ADE_T_C_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35011 with standard deviation 0.38226.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "e4d0d2ec-2248-4028-8d70-42ce921e7be8", "fitness": 0.3501106139909493, "name": "HPSO_ADE_Enhanced", "description": "Introduce a mutation-based exploration strategy to enhance diversity and avoid local optima.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35011 with standard deviation 0.38226.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "1d459d82-907c-4f9d-997c-1e2a5a029954", "fitness": 0.3403265801210934, "name": "HPSO_ADE_Enhanced_v2", "description": "Introduce stochastic variance reduction and elite learning for enhanced convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            # Stochastic variance reduction\n            if iteration % 10 == 0:\n                noise = np.random.normal(0, 0.1, (self.population_size, self.dim))\n                population = np.clip(population + noise, lb, ub)\n\n            # Elite learning strategy\n            for i in range(self.population_size):\n                if trial_scores[i] > global_best_score:\n                    trial_population[i] = 0.5 * (trial_population[i] + global_best_position)\n                    trial_scores[i] = func(trial_population[i])\n                    self.budget -= 1\n\n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 64, "feedback": "The algorithm HPSO_ADE_Enhanced_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34033 with standard deviation 0.38943.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.054547510412709665, 0.0050000000000000044, 0.0050000000000000044, 0.09220909202807837, 0.11339672799788403, 0.12859889071699981]}}
{"id": "bbc10aa8-023a-477a-a9f2-a1d4ceb76dc5", "fitness": 0.27785032568528223, "name": "HPSO_ADE_SelfAdaptive", "description": "Introduce self-adaptive velocity control and latent space exploration to enhance diversity and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_SelfAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_max - (self.w_max - self.w_min) * (iteration / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            \n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm HPSO_ADE_SelfAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27785 with standard deviation 0.32252.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.6030109131930941, 0.6446877696110924, 0.008336730529758363, 0.027977651668768755, 0.0050000000000000044, 0.08153303908246745, 0.11940338115318527, 0.10584576369162801]}}
{"id": "887def86-e3b3-4fe4-b2d7-f09fb54a6ffc", "fitness": 0.33513145661184995, "name": "HPSO_ADE_Enhanced", "description": "Introduced temperature-based scaling in velocity update to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population) * temperature)  # Updated line\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33513 with standard deviation 0.39277.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.09357818152338349, 0.11070588618461796, 0.10241394393024195]}}
{"id": "01d7cdb7-2368-41e2-b3a9-2b9bbdc8179d", "fitness": 0.3378408993557923, "name": "HPSO_ADE_MemoryEnhanced", "description": "Introduce a memory-based mechanism to adaptively select past best positions, enhancing convergence performance.", "code": "import numpy as np\n\nclass HPSO_ADE_MemoryEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n        self.memory = []  # Memory to store past best positions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n                self.memory.append(global_best_position)\n                if len(self.memory) > 5:  # Keep latest 5 best positions\n                    self.memory.pop(0)\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            # Enhanced: Memory-based position selection\n            if np.random.rand() < 0.1 and self.memory:\n                memory_best_position = self.memory[np.random.randint(len(self.memory))]\n                global_best_position = (global_best_position + memory_best_position) / 2\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm HPSO_ADE_MemoryEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33784 with standard deviation 0.39156.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.07802278402977036, 0.15173180257875318, 0.10132840972520119]}}
{"id": "9fd3828f-2df3-4e69-9ca4-3a4d10162f97", "fitness": 0.32305487770798064, "name": "HPSO_ADE_Enhanced", "description": "Integrate Lvy Flights and adaptive velocity clamping to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.1 * (ub - lb), 0.1 * (ub - lb))  # New: Adaptive velocity clamping\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            levy_flights = np.random.standard_cauchy(size=(self.population_size, self.dim))  # New: Lvy flights\n            trial_population += levy_flights * (trial_population - personal_best_positions)\n\n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32305 with standard deviation 0.39324.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9003835982514607, 0.8474144589852739, 0.8827598500187506, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.08406120991305654, 0.09026823061077138, 0.08760655159251196]}}
{"id": "cba59a97-4c39-40f7-9c68-305b16f482e1", "fitness": -Infinity, "name": "HPSO_ADE_Entropy", "description": "Introduce a dynamic population size adjustment and entropy-based position updating to enhance convergence and diversity in the search process.", "code": "import numpy as np\n\nclass HPSO_ADE_Entropy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.initial_population_size\n        \n        while self.budget > 0:\n            self.population_size = max(5, int(self.initial_population_size * (1 - iteration / max_iterations)))  # Dynamic population size\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions[:self.population_size] - population[:self.population_size]) +\n                          c2 * r2 * (global_best_position - population[:self.population_size]))\n            trial_population = population[:self.population_size] + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            entropy = -np.sum(r1 * np.log(r1 + 1e-9), axis=1)  # Entropy-based influence\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                trial_population[i] += entropy[i] * (global_best_position - trial_population[i])  # Entropy-based position updating\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores[:self.population_size]\n            personal_best_scores[:self.population_size][improvement] = trial_scores[improvement]\n            personal_best_positions[:self.population_size][improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores[:self.population_size])))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 69, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,2) (17,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,2) (17,2) ')", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {}}
{"id": "6c5a0075-bc4d-4156-84c0-2425a5dfd007", "fitness": -Infinity, "name": "HPSO_ADE_Enhanced", "description": "Introduce adaptive mutation rate based on population diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            diversity = np.mean(np.std(population, axis=0)) / (ub - lb)  # New: Diversity measure\n            adaptive_cr = self.cr * (1 - diversity)  # New: Adaptive crossover probability\n            \n            for i in range(self.population_size):\n                if np.random.rand() < adaptive_cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < adaptive_cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 70, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {}}
{"id": "23dc765c-7635-40e3-bd0a-92cb5b454803", "fitness": -Infinity, "name": "HPSO_ADE_Enhanced_Refined", "description": "Introduce multi-chaotic map initialization and adaptive mutation for enhanced solution diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map1 = lambda x: 4 * x * (1 - x)\n        self.chaotic_map2 = lambda x: np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence1 = [x0]\n        chaotic_sequence2 = [x0]\n        for _ in range(1, self.population_size // 2):\n            x0 = self.chaotic_map1(x0)\n            chaotic_sequence1.append(x0)\n        for _ in range(self.population_size // 2, self.population_size):\n            x0 = self.chaotic_map2(x0)\n            chaotic_sequence2.append(x0)\n        population = lb + np.array(chaotic_sequence1 + chaotic_sequence2) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutation_factor = 0.5 + np.random.rand() * 0.5  # Adaptive mutation factor\n                    mutant = np.clip(a + mutation_factor * adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 71, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,2) (21,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,2) (21,2) ')", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {}}
{"id": "cbb9df87-8b0c-4c2e-b762-ec9c0c12d918", "fitness": 0.3455125964076495, "name": "HPSO_ADE_Enhanced", "description": "Incorporate an adaptive mutation strategy with a nonlinear temperature scheme to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = (1 - (iteration / max_iterations))**0.5  # New: Nonlinear temperature scheme\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 1.5)  # Change: Nonlinear adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34551 with standard deviation 0.38641.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9103571180341404, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.03164514574083088, 0.0050000000000000044, 0.09952412828536383, 0.11016086536296965, 0.09916482214017563]}}
{"id": "07829a51-e421-4174-82b0-e837306b32ed", "fitness": 0.33072203846389164, "name": "HPSO_ADE_Enhanced_V2", "description": "Introduce multi-scale chaotic mappings and adaptive learning rates to enhance diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        def multi_scale_chaos(x, scale):\n            return (x + scale * np.sin(x)) % 1\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            population = multi_scale_chaos(population, scale=iteration/max_iterations)  # New: Apply multi-scale chaos\n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm HPSO_ADE_Enhanced_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33072 with standard deviation 0.39606.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.08935870169603644, 0.10878782240464402, 0.09916482214017563]}}
{"id": "dbc8596e-91aa-4c54-8b90-36a190cde957", "fitness": 0.3428713246684765, "name": "HPSO_ADE_Enhanced", "description": "Introducing adaptive mutation scaling to fine-tune exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    # Changed line below: adaptive_f calculation\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 0.5)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34287 with standard deviation 0.38743.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "409fa2bf-ebd5-443b-9fad-c9ad743be5af", "fitness": 0.2903002525092263, "name": "HPSO_ADE_LF_Chaos", "description": "Improve convergence by integrating an adaptive levy flight mechanism and dynamic chaotic mutation.", "code": "import numpy as np\n\nclass HPSO_ADE_LF_Chaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                    # Apply Levy flight\n                    trial_population[i] += self.levy_flight(adaptive_f)\n                    trial_population[i] = np.clip(trial_population[i], lb, ub)\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm HPSO_ADE_LF_Chaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29030 with standard deviation 0.34560.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.7790346514598265, 0.6875110583703172, 0.852653278231717, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.0929886429430925, 0.11376962894502096, 0.07174501263306254]}}
{"id": "881bb9b6-ac91-4235-a8e8-4f9384c2e9ff", "fitness": 0.34398124331883506, "name": "HPSO_ADE_Enhanced", "description": "Introduce diversity by chaotic mutation of a randomly selected particle when the global best does not improve.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            else:\n                idx = np.random.randint(self.population_size)\n                population[idx] = lb + self.chaotic_map(np.random.rand(self.dim)) * (ub - lb)  # Introduce diversity\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34398 with standard deviation 0.38674.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.028676799762904492, 0.04674001009137074, 0.10841922956823435, 0.10878782240464402, 0.13402032810819298]}}
{"id": "b49483cb-f10b-46b4-af0f-a11127be6f74", "fitness": 0.2866179475006187, "name": "HPSO_ADE_Enhanced", "description": "Enhance global exploration using dynamic chaotic maps and adaptive mutation strategies for faster convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n        self.beta = 0.05  # New: Perturbation factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)  # New: Temperature-based annealing\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:  # Change: Adapt crossover probability\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)  # Changed adaptive differential weight\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                    # New: Chaotic perturbation to enhance exploration\n                    if np.random.rand() < 0.1:\n                        trial_population[i] += self.beta * (ub - lb) * np.random.uniform(-1, 1, self.dim)\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            if np.random.rand() < 0.05:\n                elite_idx = np.argmin(np.hstack((trial_scores, personal_best_scores)))\n                if elite_idx < self.population_size:\n                    global_best_position = np.copy(trial_population[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28662 with standard deviation 0.33920.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.6692383416050492, 0.691999737161956, 0.0050000000000000044, 0.008571404484659984, 0.0050000000000000044, 0.09586414374607444, 0.08937954276191162, 0.10965067550837149]}}
{"id": "26926b8d-671a-4cf9-b013-f0ff67c27606", "fitness": 0.33351957998617565, "name": "HPSO_ADE_Enhanced", "description": "Integrate Lvy flight-based mutation and elitism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9  # Dynamic initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social weight\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)  # Adaptive cognitive weight\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)  # Adaptive social weight\n        self.chaotic_map = lambda x: 4 * x * (1 - x)  # Logistic map for chaotic initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // self.population_size\n        \n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n            \n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n                    # New: Lvy flight step\n                    levy_step = np.random.standard_cauchy(self.dim) * (1 / (iteration + 1))\n                    trial_population[i] = np.clip(trial_population[i] + levy_step, lb, ub)\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n            \n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n            \n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n            \n            # Changed: Elitism to enhance exploitation\n            elite_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[elite_idx] < global_best_score:\n                global_best_position = np.copy(personal_best_positions[elite_idx])\n            \n            iteration += 1\n            \n        return global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm HPSO_ADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33352 with standard deviation 0.38970.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.8665632018438058, 0.8764225266983533, 0.9044425467277724, 0.0639435581265505, 0.0050000000000000044, 0.0050000000000000044, 0.07737189723586324, 0.10878782240464402, 0.09414466683859202]}}
{"id": "67bff410-a9b1-44bd-bf73-c4d19bcb5b22", "fitness": 0.35178015790705497, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Introduce a dynamic neighborhood strategy, combined with adaptive learning rates, to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35178 with standard deviation 0.38079.", "error": "", "parent_ids": ["a5501879-ad34-4f34-aaee-8306dab51582"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.01993252429487935, 0.03529809793423733, 0.10927030712855856, 0.10888119335471602, 0.13402032810819298]}}
{"id": "71de0aff-85d7-47c4-9e6f-f88b59bac193", "fitness": 0.35178015790705497, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Incorporate a cooling schedule for the chaotic map to enhance convergence in later iterations.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x, t, T: 4 * x * (1 - x) * (1 - t / T)\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0, 0, self.budget)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35178 with standard deviation 0.38079.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.01993252429487935, 0.03529809793423733, 0.10927030712855856, 0.10888119335471602, 0.13402032810819298]}}
{"id": "085de988-d2fd-4f3b-988f-b3f0504f4ead", "fitness": 0.35178015790705497, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Refine dynamic neighborhood influence by increasing exploration probability.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.15:  # Changed from 0.1 to 0.15\n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35178 with standard deviation 0.38079.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.01993252429487935, 0.03529809793423733, 0.10927030712855856, 0.10888119335471602, 0.13402032810819298]}}
{"id": "765d4882-00b2-44bd-a3fe-8fe484886c0c", "fitness": -Infinity, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Adjust the chaotic sequence generation to improve initial population diversity for enhanced exploration.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(np.random.rand())  # Modified line\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 82, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (20,) + inhomogeneous part.')", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {}}
{"id": "fec8f500-2d2b-427e-9187-c84b49a5fb02", "fitness": 0.3432020442202713, "name": "Improved_HPSO_ADE_AdaptiveNeighborhood", "description": "Introduce a dynamic adaptive inertia weight with chaotic sequences and enhanced neighborhood selection to balance exploration and exploitation.", "code": "import numpy as np\n\nclass Improved_HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            w = self.w_min + (self.w_max - self.w_min) * (np.cos(np.pi * iteration / max_iterations))\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Enhanced Dynamic Neighborhood Influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighborhood_scores = personal_best_scores[neighbor_indices]\n                neighborhood_probs = np.exp(-neighborhood_scores / np.sum(neighborhood_scores))\n                selected_idx = np.random.choice(neighbor_indices, p=neighborhood_probs/neighborhood_probs.sum())\n                global_best_position = np.copy(personal_best_positions[selected_idx])\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm Improved_HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34320 with standard deviation 0.38689.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.05189442730901472, 0.0050000000000000044, 0.03529809793423733, 0.11150158348948624, 0.10878782240464402, 0.11214946691089056]}}
{"id": "007ee63e-71a6-4163-957f-da9b72754654", "fitness": 0.33105471369737266, "name": "HPSO_ADE_SelfAdaptive", "description": "Introduce a self-adaptive strategy to dynamically adjust neighborhood size and learning rates based on population diversity, enhancing convergence efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE_SelfAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.diversity_threshold = 0.1  # threshold for adjusting neighborhood size\n        self.adaptive_c1 = lambda diversity: 2.5 - 1.5 * diversity\n        self.adaptive_c2 = lambda diversity: 0.5 + 1.5 * diversity\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(diversity)\n            c2 = self.adaptive_c2(diversity)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Self-adaptive neighborhood influence\n            if diversity < self.diversity_threshold and np.random.rand() < 0.3: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm HPSO_ADE_SelfAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33105 with standard deviation 0.40111.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9050905253100497, 0.9021403282852286, 0.8829067909982701, 0.0050000000000000044, 0.006091575854765829, 0.03529809793423733, 0.06004558462502174, 0.08159111054357981, 0.10132840972520119]}}
{"id": "25103394-511a-4018-a94b-b44b23df6cc7", "fitness": 0.33144071263410946, "name": "Enhanced_HPSO_ADE", "description": "Integrate a dynamic opposition-based learning strategy and adaptive diversity preservation to enhance exploration capability and convergence speed.", "code": "import numpy as np\n\nclass Enhanced_HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.population_size, self.dim)\n        chaotic_sequence = [self.chaotic_map(x) for x in x0]\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            # Dynamic Opposition-based Learning\n            opposite_population = lb + ub - trial_population\n            opposite_population = np.clip(opposite_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            opposite_scores = np.array([func(ind) for ind in opposite_population])\n            self.budget -= self.population_size * 2\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            opposite_improvement = opposite_scores < personal_best_scores\n            personal_best_scores[opposite_improvement] = opposite_scores[opposite_improvement]\n            personal_best_positions[opposite_improvement] = opposite_population[opposite_improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Adaptive Diversity Preservation\n            if np.random.rand() < 0.1: \n                diversity = np.std(personal_best_positions, axis=0) / (ub - lb)\n                if np.any(diversity < 0.1):  # Reset some particles to random positions\n                    reset_indices = np.random.choice(self.population_size, 2, replace=False)\n                    for idx in reset_indices:\n                        personal_best_positions[idx] = lb + np.random.rand(self.dim) * (ub - lb)\n                        personal_best_scores[idx] = func(personal_best_positions[idx])\n                        self.budget -= 1\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm Enhanced_HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33144 with standard deviation 0.40146.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.8861598422543333, 0.9053758947117813, 0.8992244527435207, 0.0050000000000000044, 0.0050000000000000044, 0.007089179869339546, 0.08451346166800167, 0.08591051896089286, 0.10469306349911622]}}
{"id": "a8131566-c483-42bb-9318-13d7c673440b", "fitness": 0.3428713246684765, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Refine the adaptive F factor to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations))  # Change made here\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34287 with standard deviation 0.38743.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.0050000000000000044, 0.10927030712855856, 0.10878782240464402, 0.09916482214017563]}}
{"id": "c8f457cf-89d3-4c81-a0c7-cebfdc5d5a3f", "fitness": 0.3345650864064369, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Enhance exploration by introducing a perturbation factor to velocities, influenced by a sine function.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population) +\n                          np.sin(iteration * np.pi / max_iterations))  # Perturbation factor added\n\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33457 with standard deviation 0.39310.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.0050000000000000044, 0.03529809793423733, 0.09139107670960911, 0.10888119335471602, 0.10132840972520119]}}
{"id": "cec86453-cb10-4065-851e-3e7bcff6d6b3", "fitness": 0.35012098854095725, "name": "EnhancedHPSO_ADE", "description": "Integrate a chaos-enhanced dynamic neighborhood strategy with adaptive inertia and adaptive differential evolution for improved convergence precision.", "code": "import numpy as np\n\nclass EnhancedHPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n        self.sigma = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (self.w_max - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            if np.random.rand() < 0.1:\n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                neighborhood_influence = (personal_best_positions[neighbor_indices[neighbor_best_idx]] - global_best_position) * self.sigma\n                global_best_position += neighborhood_influence\n                global_best_position = np.clip(global_best_position, lb, ub)\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35012 with standard deviation 0.38226.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10888119335471602, 0.13402032810819298]}}
{"id": "1973615e-4b91-480b-a918-e490249bf2db", "fitness": 0.3501345683644642, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Enhanced dynamic neighborhood updating frequency for improved solution exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.2:  # Increased frequency from 0.1 to 0.2\n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35013 with standard deviation 0.38225.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.10927030712855856, 0.10900341176627881, 0.13402032810819298]}}
{"id": "85dd3acf-d51d-4d7f-9b54-124266a2ecf6", "fitness": 0.3443237627304508, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Enhance exploration by dynamically adjusting the velocity scaling factor 'w' based on fitness improvement.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            # Adjust 'w' based on improvement\n            recent_improvement = np.mean(personal_best_scores) - global_best_score\n            dynamic_w = self.w_min + (recent_improvement / np.abs(recent_improvement + 1e-8)) * (self.w - self.w_min)\n            self.w = np.clip(dynamic_w, self.w_min, self.w)\n            \n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34432 with standard deviation 0.38608.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.05991108231189557, 0.0050000000000000044, 0.03529809793423733, 0.11223081080858865, 0.10888119334632274, 0.1134056802388439]}}
{"id": "78f6daea-524a-4736-988d-525511e420de", "fitness": 0.3484195743496621, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Enhance adaptive learning rates by incorporating a nonlinear decay factor for better convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations) ** 1.2  # Nonlinear decay factor applied here\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34842 with standard deviation 0.38336.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.03529809793423733, 0.09395757940690241, 0.10888119335471602, 0.13402032810819298]}}
{"id": "2d045353-71e1-4549-bbe5-d7152476711b", "fitness": 0.35012480668376417, "name": "HPSO_ADE_FractalNeighborhood", "description": "Enhance exploration with stochastic fractal-based perturbation and adaptive neighborhood influence to refine convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_FractalNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n        self.fractal_perturbation = lambda x, scale: x + scale * (np.random.random(self.dim) - 0.5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence with fractal perturbation\n            if np.random.rand() < 0.2: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                neighbor_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n                global_best_position = self.fractal_perturbation(neighbor_best_position, scale=0.05)\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm HPSO_ADE_FractalNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35012 with standard deviation 0.38225.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.0050000000000000044, 0.035425832169571736, 0.10927030712855856, 0.10878782240464402, 0.13402032810819298]}}
{"id": "1b15d9de-f43b-4ba2-9ce3-3823e9d4f9ba", "fitness": -Infinity, "name": "HPSO_ADE_AdaptivePopChaos", "description": "Incorporate adaptive population resizing and chaotic perturbations to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptivePopChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 10\n        self.max_population_size = 40\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 2.5 - 1.5 * (t / T)\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.initial_population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.initial_population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            # Adaptively resize population\n            if iteration % 5 == 0 and iteration > 0:\n                if global_best_score < np.min(personal_best_scores):\n                    self.population_size = min(self.population_size + 5, self.max_population_size)\n                else:\n                    self.population_size = max(self.population_size - 5, self.min_population_size)\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 93, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,2) (20,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,2) (20,2) ')", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {}}
{"id": "44efa99f-488b-434d-a732-789428692a41", "fitness": 0.3625884175574263, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Enhance adaptive learning rates by introducing a cosine annealing schedule for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 0.5 + 2.0 * (0.5 + 0.5 * np.cos(np.pi * t / T))  # Changed line\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36259 with standard deviation 0.39694.", "error": "", "parent_ids": ["67bff410-a9b1-44bd-bf73-c4d19bcb5b22"], "operator": null, "metadata": {"aucs": [1.0, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.015357468780914263, 0.03529809793423733, 0.11597738173341099, 0.10888119335471602, 0.13402032810819298]}}
{"id": "8ce3bbbe-f14c-49dd-a45b-60086f74d45d", "fitness": 0.3386538296764318, "name": "HPSO_ADE_MultiPhaseChaos", "description": "Introduce multi-phase adaptive chaos and hybrid exploration-exploitation strategy for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE_MultiPhaseChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 0.5\n        self.c2_max = 2.5\n        self.c2_min = 0.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: self.c1_min + (self.c1_max - self.c1_min) * (1 - np.cos(np.pi * t / T))\n        self.adaptive_c2 = lambda t, T: self.c2_min + (self.c2_max - self.c2_min) * ((t / T) ** 2)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * iteration / (2 * max_iterations))\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** (1.5))\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n\n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            if np.random.rand() < 0.05: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm HPSO_ADE_MultiPhaseChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33865 with standard deviation 0.38989.", "error": "", "parent_ids": ["44efa99f-488b-434d-a732-789428692a41"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.042906485075158374, 0.030861464983747755, 0.0050000000000000044, 0.09477845198236912, 0.10878782240464402, 0.10136324270779784]}}
{"id": "377bc695-fd13-4928-acad-40fb30ea59cf", "fitness": 0.28420860795643993, "name": "QuantumWavePSO", "description": "Integrate a quantum-inspired phenomenon with a wave function collapse mechanism to enhance exploration and convergence.", "code": "import numpy as np\n\nclass QuantumWavePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 0.5 + 2.0 * (0.5 + 0.5 * np.cos(np.pi * t / T))\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.quantum_wave = lambda x: 0.5 * np.sin(2 * np.pi * x) + 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + np.random.rand(self.population_size, self.dim) * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = self.quantum_wave(iteration / max_iterations)\n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Quantum wave collapse influence\n            if np.random.rand() < 0.1:\n                collapse_indices = np.random.choice(self.population_size, 3, replace=False)\n                collapse_best_idx = np.argmin(personal_best_scores[collapse_indices])\n                global_best_position = personal_best_positions[collapse_indices[collapse_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm QuantumWavePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28421 with standard deviation 0.32683.", "error": "", "parent_ids": ["44efa99f-488b-434d-a732-789428692a41"], "operator": null, "metadata": {"aucs": [0.84037739792464, 0.8177506626669169, 0.5174247140975158, 0.0050000000000000044, 0.0050000000000000044, 0.013501620635098188, 0.11298230881480731, 0.0881746070480176, 0.15766616042096349]}}
{"id": "3d78ec84-7253-4522-8cd0-fdff592baec3", "fitness": 0.2793560026359559, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Introduce adaptive mutation scaling to enhance local exploration near convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 0.5 + 2.0 * (0.5 + 0.5 * np.cos(np.pi * t / T))  # Changed line\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2) * np.random.rand()  # Changed line\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27936 with standard deviation 0.33971.", "error": "", "parent_ids": ["44efa99f-488b-434d-a732-789428692a41"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.6780811829090874, 0.6641910679134821, 0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044, 0.08803115758832658, 0.08318479868518414, 0.08085813438997747]}}
{"id": "1710012b-f69b-459d-a112-c081b78cdc46", "fitness": 0.3318308767136658, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Incorporate a self-adaptive velocity scaling factor to enhance convergence dynamics.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 0.5 + 2.0 * (0.5 + 0.5 * np.cos(np.pi * t / T))\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity_scaling = 0.5 + 0.5 * (global_best_score / np.max(personal_best_scores))\n            velocities = velocity_scaling * (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2)\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33183 with standard deviation 0.39433.", "error": "", "parent_ids": ["44efa99f-488b-434d-a732-789428692a41"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0050000000000000044, 0.031071335690402435, 0.03529809793423733, 0.0612512093146198, 0.08834183782436222, 0.10132840972520119]}}
{"id": "7c3fab69-9b3b-4fdf-9f81-64c1b563a9d1", "fitness": 0.3452015511604901, "name": "HPSO_ADE_AdaptiveNeighborhood", "description": "Introduce an adaptive mutation scheme using a dynamic scaling factor to enhance diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE_AdaptiveNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.f = 0.8\n        self.cr = 0.9\n        self.adaptive_c1 = lambda t, T: 0.5 + 2.0 * (0.5 + 0.5 * np.cos(np.pi * t / T))  # Changed line\n        self.adaptive_c2 = lambda t, T: 0.5 + 1.5 * (t / T)\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = [x0]\n        for _ in range(1, self.population_size):\n            x0 = self.chaotic_map(x0)\n            chaotic_sequence.append(x0)\n        population = lb + np.array(chaotic_sequence) * (ub - lb)\n\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        self.budget -= self.population_size\n\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_idx])\n        global_best_score = personal_best_scores[global_best_idx]\n\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while self.budget > 0:\n            self.w = self.w_min + (0.9 - self.w_min) * ((max_iterations - iteration) / max_iterations)\n            c1 = self.adaptive_c1(iteration, max_iterations)\n            c2 = self.adaptive_c2(iteration, max_iterations)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best_positions - population) +\n                          c2 * r2 * (global_best_position - population))\n            trial_population = population + velocities\n            trial_population = np.clip(trial_population, lb, ub)\n\n            temperature = 1 - (iteration / max_iterations) \n            for i in range(self.population_size):\n                if np.random.rand() < self.cr * temperature:\n                    indices = np.random.choice(self.population_size, 5, replace=False)\n                    a, b, c, d, e = population[indices[0]], population[indices[1]], population[indices[2]], population[indices[3]], population[indices[4]]\n                    adaptive_f = self.f * (1 - (iteration / max_iterations) ** 2) * (1 + 0.1 * np.sin(2 * np.pi * iteration / max_iterations))  # Changed line\n                    mutant = np.clip(a + adaptive_f * (b - c + d - e), lb, ub)\n                    j_rand = np.random.randint(self.dim)\n                    trial_population[i] = np.array([mutant[j] if np.random.rand() < self.cr or j == j_rand else trial_population[i][j] for j in range(self.dim)])\n            \n            trial_scores = np.array([func(ind) for ind in trial_population])\n            self.budget -= self.population_size\n\n            improvement = trial_scores < personal_best_scores\n            personal_best_scores[improvement] = trial_scores[improvement]\n            personal_best_positions[improvement] = trial_population[improvement]\n\n            best_trial_idx = np.argmin(trial_scores)\n            if trial_scores[best_trial_idx] < global_best_score:\n                global_best_score = trial_scores[best_trial_idx]\n                global_best_position = np.copy(trial_population[best_trial_idx])\n\n            # Dynamic neighborhood influence\n            if np.random.rand() < 0.1: \n                neighbor_indices = np.random.choice(self.population_size, 3, replace=False)\n                neighbor_best_idx = np.argmin(personal_best_scores[neighbor_indices])\n                global_best_position = personal_best_positions[neighbor_indices[neighbor_best_idx]]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm HPSO_ADE_AdaptiveNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34520 with standard deviation 0.38581.", "error": "", "parent_ids": ["44efa99f-488b-434d-a732-789428692a41"], "operator": null, "metadata": {"aucs": [0.9048576822375455, 0.8764225266983533, 0.8829067909982701, 0.0944319704087414, 0.012245341994307157, 0.0050000000000000044, 0.11597738173341099, 0.11134575590701956, 0.10362651046676263]}}
